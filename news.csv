Link,post_title,post_content,featured_image,Date-Publish,post_category,post_tag
https://techxplore.com/news/2024-03-large-language-simple-mechanism-knowledge.html,Large language models use a surprisingly simple mechanism to retrieve some stored knowledge,"Large language models (LLMs) are incredibly complex and are used in various fields, but scientists still don't fully understand how they work. Researchers from MIT and other institutions have investigated how these models retrieve stored knowledge and have made an interesting discovery. They found that LLMs often use simple linear functions to decode and recover stored facts. These linear functions capture the straightforward relationship between variables and are used consistently for similar types of facts. By identifying these linear functions, researchers can probe the model to understand what it knows about new subjects and where that knowledge is stored.

The researchers developed a technique to estimate these linear functions and found that even when a model provides an incorrect answer, it often has the correct information stored. This approach could be used in the future to identify and correct falsehoods within the model, reducing the model's tendency to give incorrect or nonsensical answers. Despite being complex and difficult to understand, LLMs sometimes contain simple mechanisms that allow for the retrieval of stored knowledge.

The study was conducted by Evan Hernandez, an electrical engineering and computer science (EECS) graduate student at MIT, Arnab Sharma, a computer science graduate student at Northeastern University, Jacob Andreas, an associate professor in EECS at MIT, David Bau, an assistant professor of computer science at Northeastern University, and other researchers from MIT, Harvard University, and the Israeli Institute of Technology. The findings will be presented at the International Conference on Learning Representations (ICLR 2024) in Vienna.

Large language models, also known as transformer models, are neural networks that contain billions of interconnected nodes or neurons. These models encode and process data, storing knowledge in the form of relations that connect subjects and objects. For example, the relation ""Miles Davis plays the trumpet"" connects Miles Davis as the subject to the trumpet as the object. As the transformer gains more knowledge, it stores additional facts about a subject across multiple layers. When a user asks a question about a subject, the model decodes the most relevant fact to provide a response.

To understand how LLMs retrieve relational information, the researchers conducted a series of experiments. They discovered that despite their complexity, LLMs use simple linear functions for decoding. Each decoding function is specific to the type of fact being retrieved. For example, one decoding function is used to output the instrument a person plays, while a different function is used to output the state where a person was born.

The researchers developed a method to estimate these linear functions and computed functions for 47 different relations, such as ""capital city of a country"" and ""lead singer of a band."" Although there are countless possible relations, the researchers focused on this subset as they are representative of the types of facts that can be expressed in this way.

By changing the subject and testing each function, the researchers were able to determine if the correct object information could be recovered. They found that the linear functions were effective in retrieving the correct information for the selected relations.

Understanding the mechanisms behind LLMs' retrieval of stored knowledge is crucial for improving their performance and reliability. By identifying the simple linear functions used by these models, researchers can further explore ways to enhance their accuracy and reduce the occurrence of incorrect answers.

This study sheds light on the inner workings of large language models and provides insights into their ability to retrieve and decode stored facts. It highlights the presence of simple mechanisms within complex models and the potential to leverage these mechanisms to improve the overall performance of large language models. As researchers continue to delve into the complexities of these models, we can expect further advancements in their understanding and application.",https://scx2.b-cdn.net/gfx/news/hires/2024/large-language-models-2.jpg,2024-03-25 09:34:06,Innovation,Innovation
