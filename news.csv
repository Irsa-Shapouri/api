Link,Title,Text,Image,Date Publish
https://www.forbes.com/sites/brianbushard/2023/10/18/biden-backs-israels-claim-it-did-not-strike-gaza-hospital-after-palestinian-officials-blamed-israeli-airstrike-for-killing-hundreds/,Biden Backs Israel’s Claim It Did Not Strike Gaza Hospital-After Palestinian Officials Blamed Israeli Airstrike For Killing Hundreds,"Topline
President Joe Biden on Wednesday backed Israeli officials’ claim that an explosion that killed hundreds of people at a hospital in Gaza was not conducted by Israel’s military, after the Palestinian Health Ministry blamed Israel for the deadly airstrike and Israel claimed Palestinian rockets hit the hospital.
President Joe Biden backed Israeli Prime Minister Benjamin Netanyahu's claim that Israeli forces did ... [+] not launch an airstrike at a Gaza City hospital. AFP via Getty Images
Key Facts
Biden told reporters on Wednesday that Defense Department data gave him confidence the explosion was not the result of an Israeli airstrike, and told Israeli Prime Minister Benjamin Netanyahu in a visit to Israel that the strike appeared to have been launched by “the other team, not you.” In a statement, the Israel Defense Forces claimed the hospital was hit in a “failed shooting” by Gaza-based militant group Palestinian Islamic Jihad, during an “enemy rocket barrage” aimed at Israel that passed over the hospital at the time the facility was struck. Netanyahu also claimed the airstrike was the result of a failed rocket launch by the Palestinian Islamic Jihad, citing “intelligence from multiple sources.” The Palestinian Health Ministry, meanwhile, alleges the hospital was hit by an Israeli airstrike, part of a dayslong bombing campaign in the Gaza Strip. Multiple outlets, citing the Health Ministry, put the number of casualties from the strike at 500—hospitals have been functioning as a refugee camp for displaced Palestinians for the past week.
Contra
Palestinian President Mahmoud Abbas—a Hamas rival who runs the Palestinian Authority, which controls the West Bank but not the Gaza Strip—canceled a planned trip with President Joe Biden in Jordan after the hospital explosion, the Associated Press reported. Biden was scheduled to meet with Abbas as part of a Middle East trip that also includes a visit to Israel.
Crucial Quote
“Immediately upon hearing this news, I spoke with King Abdullah II of Jordan, and Prime Minister Netanyahu of Israel and have directed my national security team to continue gathering information about what exactly happened,” Biden said in a statement, adding the U.S. “stands unequivocally for the protection of civilian life during conflict.”
Key Background
The hospital explosion came amid an Israeli counter-offensive in the 10 days since Hamas launched an assault on Israel, killing more than 1,400 Israeli citizens and taking civilian hostages. Israel’s military last week gave more than one million residents of densely populated Gaza City 24 hours to evacuate to the Gaza Strip’s southern border, following Prime Minister Benjamin Netanyahu’s declaration of war against Hamas. Netanyahu says Israel’s mission in the war is to “destroy” the militant group that rules Gaza—the United Nations, however, cautioned such a swift evacuation would be “impossible” without “devastating humanitarian consequences.”
Tangent
The UN’s Palestinian refugee agency also warned on Tuesday that fuel reserves at Gaza hospitals are running precariously low, with just another 24 hours of energy from generators left, putting the “lives of thousands of patients at serious risk.” Gaza’s lone power plant had shut down late last week after Israeli officials cut energy—and food—to the territory as part of its “complete siege” on Gaza. Due to Israel’s blockade of Gaza, UN authorities also warned they would not be able to continue providing humanitarian aid into Gaza, though Israel reportedly agreed to let water and medicine into the territory through Egypt, following pleas from the U.S.
Chief Critic
Hamas’ attack—the deadliest on Israel in years, prompting a major retaliation from Israel’s military—has been widely condemned by Western officials, including Biden, who called the attack “horrific” and vowed to “stand ready to offer all appropriate means of support” to Israel.
Further Reading
Israel Orders 1.1 Million Gaza Residents To Relocate Within 24 Hours, UN Says It’s ‘Impossible’ (Forbes)
UN Body Warns Hospitals Have 24 Hours Of Fuel As Israeli Airstrikes Hit Southern Gaza (Forbes)",https://imageio.forbes.com/specials-images/imageserve/652fec2d84f104f6eb95a760/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds,2023-10-18 10:32:30
https://www.forbes.com/sites/paultassi/2023/10/18/here-are-destiny-2s-secret-twilight-triumph-objectives-for-the-lost-memento/,Here Are Destiny 2’s Secret Twilight Triumph Objectives For The Lost Memento,"Destiny 2 Bungie
Destiny 2 has started Festival of the Lost and as soon as it went live, players noticed that there was a new triumph full of question marks in order to acquire the first copy of the Lost Memento from the event, the new black-wrap shader that is so good, it’s causing a few controversies of its own. But more on that later.
Because this is the Destiny community, either through datamining or deduction, these objectives have been found already, and lord knows that you will never randomly figure these out on your own, so you should probably just listen to the instructions below.
Objective 1 – The mystery here is to complete the Fallen SABER strike with the Clovis Bray mask equipped, and yes, you can just launch it manually.
Objective 2 – The 100 here is 100/100 kills on Neomuna with the new Nimbus mask. This is probably the only one I can see you maybe figuring out randomly.
Objective 3 (these can be done in any order, by the way) – You need to perform 25 finishers in Legend Haunted Sectors while wearing the Tormentor mask. Clever.
Destiny 2 Bungie
This will get you your first copy of the Lost Memento, a Festival-only black memento that can be applied to crafted weapons like the Trials and Gambit and other ones before it. Many people thought Bungie forgot about these, but now it appears to be a way to get players to farm holiday events when they may not otherwise.
This is your first copy, but once you unlock this triumph by completing all the steps, you can then start to farm more of these as they are random drops from the event engrams. But apparently they are really, really rare drops, so you will have to go a bit crazy farming in order to actually acquire a bunch of these for your favorite weapons.
The memento system is weird. On the one hand, the shader effect is so good you will wish it was…an actual shader. On the other hand, grinding for at least something you want in Festival of the Lost that isn’t a bad new GL is mildly attractive. But the three week time limit? Yeah, that’s less fun, and I wonder if they’re going to be doing this with each event now.
The hidden challenge is cool, but yeah this whole process is bound to be pretty controversial as the event goes on. I’m out of town now, but yeah, I’ll be hunting for it when I get back.
Follow me on Twitter, Threads, YouTube, and Instagram.
Pick up my sci-fi novels the Herokiller series and The Earthborn Trilogy.",https://imageio.forbes.com/specials-images/imageserve/652fe8de96e4e34363c9b3e7/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds,2023-10-18 10:19:16
https://www.forbes.com/sites/tylerroush/2023/10/18/amazon-will-start-delivering-prescriptions-by-drone/,Amazon Will Start Delivering Prescriptions By Drone,"Topline
Amazon will begin delivering prescriptions for some Texas-based customers by drone, according to an announcement on Wednesday, becoming the latest company to test drone deliveries for medications as Amazon expands its drone delivery service.
The company said customers could receive their prescriptions within an hour of placing their order. picture alliance via Getty Images
Key Facts
Customers in College Station, Texas, will receive their medications within an hour of placing their order with Amazon Pharmacy, the company announced Wednesday. Amazon said College Station residents will be able to request more than 500 medications—including treatment for the flu, asthma and pneumonia, among others—as part of the drone delivery service. Amazon’s drones—which fly at an altitude of up to nearly 400 feet—will check to see whether the delivery zone is clear of pets, children or other obstacles before dropping the package off, the company said. Amazon Pharmacy’s drone delivery service is expected to expand to other markets, according to Amazon, which noted it has no time frame for expansion. Shares for Amazon fell slightly (1.2%) to $129.80 in early trading on Wednesday.
Tangent
Other companies have tested delivering prescriptions via drone in recent years. In a joint statement, UPS announced in 2020 that it would use drones to deliver prescriptions for CVS Health locations in The Villages, Florida, after both companies “successfully” completed their first drone deliveries in Cary, North Carolina, in 2019. That delivery service has since ended, a CVS spokesperson told the Associated Press. Intermountain Healthcare announced last year that it would begin delivering prescriptions in Salt Lake and Utah counties in Utah. The company told the Associated Press that it is continuing to expand the delivery service through Zipline, a logistics company that uses drones to drop packages by parachute. Walmart announced earlier this year that it was expanding its own drone delivery service to Dallas, though it does not provide delivery for prescriptions.
Big Number
10,000. That’s how many drone deliveries Amazon projected to have completed via drone in 2023, according to CNBC, though the company completed just 100 as of May.
Key Background
Amazon launched deliveries through Prime Air—the company’s drone delivery service—for customers in Lockeford, California, last year in an effort to deliver items “quickly” and “cost-effectively.” The launch follows comments by chief executive Jeff Bezos in 2013, after Bezos said he expected “Prime Air vehicles will be as normal as seeing mail trucks on the road.” Bezos noted that he expected the expansion to take “some number of years,” pending approval and possible regulation by the FAA. The agency approved Amazon’s request for a drone delivery fleet in 2020. Some Lockeford and College Station residents have previously expressed concerns about the drone delivery service, though an Amazon spokesperson told Insider that “safety is our top priority.”
Further Reading
Amazon Will Start Testing Drones That Will Drop Prescriptions On Your Doorstep, Literally (Associated Press)",https://imageio.forbes.com/specials-images/imageserve/652fe4c9ae942ba8af2ba1a0/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds,2023-10-18 10:01:32
https://www.forbes.com/sites/garydrenik/2023/10/18/ai--low-code-can-the-two-work-harmoniously-to-democratize-coding-for-developers/,AI & Low Code; Can They Work Together To Match Coding For Developers?,"Artificial Intelligence AdobeStock_245853295
The synergy between AI and low code is transformative, democratizing coding and expanding the horizons of software development. It empowers a diverse group of individuals, from professional developers to business analysts, to participate in and contribute to the software development process, ultimately driving innovation and efficiency in various industries. According to a recent Prosper Insights & Analytics survey, about 8-14% of people across generations use ChatGPT for development.
Prosper - Use ChatGBT For Chatbot Development Prosper Insights & Analytics
To learn how AI and low code can democratize coding, I spoke to Vikram Srivats, Chief Commercial Officer of WaveMaker, a leading Java low-code platform that helps professionals rapidly build modern, scalable, and secure software products and applications.
Gary Drenik: What are the shortcomings of AI-generated code when compared to code created in low-code platforms?
Vikram Srivats: Low Code platforms and AI take different approaches to generating code. Low Code tools have already been vetted by enterprise architects for adoption within their enterprises and many applications created by low code tools have already been deployed for end customer usage.
Right now, inconsistency in responses has plagued ChatGPT. The copilot paradigm has been put to use where a developer asks a copilot to generate code at a function level. Huge swathes of developer cycles are spent in maintaining, upgrading tech stack of solutions after the V1 is created.
This is the problem low code is able to solve better. Low code tools support iterative development and provide tools to debug and improve the code while AI generated code cannot be released without the developer understanding the code and taking ownership of it for maintenance.
Drenik: What steps can developers take, other than working alongside AI, to help scale their coding efforts effectively and accurately?
Srivats: In programming, a lot of productivity gains are made when teams are able to reuse abstractions at component, module level. When code is reused the cycle time needed to implement a customized solution reduces. This is how teams of developers work iteratively to build solutions that best fit the market needs. This process of tinkering, delivering, observing usage and planning improvement is still a very effective way to build software solutions. GitHub developer survey reveals that internal collaboration and gathering customer feedback is where most of the time in software development is spent. Hence embracing agile methodologies, reducing the cycle time needed to push change to production, a well-established feedback loop along is way to scale developer efforts.
Drenik: Analysis shows that, when prompted, 52 percent of ChatGPT answers to programming questions are incorrect and 77 percent are verbose. How can developers work alongside AI knowing they are the only ones who can catch and correct these errors?
Srivats: Working alongside AI can occasionally be a challenging experience, particularly regarding the accuracy and verbosity of responses. It's important to recognize that we are currently in an era of generative AI that is still in the early stages but improving at a faster pace than any other tech in the past. Not all applications of generative AI need to mimic chat-based interaction nor do they have to use ChatGPT only.
However, the adoption of ChatGPT has driven an expectation to build in smartness into many customer interactions. In order to build AI into solutions, developers should invest time in understanding underlying technology advancements that are underpinning the generative AI. New use cases that are not satisfactorily solved yet may become the next big market opportunity.
Drenik: As developers and business users alike dabble into AI-generated code, what use do they have for low-code tools, the original means for making coding faster for developers and accessible for non-developers?
Srivats: AI generated code is still not changing the level of abstraction where developers operate. In this way the productivity gains made are localized to dev teams, while not addressing the skill set gap and time spent in collaboration between product design, implementation, quality analysis.
However, much higher order gains in productivity can be achieved by elevating levels of abstraction and by solving the collaboration problem. This is where low code paradigm outshines simple generation of code from text. Low code tools are addressing both efficiency and skills gaps. Low code tools that also use AI in them further increase productivity of teams and not just individual developers.
Drenik: Will low-code design ever be replaced by AI entirely? Why or why not?
Srivats: As with other tools and processes, we can expect low-code platforms to become AI-infused and become more powerful than they are today. If low-code has been an accelerator for software development, then AI is an accelerator for low-code platforms. Although there will likely be classes of application that can entirely be created by AI at some point without any human intervention or low-code platforms for that matter, this does not mean that all future software development (and developers) will lose the need of low-code development platforms. In fact, there may be a new class of low-code platforms infused with AI that will become the dominant method to design, build, debug and maintain sophisticated, custom, and high-stakes applications.
Drenik: Why won’t AI replace low-code platforms?
Srivats: Even after getting trained on all of the code available in the GitHub and looking at all the answers on StackOverflow, current proficiency of the coding by the AI is at best as a copilot. All interactions to write code from just the text prompt result in frustration. The current state of AI’s proficiency in coding is simply not as good as the hype is making it out to be. We expect this to get better quickly.
A large part of a programmer’s time also goes to fixing bugs and changing the structure of the code in a way that is easier to maintain. This process of fixing a bug or refactoring code is not recorded anywhere for AI to be trained on. Initial versions of AI generated code are usually rewritten or entirely to make it easier to maintain.
Code generation in low-code development platforms is based on a visual declarative model and occurs organically each time a developer starts to build an application. In the case of AI-based code generation, there is the legal/compliance question of not knowing the source of where generated code comes from.
AI could start generating apps with cookie cutter UI atop any given API and a workflow definition. The quality of the code behind this may not matter at all as long as the user interface gets the job done. However, as the world moves more in the direction of software platforms that offer customizability, extensibility, and maintainability at low TCO, The process of development is iterative by building quickly, collecting feedback, and enhancing later. It is impossible that a developer’s mind has a crystal-clear detail of what exactly needs to be built – ahead of such an iterative process. Low code tools are better placed with such iterative development processes. They enable diverse, cross-functional teams to collaborate and iterate quickly, while AI may be used within each iteration to produce snippets of code to be refined, tested and integrated further.
Lastly, in the evolution of modern software development, we see a growing fusion upstream between designers and coders. So far, a lot of the friction, time, and effort between these 2 groups (and worlds) goes into, say, translating a product vision specified in text or a Figma design into real, working frontend and backend code. This process often needs iterative development and collaboration between 2 very different kinds of people. The skills required to ideate, and design are different from skills needed to write code. Low code platforms that integrate upstream with popular design tools and frameworks offer development and design teams to work more closely and, for example, interpret and render fully functional UI (and code) from a design. While such low-code platforms will rely on AI to generate a V1 of the UI or even generate new UI widgets not currently available in their out-of-the-box libraries, the inherent process of iterating between development and design will necessitate the future salience of a standard, robust development platform well-integrated with SDLC practices and built-in collaboration.
Drenik: Thank you for your time, Vikram, and your insights into how professional developers and business analysts can leverage both AI and low code to scale coding, increase innovation, and improve efficiency. It will certainly be interesting to see where coding goes next from here.",https://imageio.forbes.com/specials-images/imageserve/652ee1ff08f740841b955421/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds,2023-10-18 10:00:00
https://www.forbes.com/sites/tomcoughlin/2023/10/18/ocp-2023-announcements-from-jedec-ocp-foundation-kioxia-and-phison/,"OCP 2023 Announcements From JEDEC, OCP Foundation, Kioxia And Phison","Chicklets. getty
Although I wasn’t able to physically attend the Open Compute Project (OCP) Summit I did get information about several storage and memory related developments at the show. Let’s look into these developments on Chiplets, enhanced Ethernet systems, device level security auditing, data center SSDs and SSD and domain specific processor controllers.
The OCP Foundation and JEDEC Solid State Technology Association reported a joint development for automated System in Package (SiP) design and build using Chiplets. This included a Chiplet Description Schema (CDXML) specification which enables standardized Chiplet part descriptions for use with modern EDA tools and allows chiplet builders to provide electronically readable descriptions to their customers. CDML is being integrated into JEDEC JEP30. OCP is granting a compensation free and non-exclusive right to incorporate CDXML into JEP30.
The electronically readable descriptions for chiplets include: Thermal, Physical/Mechanical, Behavioral, Power/Power and Signal Integrity, Electrical test and security information. These new standards are expected to help establish an Open Chiplet economy. The objective is to build an Open Chiplet economy as illustrated below.
OCP and JEDEC Chiplet Ecosystem OCP Summit Announcements
The OCP Foundation and the Ultra Ethernet Consortium announced an alliance to help deliver data center equipment that is optimized for artificial intelligence (AI) and high-performance computing (HPC) applications. This includes solving memory size and AI cluster back-end fabric challenges posed by large language models (LLMs). This will help fast track the integration of UCE-inspired Ethernet enhancements into complete systems. This will enable OCP to support its multi-vendor supply chain to deliver on these enhanced Ethernet systems.
This enables integration of specialized silicon systems developed using Chiplets and large memory pools created with CXL and various memory appliances. The OCP Foundation also announced its Security Appraisal Framework and Enablement (S.A.F.E.) Program to enable standardized device specific security auditing. This is meant to reduce the cost, decrease redundancy and provide common security conformance to device customers.
Kioxia also participated in the OCP Summit highlighting its data center and enterprise SSD portfolio. In particular the company talked about their XD7P data center NVMe SSDs as shown below as well as Kioxia’s LD2-L NVMe SSD (in a EDSFF E1.L 9.5mm form factor) and CD8P Data Center PCIe 5.0 NVMe SSDs (in EDSFF E3.5 and 2.5-inch (U.2) 15mm thickness form factors).
KIOXIA XD7P NVMe Data Center SSDs KIOXIA OCP Summit Announcements
These products also work with Software-Enabled Flash (SEF) data management to control data placement, provide workload isolation, reduce write amplification and optimized latency. This allows advanced queueing, I/O prioritization and customized protocols with open source APIs and SDKs.
Phison introduced high-speed signal enhanced IC products at the OCP Summit to expand its PCIe 5.0 and CXL 2.0 ecosystem for AI-driven data centers. These developments include PCIe 5.0 and CXL 2.0 compatible redriver and retimer data signal conditioning IC products. These products are intended for NAND flash products for AI applications, including machine learning (ML). The company currently has PCIe 4.0 and 5.0 products in mass production and PCIe 6.0 products in design.
Phison's PS7201 and PS7202 retimer solutions are designed to meet the growing demand for data performance, and follow industry standard retimer footprints. In addition to working with NAND flash, these solutions work with accelerator technologies including GPU, CPU, FPGA, ASIC and DPUs. They boost a 5ns latency with pin-to-pin compatibility with competing products. These products are certified by PCI-SIG. Phison also offers it auto tuning tool PHiTUNE for its retimers. This tool enables development engineers to collect signal data and determine the best parameters for signal optimization within 30 minutes.
The OCP Summit introduced new Chiplet enablement, advanced Ethernet and device security auditing. Kioxia highlighted their data center SSD products and Phison announced new controller technology for PCIe 5.0 and CXL 2.0 devices.",https://imageio.forbes.com/specials-images/imageserve/652fe2c576ff253d1be722f7/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds,2023-10-18 09:55:09
https://www.forbes.com/sites/forrester/2023/10/18/what-should-revenue-enablement-do-about-sales-layoffs/,What Should Revenue Enablement Do About Sales Layoffs?,"Layoffs happen in B2B organizations too often and too regularly. For revenue enablement managers who want to be seen as leaders, you might as well be prepared for if, and when, the next one impacts your team. Here are five suggestions to simultaneously come to the aid of your internal customers and to up your enablement game for the long term.
Lead Through The Moment With Professional Change Management
While revenue enablement teams typically cover a wide range of responsibilities, now is the moment to emphasize the human element within your revenue enablement toolkit. After all, enablement staff are increasingly being populated by professionals with skills in change management. During a time when the emotional upheaval that accompanies layoffs is raw, help your colleagues near and far understand the answers to the following questions: Why is this happening, what does it mean for me, and what should I be doing about it? Your internal customers and colleagues will remember your support efforts when the stress diminishes later on and be more attuned to your ongoing efforts to prop up their successes, represent calm during the storm, and be the adult in the room when you …
Help Sellers With Stable, Streamlined Communication
The three questions above are generic reactions to change that should be interpreted more specifically for the revenue team. Follow the lead of the corporate communications and HR folks, by adapting their internal messaging to what matters most to sellers: impact on current deals, territories, accounts, and quotas. Work with HR and sales leadership to rapidly publish an approved FAQ resource, curate relevant communications and assets in a central location, and ramp up your enablement help desk support capabilities to help folks out. Reach out to revenue operations friends, who are certainly mired in seller-specific needs. Consider how product marketing and other teams have been impacted, because now is the time when reps need you all to …
Double Down On Enablement That Uplifts Sellers And Helps Them Make The Next Cut
Without interpreting this recommendation as “push all the surviving reps to the LMS,” the fact is that many departed sellers likely represent folks who didn’t “find the cheese” around newer buyers, products, and selling motions or basically did not adapt their skills quickly enough over time. Most reps who are still on staff will naturally wonder if they have the right competencies to survive the next layoff, real or imagined. New manager/rep relationships need to quickly be built. Enablement teams can leverage the communications channels mentioned above to gently suggest learning experiences that are associated with ongoing, stable, and secure professional outcomes and to identify any tribal knowledge that walked out the door. Don’t imply that “the laid-off folks didn’t take this class, so you should” — focus on the most recently introduced new competencies that management has asked enablement to support. Don’t stop at suggesting; let them see you …
Get Your Hands Dirty With Sudden Coverage Gaps
If you’re like most successful revenue enablers, you’ve carried the bag in the past and also are reasonably familiar with your reps’ basic motions. Their customers and deals are top priority right now, so what’s stopping you from digging in at a time when their support system may have just been diminished? The help desk suggestion above is an ideal way to tangibly contribute during a difficult moment but turn the service from a pull function (responding) to a push mentality (proactive). Ask reps — and managers — what current deals are slowing down as a result of the current cuts or what territories suddenly need more support. If you’re already good or great at enablement, you’ll soon be flooded with grateful requests for short-term help, which lead to long-term value-add for your function. But never forget to …
Balance Short-Term Heroics With Long-Term Value Perception
Without a doubt, this is a moment for enablement teams to shine through the pain. You absolutely need to find ways to pitch in during moments of crisis — see the recommendations above — but conversely can’t risk giving other functions the impression that, until now, you were not delivering 100% effort. This may sound overtly political or shallow, but it’s wise to accompany your short-term support efforts by temporarily scaling back some other deliverables, if not overhauling your entire charter. If enablement itself experienced headcount loss, this is easier for others to understand; otherwise, be sure to communicate your adapted focus as we’ve indicated here.
This blog was written by VP, Research Director Peter Ostrow and it was originally appeared here.",https://imageio.forbes.com/specials-images/imageserve/652fe255a69bf8b95705e82a/0x0.png?format=png&height=900&width=1600&fit=bounds,2023-10-18 09:50:05
https://www.forbes.com/sites/games/2023/10/18/super-mario-wonder-review-wonderfully-mad/,‘Super Mario Wonder’ Review: Wonderfully Mad,"The Wonder Flower is a new and integral part to 'Super Mario Wonder'. Nintendo
Super Mario Wonder is a fascinating mix of what makes classic Super Mario games tick coupled with some thoroughly surreal setpieces. So let’s get into into it.
For all intents and purposes, Super Mario Wonder is a fundamentally traditional 2D Super Mario game. While there are sections of the game where you can pop into a background plane, the game operates in two dimensions much like how the series started out.
That means the level design and platforming has to turn things up a notch and this is where the things start to get more technical than usual.
Just on the basic platforming aspects of the game, Super Mario Wonder is exacting with its demands on the player. This is not to say that it is difficult, although some levels early on can be a surprising challenge, but that you have to keep on your toes to progress smoothly.
The Wonder Flower setpieces are pretty out there. Nintendo
Each level also features a new Wonder Flower, which once touched starts a wacky and reality defying setpiece. Upon successful completion of that section and also on the completion of that level, you are awarded a Wonder Seed.
Wonder Seeds act as your currency in the over world map to unlock more levels, which is a pretty standard setup by this point.
Progressing through the overworld unlocks more levels and a boss level, which gives you a Royal Seed. This Royal Seed then allows you to chip away at Bowser’s Castle, with more areas that you complete weakening its defences further.
Sitting literally atop all of this are new Badges, that seem like a mild homage to Super Mario Odyssey. These Badges give Mario a variety of powers, such as gliding or speeding around underwater.
On top of all this you have a very robust co-operative player mode and an online setup, which at the time of my review was sadly unavailable. However, from my standpoint, I am mostly interested in the singleplayer campaign.
'Super Mario Wonder' is visually pristine throughout. Nintendo
The latter, for all intents and purposes, is one very slick package. Not only in terms of the precision in the level design and abilities at your disposal, but also the pristine visuals and sound design.
You also have these lovely little flowers that talk to you and make comments as you pass by, which is a fun touch.
All this aside though, this may be a very good game, but it doesn’t hit as hard as Super Mario Odyssey did, or even Super Mario 3D World for that matter.
Maybe I am too spoiled on functionally 3D platformers by this point, as even the recent Kirby game was exemplarily good. However, it’s been a while since a traditional 2D Super Mario game really hit home for me.
Overall though, Super Mario Wonder is an excellent 2D platformer. With excellent level design, polished visuals and mad Wonder Flower setpieces. It’s not my favorite Super Mario game in recent years, but it’s definitely worth checking out.
Super Mario Wonder
Platform: Nintendo Switch
Developer: Nintendo
Publisher: Nintendo
Released: 20th October 2023
Price: $59.99
Score: 8.5/10
Disclosure: Nintendo sent me a copy of this game for the purposes of this review.
Follow me on Twitter, Facebook and YouTube. I also manage Mecha Damashii and do toy reviews over at hobbylink.tv.
Read my Forbes blog here.",https://imageio.forbes.com/specials-images/imageserve/652fdb6a09caf398c42a77b3/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds,2023-10-18 09:28:51
https://www.forbes.com/sites/jonathankeane/2023/10/18/real-estate-tech-firm-hqo-secures-50-million-series-d-round/,Real Estate Tech Firm HqO Secures $50 Million Series D Round,"Chase Garbarino HqO
Real estate software company HqO has raised over $50 million to fuel its growth and acquisition strategy.
The Series D round was led by Koch Real Estate Investments, a subsidiary of Koch Industries, with participation from existing investors including Accomplice, Insight Partners and Related.
The round brings HqO’s total funding to date to over $200 million.
HqO develops a software ""experience"" platform for managing how tenants and employees use a building.
Its latest product is the Real Estate Experience (REX) platform, which brings together several tools for building owners and operators to manage tenant and employee experiences in their properties.
The tools include measuring employees’ workstyles, preferences and satisfaction along with marketplaces for services in the building. The company said that this can help with retention and greater efficiency with operating costs.
According to HqO, more than 350,000 users across 700 properties are using REX.
Effectively measuring how buildings are used has become increasingly important, Chase Garbarino, chief executive of HqO, said.
MORE FOR YOU What High Interest Rates Mean For Commercial Real Estate Investors
""The world has dramatically changed over the last few years, especially the way we work, live, and interact with our surroundings. In this environment of digital disruption, data, technology and a focus on the customer are not just options; they’re mission-critical to compete,"" Garbarino said.
The new round of funding will aid HqO in its M&A strategy where it targets other proptech and real estate start-ups for acquisition.
It has already completed a number of acquisitions including Leesman last year, which measures employee experience and has been integrated into HqO’s offering, and Dutch start-up Office App in 2021.
""As the real estate industry continues to radically evolve, we firmly believe that its future lies in the convergence of innovative technology, data and customer-centric experiences,"" said Justin Wilson, managing director at lead investor Koch Real Estate Investments, said.
""By developing cutting-edge technology and tools that prioritize user sentiment, HqO is not only adapting to the rapidly changing real estate industry, but driving its progression. With HqO’s vision and our investment, we are confident that together we are building a more transformative ecosystem.""
As part of the investment, Wilson will be joining HqO’s board of directors.",https://imageio.forbes.com/specials-images/imageserve/652e72fd50f8c81778de316a/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds,2023-10-18 09:07:09
https://www.forbes.com/sites/forbestechcouncil/2023/10/18/a-forward-looking-approach-to-managing-risk-in-an-uncertain-climate/,A Forward-Looking Approach To Managing Risk In An Uncertain Climate,"Ron Dembo is the founder and CEO of RiskThinking.ai.
getty
We are living in a time characterized by unprecedented uncertainty in our environment. Business leaders are paying attention to the risks of climate change and asking important questions more often in boardrooms, leadership summits and conference calls:
• How can we measure the future financial impact of climate change?
• How will factors such as rising temperatures or fuel costs affect our businesses?
• What do we need to know to make good decisions in the future?
It’s impossible to answer these questions with certainty—not just because the future is inherently uncertain but because climate change is an extremely complex problem governed by dynamic and interconnected systems. We know the climate is changing, but we can't predict with certainty what this means for the planet and its people or how it will affect our businesses.
Climate change affects the physical and financial assets of businesses. If your company has a dozen data centers in England, and heat waves force you to temporarily reduce your output or shut down centers, you may take a big financial hit. If you have offices throughout the U.S., and several locations are flooded because of storms in the northeast, you may experience serious economic losses.
I believe the traditional ways people manage uncertainty are fundamentally misguided. Forecasting is the norm in risk management, but it often falls short. Unknown factors can disrupt our plans and predictions, so we must rethink our approach to managing risk.
It is critical to use forward-looking data—aggregating a multitude of perspectives about future outcomes into probability distributions—to better prepare for climate risks and develop a data-based strategy. When there is deep uncertainty, the “form of a solution” should involve taking action but simultaneously including mitigation strategies or hedges. I recommend taking the following steps to cope with risks in an uncertain future.
1. Measure your exposure and risk using forward-looking data.
Without measuring potential risks and impacts, it's hard to plan for the future. Gather as much forward-looking data as possible from various expert sources and weigh their significance. Consider a range of possibilities, not a single forecast. This systematic, future-focused approach can help you deal with unpredictable changes.
For example, in a more carbon-constrained world, the prices of goods and services your company relies on may fluctuate. Investigate potential scenarios that could occur if the cost of raw materials, manufacturing or shipping suddenly rise.
2. Plan for mitigating risks.
Mitigation strategies can vary depending on your business context. For instance, if you run an airline, exploring hydrogen fuel or other alternative sources for planes may help mitigate future risks associated with carbon pricing and environmental concerns. Or if you're in the oil and gas industry, and your company is facing increased pressure as electric vehicles become more popular, diversifying into electric power stations could help hedge against the decline in traditional gas stations.
The key is to think beyond standard risk measurement and explore different scenarios and alternatives. Scenario thinking, or risk thinking, involves considering all possible outcomes and building a strategy that makes sense in an uncertain world. By considering various viewpoints and aggregating them into an actionable plan, you can navigate risks more effectively.
3. Set aside capital.
Setting aside capital is similar to buying insurance against potential losses. A financial buffer can provide your business with a safety net when unexpected events occur.
Perform a cost-benefit analysis to determine how much capital you need, aligning the amount with the level of risk your business is willing to bear. The more you want to eliminate risk, the more expensive this becomes—and you have to balance this tradeoff. Setting aside too much capital can be financially inefficient, just as overinsuring a low-risk event can be costly.
We need to learn to adapt our risk thinking strategies to be effective in an uncertain world. We can't predict the future with 100% accuracy, but we can develop solutions that combine action and mitigation.
Forbes Technology Council is an invitation-only community for world-class CIOs, CTOs and technology executives. Do I qualify?",https://imageio.forbes.com/specials-images/imageserve/652d77c6d6ea174fc78f5c6f/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds,2023-10-18 09:00:00
https://techxplore.com/news/2023-10-potential-electricity-urban.html,Study predicts potential for 110% electricity increases in US urban buildings,"This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:
Visualization of change in annual source energy consumption in the 2050s relative to the 2010s under four warming scenarios with a zero-carbon electric power sector. Credit: Dr. Wang.
A research study led by University of Oklahoma assistant professor Chenghao Wang and published in the journal Nature Communications tackled the critical issue of how city-scale building energy consumption in urban environments will evolve under the influence of climate change.
Fossil fuels account for approximately 40% of all building energy use in urban city centers in the United States, and the U.S. Energy Information Administration reports that residential and commercial buildings in U.S. cities are one of the major energy consumers (39%) and greenhouse gas emitters (28%).
""Understanding their future energy use is very important for developing climate change mitigation strategies, improving energy efficiency, developing and implementing energy and environmental regulations, policies, and incentive plans and enhancing the resilience and adaptation of our society under future climate and extreme weather conditions,"" said Wang, who leads the Sustainable Urban Futures, or SURF, Lab in the OU School of Meteorology.
""Previous studies made strides in estimating how energy use might change at the national or state levels in response to future changes in climate,"" he said. ""However, there is a significant gap in our understanding when it comes to the city scale. As global cities commit to ambitious sustainability goals, a more granular understanding of energy use at the city scale becomes imperative.""
The research team includes Janet Reyna and Henry Horsey from the National Renewable Energy Laboratory, Jiyun Song, Dachuan Shi and Yuyu Zhou from the University of Hong Kong, Sarah Feron from the Universidad de Santiago de Chile, Zutao Ouyang and Robert Jackson from Stanford University, and Ying Li from China Three Gorges University.
They examined 277 cities across the contiguous U.S., using model simulations and the most recent future climate projections from the Coupled Model Intercomparison Project, or CMIP6, dataset. They considered four possible warming scenarios that encompass a variety of possible climate warming scenarios and two electric power sector scenarios.
""In one power sector scenario, we assumed no future carbon policies would be implemented, but we also included a scenario that assumes rapid decarbonization and net-zero carbon emissions from the power sector by 2050, similar to with U.S. carbon-pollution-free goals announced by President Biden in 2023,"" Wang said.
To investigate how urban building energy use would evolve under future climate change, Wang's team used an indicator called energy use intensity, or EUI. The EUI is the energy used per square foot per year and is calculated by dividing the total energy consumed by the buildings by their total gross floor area.
""Due to climate change, we found that city-scale building EUI is projected to experience uneven changes by the 2050s when compared to the 2010s,"" Wang said. ""The largest increase in electricity EUI will mainly occur in the South, Southwest, West, and Southeast, which will see an increase of up to 7.2%.""
They discovered that the increase in electricity EUI during warm seasons and the hottest days will be much greater than the annual change, especially in the Northwest. This difference is mainly due to the higher air conditioning adoption rate and space cooling energy use under future warming. For each degree of warming, the average city-level space cooling EUI will increase by 13.8%.
""We found an average 10.1 to 37.7% increase in the frequency of urban summer peak building electricity EUI. However, some cities will experience over 110% increases. This will require higher grid capacity and also greater resilience against power outages during extreme heat waves,"" Wang said.
The team also assessed the potential changes in the source energy used by urban buildings, considering energy losses during generation, transmission and distribution.
""Power sector decarbonization is very effective in curbing the source energy consumption of future buildings in cities, but it's crucial to further reduce direct fossil fuel combustion in buildings,"" Wang said. ""Simply put, we need rapid electrification for future urban buildings.""
More information: Chenghao Wang et al, Impacts of climate change, population growth, and power sector decarbonization on urban building energy use, Nature Communications (2023). DOI: 10.1038/s41467-023-41458-5 Journal information: Nature Communications",https://scx2.b-cdn.net/gfx/news/hires/2023/study-predicts-potenti.jpg,2023-10-18 09:48:03
https://techxplore.com/news/2023-10-humans-lazier-robots-tasks.html,Do humans get lazier when robots help with tasks?,"This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:
Credit: Unsplash/CC0 Public Domain
Now that improvements in technology mean that some robots work alongside humans, there is evidence that those humans have learned to see them as team-mates—and teamwork can have negative as well as positive effects on people's performance.
People sometimes relax, letting their colleagues do the work instead. This is called ""social loafing,"" and it's common where people know their contribution won't be noticed or they've acclimatized to another team member's high performance. Scientists at the Technical University of Berlin investigated whether humans social loaf when they work with robots.
""Teamwork is a mixed blessing,"" said Dietlind Helene Cymek, first author of the study in Frontiers in Robotics and AI. ""Working together can motivate people to perform well but it can also lead to a loss of motivation because the individual contribution is not as visible. We were interested in whether we could also find such motivational effects when the team partner is a robot.""
A helping hand
The scientists tested their hypothesis using a simulated industrial defect-inspection task: looking at circuit boards for errors. The scientists provided images of circuit boards to 42 participants. The circuit boards were blurred, and the sharpened images could only be viewed by holding a mouse tool over them. This allowed the scientists to track participants' inspection of the board.
Half of the participants were told that they were working on circuit boards that had been inspected by a robot called Panda. Although these participants did not work directly with Panda, they had seen the robot and could hear it while they worked. After examining the boards for errors and marking them, all participants were asked to rate their own effort, how responsible for the task they felt, and how they performed.
Looking but not seeing
At first sight, it looked as if the presence of Panda had made no difference—there was no statistically significant difference between the groups in terms of time spent inspecting the circuit boards and the area searched. Participants in both groups rated their feelings of responsibility for the task, effort expended, and performance similarly.
But when the scientists looked more closely at participants' error rates, they realized that the participants working with Panda were catching fewer defects later in the task, when they'd already seen that Panda had successfully flagged many errors. This could reflect a ""looking but not seeing"" effect, where people get used to relying on something and engage with it less mentally. Although the participants thought they were paying an equivalent amount of attention, subconsciously they assumed that Panda hadn't missed any defects.
""It is easy to track where a person is looking, but much harder to tell whether that visual information is being sufficiently processed at a mental level,"" said Dr. Linda Onnasch, senior author of the study.
Safety at risk?
The authors warned that this could have safety implications. ""In our experiment, the subjects worked on the task for about 90 minutes, and we already found that fewer quality errors were detected when they worked in a team,"" said Onnasch.
""In longer shifts, when tasks are routine and the working environment offers little performance monitoring and feedback, the loss of motivation tends to be much greater. In manufacturing in general, but especially in safety-related areas where double checking is common, this can have a negative impact on work outcomes.""
The scientists pointed out that their test has some limitations. While participants were told they were in a team with the robot and shown its work, they did not work directly with Panda. Additionally, social loafing is hard to simulate in the laboratory because participants know they are being watched.
""The main limitation is the laboratory setting,"" Cymek explained. ""To find out how big the problem of loss of motivation is in human-robot interaction, we need to go into the field and test our assumptions in real work environments, with skilled workers who routinely do their work in teams with robots.""
More information: Dietlind Helene Cymek et al, Lean Back or Lean In? Exploring Social Loafing In Human-Robot Teams, Frontiers in Robotics and AI (2023). DOI: 10.3389/frobt.2023.1249252 Journal information: Frontiers in Robotics and AI",https://scx2.b-cdn.net/gfx/news/hires/2023/robot-task.jpg,2023-10-18 00:00:01
https://techxplore.com/news/2023-10-musk-users-basic-features.html,Musk's X starts charging new users for basic features in two countries,"This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:
X, formerly known as Twitter, is testing an annual $1 fee for basic features as an anti-spam measure.
The social media site X, formerly known as Twitter, said Tuesday it has started charging new users in New Zealand and the Philippines for basic features such as posting messages in a trial aimed at reducing spam.
Tech billionaire Elon Musk, who bought Twitter last year for $44 billion, has long complained about fake accounts, bots and spam on the platform, introducing a number of controversial changes that have been sharply criticized by users around the world.
Under the trial, named ""Not A Bot"", new users in New Zealand and the Philippines will have to pay an annual fee for the ability to write on X, like and reply to posts, and bookmark content.
""This new program aims to defend against bots and spammers who attempt to manipulate the platform and disrupt the experience of other X users,"" the company said on its website.
""It is not a profit driver,"" it said in a separate post on X. ""So far, subscription options have proven to be the main solution that works at scale.""
It added that existing users will not be affected by the model, which will cost around $0.75 per year for new users in the Philippines and $0.85 for those in New Zealand.
Those who decline to pay will be able to access X in read-only mode, limited to viewing content and following accounts, the company said.
""Anything that a platform does to protect their users from the harm they might experience is a step in the right direction,"" said NetSafe, an independent online safety charity in New Zealand.
""Whether trying to stop bots from contacting people indirectly, that might engage in harmful conversations, or taking steps to verify who its users are... those things are potentially useful in trying to reduce harm.""
But Jonathan de Santos, chair of the National Union of Journalists of the Philippines, said this would limit participation.
""We get that the program is meant to curb the use of bots, but this also seems like putting the burden of fighting misinformation and disinformation on users,"" he said.
Musk in September suggested charging all X users, saying it was the only way to combat the spam and bots that plague the platform.
But the idea was widely panned by users. Industry analysts said it would make X even less appealing to advertisers.
After taking over the company, the billionaire sacked thousands of staff and drew criticism for allowing banned conspiracy theorists and extremists back on the platform, sending advertisers fleeing.
Musk said in July that X had lost roughly half its ad revenue.
A month earlier, he had claimed that almost all advertisers had returned and that 90 percent of bots had been removed.
© 2023 AFP",https://scx2.b-cdn.net/gfx/news/2023/x-formerly-known-as-tw.jpg,2023-10-18 04:07:05
https://techxplore.com/news/2023-10-tech-giants-foxconn-nvidia-ai.html,"Tech giants Foxconn, Nvidia announce they are building 'AI factories'","This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:
Chairman of Foxconn Technology Group Young Liu (R) and Nvidia CEO Jensen Huang Taiwanese announced Wednesday they are building 'AI factories'
Taiwanese tech giant Foxconn and US hardware leader Nvidia said Wednesday they would team up to create ""AI factories"", powerful data processing centers that would drive the manufacturing of next-generation products such as electric cars.
The world's largest contract electronics maker, Foxconn—officially known as Hon Hai Technology Group—already plays a lynchpin role in assembling gadgets for top global brands, including Apple's iPhone.
But it has ambitions to diversify beyond electronics assembly—even embracing the competitive but rapidly expanding electric vehicle business by unveiling concept cars on its ""Hon Hai Tech Day"" in past years.
This year, chairman Young Liu opened the annual event with Nvidia's CEO Jensen Huang to introduce a ""new class of data centers powering a wide range of applications"".
Silicon Valley-based Nvidia made its name developing graphics processing units (GPUs), a powerful chip technology that started as the backbone of modern video games—but has now become a crucial pillar in the rapid development of generative AI.
""Together we will be helping the whole industry move much faster into the new AI era,"" Liu announced onstage with Huang.
The ""factories"" would include ""digitalization of manufacturing and inspection workflows, development of AI-powered electric vehicle and robotics platforms, and a growing number of language-based generative AI services"", according to Nvidia.
Huang said Foxconn ""has the expertise and scale to build AI factories globally"".
If successful, Foxconn's customers could use these systems to deliver generative AI services and use simulation to train autonomous machines like industrial robots and self-driving cars.
The announcement Wednesday came a day after the United States unveiled tightening curbs on exports of state-of-the-art chips to China—the latest move to prevent Beijing's advances in cutting-edge tech, seen by Washington as a national security threat.
The ban would hit Nvidia's chips that had previously gone to China—a major supplier base for many contract electronics manufacturers, including Foxconn—and sent the company's share price plummeting on Wall Street on Tuesday.
Nvidia said the new rules by the US Department of Commerce may ""require the company to transition certain operations out of one or more of the identified countries"".
© 2023 AFP",https://scx2.b-cdn.net/gfx/news/2023/chairman-of-foxconn-te.jpg,2023-10-18 03:45:36
https://www.reuters.com/innovation/article/cyber-survey/major-cyber-attack-could-cost-the-world-3-5-trillion-lloyds-of-london-idUSKBN31I0OI,Major cyber attack could cost the world $3.5 trillion -Lloyd's of London,"FILE PHOTO: 3D printed models of people working on computers and padlock are seen in front of a displayed CYBER ATTACK words and binary code in this picture illustration taken, February 1, 2022. REUTERS/Dado Ruvic/Illustration/File photo
LONDON (Reuters) - A major cyber attack on a financial services payments system could lead to global losses of $3.5 trillion, with much of it not covered by insurance, commercial insurance market Lloyd’s of London said on Wednesday.
The United States would suffer losses of $1.1 trillion over a five-year period from such an attack, which would cause widespread disruption to global business, according to a systemic risk scenario developed by Lloyd’s and the Cambridge Centre for Risk Studies.
China would face $470 billion in losses and Japan $200 billion over the same period, Lloyd’s said.
“The global interconnectedness of cyber means it is too substantial a risk for one sector to face alone and therefore we must continue to share knowledge, expertise and innovative ideas across government, industry and the insurance market to ensure we build society’s resilience against the potential scale of this risk,” Lloyd’s chairman Bruce Carnegie-Brown said.
Cyber insurance saw over $9 billion in gross written premiums in 2022 and is forecast to grow to $13 billion to $25 billion by 2025, Lloyd’s said.
Concern about the cost of such insurance and whether it will provide cover in the case of war are deterring some potential customers, brokers say.
Over 20% of the world’s cyber premium is placed in the Lloyd’s market, Lloyd’s said.
Major cyber insurers Beazley and Hiscox are among more than 50 insurance companies in the Lloyd’s market.",https://s4.reutersmedia.net/resources/r/?m=02&d=20231018&t=2&i=1648065527&w=1200&r=LYNXMPEJ9H0DS,2023-10-18 09:04:57
https://www.reuters.com/innovation/article/usa-cyber-china/five-eyes-intelligence-chiefs-warn-on-chinas-theft-of-intellectual-property-idUSKBN31I06U,Five Eyes intelligence chiefs warn on China's 'theft' of intellectual property,"STANFORD, California (Reuters) - The Five Eyes countries’ intelligence chiefs came together on Tuesday to accuse China of intellectual property theft and using artificial intelligence for hacking and spying against the nations, in a rare joint statement by the allies.
FILE PHOTO: FBI Director Christopher Wray testifies before a Senate Judiciary Committee hearing entitled ""Oversight of the Federal Bureau of Investigation,"" on Capitol Hill in Washington, U.S. August 4, 2022. REUTERS/Jim Bourg/File Photo
The officials from the United States, Britain, Canada, Australia and New Zealand - known as the Five Eyes intelligence sharing network - made the comments following meetings with private companies in the U.S. innovation hub Silicon Valley.
U.S. FBI Director Christopher Wray said the “unprecedented” joint call was meant to confront the “unprecedented threat” China poses to innovation across the world.
From quantum technology and robotics to biotechnology and artificial intelligence, China was stealing secrets in various sectors, the officials said.
“China has long targeted businesses with a web of techniques all at once: cyber intrusions, human intelligence operations, seemingly innocuous corporate investments and transactions,” Wray said. “Every strand of that web had become more brazen, and more dangerous.”
In response, Chinese government spokesman Liu Pengyu said the country was committed to intellectual property protection.
“We firmly oppose to the groundless allegations and smears towards China and hope the relevant parties can view China’s development objectively and fairly,” the spokesperson for China’s embassy in Washington said in a statement to Reuters.
The U.S. has long accused China of intellectual property theft and the issue has been a key sore point in U.S.-China relations. But this is the first time the Five Eyes members have joined publicly to call out China on it.
“The Chinese government is engaged in the most sustained scaled and sophisticated theft of intellectual property and expertise in human history,” said Mike Burgess, the Australian Security Intelligence Organisation’s director-general.
While China’s intention to innovate for its own national interest was “fine and entirely appropriate”, Burgess said “the behaviour we’re talking about here goes well beyond traditional espionage.”
Last month, his department busted a Chinese plot to infiltrate a prestigious Australian research institution that involved planting an academic there to steal secrets, he said.
“This sort of thing is happening every day in Australia, as it is in the countries here,” Burgess said.
The Five Eyes statement follows the group’s warning in May of a widespread Chinese spy operation it said was targeting critical infrastructure and various other sectors.
The Chinese government dismissed those allegations as a “collective disinformation campaign.”
Wray said China had “a bigger hacking program than that of every other major nation combined” that together with Beijing’s physical spies and stealing of trade secrets from private businesses and research institutions gave the country enormous power.
“Part of what makes it so challenging is all of those tools deployed in tandem, at a scale the likes of which we’ve never seen,” Wray said.
Soo C. Song, acting U.S. attorney for the Western District of Pennsylvania, and Robert Johnson, FBI special agent in charge, announce charges against three Chinese nationals for hacking intellectual property from three international conglomerates in the district attorney's office at the U.S. Courthouse in Pittsburgh, Pennsylvania, U.S. November 27, 2017. REUTERS/Nick Keppler
The officials called for private industry and academia to help in countering those threats, chief among which they said were artificial intelligence tools.
“We worry about AI as an amplifier for all sorts of misconduct,” Wray said, accusing China of stealing more personal and corporate data than any other nation by orders of magnitude.
“If you think about what AI can do to help leverage that data to take what’s already the largest hacking program in the world by a country mile, and make it that much more effective - that’s what we’re worried about,” he said.",https://s2.reutersmedia.net/resources/r/?m=02&d=20231018&t=2&i=1648038297&w=1200&r=LYNXMPEJ9H03D,2023-10-18 02:54:03
https://www.reuters.com/innovation/article/autos-emissions-tesla/tesla-urges-us-to-adopt-much-tougher-fuel-efficiency-rules-idUSKBN31H1H7,Tesla urges US to adopt much tougher fuel efficiency rules,"WASHINGTON (Reuters) -Electric vehicle manufacturer Tesla on Tuesday urged the Biden administration to finalize much tougher fuel economy standards through 2032 than U.S. regulators have proposed.
FILE PHOTO: A view shows the Tesla logo on the hood of a car in Oslo, Norway November 10, 2022. REUTERS/Victoria Klesty/File Photo
The National Highway Traffic Safety Administration (NHTSA) in July proposed raising Corporate Average Fuel Economy (CAFE) car requirements by 2% and by 4% for trucks and SUVs annually between 2027 and 2032. Tesla wants the agency to finalize rules increasing stringency for cars by 6% annually and 8% for trucks and SUVs, saying it would best “conserve energy and address climate change.”
The NHTSA’s proposal would result in a fleet-wide average fuel efficiency of 58 miles (93 km) per gallon by 2032.
Tesla’s position puts it sharply at odds with major automakers.
On Monday a group representing General Motors, Toyota Motor, Volkswagen and nearly all other major automakers sharply criticized NHTSA’s proposal, saying it is unreasonable and requested significant revisions.
The American Automotive Policy Council, a group representing the Detroit Three automakers, separately urged NHTSA to halve its proposed fuel economy increases to 2% annually for trucks, saying the proposal “would disproportionately impact the truck fleet.”
The group noted 83% of vehicles produced by Ford, GM and Chrysler parent Stellantis are trucks.
NHTSA said in response its rule “is focused on saving Americans money at the gas pump and strengthening American energy independence” and estimated the combined benefits of the proposal exceed costs by more than $18 billion.
The Alliance for Automotive Innovation said last month automakers would face more than $14 billion in non-compliance penalties between 2027 and 2032.
Toyota said on Tuesday the fines are “proof that there is insufficient technology to meet the proposed standards and that such standards have been set beyond maximum feasible.”U.S. automakers separately have warned the fines would cost GM $6.5 billion, Stellantis $3.1 billion and Ford $1 billion, citing NHTSA’s projections.
Automakers also raised alarm at the Energy Department’s proposal to significantly revise how it calculates the petroleum-equivalent fuel economy rating for EVs in NHTSA’s CAFE program, saying it would “devalue the fuel economy of electric vehicles by 72%.”",https://s2.reutersmedia.net/resources/r/?m=02&d=20231017&t=2&i=1648024929&w=1200&r=LYNXMPEJ9G0Q4,2023-10-17 23:44:34
https://techcrunch.com/2023/10/18/openai-formally-brings-bing-powered-search-to-chatgpt-as-dall-e-3-arrives-in-beta/,ChatGPT officially gets web search as DALL-E 3 integration arrives in beta,"OpenAI has formally launched its internet-browsing feature to ChatGPT, some three weeks after re-introducing the feature in beta after several months in hiatus.
ChatGPT, the generative AI chatbot that has taken the world by storm these past 12 months, has historically been limited to data up to September, 2021 — rendering it useless as a real-time search engine. However, OpenAI started bringing internet services to ChatGPT back in March, a move that always came with inherent risks, given that the live web isn’t curated in the same way a static training data set is — this potentially opened the doors to abuse by bad actors and good old-fashioned algorithmic chaos.
Then in May, OpenAI started rolling out web search via Bing, the search engine belonging to OpenAI’s corporate backer Microsoft, before extending access to the ChatGPT mobile app in late June. However, the new feature was swiftly pulled after it was discovered that ChatGPT was capable of displaying paywalled content.
Fast-forward to late September, and OpenAI started rolling the Browse with Bing feature out again, having fine-tuned how ChatGPT follows instructions laid out by content owners — essentially, it now promised to adhere to whatever a site-owner said in its Robots.txt file, similar to traditional web crawlers.
Now, Browse with Bing is officially available to all Plus and Enterprise subscribers, with no need to toggle their beta switch in settings.
In related news, OpenAI also transitioned DALL-E 3 into beta, a month after debuting the latest incarnation of the text-to-image generator.
DALL-E 3 sports integration with ChatGPT, meaning that users don’t have to think so carefully about their text-prompts when asking DALL-E to create an image — ChatGPT can do a lot of the heavylifting to ensure that the image the user gets, is closer to what they want.
But more than that, with DALL-E 3 embedded directly into ChatGPT, users will now be able to receive images as part of their text-based queries without having to switch between apps.
DALL-E 3 is available in beta now on the web and mobile, with users able to activate the feature by selecting “DALL-E 3 (Beta)” from the GPT-4 tab inside ChatGPT.
Vocal range
This all constitutes part of a broader expansion that is leading ChatGPT farther from a pure text-based generator, and down a path where audio and visuals are very much part of its remit.
Last month, OpenAI gave ChatGPT a mouth and ears with users able to have a verbal conversation with the chatbot, bringing together the worlds of Alexa-style voice assistants with powerful large language models (LLMs). For example, a user will be able to ask ChatGPT to create and narrate a bedtime story for their kid on the spot, though it’s maybe worth being on hand to see what it comes up with.
Additionally, ChatGPT will also allow users to search for answers using images, meaning that someone can upload a picture of an object and discover what it is or find similar items.
So today’s news very much fits into OpenAI’s push to make ChatGPT a fully integrated, real-time, multimedia generative search engine.","https://techcrunch.com/wp-content/uploads/2023/09/GettyImages-1647521480-e1694685235777.jpg?resize=1200,676",2023-10-18 10:32:40
https://techcrunch.com/2023/10/18/openai-formally-brings-bing-powered-search-to-chatgpt-as-dall-e-3-arrives-in-beta/,ChatGPT officially gets web search as DALL-E 3 integration arrives in beta,"OpenAI has formally launched its internet-browsing feature to ChatGPT, some three weeks after re-introducing the feature in beta after several months in hiatus.
ChatGPT, the generative AI chatbot that has taken the world by storm these past 12 months, has historically been limited to data up to September, 2021 — rendering it useless as a real-time search engine. However, OpenAI started bringing internet services to ChatGPT back in March, a move that always came with inherent risks, given that the live web isn’t curated in the same way a static training data set is — this potentially opened the doors to abuse by bad actors and good old-fashioned algorithmic chaos.
Then in May, OpenAI started rolling out web search via Bing, the search engine belonging to OpenAI’s corporate backer Microsoft, before extending access to the ChatGPT mobile app in late June. However, the new feature was swiftly pulled after it was discovered that ChatGPT was capable of displaying paywalled content.
Fast-forward to late September, and OpenAI started rolling the Browse with Bing feature out again, having fine-tuned how ChatGPT follows instructions laid out by content owners — essentially, it now promised to adhere to whatever a site-owner said in its Robots.txt file, similar to traditional web crawlers.
Now, Browse with Bing is officially available to all Plus and Enterprise subscribers, with no need to toggle their beta switch in settings.
In related news, OpenAI also transitioned DALL-E 3 into beta, a month after debuting the latest incarnation of the text-to-image generator.
DALL-E 3 sports integration with ChatGPT, meaning that users don’t have to think so carefully about their text-prompts when asking DALL-E to create an image — ChatGPT can do a lot of the heavylifting to ensure that the image the user gets, is closer to what they want.
But more than that, with DALL-E 3 embedded directly into ChatGPT, users will now be able to receive images as part of their text-based queries without having to switch between apps.
DALL-E 3 is available in beta now on the web and mobile, with users able to activate the feature by selecting “DALL-E 3 (Beta)” from the GPT-4 tab inside ChatGPT.
Vocal range
This all constitutes part of a broader expansion that is leading ChatGPT farther from a pure text-based generator, and down a path where audio and visuals are very much part of its remit.
Last month, OpenAI gave ChatGPT a mouth and ears with users able to have a verbal conversation with the chatbot, bringing together the worlds of Alexa-style voice assistants with powerful large language models (LLMs). For example, a user will be able to ask ChatGPT to create and narrate a bedtime story for their kid on the spot, though it’s maybe worth being on hand to see what it comes up with.
Additionally, ChatGPT will also allow users to search for answers using images, meaning that someone can upload a picture of an object and discover what it is or find similar items.
So today’s news very much fits into OpenAI’s push to make ChatGPT a fully integrated, real-time, multimedia generative search engine.","https://techcrunch.com/wp-content/uploads/2023/09/GettyImages-1647521480-e1694685235777.jpg?resize=1200,676",2023-10-18 10:32:40
https://techcrunch.com/2023/10/18/the-venture-market-is-overcorrecting/,The venture market is overcorrecting,"Listen here or wherever you get your podcasts.
Hello, and welcome back to Equity, the podcast about the business of startups, where we unpack the numbers and nuance behind the headlines.
This is our Wednesday show, where we sit down with a guest, talk about their work and dive deep into the rest. This week Gené Teare from Crunchbase and Crunchbase News joined the podcast. She’s a well-known analyst of the global venture capital market, and was instrumental to Crunchbase’s early life and remains one of its more tenured staffers.
So, what did the three of us get into? Here’s the rundown:
The big picture: What should we think about when we consider the Q3 2023 venture capital market as a whole. (More on Latin America here, Canada here, and global data here from TechCrunch+.) Here’s Gené on Q3 data as well.
Stage-level health. Which level of startup maturity is seeing the most capital? The least?
And, venture capital flows around the world. As always, where venture dollars land is nearly as important as their total number for any particular period.
Equity is back on Friday with our weekly news roundup. Chat then!
Before we let you go, some disclosures: We invited Gené on the show because we wanted to pick her brain regarding the venture capital markets. We knew she’d be great on the topic, because both Mary Ann and Alex worked with her for years at Crunchbase. During their tenure at Crunchbase, this podcast’s cohosts were paid partially in stock options, and retain minor stakes in the startup itself. We do our best at Equity to cite the best data source for whatever topic we’re looking at, which means we use Crunchbase data as well as information from its competitors at PitchBook and CB Insights; indeed, we had a PitchBook denizen on the show to chat through Q2 2023 results just a few months back. All that’s to say that we think we put together the best possible show for you on its merits alone, but did want to note some professional overlaps right up top.","https://techcrunch.com/wp-content/uploads/2023/04/robot-arm-money-1.jpg?resize=1200,645",2023-10-18 14:05:14
https://techcrunch.com/2023/10/18/new-york-vc-firms-form-alliance-to-back-diversity/,New York VC firms form alliance to back diversity,"Despite what numbers might show, some venture capitalists are quite serious in their commitment toward diversity, equity, and inclusion are not going away.
The New York City Economic Development Corporation (NYCEDC) on Wednesday announced the launch of Venture Access Alliance, a group of 70 investors who have promised to boost diversity in the Big Apple’s startup ecosystem. It is part of the city’s Venture Access NYC initiative, which also provides fellowships and a career program for diverse talent looking to enter venture capital.
New York City is the second largest tech ecosystem in the world, making such a public-private partnership significant in the impact it could have. The Alliance encourages firms and investors to collect diversity data and increase the number of women and minorities hired and funded annually. From there, the Alliance hopes to track the progress of the city’s landscape and ask investors to fund and implement programs that can help develop diverse talent in the city.
Harlem Capital Partner Jarrid Tingle and Union Square Ventures Partner Fred Wilson chair the Alliance in partnership with the Ford Foundation, Annenberg Foundation and Tech:NYC. The Alliance was created to ensure that New York City was tapping into the next generation of talent, Tingle told TechCrunch.
“Creating an inclusive ecosystem is the right thing to do, but it also ensures that NYC is not leaving GDP and innovation on the table,” Tingle said.
Today, the NYCEDC released its latest diversity in venture capital report and cited data from Kauffman Fellows Research Center that found diverse founding teams have higher investor returns compared to founding teams that are all white. The report also highlighted data from Cambridge Associates, which found that new and emerging fund managers are constantly at the top of the asset class.
“The Alliance is putting a stake in the ground [saying] that we want to do more, we want to do better, and that means driving more investment to diverse founders, it means hiring more diverse staffers, it means mentoring, that means internships,” NYCEDC’s President & CEO Andrew Kimball said. “We’re very excited.”
Other firms have signed on, including Citi Impact Fund, M13, Streetlife Ventures and Primary VC. The Alliance is still in the early stages; members hope to start working together in the next few months. It builds on Mayor Eric Adam’s economic recovery plan, which focuses on helping underserved entrepreneurs have greater access to capital. Its mission is essential given the fact that almost 30% of businesses in New York City are minority-owned, with Black-owned businesses in particular seeing a dramatic increase.
“It’s clear that diverse founders consistently outperform, and we have an opportunity in New York City to harness our unmatched diversity to build the most robust and inclusive innovation hub in the world,” Kimball continued.
The NYCEDC’s work is essential and timely, given the backlash to DEI brewing in the ecosystem. California SB 54, which Gov. Gavin Newsom signed last week, requires firms operating in the state to report the diversity breakdown of who they back. As debates ensue on the role of policy in increasing diversity in venture capital, private organizations have taken to helping increase diversity on their own terms. The Venture Alliance takes inspiration from the PledgeLA, which was launched by the Annenberg Foundation and the City of Los Angeles.
Local efforts like this matter, Kimball said, and he sees hope for an organization like this throughout the nation. “We feel like we can hopefully turbocharge the effort by having it open in New York,” he said. “We’d love to see it expand beyond the five boroughs.”","https://techcrunch.com/wp-content/uploads/2023/10/GettyImages-1455881718-e1697626384284.jpg?resize=1200,699",2023-10-18 14:00:41
https://techcrunch.com/2023/10/18/youtubes-latest-features-aim-to-help-creators-make-more-money-from-shoppable-videos/,YouTube's latest features aim to help creators make more money from shoppable videos,"Only weeks after TikTok Shop’s entry into the U.S. market, YouTube today is making it easier for consumers to shop products presented by its own creator community. The company is introducing new creator-focused features that will allow them to add timestamps to videos for their tagged products and tag their affiliate products in bulk across their video library. Combined, the additions will simplify the process of marketing products through YouTube videos and potentially increase sales, netting creators more money.
YouTube has been steadily rolling out more tools for shopping from its videos for many months, having last year partnered with Shopify to allow merchants to feature their products in videos, expanded livestream shopping features, and added shopping features to YouTube Shorts, among other efforts.
Now it’s experimenting with more ways to connect consumers to products creators are showcasing in their videos with the new releases. With the timestamps feature, creators will be able to make the shopping button appear at the relevant points in their video — like when they’re showing off a favorite gadget or beauty product, for example. YouTube tested the feature in the U.S. last month and found that people who saw these timestamps clicked on tagged products twice as often. The feature is only available on long-form content, not Shorts, however. And video must be at least a minute long with a maximum of 30 seconds in between timestamps, YouTube says.
The company is also adding new tools to tag affiliate products across the creator’s video library in bulk, based on products added to the video’s description. To use this feature, creators will access the Shopping tab in YouTube Studio to see a list of their videos with products mentioned in the description. From there, they can click the videos they want to tag, make adjustments, then click “Save” to complete the process. The feature will allow creators to quickly monetize videos from their back catalog that are still seeing high views with little effort, the company notes.
Though not available today, YouTube is also teasing new insights and analytics for affiliate products that will allow creators to see things like sales metrics, orders, offer clicks and impressions from Studio’s “Analytics” tab under “Revenue” then “Affiliate program.”
The changes come as TikTok is ramping up its own e-commerce features in the U.S., which include a dedicated shop tab on the home screen, live video shopping, shoppable ads and affiliate programs for creators.
Though a number of video shopping efforts are stalling in the U.S., with some startups failing to gain traction, other efforts are just taking off. For instance, TalkShopLive just launched a new app this week to allow sellers to broadcast on its platform, digital sports and apparel platform Fanatics just launched a live commerce app, a former Amazon exec launched a video shopping app for beauty items Trendio, and Elon Muks’s X is planning to experiment with live shopping in a partnership with Paris Hilton’s 11:11 Media company as part of a broader 2-year deal. Even Apple is embracing live shopping to some extent with a new experience launched earlier this year that connects online shoppers to live Apple sales reps to answer their questions.",https://techcrunch.com/wp-content/uploads/2022/04/youtube-ios-app.webp?w=1024,2023-10-18 13:46:16
https://techcrunch.com/2023/10/18/revroad-capital-raises-61-million-for-early-stage-startups-in-utah-and-beyond/,RevRoad Capital raises $61 million for early-stage startups in Utah and beyond,"RevRoad was started in 2017 as a venture services firm for startups in Utah. The organization offered a two-year program with access to 12 resources ranging from legal services to sales help to mentorship in exchange for equity. But unlike many entities, it didn’t have capital to invest in the startups that completed the program. Now it has a solution for that.
RevRoad Capital raised $61 million for its debut fund to focus on early-stage investments, mainly at seed. The Provo, Utah-based fund will operate as a sister organization to RevRoad and will invest the majority of its capital into companies that went through RevRoad’s program. It will also make investments in select other startups as well.
David Mann has been working with RevRoad since 2018 when he got involved after he left his job as the director of Amazon Game Studio. When RevRoad began to formulate the idea of launching a venture fund back in 2022, Mann knew he wanted to be a part of it and signed on as the fund’s executive managing director.
“I decided to un-retire and lead this fund and really try to shape it in a way that fulfills the vision of RevRoad and helps founders get hard dollars and also great support from their venture partners as they scale,” Mann told TechCrunch.
While the timing made sense for RevRoad, the market conditions weren’t ideal. The past year has been one of toughest periods for fundraising — especially for emerging managers. First-time funds are on track to close the smallest amount of funds — and raise the lowest amount of capital — in 2023 compared to the last decade, according to Q3 data from PitchBook.
Managing director Rachelle Morris told TechCrunch that they weren’t immune to the market pressures. “We definitely felt the headwinds,” Morris said. “There were a lot of folks who told us, ‘Wow, we love your thesis and we love the team, we just don’t have liquidity right now.’”
But they did find particular success with a specific group of LPs: women operators, which in Utah were largely an untapped resource. When Morris started the fundraising process, she reached out to a longtime acquaintance and local business leader and was shocked to find out she’d never been asked to invest before.
“You would expect that if there is any woman in the Utah community who would have been shown deals in funds, she would have been one of those 20 women,” Morris said. “That’s where we gained confidence of, ‘Huh, women are being underestimated as investors.'”
She was right. These local women operators ended up making up 30% of the fund’s LP base.
Mann said he also thinks their strategy helped them in a tougher fundraising environment. The majority of RevRoad Capital’s investments are built off of existing relationships with startups from RevRoad, which means the firm already has two years of data and diligence on a startup before it gets a check. He thinks that makes the firm look less risky in LP’s eyes.
Because RevRoad’s headquarters are in Utah, Mann said the majority of the portfolio companies for Fund I will be in Utah, but as RevRoad continues to expand into other geographies, RevRoad Capital will as well. But the current focus isn’t limiting, because Utah is a great place for startups, he said: There is a good startup culture and the local government has made it so there are few barriers for startups to launch.
The fund will invest as a generalist but with a stronger focus in areas, including electric vehicles, AI, SaaS, retail and manufacturing. The firm’s portfolio companies will still get access to many of RevRoad’s startup services regardless of whether they went through the program initially.
“Once a company is in RevRoad LLC or RevRoad Capital, they are a RevRoad company,” Mann said. “We pull that expertise in where needed. RevRoad is happy to help RevRoad Capital companies. They can have an impact.”","https://techcrunch.com/wp-content/uploads/2023/10/01_L-R-Scott-Petersen-Rachelle-Morris-David-Mann-Bart-Skalla.jpg?resize=1200,800",2023-10-18 13:05:16
https://techcrunch.com/2023/10/18/statement-a-cash-flow-management-platform-for-enterprises-raises-12m/,"Statement, a cash flow management platform for enterprises, raises $12M","Statement, a startup developing a platform for enterprise cash flow management, today announced that it raised $12 million in seed funding.
Glilot Capital Partners contributed to the tranche with participation from Citi, Mensch Capital Partners, Titan Capital and Operator Partners. Co-founder and CEO Idan Vlodinger says that it’ll be used to “double down” on Statement’s go-to-market efforts and “accelerate” the pace of product development.
“Many traditional finance and treasury operations are manual, time-consuming and complex,” Vlodinger told TechCrunch in an email interview. “Tasks like monitoring all of the company’s cash in real time across all legal entities, regions and financial institutions are extremely labor-intensive and time-consuming. Finance and treasury teams are ultimately in charge of their company’s financial health and bear the weight of the world on their shoulders, but they don’t have access to the information needed to make timely, mission-critical decisions.”
Before founding Statement, Vlodinger worked at Amazon, where he was a senior product manager at Prime Video. After leaving Amazon for Mastercard, where he eventually graduated to the role of VP of products and innovation, Vlodinger teamed up with Shahar Lahav, a former researcher in the Israel Defense Forces, to launch Statement.
Vlodinger describes Statement as a “cash intelligence” platform for companies working with multiple banks, managing liquidity and attempting to forecast their cash flow. Statement connects with banks and integrates with existing systems, including business tools (e.g. Google Sheets), enterprise resource management platforms (e.g. Oracle Cloud, NetSuite) and payment providers (e.g. PayPal, Stripe), to reconcile and sync real-time financial data to give visibility into a firm’s cash performance, Vlodinger says.
Statement can automatically categorize transactions for financial reports. And it can forecast short- and long-term cash flow, establishing a baseline and analyzing historical trends to improve overall forecast accuracy. Elsewhere, Statement’s workflow automation tools allow teams to automate repetitive and manual tasks like cross-checking between banks and reporting errors.
“Statement saves the office of the CFO hundreds of hours per month on manual data collection and enrichment, and hundreds of thousands to millions of dollars by being able to manage their money faster and better,” Vlodinger said. “CFOs deserve to work with great software, with a fantastic user interface, that has real-time data, and have the systems “speak” to each other with true data reconciliation, so they can focus on growing their businesses.”
Vlodinger claims that Statement, founded in 2022, already has dozens of companies in its customer roster. Revenue has increased 10x over the past year, meanwhile — despite competition from vendors like Kyriba, Trovata, Ion and Gtreasury.
Gearing up for further growth, Statement plans to expand its 31-person team, which is split between offices in New York and Tel Aviv, to 35 people by the end of next year.
“The pandemic, supply chain risk, volatile markets, rising interest rates and high inflation have caused global enterprises’ management to be laser-focused on their finances and cash. The technology stack for the office of the CFO has emerged as a key component in this landscape. As a result, it now represents one of the most exciting opportunities and areas for development and innovation.",https://techcrunch.com/wp-content/uploads/2023/10/64775edd75800e25ab18f3e9_Newinfinityv5-1-min.jpg,2023-10-18 13:00:49
https://techcrunch.com/2023/10/18/whisper-aero-unveils-ultra-quiet-electric-leaf-blower-powered-by-aerospace-tech/,"Whisper Aero unveils ultra-quiet electric leaf blower, powered by aerospace tech","Whisper Aero emerged from stealth a little over two years ago with a straightforward (if ambitious) plan: to radically reduce noise emissions from next-gen aircraft with a never-been-done-before electric thruster.
But according to Whisper COO Ian Villa, from the very beginning, the company was thinking more expansively. The startup was founded by Villa and CEO Mark Moore, both former executives at Uber’s aerial ridesharing project Elevate. Early on, the two founders had a hunch that the electric propulsor could be scaled down for products outside the aviation industry.
Like, say, lawn care.
“If we showed you our seed round deck, we had a leaf blower in it,” Villa said in a recent interview. “We’ve always known leaf blowers would be on the path. The real question was when.”
The answer to that question is now. Today, Whisper has unveiled “Whisper Drive,” a scaled-down electric ducted fan that can be integrated into leaf blowers, commercial drones or other consumer products. The company says that a Whisper Drive-enabled leaf blower can be up to forty times quieter at fifty feet than its competitors, effectively turning a neighborhood nuisance into a barely perceptible hush.
The result is a leaf blower that emits just 45 decibels of noise at fifty feet and full throttle. In comparison, gas leaf blowers emit between 70-90 decibels of sound at the same condition, while the quietest electric leaf blowers on the market emit around 57-59 decibels.
Whisper engineers started playing around with the concept for a quiet leaf blower after the company had already developed and flown an early-generation 10-pound thruster for a demonstrator drone. Using some 3D printed parts and spare batteries, they modified the propulsor into a leaf blower MVP.
“We were blown away,” Villa said, likely not intending to make such a good pun. “It was just insane how magically quiet it was. We looked at the numbers and we said, Okay, we know how much thrust this produces. […] And it dawned on us, not only was it quiet, but it has to be moving more air than an equivalent handheld leaf blower.”
Whisper set up the very same testing rigs that outdoor power equipment vendors use, so they’ve been able to do direct comparisons between a Whisper Drive-enabled blower and blowers available for purchase. Whisper engineers have also been able to subject the blower to aviation-grade testing, which has allowed them to measure thrust and noise to a highly precise degree, Villa said.
While the company was able to prove tremendous noise reduction with just a prototype, it wasn’t consumer-friendly in terms of costs, so Whisper had to think seriously about how to scale manufacturing up and drive costs down.
“The leaf blower was a way to tackle that in a product aligned way, where we can perform these experiments, come up with something that we knew the public wanted, but then also solve [the question of] how are we going to make these thrusters cheap enough for commercial drones. To us it was a win-win.”
The biggest way the company’s been able to bring costs down is via an injection molding technique using low-cost materials. The most expensive part of the leaf blower is the battery, and Villa said that Whisper Drive’s improved efficiency will generate longer run times and decreased battery weight.
Leaf blowers may seem relatively low tech – blow air, move leaves – but this is exactly why they’re such a prime product to target, Whisper says. More and more communities have enacted usage restrictions on leaf blowers due to the noise, which is bad news for lawncare workers, especially those that live in hot areas and may not be able to start work during the coolest parts of the day. Depending on use, workers may also be required under federal law to wear hearing protection. Whisper Drive-enabled leaf blowers would make noise restrictions irrelevant and hearing protection unnecessary.
To be clear, Whisper is not building a leaf blower (just the propulsor), but the company is already in talks with a few potential partners to bring the ultra-quiet blower to the market. Villa said the company’s goal is to lock in a partnership toward the end of this year or beginning of next year, so that the blower can be available for purchase by 2025 or sooner.
The new product is part of Whisper’s broader strategy to bring in early revenue and diversify its portfolio – going after high-thrust defense and commercial aviation on one end, to lower-thrust products like leaf blowers or commercial drones on the other.
“We have a significant portion of the team working on high thrust we also have a significant portion of the team are working on low thrust,” Villa said. “Really, they’re synergistic.”
A quieter, more efficient and affordable electric leaf blower may even be the final nudge in turning the lawncare industry – which has historically relied on gas-powered machinery – greener. While the percentage of the electric lawn equipment market has been rapidly growing, especially amongst individual consumers, it’s still not the majority.
“A lot of landscapers have already gotten on the bandwagon,” Villa said. “When you look at the dollars and look at the economics of it, just like how electric aviation has favorable economics to some alternatives, the same thing is true in the landscaping space. The trouble is, you have these favorable economics, but there’s limitations. To break through those limitations in terms of run time, in terms of performance, in terms of noise, you need enabling technology.”
“This Whisper Drive that we’re able to use in a leaf blower application, is that key enabler.”","https://techcrunch.com/wp-content/uploads/2023/10/Whisper-Leaf-Blower-Demo-Prototype.jpg?resize=1200,900",2023-10-18 13:00:43
https://techcrunch.com/2023/10/18/allara-a-telehealth-platform-for-women-with-chronic-hormonal-conditions-raises-10m-series-a/,"Allara, a telehealth platform for women with chronic hormonal conditions, raises $10M Series A","Chronic hormonal conditions such as polycystic ovarian syndrome (PCOS) and endometriosis are common in women, but also commonly go undiagnosed or inadequately treated. Allara, a New York–based telehealth startup, wants to help connect women with conditions like these with qualified medical practitioners and registered dietitians via its platform.
PCOS is one of the most common causes of female infertility, affecting as many as 5 million women, or 1 in 10 of reproductive age in the U.S., according to the CDC. Moreover, about 10% of women across the globe, which is equivalent to 176 million, have endometriosis.
Despite how widespread these conditions are, patients with chronic hormonal disorders often undergo years of suffering before receiving treatment, and “up to 70% of cases are undiagnosed worldwide,” per the World Health Organization.
Allara CEO and founder Rachel Blank experienced firsthand how challenging it is to get adequate support for PCOS; she was diagnosed with it at 21, after years of unexplained medical issues.
“I sought support from various doctors and specialists, did my own research, and played whack-a-mole with lifestyle changes, but wasn’t able to find effective and holistic care for my condition,” Blank told TechCrunch. “There is no FDA-approved treatment for this widespread, chronic condition.”
Allara hopes to change that with its comprehensive approach and care team that includes OB-GYNs, women’s health nurse practitioners, endocrinologists and registered dietitians who deeply understand hormonal and metabolic care. Dr. Heather Huddleston, chief medical advisor of Allara and director of the PCOS clinic at the University of California, San Francisco, leads Allara’s expert advisory board.
The two-year-old startup said it has raised $10 million in a Series A round led by Google Ventures with participation from Great Oaks Venture Capital, Humbition, Vanterra, Gaingels and angel investors like One Medical founder Tom Lee and Maggie Sellers. Google Ventures’ general partner Frédérique Dame will join Allara’s board of directors. The new money brings its total capital raised to $17.5 million.
Blank has worked in digital health since 2018 and was formerly director of strategy at health tech startup Ro. Allara’s virtual care platform offers a monthly subscription service that enables patients to access ongoing medical, lifestyle, nutrition, and emotional support for hormonal, metabolic and gynecological conditions and helps them see improved health outcomes. The startup claims that 75% of patients start to feel better within one month of working with Allara.
Since the launch, Allara has expanded “from specialized PCOS care to comprehensive care services for women with hormonal, metabolic and gynecologic conditions,” Blank said.
Over the past year alone, the startup’s patient base grew fivefold, and it partnered with major insurers, including Cigna, Anthem, Aetna, Empire and United Healthcare, in eight states, covering approximately 30 million lives to provide quality care for women nationwide.
The Series A proceeds will help Allara extend its insurance coverage, launch partnerships with health systems to continue patient care, conduct clinical research and scale its operations for further care, which currently includes research-backed supplements and mental health services based on patient requests.
When asked about its partnerships with the health system, Blank said, “Allara was not built to compete with the traditional health system, but to help close a massive care gap that exists for women’s health.”
The company is in talks with health systems and large fertility groups “to help improve access to chronic care and pre- and post-op management, delivered virtually — rather than requiring patients to visit multiple providers and put their care together themselves. Allara’s platform “allows these health systems and highly specialized providers to focus more on the procedures that need to be done in person.”
“The health system often views women’s healthcare as limited to pregnancy and fertility, but many women deal with chronic, specific conditions that require a whole-body, preventative approach,” Blank said. “Our patients are often in their 20s and 30s and looking to improve their overall health or are a few years out from conception and trying to get a head start on improving their health and fertility.”","https://techcrunch.com/wp-content/uploads/2021/04/GettyImages-1124695995.jpg?resize=1200,800",2023-10-18 13:00:37
https://techcrunch.com/2023/10/18/squares-new-ai-features-include-a-website-and-restaurant-menu-generator/,Square's new AI features include a website and restaurant menu generator,"Square, the financial services platform, is embracing generative AI in a very visible way.
After announcing earlier this year that it would bring AI features to drive retail sales, Square this morning took the wraps off of new ten — count ’em, ten — generative AI capabilities focused on customer content creation, onboarding and setup.
All are available as of today, albeit some gated behind Square’s beta program
The push, it might be said, is an attempt by Square — and parent company Block — to reinvigorate the Square platform after a difficult, downward-trending year and change.
Revenues from Block’s Cash App, the peer-to-peer payments service, have declined steeply. Meanwhile, the buy now, pay later service Afterpay, which Block acquired in 2021 for $29 billion, has posted serious losses. Block’s Bitcoin revenue has fallen corresponding with the fall in the price of the cryptocurrency last year. And Square faces growing competition on multiple fronts. including from Fiserv’s Clover, Toast and Stripe.
Investors are displeased. Square stock has retreated around 30% so far in 2023, as Block founder Jack Dorsey prepares to take the reigns from former Square head Alyssa Henry.
So Square’s giving stockholders generative AI.
One of the new AI-powered features, Menu Generator, allows restaurants to create a “full menu” on Square in “just minutes,” the platform promises in a press release.
“This is a valuable tool in particular for new restaurant sellers who don’t have or aren’t ready to upload a menu during onboarding,” a Square clarified to me via email. “With Menu Generator, restaurants can now create a full menu on Square … with the flexibility to come back and change or update that menu later after they’ve finished other set-up tasks. This gives them — or any business looking to expand into food and drink offerings — valuable momentum when launching operations on Square.”
Given generative AI’s tendency to go off the rails, I’d be wary of using it to publish a menu — particularly considering that gross inaccuracies could land restaurants on the hook for lawsuits over false advertising. But Square emphasizes that the process — which relies on a range of third-party generative AI models including OpenAI’s GPT-3, GPT-3.5 and GPT-4 — isn’t fully automated and that customers are afforded the chance to make edits before a menu hits the web.
“All of our AI-generated content is offered as suggestions to sellers, giving them the ability to save as-is or make further edits,” the spokesperson said. “The human review process comes from sellers themselves, who approve or modify all copy created to ensure it helps them meet their business goals.”
Human review is also baked into Square’s new generative email copy feature, according to the spokesperson, which taps generative AI to create personalized email messages to customers. And it’s a component of Square’s newly-launched website copy generator, which writes headlines — and entire blogs — given a brief text prompt.
I asked Square whether it’d taken steps to ensure that copy from its website tool wouldn’t result in downranking by search engines who don’t look kindly on certain, obviously duplicative forms of AI-generated content. In response, the spokesperson pointed to Square’s partnerships and integrations with Google to “help small businesses overcome … discoverability hurdles” — but didn’t answer the question directly.
As a part of the raft of new generative AI capabilities, Square’s point of sales system can now auto-generate item descriptions for seller catalogs. Square pitches this as a massive time saver — but color me skeptical. eBay recently rolled out a similar item description generator and the feedback has been less than stellar, with users complaining about repetitiveness and fluff in the AI-generated descriptions.
When presented with these concerns, the Square spokesperson noted that item descriptions from the generator are created “based on inputs from sellers, including keywords to keep descriptions focused, and length and tone guidelines to avoid overly verbose or fluffy results.” But it remains to be seen if sellers adhere to these guidelines.
Elsewhere on the AI front (not necessarily generative AI, despite how Square refers to them in the press release), the Kitchen Display System, Square’s kiosk for restaurant order management, can now auto-assign menu items to kitchen categories and station screens. Square’s scheduling system, Appointments, can automatically import service names, descriptions, durations and prices during onboarding, meanwhile. And Square’s namesake point-of-sales platform now suggests items for sellers to adopt “based on insights about their business.” (It’s not clear exactly which insights — the press release doesn’t specify.)
Square Team Communication, which adds announcements and messaging to Square Team, Square’s app for employee scheduling and time tracking, is now able to generate and send out announcements to let employees know about new products and upcoming promotions. (The topic, length and tone are adjustable, Square says.) And Square Messages, Square’s business-customer messaging platform, can now suggest “sophisticated” AI responses, with the ability to personalize messages with replies that prepopulate customer names. (This upgrades Square Messages’ existing reply generator, which Square claims is generating 450,000 messages per month.)
In the press release, Saumil Mehta, Square’s head of point of sale, is quoted as saying that the new generative AI capabilities put Square “at the forefront of technology.”
“Square is uniquely positioned to be the technology partner that enables the most seamless, intuitive applications of AI,” Mehta said.
Me, I’m not so sure. But if the sheer breadth of today’s rollout is any indication, Square’s ambitious if nothing else.","https://techcrunch.com/wp-content/uploads/2022/02/GettyImages-608877629.jpg?resize=1200,871",2023-10-18 13:00:02
https://techcrunch.com/2023/10/18/amazon-pharmacy-launches-its-first-drone-deliveries/,Amazon Pharmacy launches its first drone deliveries,"Amazon’s Prime Air drone service has been slow to take off for the company, with limited operations in just two locales a whole decade after Amazon first started development of the program. Now, Prime Air is getting a small injection of activity, quite literally: today, Amazon announced the launch of drone deliveries of medicines purchased through Amazon Pharmacy, its online prescription drug store.
Amazon said packages will be dropped by drone within 60 minutes of being ordered via Amazon Pharmacy. The first city for the service will be College Station, Texas.
Amazon Pharmacy currently covers around 500 medications, including those for flu, asthma, and pneumonia; and (for now) the drone service will be free to use, Amazon said. (And despite the name “Prime” in its branding, it’s open to all customers, not just those paying for the company’s Prime membership.)
Amazon had signalled its plans to offer Pharmacy deliveries in College Station previously, but the company has declined to say where else it might expand, or when. College Station, along with Lockeford, California, are the only two markets where Prime Air drones have been rolled out so far (deliveries up to now have covered a limited set of non-Pharmacy products including household products, office supplies and beauty items).
Markets where Amazon has launched same-day delivery for Pharmacy are Austin, Indianapolis, Miami, Phoenix, and Seattle — so those might be some of the next markets for drone deliveries, too (pending regulatory clearance).
Amazon has been slowly adding new services into Pharmacy to make it more market-competitive — for example RxPass, launched earlier this year, lets customers get access to certain medications they take regularly for a $5 flat fee). Prime Air, on the other hand, has been a slow burner for the company.
Amazon’s drone delivery program, in the works since 2013, made its first delivery in 2016, in England. In the U.S., Amazon scored a win in 2020, when it got approval from the Federal Aviation Authority to trial services.
But a series of regulatory and other technical issues have impeded the tech giant from making any significant roll out since then, with a mere 100 deliveries to its name as of May 2023. To that end, multiple observers have pointed out how it’s been surpassed by offerings from some of its biggest competitors. For instance, Walmart, which has worked with third-party drone providers rather than building a service in-house, has made tens of thousands of deliveries with partners Zipline (a specialist in drone-based medical deliveries) and soon Alphabet’s Wing.
There is an obvious logic to adding drone delivery to Amazon’s pharmacy service. If a person is unwell and unable to collect prescriptions in person, but is also needing them urgently and may not have someone else to help them out, drone becomes a quick and easy route for that customer.
Amazon’s focus on that at-home opportunity is not contained just to the delivery of meds. Amazon Clinic provides virtual evaluations and treatment recommendations covering some 35 conditions; and the company’s One Medical service (which it acquired for $3.9 billion in July 2022) provides virtual and in-person primary care services. Adding drones into that mix completes the virtual service loop.
“We’re taught from the first days of medical school that there is a golden window that matters in clinical medicine,” said Dr. Vin Gupta, chief medical officer of Amazon Pharmacy, in a statement. “That’s the time between when a patient feels unwell and when they’re able to get treatment. We’re working hard at Amazon to dramatically narrow the golden window from diagnosis to treatment, and drone delivery marks a significant step forward. Whether it’s an infectious disease or respiratory illness, early intervention can be critical to improving patient outcomes.”
There is a business logic too: delivery trucks have very high costs associated with them, from labor through to the operation (and insurance) of the vehicles themselves.
The company tells me that the operation in College Station is based around a pharmacy it opened in the town to lay the groundwork for the drone delivery service: the medications are overseen by a pharmacist onsite and then loaded on the drone located immediately outside the pharmacy. This also points to is an interesting opportunity down the line: Amazon working with other pharmacies, not owned by Amazon, offering similar drone delivery services to them.","https://techcrunch.com/wp-content/uploads/2023/10/AP_Drone_Bottle-Azythromycin.jpg?resize=1200,675",2023-10-18 12:38:47
https://techcrunch.com/2023/10/18/clearview-wins-ico-appeal/,"Selfie-scraper, Clearview AI, wins appeal against UK privacy sanction","Controversial US facial recognition company, Clearview AI, has won an appeal against a privacy sanction issued by the UK last year.
In May 2022, the Information Commissioner’s Office (ICO) issued a formal enforcement notice on Clearview — which included a fine of around £7.5 million (~$10M) — after concluding the self-scraping AI firm had committed a string of breaches of local privacy laws. It also ordered the company, which uses the scraped personal data to sell an identity-matching service to law enforcement and national security bodies, to delete information it held on UK citizens.
Clearview filed an appeal against the decision. And in a ruling issued yesterday its legal challenge to the ICO prevailed on jurisdiction grounds after the tribunal ruled the company’s activities fall outside the jurisdiction of UK data protection law owing to an exemption related to foreign law enforcement.
Although the tribunal did agree with the ICO’s argument that Clearview’s processing was related to the monitoring of data subjects’ behavior carried out by its clients. It also found the company to be a joint controller for the processing. But the ICO’s case came unstuck on legal jurisdiction.
The UK’s General Data Protection Regulation (GDPR) stipulates that the processing of personal data by competent authorities for law enforcement purposes is outside its scope — and is instead subject to rules in Part 3 of the Data Protection Act 2018 (which brought the EU Law Enforcement Directive EU2016/680 into UK law, post-Brexit).
Per the ruling, Clearview argued it’s a foreign company providing its service to “foreign clients, using foreign IP addresses, and in support of the public interest activities of foreign governments and government agencies, in particular in relation to their national security and criminal law enforcement functions”.
The tribunal accepted its claim to provide service exclusively to non-UK/EU law enforcement or national security bodies and their contractors (and that all such contractors also only carry out criminal law enforcement and/or national security functions) — overturning the ICO’s enforcement decision finding a string of breaches of the UK GDPR.
Contacted for a response to the ruling, an ICO spokesperson emailed us this statement:
The ICO will take stock of today’s judgment and carefully consider next steps. It is important to note that this judgment does not remove the ICO’s ability to act against companies based internationally who process data of people in the UK, particularly businesses scraping data of people in the UK, and instead covers a specific exemption around foreign law enforcement.
The data protection watchdog did not confirm whether or not it will appeal. It’s also not clear why the ICO did not bring a claim against the Clearview under the DPA 2018, rather than the UK GDPR.
Clearview, meanwhile, welcomed the tribunal ruling. “We are pleased with the tribunal’s decision to reverse the UK ICO’s unlawful order against Clearview AI,” said general counsel, Jack Mulcaire, in a brief response statement.
The UK sanction was just one of a number of enforcements that have been brought against Clearview in recent years under regional data protection laws.
Data protection authorities in France, Italy and Greece have found the US firm in breach of the EU’s GDPR — which the UK’s domestic data protection framework is based on. However, since Brexit, the UK GDPR is distinct law — so it’s not clear whether this tribunal ruling will have direct implications for other enforcements against Clearview which make reference to the EU’s GDPR.
Nonetheless, DPAs in the bloc have also struggled to enforce their will on Clearview.
Back in May, France’s CNIL confirmed Clearview had not paid the penalties it had levied — and announced a further fine for non-payment at that point. The authority had also ordered Clearview to delete data on French citizens and banned further unlawful processing. But it’s not clear the CNIL has been able to enforce those injunctions either.
Earlier this year the French authority told TechCrunch it was talking to the US Federal Trade Commission — “to discuss how we can ensure that the injunction issued against the company is enforced”. We’ve contacted CNIL for an update on its efforts to make Clearview comply with its orders. Update: A CNIL spokesperson confirmed Clearview still has not paid the penalties ordered. They also told us it has not appealed the regulatory sanction either.
We’ve also reached out to the Italian and Greek DPAs with questions about their own procedures against it and will update this report with any responses.
The Clearview case highlights the challenges for European regulators of trying to enforce data protection rules, which — in the case of the GDPR at least — do apply extraterritorially, i.e. against foreign-located firms processing local people’s data. But Clearview’s pivot to fully focusing its business on law enforcement and national security agencies appears to have complicated the legal picture.
The company claims it does not have any local customers, saying it does not provide its service to users located in the UK or EU. But that was not always the case. Back in 2021, Sweden’s data protection authority targeted a previous Clearview customer for enforcement — fining the Swedish Police Authority €250,000 ($300,000+) for unlawful use of its AI tech which it found was in breach of the country’s Criminal Data Act.
That investigation was specific to the local police authority’s use of Clearview’s tool — with the Swedish authority finding it had not fulfilled its legal obligations as a data controller, including by failing to implement sufficient organisational measures to demonstrate the processing was compliant with the law (such as not conducting a data protection impact assessment). But it underlines that law enforcement authorities operating in the EU don’t have carte blanche to use Clearview.
Indeed, the opposite may be true; it may be that local law enforcement cannot — lawfully — make use of a tool that triggers so many fundamental rights concerns.
The European Data Protection Board (EDPB) and the European Data Protection Supervisor have previously called for a ban on the processing of personal data in a law enforcement context “that would rely on a database populated by collection of personal data on a mass-scale and in an indiscriminate way”, as the EDPB put it last year — explicitly giving the example of scraping photographs and facial pictures from the public internet (as Clearview does).
The EDPB also published detailed guidance on the use of facial recognition in law enforcement that cautions authorities they can’t ignore data protection rules and principles — and must make careful assessments of “necessity and proportionality”, when considering adopting AI tools; as well as examining “all possible implications for other fundamental rights”.
So the bloc’s data protection framework does make it very difficult — or even impossible — for Clearview to sell its privacy-hostile services to regional law enforcement clients. Even as the GDPR puts limits on its ability to sell services to regional customers for any other purposes.
Over the pond, meanwhile, recent US litigation against Clearview by the ACLU, under an Illinois law banning the use of individuals’ biometric data without consent, ended in a settlement last year that included a national ban on the company selling or giving away access to its facial recognition database to private companies and individuals — essentially limiting its business to US government contracts (except for state or local government entities in Illinois itself, which were covered by the ban).
So, for European regulators, the question is whether they can do anything much to stop a US company hoovering up data on their citizens and selling privacy-hostile facial-matching to US law enforcement or other foreign authorities and state agencies?
Under current laws and enforcement powers that looks tricky.
The controversy around Clearview has landed on the radar of EU lawmakers who are working on establishing a risk-based framework for regulating applications of artificial intelligence. And, earlier this year, MEPs in the European Parliament backed amendments to the draft EU AI Act that proposed expanding a list of prohibited AI practices to include what amounts to a Clearview clause. This amendment would explicitly ban indiscriminate scraping of biometric data from social media sites (and elsewhere) to create facial recognition databases — an action MEPs affirmed as violating human rights, including the right to privacy.
The bloc’s co-legislators are still working on the AI Act file. So it remains to be seen whether the proposed prohibition on scraping selfies to power facial recognition-based ID matching will make it into the final text. If it does, it would clearly further harden regional law against Clearview.
But, once again, whether a fresh network of regional regulators, tasked with enforcing the AI Act, will have any more success at forcing an uncooperative foreign firm to stop abusing Europeans’ rights remains to be seen.","https://techcrunch.com/wp-content/uploads/2023/07/GettyImages-1306235479.jpg?resize=1200,1133",2023-10-18 12:37:32
https://techcrunch.com/2023/10/18/biden-china-nvidia-a800-h800-chips/,Biden further chokes off China's AI chip supply with Nvidia bans,"In August last year, a ban on Nvidia’s chip export to China sent the country’s budding artificial intelligence startups scrambling for alternatives. A momentary sense of relief came when Nvidia unveiled chips with reduced performance to bypass export restrictions. But this respite was short-lived.
On Tuesday, the Biden administration announced a slew of measures to curb Beijing’s military ambitions, including a further restriction on Nvidia’s AI chip shipments to China. A800 and H800, the two AI chips Nvidia designed specifically to continue shipping to China, will be hit by the fresh round of new rules.
The chip bans are originally targeted at China’s military use, but the more visible victims are arguably the country’s raft of startups riding the rapid advancement of large language models. Many of them rushed to stockpile Nvidia’s A100 and H100 before the bans went into effect, shelling out millions of dollars for the inflated costs. Alibaba, Baidu, ByteDance, and Tencent, collectively ordered $5 billion of A800 chips this year and the next, according to a report from the Financial Times.
Nascent startups, meanwhile, are driven to raise venture capital hastily to support their costly AI dreams.
The U.S. chip bans have not stopped Chinese giants from pursuing their AI ambitions. On Tuesday, Baidu unveiled the latest version of its flagship foundation model, Ernie 4.0, and claimed that it now matches GPT4. To date, Ernie has amassed 45 million users, the company claimed.
The challenge of entering China’s AI fray goes beyond increasingly limited semiconductor access. The country’s regulations require that LLM-based services obtain a license before serving public users, a test of companies’ government relations and their ability to navigate the red tape.
Ultimately, a shortage of high-end chips and the intricate nature of Beijing’s censorship requirements created an environment for generative business intelligence services to flourish, as they require less computational power (data sources are internal rather than the entire internet) and are comparatively easier to control as prompts are more scenario-based. Qianfan, Baidu’s enterprise-facing AI platform built on Ernie, has amassed some 17,000 customers.",https://techcrunch.com/wp-content/uploads/2023/05/T-15882236-L.jpg?w=1200,2023-10-18 12:15:08
https://techcrunch.com/2023/10/18/snap-partners-edtech-company-inspirit-bring-ar-tech-50-us-schools/,Snap partners with edtech company Inspirit to bring its AR tech to 50 US schools,"Snap is partnering with edtech company Inspirit to bring augmented reality into classrooms to help students better understand STEM lessons, the company announced on Wednesday. The two companies are working together to create 25 AR Lenses and STEM curriculums that will be used by at least 50 across the United States next year.
One of the AR Lenses is designed to help students find the volume of a cylinder, while another gets users to tap on bubbles and choose the correct volume to pop them.
Snap says that since launching its pilot program, it found that 85% of students said AR helped with memory and retention. The company says it also found that AR lessons increased engagement by nearly 50%, and that 92% of students found AR content easy to understand.
“With custom-built Lenses brought into an easy to use mobile application with Camera Kit, Inspirit designed a transformative curriculum that pairs Snap’s AR technology with a comprehensive learning guide, empowering teachers to facilitate dynamic learning and students to achieve their best, whether they’re learning from the classroom or at home,” the company wrote in a blog post. “The curriculum is designed to stimulate classroom engagement, boost confidence levels, and improve students’ self-efficacy.”
Snap’s venture into AR for education comes a month after the company shut down its AR Enterprise Services division after less than a year of its launch. The initiative, which was announced in March, gave brands access to tools that allowed them to do things like access AR try-on features, a 3D viewer for looking at a product from multiple angles, fit and sizing recommendation technology and an enterprise manager for their digital assets. The company said that building up the initiative would take “significant” investment and it that couldn’t continue to fund those efforts.
Although Snap has seen declining revenue, the company’s shares rose nearly 12% yesterday after reports revealed than an internal memo said Snap could post better-than-expected results next year. The memo revealed that Snap could reach more than 475 million daily active users in 2024, beating analysts’ predictions of 448 million, according to a report from The Verge.
Snap is scheduled to release its Q3 2023 earnings results on October 24.","https://techcrunch.com/wp-content/uploads/2022/07/GettyImages-647104884.jpg?resize=1200,800",2023-10-18 12:00:48
https://techcrunch.com/2023/10/18/passwordless-authentication-startup-securew2-raises-80m-from-insight-partners/,Passwordless authentication startup SecureW2 raises $80M from Insight Partners,"Passwordless authentication offers a host of advantages over traditional pins, passphrases and passcodes. Surveys around the web show that compromised passwords cause an estimated 81% of all breaches and that the average person reuses passwords up to 14 times, giving hackers access to a big chunk of one’s digital footprint if they crack the code just once.
But despite the fact that it’s more secure, passwordless tech is running up against barriers to adoption — at least in the enterprise. A Harris Poll study found that 48% of companies didn’t have passwordless authentication as of 2021, in part because they believed that they lacked the right skills and teams to successfully implement it.
This is to the benefit of platforms like SecureW2, who’ve made a business out of abstracting away the steps required to deploy and maintain infrastructure for passwordless authentication. Case in point, SecureW2 this morning announced that it raised $80 million in funding from Insight Partners, SecureW2’s first-ever round.
Max Wolff, a principal at Insight Partners, which not long ago led a massive investment in passwordless security vendor Transmit Security, says that SecureW2’s customer momentum is what clinched the deal.
“Organizations are increasingly looking for alternatives to traditional passwords to authenticate access to networks and applications,” Wolff said via email. “SecureW2 provides an easy-to-use, cloud-native solution to address this need that’s already being used by hundreds of customers worldwide.”
SecureW2, based in Seattle, started as an open source project that allowed IT departments with “non-Windows” identity environments to connect Windows devices to their wired and wireless network infrastructure. The creators, Tom Rixom and Bert Kashyap, were spurred to launch the project by the growing frequency of password-based attacks — and, they say, by the unattractiveness of enterprise passwordless authentication solutions at the time.
“It became clear to us that there was a need for a fresh software-as-a-service-based and low-friction approach for IT teams,” Kashyap, SecureW2’s CEO, told TechCrunch in an email interview.
Rixom and Kashyap eventually incorporated SecureW2, which today offers a suite of passwordless technologies including a tool to issues certificates — digital replacements for passwords — to authorize access to a customer’s Wi-Fi, ethernet or VPN. SecureW2’s platform makes certificates available across most mobile and desktop operating systems, and can connect to cloud identity environments like Okta to extend policy-based security across a company’s environment.
“From business and government organizations to colleges and school districts, password-based connectivity to network infrastructure leads to potential disconnects due to password rotation procedures,” Kashyap said. “Eliminating user frustration and productivity loss drives direct return on investment along with the security benefits of ensuring those passwords that are used to also access other apps and resources aren’t susceptible to compromise.”
SecureW2, which has just under a thousand customers and “millions” of users, according to Kashyap, has been bootstrapped until now — and profitable with free cash flow. But it took on funding for two reasons: expanding its go-to-market efforts and ramping up software development and R&D in “product categories that surround SecureW2’s space,” Kashyap said.
“We’ve historically used machine learning to understand and predict how devices are connecting to infrastructure environments, and we have plans to expose some of these elements directly to the customer so that they may benefit from security anomaly detection, capacity planning and more,” Kashyap said. “As awareness grows of the need for a passwordless approach in both corporate environments and non-corporate infrastructure, we’re providing simple and cost-competitive solutions to drive adoption and growth.”
SecureW2 has 70 employees currently and expects to end the year with around 80.","https://techcrunch.com/wp-content/uploads/2023/05/GettyImages-1399729683-1.jpg?resize=1200,708",2023-10-18 12:00:21
https://techcrunch.com/2023/10/18/darwinium-brings-digital-security-and-fraud-prevention-to-the-edge/,Darwinium brings digital security and fraud prevention to the perimeter,"Back in 2018, LexisNexis acquired the digital identity platform ThreatMetrix for just under $820 million in cash. In 2021, ThreatMetrix co-founders Reed Taussig and Alisdair Faulkner returned to the world of startups when, together with a number of ex-ThreatMetrix engineers and execs Vic, they launched Darwinium, a fraud prevention platform that focuses on protecting fintech, e-commerce, financial services, gaming and gambling services at their digital perimeter without putting too much of a burden on users.
In late 2022, the company raised a $10 million seed round led by Australian VC firm Blackbird alongside Airtree. A number of prominent angel investors, including Naval Ravikant and Jeff Fagnan also participated in this round. Today, Darwinium announced that it has raised another $18 million in a Series A round led by U.S. venture partners, with participation from its existing investors.
“Fraud is just getting worse,” Faulkner explained. “There’s a lot of companies — ThreatMetrix among them — that are doing an admirable job. But fraud still is getting worse despite all of these tools. Merchants and banks are just deploying more and more and more [of these tools], but they’re all disconnected, they don’t share the same data model, and the result is increasing costs to try and stop the fraud, increasing friction for customers, and just more lost revenue over time. Then you throw in the potential of AI and it just suggests that things are going to get worse before they get better.”
Faulkner described Darwinium as ‘the self-driving car for digital security and fraud.” You can’t just build a defense, you actually have to build something that simulates the attack using generative AI models. People are looking at that in terms of images, deep fakes, and others. Darwinium is the first company that is pioneering this approach to be able to have not just defense but also simulating attacks and having those solutions duke it out” (I guess that’s AI security Darwinism at work…).
Faulkner argues that even the best bot detection tools today are still blunt tools that can’t understand customer behaviors — something that fraudsters can now leverage thanks to AI. For customers, that means more CAPTCHAs they have to solve before they can make a purchase, which isn’t a great user experience, all while fraud teams can’t be sure that bots aren’t making it past their perimeter.
In contrast, Darwinium aims to collect more signals at the perimeter — long before a customer (or bot) enters a credit card number, for example. Ideally, Darwinium can understand the behavioral context of a user journey and allow downstream tools — and fraud teams — to take more tailored action based on the company’s bot score.
One nifty aspect of Darwinium is that it places its service right there at the perimeter, too, integrating with content delivery networks like Cloudflare and AWS CloudFront. The service also integrates with other third-party tools to enrich its data.
“The Darwinium team has built something truly unique,” says Rick Lewis, General Partner at
USVP. “Darwinium offers a product that is both simple to deploy and effective at reducing fraud
losses and reputational damage associated with the ever-more complex web of digital fraud.
Darwinium is a game-changer, differentiated in a crowded market, offering the innovation that
businesses are asking for to simplify their risk stack.”","https://techcrunch.com/wp-content/uploads/2023/10/GettyImages-1310129244.jpg?resize=1200,646",2023-10-18 12:00:14
https://techcrunch.com/2023/10/18/peak-xv-invests-35-million-in-wealth-and-asset-management-startup-neo/,Peak XV invests $35 million in wealth and asset management startup Neo,"Peak XV Partners has invested $35 million in Neo, a fintech startup founded by industry veterans that is increasingly challenging incumbents including IIFL, Edelweiss and Waterfield Advisors, as the largest India-focused VC broadens its bets on wealth and asset management.
Neo operates a suite of wealth and asset management services, serving businesses, sovereign and pension funds and large family offices and individuals with ultra-high net-worths. The firm, which began operations in 2021, has already amassed over a 1,000 customers, said Neo founder Nitin Jain in an interview.
The two firms reserve the optionality to extend the size of the investment, they said. TechCrunch reported in August that Peak XV was engaging with Neo for an investment. Neo earlier raised about $40 million from a list of undisclosed investors.
Despite being second only to China in high-net-worth individuals among BRICS countries, and being home to more than 14,000 ultra high net-worth households, India’s wealth management sector remains underdeveloped, plagued by a trust deficit and misaligned incentives.
Part of the reason is that the industry is often more geared toward product sales than tailored financial advice, said Jain, who like many of his co-founders and other founding members of Neo started the venture after long stints at investment giant Edelweiss.
On the advisory side, Neo serves as an extended CIO to multi-family offices, participating in their investment committees and offering views on asset allocation, corporate holding structure and taxations.
“We sit on their side. It’s slightly different from the classical wealth management practice as we are advising as well as selling products to them. So this is a very unique proposition,” he said.
The startup works with multiple relationship managers, providing them with additional resources and incentives that supplement their existing practices. Jain said he estimates that 350 to 400 RMs in India control 70 to 75% of assets. Neo will aim to attract about 100 of them in the next two to three years, he said.
On the asset management side, Neo focuses on long-term yield-based solutions in real estate and private credit for clients that are looking to generate an income from their investments.
Neo already has about $3 billion of assets under management, it said. The startup didn’t need new capital and doesn’t anticipate raising more than one more round in the future, said Jain.
Sakshi Chopra, an MD at Peak XV Partners, said the firm had been tracking Jain’s journey for over a year and in Neo it found the right combination of experience, expertise and opportunity.
“The founding team, they built asset businesses at Nuvama and Edelweiss, is very high-quality and this is all they have done through their lives,” she said in an interview, adding that the two firms began engaging about 15 months ago. “We share the philosophy on doing good for the people who trust us with their money.”
Having Peak XV becoming a partner will help Neo recruit high-quality talent, said Jain, citing the venture firm’s strong reputation and brand image.
With the investment in Neo, Peak XV Partners is expanding its portfolio of startups that operate in the asset and wealth management category. The venture firm is also backer of CRED and Groww, though both are currently serving different sets of audiences.
And more players are gearing up to serve the market. Jio Financial Services — backed by Reliance Industries, run by Asia’s richest man Mukesh Ambani — in July said it had partnered with BlackRock to form an asset manager venture, called Jio BlackRock, that will aim to serve India’s growing investor base.","https://techcrunch.com/wp-content/uploads/2022/06/GettyImages-520120864.jpg?resize=1200,780",2023-10-18 11:33:16
https://techcrunch.com/2023/10/18/meta-consolidates-options-to-manage-your-meta-data/,Meta consolidates options to manage your Meta data,"Meta is rolling out new options to better manage your data related to its own platforms such as Instagram and Facebook.
The company now has a single place in the Accounts Center for you to request a download of your information on Instagram and Facebook at the same time. Users can also choose to download a copy of their information from one of the social networks.
The company already offered users control over off-site activities on Facebook. That means users could change the way other apps sent data back to Facebook about them. Now, the social network is a combination of off-Meta information for both Facebook and Instagram. This hub will let you disconnect your account from services where you have used Facebook or Instagram login as well. You can also see what sites are collecting your Instagram information.
Additionally, Meta is expanding the ‘Transfer Your Information’ option to Instagram. That means you can easily export your Instagram photos and videos and import them into another service such as Google Photos. This could be related to recent regulatory changes in Europe as the Digital Services Act requires big platforms to provide tools to export user data.
Meta said that users will be able to find all these options in the Accounts Center. Earlier this year, the company rolled out a revamped Accounts Center by placing settings for personal details, passwords, security options, and ad preferences in one location.","https://techcrunch.com/wp-content/uploads/2021/11/facebook-meta-rotate-pattern.jpg?resize=1200,675",2023-10-18 11:13:09
https://techcrunch.com/2023/10/18/objective-emerges-from-stealth-to-deliver-multimodal-search-to-developers-as-an-api-platform/,Objective emerges from stealth to deliver multimodal search to developers as an API platform,"Objective emerges from stealth to deliver multimodal search to developers as an API platform
Objective (previously named Kailua Labs), a multimodal search platform built by machine learning experts from Apple, Google, Meta, Amazon and Twilio, emerged from stealth today with $13 million in venture funding.
Objective is a low-code platform that allows developers to build multi-search apps that handle input and output in multiple formats– text, images, video and audio. Unlike traditional keyword-based search algorithms, Objective’s in-house technology produces contextually relevant results, allowing users to search using natural language or even a combination of data like simultaneously entering image and text queries. As users interact and search different terms, the system further learns how to optimize for the types of user behavior that it sees.
Multimodal search has been a topic of conversation among technology companies for years. In the same way that OpenAI’s ChatGPT-4 has brought generative AI to the mainstream, tech giants Google and Microsoft are influencing more and more companies to invest in multimodal large language models in order to improve the search and discovery experience.
Objective aims to be the go-to affordable solution for all developers to have multimodal search in their toolkits.
“The way the systems are built is super difficult,” Co-founder and CEO Pablo Mendes said during our interview. “Every top 1% most sophisticated company is working on that. We have this hypothesis that most companies in the world would prefer to buy a solution rather than try to build a team in-house… We’re building a platform to make it easy and level the playing field.”
Objective was co-founded by three ex-Apple employees – Mendes, Joachim Daiber and Lance Hasson — who worked in the AI machine learning division and were responsible for general knowledge queries for Siri.
“We saw this huge movement happening around machine learning,” Mendes added. “We knew that this was going to change the way that everybody will approach search.”
Objective has raised $13 million across multiple funding rounds. It’s backed by Matrix Partners, Two Sigma Ventures and angel investors such as Topsy co-founder Vipul Ved Prakash, Lattice co-founder Mike Cafarella and former director at Airbnb Georg Bauser, among others.
“Here’s a team who’ve built search for iOS, YouTube – some of the most loved products in history – and every developer in the world can leverage their experience with just a few lines of code,” said Patrick Malatack, partner at Matrix, in a statement.
Nearly a dozen launch partners are using Objective Search, including food distribution company Pod Foods, digital designer’s platform Dribbble and major news publication The Information.
“You can only do so much with manual tagging and scrubbing of results,” said Zack Onisko, CEO of Dribbble. “Implementing semantic search in-house was taking very long. We saw a demo of Objective Search and it was night and day! This partnership will significantly accelerate our data science roadmap.”
Developers can schedule a demo with Objective today. Pricing depends on the company size, how much data they have and how many queries they get, among other factors.","https://techcrunch.com/wp-content/uploads/2023/10/Objective-inc-founders.jpg?resize=1200,911",2023-10-18 11:00:48
https://techcrunch.com/2023/10/18/openai-formally-brings-bing-powered-search-to-chatgpt-as-dall-e-3-arrives-in-beta/,ChatGPT officially gets web search as DALL-E 3 integration arrives in beta,"OpenAI has formally launched its internet-browsing feature to ChatGPT, some three weeks after re-introducing the feature in beta after several months in hiatus.
ChatGPT, the generative AI chatbot that has taken the world by storm these past 12 months, has historically been limited to data up to September, 2021 — rendering it useless as a real-time search engine. However, OpenAI started bringing internet services to ChatGPT back in March, a move that always came with inherent risks, given that the live web isn’t curated in the same way a static training data set is — this potentially opened the doors to abuse by bad actors and good old-fashioned algorithmic chaos.
Then in May, OpenAI started rolling out web search via Bing, the search engine belonging to OpenAI’s corporate backer Microsoft, before extending access to the ChatGPT mobile app in late June. However, the new feature was swiftly pulled after it was discovered that ChatGPT was capable of displaying paywalled content.
Fast-forward to late September, and OpenAI started rolling the Browse with Bing feature out again, having fine-tuned how ChatGPT follows instructions laid out by content owners — essentially, it now promised to adhere to whatever a site-owner said in its Robots.txt file, similar to traditional web crawlers.
Now, Browse with Bing is officially available to all Plus and Enterprise subscribers, with no need to toggle their beta switch in settings.
In related news, OpenAI also transitioned DALL-E 3 into beta, a month after debuting the latest incarnation of the text-to-image generator.
DALL-E 3 sports integration with ChatGPT, meaning that users don’t have to think so carefully about their text-prompts when asking DALL-E to create an image — ChatGPT can do a lot of the heavylifting to ensure that the image the user gets, is closer to what they want.
But more than that, with DALL-E 3 embedded directly into ChatGPT, users will now be able to receive images as part of their text-based queries without having to switch between apps.
DALL-E 3 is available in beta now on the web and mobile, with users able to activate the feature by selecting “DALL-E 3 (Beta)” from the GPT-4 tab inside ChatGPT.
Vocal range
This all constitutes part of a broader expansion that is leading ChatGPT farther from a pure text-based generator, and down a path where audio and visuals are very much part of its remit.
Last month, OpenAI gave ChatGPT a mouth and ears with users able to have a verbal conversation with the chatbot, bringing together the worlds of Alexa-style voice assistants with powerful large language models (LLMs). For example, a user will be able to ask ChatGPT to create and narrate a bedtime story for their kid on the spot, though it’s maybe worth being on hand to see what it comes up with.
Additionally, ChatGPT will also allow users to search for answers using images, meaning that someone can upload a picture of an object and discover what it is or find similar items.
So today’s news very much fits into OpenAI’s push to make ChatGPT a fully integrated, real-time, multimedia generative search engine.","https://techcrunch.com/wp-content/uploads/2023/09/GettyImages-1647521480-e1694685235777.jpg?resize=1200,676",2023-10-18 10:32:40
https://techcrunch.com/2023/10/17/zygon-helps-startups-avoid-data-breaches-from-saas-providers/,Zygon helps startups avoid data breaches from SaaS providers,"Last week, cloud computing company Shadow confirmed a data breach involving customers’ personal information. The hacker claims to have access to the data of more than 530,000 customers. According to an email from Shadow CEO Eric Sèle, the hacker managed to download this data from a software-as-a-service (SaaS) provider’s API. This is just a recent example in a long list of data breaches that have affected companies of all sizes.
And if you’re a tech CEO, you probably don’t want to be in that position. In the current regulatory landscape, you often have to notify privacy watchdogs and navigate regulatory obligations. More importantly, you risk losing the trust of your clients when you notify them of the breach.
That’s the reason why Zygon caught my attention. This new French startup reviews all the SaaS applications used by your team — and it doesn’t just focus on official services as it can identify shadow SaaS services that some teams have been quietly using without telling the IT department.
At first, I thought Zygon could be particularly useful as a cost saving service. As many VC firms are still passing on deals that would have made sense a few years ago, some startups are actively reviewing their SaaS contracts to see if they can cancel a few subscriptions and extend their runway.
But the startup wants to go beyond this initial usage and build a security startup for your SaaS services. Zygon recently raised a $3 million seed round with Axeleo Capital leading the round, Kima Ventures and several business angels also participating.
Visibility on shadow IT
After the initial inventory process, Zygon customers get a dashboard with all the SaaS applications with the number of users per application.
“We are using the metadata of employee emails, we go through the entire email history and detect those that are related to a SaaS usage,” Zygon co-founder and Chief Product Officer Kevin Smouts told me.
For SaaS applications that are connected to the official identity management solution, such as Okta, Zygon isn’t going to be particularly useful. But some SaaS startups have been particularly successful in recent years because it takes just a few minutes to create an account and get started.
They are taking advantage of that by promoting bottom-up adoption with freemium plans, self-service usage and virality features. Dropbox, Zoom or Notion are popular examples of this trend.
And SaaS sprawl creates three different issues for businesses — security, legal and costs.
Instead of building integration with every single SaaS product on earth, Zygon is using the same approach and decentralizing security across the organization. Zygon encourages you to designate SaaS admins. From now on, they are in charge of the usage of a specific tool in the organization.
They get recommendations when it comes to security configuration tasks, multi-factor authentication and more. For popular application, IT departments can take over as admins, prioritize the rollout of SSO authentication to control account orchestration and more.
More generally speaking, Zygon brings some sort of control over SaaS usage. If someone has multiple accounts for the same service, Zygon can flag that. If several employees are sharing an account, Zygon can also identify that. And if a company wants to comply with SOC 2 and ISO frameworks, Zygon can mitigate risks by minimizing the attack surface.
Zygon can be particularly useful when someone quits or when there is a wave of layoffs. It can list services that are still active even after an employee has left the company.
“In the current situation, IT is only in control of a very small number of SaaS applications. And most accounts remain active for a very long time after employees’ departures — in the current context of layoffs, these are gaping security holes. We go further by detecting which SaaS applications have APIs or access keys that also need to be ‘rotated’ in the event of an employee departure,” Smouts said.","https://techcrunch.com/wp-content/uploads/2023/10/GettyImages-597318809.jpg?resize=1200,1081",2023-10-18 06:30:00
https://www.innovationnewsnetwork.com/hardt-and-zeleros-sign-mou-to-european-hyperloop-deployment/38417/,Hardt and Zeleros sign MoU to European hyperloop deployment,"Leading hyperloop innovators Hardt, from the Netherlands and Zeleros, from Spain, have signed a Memorandum of Understanding (MoU) to expedite the technical and commercial development of hyperloop.
The two leading hyperloop pioneers will work closely on a shared development roadmap to ensure their technologies are fully compatible across borders – overcoming an issue that plagues traditional transport, such as rail.
This synergistic approach to development is hoped to accelerate the deployment of the technology significantly, with both companies targeting 2030 for an operational pilot route.
David Pistoni, CEO of Zeleros, commented: “Together, we are able to multiply our impact to speed up the process of hyperloop commercialisation.
“We consider this as a first step of collaboration where others can add to further consolidate the industry.”
What is hyperloop?
Hyperloop is an ultra-high-speed, low-emission, fully autonomous mode of land transportation that promises to not only decarbonise passenger and cargo travel but also slash journey times significantly across Europe.
Capable of speeds of over 800km/h, in the hyperloop, vehicles are guided through a low-pressure system of tubes and are propelled, suspended, and guided with magnets.
This process drastically reduces rolling and aerodynamic friction, which reduces energy requirements. For example, hyperloop is ten times more energy efficient than road transport and aviation and uses 50% less energy than traditional rail.
The combined effects of this almost sci-fi-inspired transportation are astounding; it is estimated that trips across Europe that would once take up to six hours will be a mere fraction of that.
For example, hyperloop journeys from Munich to Milan or from Berlin to Warsaw would take just over an hour.
Now, the new MoU signed between Hardt and Zeleros looks to accelerate the technology considerably to make journeys between Europe’s major cities faster, cleaner, and more efficient than ever.
What will the collaboration involve?
Hardt and Zeleros will work together on the demonstration, de-risking, and implementation of the technology, with the development of an interoperable system to allow seamless transport across borders as the main priority.
Such technologies are currently under development in the Netherlands and Spain, with pilot projects at the European Hyperloop Center, Groningen, and the HyperTrack, Valencia.
By 2030, the companies are targeting an operational pilot route and are preparing for large-scale deployment whilst working to establish an open, accessible, and competitive hyperloop ecosystem throughout Europe.
Mars Geuze, co-founder and Chief Hyperloop Officer of Hardt Hyperloop, said: “The signing of this MoU with Zeleros is a great sign of collaboration and convergence within the hyperloop developments.
“Instead of competing, we are collaborating to make the hyperloop a reality in Europe and beyond.”
Innovation News Network will be publishing our experience of an exclusive visit to Hardt Hyperloop to provide a more in-depth look at the groundbreaking transport modality.",https://www.innovationnewsnetwork.com/wp-content/uploads/2023/10/MoUZeleros1.jpeg,2023-10-18 13:43:08
https://www.innovationnewsnetwork.com/unlocking-space-for-business-set-benefit-organisations-around-uk/38411/,Unlocking Space for Business set to benefit organisations around the UK,"The UK Space Agency has launched the Unlocking Space for Business programme to help organisations take advantages of satellite data and services.
Unlocking Space for Business is an 18-month programme that will bring the benefits of satellite data and services to hundreds of new organisations across the UK. The programme primarily focuses on the leading transport, logistics, and financial services sectors.
The programme will offer the opportunity to bid for a share of up to £6m UK Space Agency funding later this year to help launch pilot projects, data procurement, and partnerships.
As well as this, Unlocking Space for Business will provide workshops, networking events, learning and development opportunities, and online resources to support companies in their understanding of what satellite data can do for them.
Dr Paul Bate, Chief Executive of the UK Space Agency, said: “Unlocking Space for Business will champion the use of space and help tackle barriers facing organisations that have not traditionally used satellite data or services.
“This will help catalyse further investment into our growing space sector and deliver greater benefits for businesses, people, and the environment.”
Harnessing the advantages offered by satellites
Global satellite services support activity that contributes £370bn to the UK economy. This is around 17.7% of the GDP.
A large number of businesses have the opportunity to harness the advantages offered by satellites, due to the cost of accessing space falling and the pace of innovation increasing. The advantages include enhanced imagery, connectivity, and navigation capabilities.
Specifically, satellite imagery can be used to improve the measurement of climate variables and verification of customer insurance claims after extreme weather events. Satellite position and navigation can also be utilised to support location tracking.
Passengers and crews can use satellite connectivity to stay in touch with operators on shore.
George Freeman MP, Minister of State at the Department for Science, Innovation and Technology, said: “With UK space open for business like never before, sectors as diverse as transport and finance have a huge opportunity to bring the benefits of satellite data down to Earth and improve their operations, deliver for customers and ultimately grow their industries.”
Satellite data can unlock and deliver new revenue growth opportunities, operational efficiencies, ESG benefits, and improved customer experiences for businesses.
About the Unlocking Space for Business programme
Unlocking Space for Business is set to connect leading data suppliers, technology integrators, insight providers, and end-users with innovative solutions using satellite data and services.
PwC is supporting the delivery of the project.
Organisations can get involved with the Unlocking Space for Business programme and keep up to date with planned activities ahead of the funding call opening later in the year.
Unlocking Space for Business is part of the UK Space Agency’s Inspiration Programme, delivering the National Space Strategy goal.
Lucy Edge, Chief Operating Officer and Acting CEO at the Satellite Applications Catapult, said: “We’re excited to launch Unlocking Space for Business today.
“By bringing together key players in the satellite industry, integrators and end users, we’ll make it easier for businesses to access the business-critical data they did not even know was available to them.
“We’ll also connect companies with government funding sources to test out pilot projects using satellite tech.”",https://www.innovationnewsnetwork.com/wp-content/uploads/2023/10/©-shutterstockgreenbutterfly_1421446100-1024x576.jpg,2023-10-18 13:37:49
https://www.innovationnewsnetwork.com/barriers-to-solar-energy-transition-identified-researchers/38395/,Barriers to solar energy transition identified by researchers,"In a study led by the University of Exeter and University College London, researchers have found four barriers to solar energy that must be resolved by the government.
The four barriers to solar energy are the creation of stable power grids, financing solar in developing economies, capacity of supply chains, and political resistance from regions that lose jobs.
Policies to resolve these barriers are thought to be more effective than price instruments such as carbon taxes in accelerating the clean energy transition.
The study, ‘The momentum of the solar energy transition,’ is part of the Economics of Energy Innovation and System Transition project, funded by the UK Government’s Department for Energy Security and Net Zero and the Children’s Investment Fund Foundation (CIFF).
Solar PV is set to become the dominant power source
Based on a data-driven model of technology and economics, the study found that solar PV is expected to dominate the global power mix before 2050.
Solar energy is projected to become our main energy source, even without support from more ambitious climate policies.
Dr Femke Nijsse, from Exeter’s Global Systems Institute, said: “The recent progress of renewables means that fossil fuel-dominated projections are no longer realistic.
“In other words, we have avoided the ‘business as usual’ scenario for the power sector.
“However, older projections often rely on models that see innovation as something happening outside of the economy.
“In reality, there is a virtuous cycle between technologies being deployed and companies learning to do so more cheaply.
“When you include this cycle in projections, you can represent the rapid growth of solar in the past decade and into the future.
“Traditional models also tend to assume the ‘end of learning’ at some point in the near future – when in fact we are still seeing very rapid innovation in solar technology.
“Using three models that track positive feedbacks, we project that solar PV will dominate the global energy mix by the middle of this century.”
Four barriers to solar energy
However, energy systems dominated by solar energy could become “locked into configurations that are neither resilient nor sustainable, with a reliance on fossil fuel for dispatchable power.”
The government must therefore overcome the barriers to solar energy, rather than trying to bring about the solar transition in itself. These key barriers are:
Grid resilience
Solar generation is variable so processes must be put into place to deal with the variability. To build resilience instead of burning fossil fuels, the government could invest in other renewables, transmission cables linking different regions, and electricity storage and policy to manage demand.
The study stated that government subsidies and funding for research and development are important for initially creating grid resilience.
Access to finance
Another barrier to the solar energy transition is the availability of finance. Currently, low-carbon finance is concentrated in high-income countries.
International funding favours middle-income countries, leaving low-income countries deficient in solar finance despite the huge potential for investment.
Critical minerals supply chains
The solar energy transition requires many critical minerals, causing demand to increase.
It is estimated that renewable technologies will make up 40% of total mineral demand for copper and rare earth elements, between 60 and 70% for nickel and cobalt, and around 90% for lithium by 2040.
Securing a sustainable supply chain of these materials is a major challenge.
Political opposition
The final barrier to solar energy is resistance from declining industries. The pace of the solar energy transition depends on both the economic decisions of entrepreneurs and how desirable policymakers consider it.
If the solar energy transition is to accelerate quickly, the livelihood of around 13 million people working in fossil fuel industries globally may be put at risk.
Regional economic and industrial development policies can mitigate risks posed by resistance from declining industries.
These four barriers must be overcome to facilitate the solar energy transition, and to ensure that net zero goals are met.",https://www.innovationnewsnetwork.com/wp-content/uploads/2023/10/shutterstockKampan_1614874936.jpg,2023-10-18 09:58:17
https://www.innovationnewsnetwork.com/urgent-action-is-needed-to-tackle-the-plastic-recycling-postcode-lottery/36152/,Urgent action is needed to tackle the plastic recycling ‘postcode lottery’,"The University of Manchester ‘One Bin to Rule Them All’ project team outline how implementing a new plastic recycling system in the UK could improve participation rates.
Our ineffectiveness at recycling plastic packaging waste is causing a significant environmental problem.
Of the 2.5 million tonnes of plastic waste generated in the UK in 2021, just 44% was recycled and over 60% was sent abroad, exporting the problem of plastic waste to countries that often do not have the ability to re-use or dispose of this waste sustainably.
Recent years have seen consumers bombarded with campaigns promoting the importance of recycling, in an attempt drive up participation rates. However, whilst the intention and effort of such policies are welcome, they have had little success.
And, as shown in a new report written by The University of Manchester’s ‘One Bin to Rule Them All‘ project team – which involves a cross-sector consortium of 25 industry partners and local authorities – the blame does not in fact lie with consumers, but with the convoluted nature of the recycling system.
Trialling a ‘one bin for all plastics’ system
Our research involved trialling a ‘one bin for all plastics’ system, which saw 30 households get a separate bin for all of their plastic waste for a two-week period.
This allowed the project team to explore how consumers engage with recycling, and showed that the blame levelled against households for poor quality recycling is largely misplaced.
Indeed, most households are eager to do the right thing, with numerous respondents demonstrating a willingness to go above and beyond to correctly dispose of their plastic.
So, what needs to change to make sure their efforts don’t go to waste?
Low recycling rates are driven by confusion over rules
The research found that the key driver of low recycling rates is confusion over rules as to what can and can’t be thrown away – and with an estimated 39 differing bin regimes currently in place across the UK, as well as 3,500 waste recycling plants with varying capabilities in infrastructure, it’s understandable why.
Described as a ‘postcode lottery’, this siloed and fragmented system has caused a lack of clarity over correct procedure, whilst the inability of some local authorities to process certain plastics holds back consumers from recycling what may be possible to recycle elsewhere.
Introducing a standardised approach to plastic recycling
A first step in tackling this would involve the adoption of a standardised approach to plastic recycling, to allow for a consistent method of waste management across the country.
Two years ago, the government outlined plans to do just that, by introducing nationwide consistency in recycling standards by October this year. However, in a new ‘waste prevention programme’ published in July, officials quietly confirmed that consistent recycling collections would be delayed until late 2025.
This is a huge blow. Introducing recycling consistency could create a platform on which the government can begin to effectively deliver the transition towards a circular economy of plastic waste, and these plans should be prioritised rather than kicked further down the road.
Crucially, it is worth noting that the onus does not lie solely on government or local authorities. Consistency in collection can only be truly effective if packaging designers and plastic producers adopt a large-scale, standardised approach to manufacturing.
Multi-material packaging is much harder to recycle
The 30 households involved in the ‘One Bin’ project trial disposed of a total of 5,800 pieces of plastic over the two-week trial period. Of this total, nearly half of the items collected consisted of multi-material packaging.
Made up of a combination of materials, these are much harder to recycle, with their inconsistency in composition meaning that a lot more plastic ends up in the general bin instead of being collected for reuse.
Maximising the recycling of such materials will involve simplifying their design and disposal. In this regard, delivering any real change would require broad adoption across sectors. This may take some time to co-ordinate, but it would pay dividends by increasing the amount of high-quality recycled plastic that can be used in packaging moving forward.
The research shows the willingness for change amongst consumers, but we need to ensure the infrastructure is in place to support this. The issue can no longer be ignored if the UK is to truly achieve its sustainability goals.
The University of Manchester’s ‘One Bin to Rule Them All’ project team
Dr Helen Holmes, Dr Maria Sharmina, Professor Michael Shaver, Dr Adeyemi Adelekan, Dr Kristoffer Kortsen, and Dr Torik Holmes.
Please note, this article will also appear in the fifteenth edition of our quarterly publication.",https://www.innovationnewsnetwork.com/wp-content/uploads/2023/08/shutterstockStokkete_2149480407.jpg,2023-10-18 09:00:18
https://www.innovationnewsnetwork.com/developing-responsible-sources-of-magnet-metals-at-the-monte-muambe-project/38352/,Developing responsible magnet metals at the Monte Muambe project,"Altona Rare Earths tell us about the state of magnet metals and provides an update on their Monte Muambe project.
Rare earths are a group of 17 chemical elements. Each of these elements has its own properties, uses, and prices. Among other uses, four elements – neodymium, praseodymium, terbium, and dysprosium, collectively known as the ‘magnet metals’ – are necessary for the manufacturing of high-performance permanent magnets.
By volume, permanent magnets represent about 50% of the world’s rare earth consumption. By value, they represent more than 95%.
Ryan Castilloux, the founder of Adamas Intelligence, recently revealed that nine out of ten electric vehicles (EV) deployed during September 2023 were permanent magnet synchronous motors or magnet-assisted synchronous reluctant motors. Both types contain rare earth magnets.
The same company forecasts that the current supply deficit of neodymium-praseodymium oxide will grow from a few thousand tons currently to 90,000 tons per year by 2040.
Magnet metals are already an essential raw material for many industrial and high-technology applications. They are critical to the decarbonisation of the world’s energy sources through the production of EV drive trains and wind turbines. While alternatives exist, these have drawbacks in terms of performance and cost that make them second choices.
The share of EV and wind turbines in the consumption of magnet metals is set to grow during the next decades, driven by the green energy transition and policy changes aimed at implementing it.
Altona Rare Earths’ acquisition strategy
Altona Rare Earths is a British mineral resources exploration and development company specialised in rare earths and focussed on Africa. The company joined the Main Market of the London Stock Exchange on 9 June 2023.
Altona Rare Earths started to implement its rare earths project acquisition strategy in early 2020 and reviewed different projects in various African jurisdictions, applying its strict selection criteria.
In 2021, the company settled on the Monte Muambe carbonatite-hosted rare earths deposit, located in the Tete Province in the Northwest part of Mozambique. The project now has a maiden JORC Mineral Resource Estimate published, and a Scoping Study will soon be completed.
Taking advantage of its position in Africa, its networks, and its knowledge of the African continent’s geology, Altona Rare Earths continues to assess new potential project acquisition opportunities and expects to add at least one other rare earths project to its portfolio over the next year.
Africa’s geological history
The African continent has a long and complex geological history, which has been favourable to the development of rare earth deposits over time. The crustal abundance of rare earths is of the same order of magnitude as that of metals such as copper, vanadium, and lead.
However, economically viable concentrations are rare, and they are found in very different geological environments.
The main sources of rare earths are carbonatites, ionic clay deposits, and heavy mineral sands. The grade of rare earth deposits is expressed as total rare earth oxide (TREO), either as a percentage or in parts per million (ppm).
Ionic clay deposits typically have a low grade, usually ranging from 500 to 2,000 ppm TREO (0.05 to 0.2% TREO), which is compensated for by lower development and exploitation costs, and they can be exploited on a small scale. Carbonatite deposits such as Monte Muambe have higher grades, typically ranging from 1-10% TREO, but have higher development and exploitation costs.
Assessing a rare earths project is difficult
Rare earth projects are relatively new to the mining industry. Production currently originates mostly from a few carbonatite mines in China, one in Australia, and one in the United States, as well as a flurry of small-scale ionic clay deposits in Southeast China and neighbouring countries.
Therefore, when benchmarking a rare earths project, it is difficult to compare with existing operations, and comparisons are more easily made with advanced projects at the definitive feasibility study stage.
However, the complexity of rare earth deposits is such that every deposit is different in terms of geology, mineralogy, metallurgy, and costs. Therefore, comparisons also have their limitations.
While assessing a rare earths project, it is also important to distinguish between mineral resources, which represent the quantity of minerals contained in the ground, from ore reserves, which show the quantity of minerals viably extractable, as demonstrated in a feasibility study.
For example, mineral resource statements for carbonatite rare earth deposits can reach several hundreds of millions of tons, but the ore reserve statements for such projects rarely exceed 30 million tons.
An update on the Monte Muambe project
Since 2021, Altona Rare Earths has carried out several drilling campaigns at Monte Muambe, as well as soil sampling and ground geophysical surveys. Over 100 boreholes have been drilled for a total of more than 7,800m. This focused exploration work has allowed the company to discover and define two significant orebodies, referred to as Target 1 and Target 4.
On 25 September 2023, Altona Rare Earths announced its maiden JORC Mineral Resource Estimate for the Monte Muambe project, totalling 13.6 million tons at 2.42% TREO. This includes 45,000 tons of Magnet Metals oxides. This result provides a solid base for a mining project, and the tonnage is expected to increase through additional drilling during the pre-feasibility study without reducing the grade.
Importantly, about 58% of the resource’s tonnage belongs to the Indicated category (the rest being inferred), which demonstrates a high level of confidence in the resource figures. This is in line with the company’s strategy to avoid ‘drilling for numbers’ and rather to focus on defining the mineral resources that can be converted into an ore reserve and ultimately into a mining operation, from the onset.
So far, the Monte Muambe project ticks all the boxes of a low strip ratio open-pit mining operation.
Altona Rare Earths is now about to publish a scoping study, which will give a first pass test of economic viability for the project. The completion of this important milestone will allow Altona Rare Earths to increase its holding of the project to 51%, thus further de-risking the project for its shareholders.
The new challenges of the supply chain
While about 40% of rare earths mining is done outside of China, this country clearly dominates the supply chain, with over 90% of the separation, refining, and conversion of oxide to metal and magnet manufacturing being done in China. The country has heavily invested over the past 30 years, both domestically and abroad, to create this dominance. This has created a situation of dependence on China for other nations, not just for the supply of permanent magnets and EVs but also for critical high-technology applications such as within the communications and defence industries.
Western countries have recently started to recognise this situation and its associated risks, and are reacting by putting in place policies to develop domestic, or at least China-independent, supply chains for rare earths and other critical minerals. Rare earth processing facilities are starting to appear outside of China and will reduce the reliance on China. These changes will take time but will happen. They will, in our opinion, ultimately lead to the integration of Chinese and non-Chinese supply chains rather than their separation and to a more balanced market with more stable rare earths prices.
However, developing rare earth mines in the West, such as Europe, is proving to be a lot more difficult. This is because there are not many mineable rare earth deposits in Europe and also because the regulatory and social environment in Europe has, over time, become very adverse to mining.
The role of African, Asian, and South American countries hosting rare earths and other critical mineral resources will become essential to ensuring supplies of rare earths to both Chinese and non-Chinese markets. Africa has a long history of producing raw minerals, which have been exported to be processed and transformed in other countries. There is a strong sentiment in Africa that this must stop. Several countries have put in place bans on raw mineral products exports.
It is essential for mineral project developers to take this changing environment into consideration and integrate in-country value addition as much as possible. This is best done by starting to assess opportunities for value addition at an early stage in the life of projects rather than when reaching the final stages of the feasibility studies.
However, ultimately, the viability of a project depends on whether it can be economically implemented or not. African Governments therefore have a duty to put in place favourable conditions and lift obstacles to such value addition projects.
Another important angle in the developing rare earths supply chains is that of responsible sourcing. Western supply chains typically want to be able to guarantee to their customers, especially the end consumers, that the raw materials used to manufacture products have been extracted with no harm to people or the environment.
Responsible sourcing systems have previously been put in place, with more-or-less success, for minerals such as diamond or columbo-tantalite. Responsible sourcing is bound to become a topic of major importance in the development of critical minerals supply chains. Large and well-managed rare earth projects such as Monte Muambe can be certified and audited by responsible sourcing organisations, contrary to Southeast China artisan ionic clay operations, which are very environmentally destructive.
The outlook for 2024 at Monte Muambe
Buoyed by a rare earths market with solid long-term fundamentals and highly encouraging exploration results at Monte Muambe, including the recently published mineral resource estimate, Altona Rare Earths looks forward to a busy 2024 with the preparation of a pre-feasibility study for Monte Muambe.
A lot of emphasis will be put on the metallurgy part of the project and fine-tuning the process flow chart.
The increase of the company’s holding in the project to 51%, as well as securing a mining concession, are also important milestones that will happen during this time frame and will contribute greatly to de-risking Monte Muambe.
Please note, this article will also appear in the sixteenth edition of our quarterly publication.
Go to this partner's profile page to learn more about them",https://www.innovationnewsnetwork.com/wp-content/uploads/2023/10/ALTONAR1-28277-Monte-Muambe-from-the-Air-June-23.jpg,2023-10-18 08:00:24
https://www.innovationnewsnetwork.com/navigating-turbulent-waters-modern-cyber-security-threats/38374/,Navigating the turbulent waters of modern cyber security threats,"Kamal Srinivasan, SVP of Product and Program Management at Parallels (part of Alludo), explains that technological advances require new approaches to dealing with cyber security threats.
“The only constant in life is change.” I’m very sure that when Heraclitus said this, he was not referring to the ever-changing cyber security landscape. But had he been, he would have been spot on. In the rapidly evolving technological realm of cyber security, the conventional approach to addressing cyber security threats that businesses face is no longer sufficient.
With the increased reliance upon technology to help businesses meet their internal and external goals, there is a necessity for a more robust and adaptive approach towards cyber security.
According to a recent survey by Alludo – in partnership with Qualtrics, featuring nearly 500 IT professionals, eight out of ten respondents stated that security is a top priority. Even still, with this increased importance placed upon cyber security, there were more than 79 million breached records in August alone.
It’s clear to see that the desire is there from companies to attack cyber security threats head-on, yet still, it wouldn’t be out of the ordinary to wonder why many cyber security breaches take place.
Technology is evolving faster than ever before
From cloud computing to Artificial Intelligence, the recent developments made in technology have led businesses from numerous sectors to implement new technologies to improve all aspects of business operations and customer satisfaction.
However, whilst doing this, reaping the benefits and capabilities of these technological advancements, they also at times inadvertently leave themselves exposed to cyber security threats.
An increased demand from both customers and employees for a more contactless on-demand experience has led businesses to invest in technology to meet both parties’ desires. At an ever-growing rate, cloud computing is being adopted to make data more readily available when customers and employees desire it.
41.4% of IT leaders reported that they were increasing their use of the cloud. A further 32.8% announced they were migrating on-premises workloads to the cloud.
This sudden shift to the cloud has undeniably improved operations for businesses from a productivity, flexibility, and collaborative standpoint.
Nevertheless, it has also left behind traditional security enterprise controls, rooted in the firewall-centric approach, making it increasingly more apparent that such and often used cyber security approaches can’t keep up with the new dynamic landscape.
There is no denying that in the future, the cloud will become more prominent in the way that businesses operate. Although IT decision-makers from businesses may be reluctant to do so, it is time to let go of the old and outdated cyber security measures and put in place newer approaches such as the Zero-Trust Architecture (ZTA). This approach operates under the principles that all entities are untrusted by default, least privileged access is enforced, and comprehensive security monitoring is implemented as is a core foundational requirement of secure remote access.
A ZTA approach challenges traditional thought processes and ways of working by assuming ‘trust in good, but control is better.’ This means that no user or system should be inherently trusted, no matter their location within or outside the network. Addressing the limitations of traditional enterprise controls and extending protective measures beyond the typical boundaries.
Double trouble: Tackling dual cyber security threats in a connected world
If the last few years have shown business leaders and IT decision-makers anything it’s that the future is unpredictable. Take the most conventional form of working now. No one would have thought that 47% of all workers would be hybrid and a further 11% were fully remote before the pandemic. But that’s where we currently find ourselves today.
The increase in employees working from both a hybrid and remote capacity though has had positives, it has also increased the chances of businesses falling victim to cyber security threats from a dual perspective. It shouldn’t be a surprise that with all the potential security threats out there such as phishing attacks, organisations plan to increase their security expenditures. 78% of IT leaders reported that they planned to up their security budgets either moderately or significantly in the coming year.
As all professional sectors increasingly become interconnected and work no longer has to be confined specifically to one place, it wouldn’t be a surprise if mobile devices and cloud computing become integral components of business operations. If they’re not already.
Bearing all of this in mind, businesses must invest in the necessary technologies such as remote application servers and remote browser isolation to deal with both external cyber security threats whilst employees work away from home.
In tandem with implementing the necessary technology, businesses should also implement a culture where all decisions by employees relating to data take into consideration the cyber security risks. Having principles as such whilst leveraging the right technology, gives businesses the best chance of not falling victim to cyber attacks.
The battle in the landscape will be continuous
According to IT professionals, the top three external threats to sensitive data in their organisations were malware and ransomware attacks (64%), cloud vulnerabilities (42%), and phishing attacks (38%). This isn’t a surprise considering the fact the dependability that has been placed on certain technologies such as the cloud.
But with the increased developments in other areas within the technological landscape, such as in AI, it wouldn’t be surprising if new avenues and loopholes arise for cyber attacks to take place.
So even though 59% of IT leaders have not experienced a security breach, organisations should not rest on their laurels. In today’s reality of hybrid and remote work, along with technological developments means that organisations must be forever alert and take a holistic approach to cyber security to adapt to the ever-changing landscape.",https://www.innovationnewsnetwork.com/wp-content/uploads/2023/10/shutterstockGorodenkoff_2136788157.jpg,2023-10-18 07:52:54
https://www.innovationnewsnetwork.com/digibuild-project-high-quality-data-driven-services-digital-built-environment/36291/,DigiBUILD Project: High-quality data-driven services for a digital built environment,"The DigiBUILD Project combines Big Data and Artificial Intelligence tools with the aim of making the EU’s building stock climate neutral.
It might sound shocking to many that more than 75% of the European Union’s (EU) building stock is not considered energy efficient. The vast majority (75-90%) of these energy-intensive buildings standing today will still be in use in 2050, given that the construction rate is low overall. Low demolition and renovation rates also lead to an inexorably ageing building stock, with 75% of it built before 1990. Since the building sector accounts for nearly 40% of the total energy consumption in the EU, we shall move fast.
On the policy level, EU officials have raised the energy density reduction of the building sector quite high in their agenda. The EU’s climate policy is underpinned by a number of European Directives which set strict objectives on Member States for building stock energy performance. The building renovation is included as well as in several high-profile policy initiatives.
The EU must accelerate the number of deep renovations (with expected savings of 60% or more) and increase the rate of retrofitting (more than 2% per year) to improve the performance of the building stock, and at the same time reduce the pressure on the energy grids. In this respect, evidence-based decision support is required for sound planning on retrofitting. This is what the innovative DigiBUILD services will help with. The DigiBUILD Project is among the initiatives the European Commission (EC) fosters in order to address this challenging situation.
The crucial role of digitalisation in the building stock
Moving toward smart buildings equipped with digital technologies is fully aligned with the importance of data economy and prioritisation as set by the EC within the strategies ‘Digital Single Market’ and ‘A Europe fit for the digital age’.
Due to the increasing adoption of leading-edge Information and Communication Technologies (ICTs), such as the Internet of Things (IoT), Artificial Intelligence (AI), Distributed Ledger Technology (DLT)/blockchain and Big Data, more and more data is being generated within buildings.
Data concerns almost every aspect of the built environment, from how individuals and businesses use and interact with properties to how the building’s energy consumption and construction details are recorded and analysed to support informed decisions about construction and real estate processes. Data-informed decision-making and digital upgrading, such as energy conservation measures, can help upyield operational efficiencies at a low cost. The high-quality data services included in the DigiBUILD toolbox will provide support for the decision making process.
What is the vision of the DigiBUILD Project?
To accelerate and achieve the ambitious energy and environmental targets for a climate-neutral building stock, it is crucial to engage a large number of stakeholders from the building’s lifecycle: from conceptualisation and construction to refurbishment and demolition.
The inclusion of all related parties will ensure that the transition towards low-carbon and sustainable living is acceptable and feasible for all. But, how can the built environment be freed from the constraints of current silo thinking?
Traditional silo approaches, where the different building stakeholders access and manage only their own data, can be replaced by digital and smart buildings, merging heterogeneous data sources, and placing all the stakeholders at the core of these buildings in an integrated and comprehensive approach.
The overall vision of the DigiBUILD Project is to catalyse this much-needed transformation by using high-quality data and next-generation digital building services for assuring trust, transparency, and better-informed decision-making processes.
The development of data-driven services
The DigiBUILD consortium will deliver high-quality data-driven services for a digital and sustainable built environment, supporting the deployment of EU-wide framework for a digital building logbook. DigiBUILD is creating an innovative open, interoperable, and cloud-based toolbox to transform current ‘silo’ buildings into digital, interoperable and smarter facilities, based on consistent and reliable data. The strategic objective consists of designing, developing, and deploying a holistic people-centric framework across nine different pilots connected to ten use cases. The latter are clustered by theme into three groups: ‘Buildings Performance’, ‘Buildings vs Infrastructure Optimal Management’ and ‘Policy & Finance’. The use cases are currently being prepared to test the DigiBUILD services which include:
AI-based services for finer-grained energy profiling and forecasting;
Data-driven services for energy resources management;
Data-driven energy and nonenergy services for enhanced comfort and wellbeing;
Data-driven services for renovation roadmaps and energy efficiency financing; and
Decision-making under uncertainty tools for efficient and climate-resilient buildings.
The DigiBUILD project is funded by the European Union under the research and innovation framework programme, ‘Horizon Europe’. The project consortium, led by Engineering Ingegneria Informatica, consists of 17 partner organisations with complementary expertise from the research and industrial area from 11 European countries representing the whole building value chain and more.
Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union or the European Climate, Infrastructure and Environment Executive Agency (CINEA). Neither the European Union nor the granting authority can be held responsible for them.
Please note, this article will also appear in the fifteenth edition of our quarterly publication.",https://www.innovationnewsnetwork.com/wp-content/uploads/2023/08/shutterstockOlivier-Le-Moal_1009692889.jpg,2023-10-17 19:40:55
https://venturebeat.com/business/hbx-group-marks-start-of-new-era-for-hotelbeds/,HBX Group Marks Start of New Era for Hotelbeds,"Introduction of group brand is next evolution of TravelTech transformation
New Fintech products enhance HBX Group’s ecosystem player status
PALMA, Spain–(BUSINESS WIRE)–October 18, 2023–
Hotelbeds has launched its new group brand, HBX Group to lead the B2B TravelTech company into the next phase of its evolution.
Two years on from its shift to being a leader in the TravelTech space, the company is today establishing itself as a global travel ecosystem player, introducing new product lines to meet the needs of the end consumer as they seek a frictionless end-to-end travel experience.
“As we continue our transformation as a world-leading TravelTech company, HBX Group simplifies our structure into four distinct brands under our new umbrella,” said CEO Nicolas Huss. “We have completely rebuilt our tech stack over the past year to support this shift and better serve our clients and partners by improving our reliability and number of self-service tools to maintain our market position.”
HBX Group will go to market with a collection of best-in-class B2B solutions, each with a clear proposition and market focus that meets the needs of its growing and diverse client base across more than 190 global markets. These are:
Hotelbeds, who cater for the specific needs of hoteliers, tour operators, airlines and online travel agents
Bedsonline, exclusively serving the retail travel segment bringing together all the travel products they need to complete and serve their travellers’ needs
Roiback, the HotelTech partner for independent hotels and chains seeking growth through direct channel solutions
TravelStack, providing all products, services and solutions to businesses looking to enter into the lucrative travel arena
HBX Group will also be vastly simplifying its brand architecture, to provide a much clearer and streamlined experience for all partners. As a result, existing product brands including last minute travel and Carnect, will continue to operate but will eventually be fully integrated into the HBX Group ecosystem. Hotelbeds’ long-standing flagship event, the MarketHub, as well as its innovation hub, the TravelTech Lab, will also be endorsed by HBX Group.
Technology Rebuild
HBX Group will be underpinned by new technology, which has been re-engineered in just under one year. The new HBX Group transaction platform is an open-source relational database management system emphasising extensibility and SQL compliance, allowing for more effective use of data and unlimited scalability. This complete re-platforming, re-architecture and new cloud based infrastructure enables HBX to have a global, cloud-based modern tech stack on which to build its future ecosystem strategy.
The technological transformation effectively futureproofs the company, with further functional changes easier to implement and benefits reaped by agents through easier access to more accurate data, reduced downtime and quicker responses.
The company has refactored all visible channels – including its websites – which are now device agnostic. The changes are driving tangible increase in booking conversion and have been achieved for a capital expenditure of €11 million.
Ecosystem creation
HBX Group is an ecosystem player within the world of travel. By combining the company’s four pillars – making up the “X” – technology, data, product and people, HBX Group is better-placed to support its clients and partners by offering the full scope of travel products, including ancillary services, and selling them in one package. It also encompasses the multiplier effect businesses that choose to work with the Group will benefit from.
“Being an ecosystem player enables us to provide our customers with interconnected products and services, which complement each other and which, when combined and sold seamlessly together, gives our clients what they want, when they want it.” adds Nicolas Huss. “It also streamlines the buying process while enabling clients to upsell ancillary products, enhancing their business and providing frictionless travel to the end consumer.”
Supporting the transition into an ecosystem player, Hotelbeds’ accommodation, mobility and attractions sales teams have been brought together as part of the new Group infrastructure, enabling them to cross-sell all product lines and streamline client relationships as they will now have one point of contact for all sales activity.
New fintech solutions
As part of the evolution to HBX Group, the company will introduce fintech products in 2024, including travel insurance, payment solutions, and multi-currency solutions. These products will be embedded into the company’s core business to offer its clients and partners these services across their total business volumes.
The size of these opportunities is already large and growing. For example the travel insurance sector alone is currently worth €15 billion and is expected to grow to €99bn by 2030, according to research by Spherical Insights & Consulting.
“As travellers increasingly seek the connected trip experience with all aspects of their travel included in the same ticket, we must ensure we’re meeting this need through travel insurance and associated financial products,” added Nicolas Huss. “We have offered hotels since our inception in 2001, later adding car hire, transfers and attractions. Financial services are the natural next step in our business development and one our clients have asked us to provide.”
Learn more about HBX Group at hbxgroup.com.
Follow us:
LinkedIn: https://www.linkedin.com/company/hbxgroup
Facebook: https://www.facebook.com/hbxgroup
View source version on businesswire.com: https://www.businesswire.com/news/home/20231018669983/en/
HBX Group Media Contact
PR & Media Relations
hotelbeds@fireoth.com",https://venturebeat.com/wp-content/uploads/2015/10/BusinessWire_FeaturedImage.jpg?w=1200&strip=all,2023-10-18 14:25:50
https://venturebeat.com/programming-development/how-product-management-can-drive-tomorrows-most-innovative-products-and-experiences/,How product management can drive tomorrow's most innovative products and experiences,"This article is part of a VB Lab Insights series paid for by Capital One.
For most people, naming their favorite tech product or service is easy. The opposite is also true — there are lots of infamous examples of products that have failed. Why? When a product isn’t successful, it’s almost always because the team behind it lacked clarity of thought and a culture of unconstrained thinking. Great product development is the sum of many parts coming together to achieve a vision that maps back to a real customer need. Today’s product managers help inspire and bring all these pieces together, typically via influence versus direct management, and their role is becoming more and more important as both customer expectations and technology evolve.
From new advances in areas like generative AI to data engineering and software delivery, there’s massive potential to deliver innovative customer experiences like never before. It’s good timing, as customers are saying they expect brands to deliver more and more personalized experiences.
McKinsey research shows that strong product management is one of the top drivers of business performance and customer value across industries. But research also shows that at least three quarters of product managers think their organization’s product functions are either non-existent or not up to par. This signals a clear shift in the type of environment and skill sets needed to unlock the power of product management today.
Product managers often serve as the lynchpin of delivering immersive products and experiences to both internal and external customers. They sit at the intersection of engineering, design, marketing, strategy and many other areas needed to ship products. As with any of the top innovations you’ll see in product and tech today, the most effective product managers operate within a culture of experimentation.
But just like technology and customer expectations, the role of product management has evolved, along with the skill sets and environment needed to be a successful product leader. Today’s product managers are all-purpose athletes, bringing an entrepreneurial spirit, curiosity, flexibility and an ability to lead through change. They understand how to use technology and leverage data to make informed decisions, while looking around corners to where the world is going. They experiment to challenge assumptions, identify risks and understand where to make smart bets on where the most leverage is for the customer and the business.
Leading product practitioners excel in a few key areas that, when combined, add up to world-class capabilities:
Human-centered : They use best practices, research, insights and design craft to understand their customers’ fundamental needs.
: They use best practices, research, insights and design craft to understand their customers’ fundamental needs. Business-focused : They understand the business, its goals and how the product will map back to meet those goals and drive value.
: They understand the business, its goals and how the product will map back to meet those goals and drive value. Technology-driven : They have a deep understanding of the underlying tech stack and speak the same language as their data science and software developer partners.
: They have a deep understanding of the underlying tech stack and speak the same language as their data science and software developer partners. Integrated problem-solving : They can analyze data and leverage anecdotes to probe deeper and identify points of leverage, mitigate risk and anticipate future business and global trends.
: They can analyze data and leverage anecdotes to probe deeper and identify points of leverage, mitigate risk and anticipate future business and global trends. Cross-functional leadership: They are strategic problem solvers who can navigate complexity and adapt to change.
With these factors, today’s product managers are better able to help organizations align on strategic priorities, define intent and land on an end-state vision to drive impactful product results. It requires high judgment and an inordinate amount of perseverance to stay true to the customer and the end vision. And underlining all of this: the ability to research, test and experiment, iterate, build, test again and deploy — and repeat.
At the end of the day, a company can have the most sophisticated technology in the market, but without a product mindset as part of their culture, where problem solving on behalf of customers takes priority over working back from a solution — and where product managers or related teammates help bring it all together — it can end up going nowhere.
To build lasting connections with customers, the first step is to build beloved products and experiences that address real customer pain points. To build lovable products, it all starts with an environment where product managers and teams “fall in love with the problem, not the solution.”
Rob Pulciani is Chief Product Officer, Enterprise Services at Capital One.
VB Lab Insights content is created in collaboration with a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",https://venturebeat.com/wp-content/uploads/2023/10/AdobeStock_541656916_Preview.jpeg?w=1200&strip=all,2023-10-18 13:40:00
https://venturebeat.com/business/lottiefiles-announces-its-canva-integration-bringing-the-power-of-motion-design-to-everyday-creations/,"LottieFiles Announces its Canva Integration, Bringing the Power of Motion Design to Everyday Creations","Access the world’s most extensive library of Lottie animations, or bring your team’s private library to Canva in just a few clicks.
SAN FRANCISCO–(BUSINESS WIRE)–October 18, 2023–
LottieFiles, the world’s leading platform for Lottie animations, proudly announces it is teaming up with Canva, the world’s only all-in-one visual communication platform, to give Canva users free access to more than 100,000 ready-to-use animations. This integration, a global first, melds LottieFiles’ extensive animation library with Canva’s unparalleled design platform, giving Canva users the ability to transform their static designs by leveraging the emotive and storytelling power of motion like never before.
This press release features multimedia. View the full release here: https://www.businesswire.com/news/home/20231018406909/en/
LottieFiles announces Canva integration (Graphic: Business Wire)
The LottieFiles app for Canva isn’t just another integration; it’s a revolution in the design landscape led by motion.
With the LottieFiles app for Canva, users can access:
Over 100,000 free, ready-to-use animations: Canva users will have access to animations with hundreds added daily for every industry and every use case.
Canva users will have access to animations with hundreds added daily for every industry and every use case. Customizable animations to match any brand: Each animation is transparent and background-free that can fit any color palette.
Each animation is transparent and background-free that can fit any color palette. ‘ Tiny but Mighty’ file format: Lottie animations, which are six times smaller than GIFs, can now be natively used in Canva. This gives users high quality animations with faster load speeds.
Lottie animations, which are six times smaller than GIFs, can now be natively used in Canva. This gives users high quality animations with faster load speeds. Access private animations from the LottieFiles platform: Organizations and teams can bring their Private Lottie Library into Canva.
Redefining Creative Boundaries Beyond Static Designs
Serving over 6.5 million designers and developers globally and endorsed by teams from over 275,000 organizations, LottieFiles is no stranger to the design world.
“Our mission at LottieFiles has always been to empower Creators to bring elements of joy into their creations; this integration is a significant stride in that direction. Combining Canva’s easy-to-use design platform with the power of Lottie creates a dynamic duo experience like never before,” said K Minglani, Co-Founder and CEO of LottieFiles.
The LottieFiles app for Canva emerges as a testament to the transformative power of animation, seamlessly blending intuitive design with rich customizations. It allows users to inject motion and powerful storytelling into their creations. As Canva emphasizes its dedication to simplifying design processes while heightening visual impact, this collaboration with LottieFiles is a testament to that commitment.
“The integration with LottieFiles brings powerful new creative possibilities when creating presentations, videos, whiteboards and more in Canva. Canva aims to make design accessible by integrating the world’s best content and technology into one simple platform. By partnering with LottieFiles, we’re ensuring that users can effortlessly tap into the captivating appeal of motion graphics,” said Anwar Haneef, Head of Ecosystem at Canva.
The LottieFiles app for Canva promises a blend of simplicity with profound customization, ensuring a delightful user experience. To explore the LottieFiles app for Canva: www.lottiefiles.com/canva
About LottieFiles
LottieFiles is a leading animation workflow platform dedicated to Lottie animations and their seamless integration across other design platforms. LottieFiles is the go-to-platform for over 6.5 million designers, marketers and developers to Create, Collaborate and Ship animations across everyday designs. Every 6 seconds, a new animation goes through LottieFiles and its tooling. Endorsed by teams and organizations worldwide, LottieFiles continues its mission to empower creators to infuse joy, emotion, and life into their digital designs with the power of motion. For more information, visit www.lottiefiles.com.
View source version on businesswire.com: https://www.businesswire.com/news/home/20231018406909/en/
Press Contact: [K Minglani] [K@lottiefiles.com]",https://venturebeat.com/wp-content/uploads/2015/10/BusinessWire_FeaturedImage.jpg?w=1200&strip=all,2023-10-18 13:25:50
https://venturebeat.com/business/darwinium-raises-18-million-to-accelerate-global-adoption-of-its-edge-based-digital-security-and-fraud-prevention-platform/,Darwinium Raises $18 Million to Accelerate Global Adoption of its Edge-based Digital Security and Fraud Prevention Platform,"Led by U.S. Venture Partners, Darwinium’s Series A brings its total funding to $26 million, positioning it to capitalize on the demand for its disruptive approach to curbing online fraud
SAN FRANCISCO–(BUSINESS WIRE)–October 18, 2023–
Darwinium, a next-generation digital security and fraud prevention platform, today announced it has raised $18 million in Series A financing led by U.S. Venture Partners (USVP), with participation from seed investors: Blackbird, Airtree Ventures and Accomplice. The new funding brings total investment to $26 million and enables Darwinium to scale its edge-based solution across global geographies, where it is quickly gaining traction across multiple vertical industries including fintech, eCommerce, financial services and gaming/gambling.
This press release features multimedia. View the full release here: https://www.businesswire.com/news/home/20231018042938/en/
Darwinium raises $18 million to accelerate global adoption of its edge-based digital security and fraud prevention platform. (Photo: Business Wire)
Online fraud has become more complex and harder to detect, facilitated by AI-tooling that is being exploited by adversaries. Businesses have responded with multiple point solutions deployed across the customer journey which have created friction for good users, and information siloes that continue to favor the fraudster.
The 2022 Gartner® Market Guide for Online Fraud Detection* states “Detecting fraud in digital channels is a challenge, due to the competing requirements of dealing with emerging attack vectors and delivering a smooth user experience.” They recommend that “Security and risk management leaders must orchestrate multiple capabilities to create dynamic user journeys while minimizing risk.”
We believe Darwinium addresses these challenges by delivering two key innovations: first, it moves fraud detection processes to the customer’s network perimeter (or ‘to the edge’) to provide businesses a holistic view of their customers’ online experience or “journey” across every digital touchpoint, and better separate trusted and risky behavior. Second, it has pioneered a SaaS-based approach to data protection that weaves strong, strategic data security into its unique, edge-based approach.
“The Darwinium team has built something truly unique,” says Rick Lewis, General Partner at USVP. “Darwinium offers a product that is both simple to deploy and effective at reducing fraud losses and reputational damage associated with the ever-more complex web of digital fraud. Darwinium is a game-changer, differentiated in a crowded market, offering the innovation that businesses are asking for to simplify their risk stack.”
Darwinium levels a playing field that favors fraudsters
By shifting detection processes to the edge, Darwinium is disrupting a market dominated by API-based products that risk-assess ‘moments-in-time’ – an approach that lacks the agility and context required to respond to evolving fraud.
Leveraging content delivery networks (CDNs) such as Cloudflare and AWS CloudFront to integrate at the network perimeter, Darwinium provides a continuous view of user behavior with flexible journey-time orchestration. This simpler, smarter deployment model puts full control of fraud and risk mitigation into the hands of businesses, providing the ability to decision and act on intelligence in real time, dynamically tailoring customer journeys according to trust and risk.
Darwinium’s platform also has out-of-the-box integrations with third-party services that further enrich risk decisions with additional intelligence, making it easy for customers to simplify their cyber-fraud strategy by consolidating multiple solutions.
With a SaaS-based approach to managing sensitive customer data identities, Darwinium encrypts and anonymizes data on the edge. Any analyzed customer data is stored within an organization’s own infrastructure, with its own keys. The platform uses a fully anonymized version of this data that can be processed and leveraged globally while remaining unexposed/unrecoverable to fraudsters. This streamlines compliance with regulations such as the California Consumer Privacy Act of 2018 (CCPA) and the EU General Data Protection Regulation (GDPR), while better preserving user privacy.
“AI capabilities have given fraudsters the upper hand of speed, scale and greater efficiency. This is why we designed Darwinium to deliver the visibility and coverage of a security tool, the context and insight of fraud solutions, with the agility of AI. It’s the platform that will future-proof organizations against the most complex attacks,” said Alisdair Faulkner, co-founder and CEO of Darwinium and former co-founder and CPO ThreatMetrix (acquired by LexisNexis Risk Solutions in 2018 for $830 million). “With this round, we can more effectively execute on our vision to protect every customer from the consequences of fraud, scams and abuse.”
Darwinium has been recognized as a Representative Vendor for Online Fraud Detection in the 2022 Gartner® Market Guide for Online Fraud Detection,* and a Representative Vendor with emerging orchestration capabilities in the 2022 Gartner Innovation Insight: Journey Time Orchestration Mitigates Fraud Risk and Delivers Better UX report.**
An established innovator, Darwinium’s solution has already been adopted worldwide by leading companies across its key verticals.
*Gartner, Market Guide for Online Fraud Detection, Akif Khan, Dan Ayoub, 12 December 2022.
**Gartner, Innovation Insight: Journey-Time Orchestration Mitigates Fraud Risk and Delivers Better UX, Akif Khan, 10 June 2022.
GARTNER is a registered trademark and service mark of Gartner, Inc. and/or its affiliates in the U.S. and internationally and is used herein with permission. All rights reserved. Gartner does not endorse any vendor, product or service depicted in its research publications, and does not advise technology users to select only those vendors with the highest ratings or other designation. Gartner research publications consist of the opinions of Gartner’s research organization and should not be construed as statements of fact. Gartner disclaims all warranties, expressed or implied, with respect to this research, including any warranties of merchantability or fitness for a particular purpose.
About Darwinium
Darwinium’s pioneering approach to continuous customer protection takes security and fraud prevention to the edge, removing the operational burden of implementing and maintaining API-based solutions. Darwinium provides complete visibility and control of every digital interaction – across web, apps and APIs – to separate good and bad behavior, in real time. Businesses can make more accurate, real-time decisions, and take dynamic, tailored remediation that favors the customer and not the fraudster.
About U.S. Venture Partners
U.S. Venture Partners (USVP) is a leading Silicon Valley venture capital firm, partnering with entrepreneurs to transform their ideas into world-changing companies. USVP has invested in over 500 companies spanning four decades, including: Arkose Labs, Box, Carrot Fertility, Cato Networks, Check Point Software, Guidewire, Happy Returns, HeartFlow, HotelTonight, Human Interest, Imperva, Inari Medical, Inspire Medical Systems, Intersect ENT, Kenna, Medigate, Omada Health, Pluto TV, Standard Bariatrics, ThreatMetrix, Trunk Club, Trusteer, Yammer and Zerto. USVP focuses on early-stage start-ups that transform cybersecurity, enterprise software, consumer and healthcare. The USVP team consists of former entrepreneurs, technologists, corporate executives, and financial professionals who assist with strategy, scaling, team building, product development, and business development. USVP is based in Menlo Park, California.
View source version on businesswire.com: https://www.businesswire.com/news/home/20231018042938/en/
Sherlyn Rijos-Altman
Montner Tech PR
Srijos@montner.com",https://venturebeat.com/wp-content/uploads/2015/10/BusinessWire_FeaturedImage.jpg?w=1200&strip=all,2023-10-18 12:25:48
https://venturebeat.com/games/nvidia-teams-with-foxconn-to-boost-electric-vehicle-ai/,Nvidia teams with Foxconn to boost electric vehicle AI,"GamesBeat Next unites gaming industry leaders for exceptional content, networking, and deal-making opportunities. Join us on Oct 23-24 in San Francisco. Register Now
Foxconn, the world’s biggest electronics manufacturer, announced a strategic partnership with Nvidia to accelerate the development of electric vehicles and the AI that drives them.
The collaboration, unveiled at Hon Hai Tech Day in Taiwan, marks a significant step towards realizing Foxconn’s vision for the future of EVs. Hon Hai is the parent firm for Foxconn.
Nvidia CEO Jensen Huang joined Hon Hai CEO Young Liu to present the latest advancements resulting from their ongoing partnership. The collaboration will leverage Nvidia’s comprehensive suite of automotive solutions, including the Nvidia Drive Hyperion 9 platform, the Drive Thor central computer, and an advanced sensor architecture.
The announcement coincided with a story in the Wall Street Journal that suggested the Biden administration will further restrict AI chips being shipped into China. On that point, an Nvidia spokesperson said, “We comply with all applicable regulations while working to provide products that support thousands of applications across many different industries. Given the demand worldwide for our products, we don’t expect a near-term meaningful impact on our financial results. Nvidia issued this 8-K with more details about the Commerce Department’s latest export curbs.”
Event GamesBeat Next 2023 Join the GamesBeat community in San Francisco this October 23-24. You’ll hear from the brightest minds within the gaming industry on latest developments and their take on the future of gaming.
Learn More
The computational demands of highly automated and self-driving vehicles are immense, requiring cutting-edge AI capabilities. Nvidia’s Drive Orin platform, already chosen by over 25 global automakers, will serve as the AI brain for Foxconn’s EVs. Foxconn, known for manufacturing Drive Orin-powered electronic control units (ECUs), will also produce ECUs featuring the upcoming Drive Thor superchip.
The Drive Thor superchip builds on the advanced AI capabilities found in Nvidia’s Grace CPUs and Hopper and Ada Lovelace architecture-based GPUs. It is expected to deliver 2,000 teraflops of high-performance compute power, enabling safe and secure intelligent driving.
At the center of the collaboration is the DRIVE Hyperion 9 platform, a modular development platform for automated and autonomous vehicles. Powered by DRIVE Thor, it integrates a qualified sensor architecture capable of level 3 urban and level 4 highway driving scenarios. With a combination of high-resolution cameras, radar, lidar, and ultrasonic sensors, DRIVE Hyperion processes a vast amount of safety-critical data to enable precise navigation.
One of the key advantages of Drive Hyperion is its compatibility across generations, ensuring a seamless transition from Drive Orin to Drive Thor and beyond. This compatibility, along with Nvidia’s stringent qualification processes for sensors, helps streamline development time and reduce costs for manufacturers like Foxconn.
The shift towards software-defined vehicles with centralized electronic architectures necessitates high-performance and energy-efficient computing solutions like Drive Thor. When combined with the Drive Hyperion sensor architecture, Foxconn and its automotive partners can usher in a new era of safe and intelligent EVs.",https://venturebeat.com/wp-content/uploads/2023/10/NVIDIA-DRIVE-Thor.jpg?w=1200&strip=all,2023-10-18 03:00:00
https://venturebeat.com/ai/pytorch-executorch-extends-open-source-ai-for-new-quests-at-the-edge/,PyTorch ExecuTorch extends AI for new quests at the edge,"VentureBeat presents: AI Unleashed - An exclusive executive event for enterprise data leaders. Network and learn with industry peers. Learn More
The open source machine learning (ML) framework PyTorch is moving forward with a new release, as well as a new project for enabling AI inference at the edge and on mobile devices.
The new developments were announced today at the PyTorch Conference, which loosely coincided with the one year anniversary of the formation of the PyTorch Foundation, at the Linux Foundation. As part of the event, technical details on the PyTorch 2.1 update which was released on Oct. 4, were discussed.
Most notable, however, was the announcement of new mobile and edge efforts with PyTorch Edge and the open sourcing of ExecuTorch by Meta Platforms (formerly Facebook). ExecuTorch is technology for deploying AI models for on-device inference, specifically on mobile and edge devices.
Meta has already proven the technology and is using it to power the latest generation of Ray-Ban smart glasses and it’s also part of the recently released Quest 3 VR headset. As part of the open source PyTorch project the goal is to push the technology further enabling what could be a new era of on-device AI inference capabilities.
Event AI Unleashed An exclusive invite-only evening of insights and networking, designed for senior enterprise executives overseeing data stacks and strategies. Learn More
During the opening keynote at PyTorch Conference, Ibrahim Haddad, executive director of the PyTorch Foundation outlined the progress the organization has made over the past year.
“At the Linux Foundation we host over 900 technical projects, PyTorch is one of them,” Haddad said. “There are over 900 examples of how a neutral open home for projects help projects grow and PyTorch is a great example of that.”
The expanding capabilities for inference of PyTorch 2.1
PyTorch has long been one of the most widely used tools underpinning training of AI, including many of the world’s most popular large language models (LLMs) including GPT models from OpenAI and Meta’s Llama to name a few.
Historically, PyTorch has not been widely used for inference, but that is now changing. In a recent exclusive with VentureBeat, IBM detailed its efforts and contributions into PyTorch 2.1 that help to improve inference for server deployments.
PyTorch 2.1 also provides performance enhancement that should help to improve operations for the torch.compile function that is at the foundation for the technology. The addition of support for automatic dynamic shapes will minimize the need for recompilations due to tensor shape changes, and Meta developers added support to translate NumPy operations into PyTorch to accelerate certain types of numerical calculations that are commonly used for data science.
ExecuTorch is on a quest to change the game for AI inference
In a keynote session at the PyTorch Conference, Mergen Nachin, Software Engineer at Meta detailed what the new ExecuTorch technology is all about and why it matters.
Nachin said that ExecuTorch is a new end-to-end solution for deploying AI for on-device inference, specifically for mobile and edge devices.
He noted that today’s AI models are extending beyond servers to edge devices such as mobile, AR, VR and AR headsets, wearables, embedded systems and microcontrollers.
ExecuTorch addresses the challenges of restricted edge devices by providing an end-to-end workflow from PyTorch models to deliver optimized native programs.
Nachin explained that ExecuTorch starts with a standard PyTorch module, but coverts it into an exporter graph, and then optimizes it with further transformations and compilations to target specific devices.
A key benefit of ExecuTorch is portability with the ability to run on both mobile and embedded devices. Nachin noted that ExecuTorch can also help to improve developer productivity by using consistent APIs and software development kits across different targets.
ExecuTorch was validated and vetted by actual real-world engineering problems and Meta has already proven the technology with deployment in its Ray-Ban Meta smart glasses.
With the technology now being made available as open source as part of the PyTorch Foundation, Nachin said the goal is to help the industry collaboratively address fragmentation in deploying AI models to the wide array of edge devices. Meta believes ExecuTorch can help more organizations take advantage of on-device AI through its optimized and portable workflow.
“Today we are open sourcing ExecuTorch and it’s still very early, but we’re open sourcing because we want to get feedback from the community and embrace the community,” he said.",https://venturebeat.com/wp-content/uploads/2023/10/cfr0z3n_a_virtual_reality_headset_displaying_neon_fire_ab1a2c58-33f2-4f0d-ae81-e17de062897d.png?w=1200&strip=all,2023-10-17 22:54:48
https://venturebeat.com/ai/deepmind-unisim-simulates-reality-to-train-robots-game-characters/,"DeepMind UniSim simulates reality to train robots, game characters","VentureBeat presents: AI Unleashed - An exclusive executive event for enterprise data leaders. Network and learn with industry peers. Learn More
Researchers at Google DeepMind, in collaboration with UC Berkeley, MIT, and the University of Alberta, have developed a new machine learning model to create realistic simulations for training all kinds of AI systems.
“The next milestone for generative models is to simulate realistic experience in response to actions taken by humans, robots, and other interactive agents,” the researchers write. And this is what they hope to achieve with UniSim, a generative AI system that creates a “universal simulator of real-world interaction.”
Although UniSim is in its early stages, it shows the first step toward achieving this milestone. UniSim could prove to be an invaluable asset for fields requiring intricate real-world interactions, such as robotics and autonomous vehicles.
What is UniSim?
UniSim is a generative model that can mimic the interaction between humans and agents with the world. It can simulate the visual outcomes of both high-level instructions, such as “open the drawer,” and low-level controls, like “move by x, y.” This simulated data can then serve as training examples for other models that would need data collection from the real world.
Event AI Unleashed An exclusive invite-only evening of insights and networking, designed for senior enterprise executives overseeing data stacks and strategies. Learn More
“We propose to combine a wealth of data—ranging from internet text-image pairs, to motion and action rich data from navigation, manipulation, human activities, robotics, and data from simulations and renderings—in a conditional video generation framework,” the researchers write.
According to the researchers, UniSim can successfully merge the vast knowledge contained in its training data and generalize beyond its training examples, “enabling rich interaction through fine-grained motion control of otherwise static scenes and objects.”
UniSim’s ability to simulate realistic experiences has far-reaching implications. It can be used to train embodied planners, low-level control policies, video captioning models, and other machine learning models that demand high-quality and consistent visual data.
Bringing diverse data sources together
Diagram showing UniSim’s data sources. Credit: DeepMind
UniSim was trained on dataset gathered from simulation engines, real-world robot data, human activity videos, and image-description pairs. However, the diversity of data formats posed a great challenge to training the model.
“Since different datasets are curated by different industrial or research communities for different tasks, divergence in information is natural and hard to overcome, posing difficulties to building a real-world simulator that seeks to capture realistic experience of the world we live in,” the researchers write.
These datasets have been labeled differently and serve distinct purposes. For instance, paired text-image data offers rich scenes and objects but lacks movement.
Video captioning and question-answering data provide high-level activity descriptions but offer little detail on low-level movement.
Human activity data is rich in human action but lacks mechanical motion, and robotics data, while rich in robot action, is limited in quantity.
To address this challenge, the researchers first converted all the disparate datasets into a unified format. They employed transformer models, the deep learning architecture used in large language models, to create embeddings from text descriptions and non-visual modalities such as motor controls and camera angles. They trained a diffusion model to encode the visual observations that depict the actions. They then conditioned the diffusion model to the embeddings, connecting observations, actions, and outcomes.
Once trained, UniSim can generate a wide range of photorealistic videos, including people performing actions and navigation of environments.
It can also execute long-horizon simulations, such as a robot hand performing a sequence of multiple actions. The generated examples demonstrate that UniSim successfully preserves the structure of the scene and the objects it contains in these long-horizon simulations.
Furthermore, UniSim can generate “stochastic environment transitions,” such as revealing different objects under a cloth or towel. This ability is particularly useful when simulating counterfactuals and different scenarios in computer vision applications.
Bridging the sim-to-real gap
Video showing UniSim’s robot action simulation capabilities. The entire scene is rendered in photorealistic video, and is not a real view. Credit: DeepMind
UniSim’s ability to generate realistic videos from text descriptions is remarkable, but its true value lies in integration with reinforcement learning environments. Here, UniSim can simulate various outcomes in applications such as robotics, enabling offline training of models and agents without the need for real-world training.
The researchers highlight the benefits of this approach: “Using UniSim as an environment to train policies has a few advantages including unlimited environment access (through parallelizable video servers), real-world like observations (through photorealistic diffusion outputs), and flexible temporal control frequencies (through temporally extended actions across low-level robot controls and high-level text actions).”
Simulation environments are a staple in reinforcement learning. However, UniSim’s high visual quality can help diminish the disparity between learning in simulation and in the real world, a challenge often referred to as the “sim-to-real gap.”
According to the researchers, models trained with UniSim “can generalize to real robot settings in a zero-shot manner, achieving one step towards bridging the sim-to-real gap in embodied learning.”
Applications of UniSim
A real-world simulator like UniSim has many potential applications, spanning from controllable content creation in games and movies to training embodied agents purely in simulation for direct deployment in the real world. UniSim can also complement the advances in vision language models (VLM) such as DeepMind’s recent RT-X models.
VLM agents require substantial real-world data, particularly when executing complex, multi-step tasks. The researchers demonstrate that UniSim can generate large volumes of training data for VLM policies.
“We use UniSim to train both high-level vision-language planners and low-level reinforcement learning policies, each of which exhibit zero-shot real-world transfer after training purely in a learned real-world simulator,” the researchers state. This approach extends to other types of models, such as video captioning models, which can benefit from training with simulated experience in UniSim.
UniSim can also simulate rare events, a feature that is particularly useful in robotics and self-driving car applications, where data collection can be costly and risky.
The researchers acknowledge that “UniSim requires large compute resources to train similar to other modern foundation models.” According to the paper, the model required 512 Google TPU-v3 chips during training. “Despite this disadvantage,” the researchers note, “we hope UniSim will instigate broad interest in learning and applying real-world simulators to improve machine intelligence.”",https://venturebeat.com/wp-content/uploads/2023/10/DALL·E-2023-10-17-16.46.59-Photo-of-a-modern-sleek-robot-with-its-hand-positioned-more-to-the-left-away-from-its-chin-intently-watching-a-computer-monitor.-The-screen-display.png?w=1200&strip=all,2023-10-17 20:48:04
https://venturebeat.com/ai/stardog-launches-voicebox-an-llm-powered-layer-to-query-enterprise-data/,Stardog launches LLM-powered Voicebox to query enterprise data,"VentureBeat presents: AI Unleashed - An exclusive executive event for enterprise data leaders. Network and learn with industry peers. Learn More
Washington, DC area startup Stardog, a company that helps the U.S. Department of Defense and many other government agencies manage, query and reason with their structured and unstructured data, today announced an LLM-powered conversational layer aimed at simplifying access to business insights.
Officially dubbed Voicebox, the solution will be available as part of Stardog’s flagship platform, allowing users to ask questions using ordinary language and get answers based on enterprise data— without needing any technical skill.
The move marks the latest effort to loop in large language models to simplify how teams work with data, joining the likes of Kinetica, Databricks, Dremio and many other data ecosystem players.
“It’s hard to overstate this solution’s impact on competitiveness and profitability as universal access to relevant data has long been one of the biggest obstacles to getting work done,” Kendall Clark, cofounder and CEO of Stardog, said in a statement. “Self-serve analytics is no longer the exclusive preserve of technical folks who’re able to program.”
Event AI Unleashed An exclusive invite-only evening of insights and networking, designed for senior enterprise executives overseeing data stacks and strategies. Learn More
How does Voicebox work?
At the core, Voicebox works like any other natural language processing (NLP) bot, where the user just has to type their query to get an answer.
However, the AI layer does more than just pull from raw data on a customer’s platform: it interfaces with the Enterprise Knowledge Graph of Stardog.
The Enterprise Knowledge Graph connects to all data sources within a company, enriches information from those sources with relevant context, and creates human and machine-understandable knowledge — all designed to provide answers through Voicebox based on timely, trusted and accurate enterprise data.
“It all works by taking in natural language and using our models to turn human intent into structured graph queries that Stardog executes,” Clark told VentureBeat.
The solution eliminates the task of writing queries for the knowledge graph platform, offering “data democratization” to all knowledge workers, and produces answers that are free from hallucinations.
Prompt engineering and agent techniques
Notably, Stardog also uses cutting-edge prompt engineering and agent techniques for summarizing schemas, doing data integrity checks and generally making user input safe, trusted, and contextually relevant for querying.
Clark further pointed out that “Stardog’s knowledge graph platform also includes additional services like entity resolution, hybrid AI inference, and federated graph streams and it’s this backend that Voicebox opens up for everyone, regardless of their technical skill.”
Currently, the company is using an ensemble of finetuned models based on two open-source projects and trained on data from a crowdsource project, R&D and synthetic datasets.
It will also add a self-hosted LLM into the mix to offer more commercial flexibility as well as to create a more competitive offering for customers. The timeline for this, however, remains unclear at this stage.
Plans for Voicebox
While Clark did not share the names of enterprises using the new conversational AI layer, he did confirm that early access has been given to dozens of existing customers and new prospects, including those in manufacturing and pharmaceuticals.
“We’re talking to them regularly during the program to learn how they want to include LLM in their data projects, what benefits they’re seeing and what they’re looking for. Most of our customers and our growth programs focus on risk management and compliance in financial services; drug discovery and supply chain management in pharma; and Product360 and factory of the future in manufacturing,” he said.
For now, the company is working on introducing SMS and WhatsApp support for Voicebox, making sure that the question-answering abilities are fully integrated into the digital workflow of users. It is also looking at the possibility of introducing support for voice prompts, although there is no set timeline for this shared publicly.
Since its launch in 2015, Stardog has raised over $23 million in funding and roped in customers like Boehringer Ingelheim, Schneider Electric, NASA and the Department of Defense for its Enterprise Knowledge Graph. According to Forrester, the platform can provide an ROI of 320% and total benefits of over $9.86 million over three years.
LLMs helping with data challenges
Even though Stardog has the advantage of its knowledge graph, it is not the only one working to make data access easier with large language models.
In recent months, a number of enterprises have moved to simplify different aspects of data handling with generative AI. Kinetica launched a ChatGPT integration, followed by its own LLM, for querying data; Snowflake launched Document AI for unstructured data search; and Databricks debuted LakehouseIQ as a generative AI “knowledge engine” that allows anyone to search, understand and query internal corporate data by simply asking questions.
Informatica has also made a move in this space by launching Claire GPT to help users discover, interact with and manage their data assets via language prompts.",https://venturebeat.com/wp-content/uploads/2023/08/ideogram-2-e1693341489221.jpeg?w=1200&strip=all,2023-10-17 20:14:58
https://venturebeat.com/business/d3-securitys-smart-soar-now-available-in-the-microsoft-azure-marketplace/,D3 Security's Smart SOAR Now Available in the Microsoft Azure Marketplace,"Microsoft Azure customers worldwide now gain access to D3 Smart SOAR to take advantage of the scalability, reliability, and agility of Azure to drive application development and shape business strategies.
VANCOUVER, British Columbia–(BUSINESS WIRE)–October 17, 2023–
Security orchestration, automation, and response (SOAR) vendor D3 Security today announced the availability of Smart SOAR in the Microsoft Azure Marketplace, an online store providing applications and services for use on Azure. D3 Security customers can now take advantage of the productive and trusted Azure cloud platform, with streamlined deployment and management.
D3 Security’s Smart SOAR is an independent SOAR platform for enterprises, MSSPs, and public sector entities that want to eliminate 90-98% of the noise from their security alerts, seamlessly integrate their entire security stack, and rapidly respond to threats across their environment. As a proud member of the Microsoft Intelligent Security Association (MISA), D3 Security provides the ideal SOAR platform for Microsoft-centric security operations centers (SOCs). Smart SOAR boasts 36 integrations with Microsoft products, including:
Microsoft Defender for Endpoint: for orchestrating responses to malware and other threats to endpoints.
Microsoft 365: for mitigating phishing campaigns and other email-based incidents.
Azure Active Directory: for enriching incidents with identity information.
Microsoft Sentinel: for ingestion of Sentinel events and managing investigations.
“Smart SOAR enables Microsoft Security customers to use best-in-class tools across their SOC in the most flexible, efficient, and effective manner possible,” said Amardeep Dhingra, Director of Strategic Alliances at D3 Security. “We collaborate closely with Microsoft to build and maintain integrations, to deliver world-class joint solutions, and now, to share Smart SOAR through the Microsoft Azure Marketplace.”
“Through Microsoft Azure Marketplace, customers around the world can easily find, buy, and deploy partner solutions they can trust, all certified and optimized to run on Azure,” said Jake Zborowski, General Manager, Microsoft Azure Platform at Microsoft Corp. “We’re happy to welcome D3 Security’s solution to the growing Azure Marketplace ecosystem.”
The Azure Marketplace is an online market for buying and selling cloud solutions certified to run on Azure. The Azure Marketplace helps connect companies seeking innovative, cloud-based solutions with partners who have developed solutions that are ready to use.
About D3 Security
D3 Security’s Smart SOAR™ helps solve many of the most entrenched problems in cybersecurity-including analyst burnout, alert overwhelm, and information silos-by transforming separate tools into a unified ecosystem with multi-tier automation, codeless orchestration, robust case management, and environment-wide reporting. Smart SOAR performs autonomous triage and drastically reduces false positives so that enterprise, MSSP, and public sector security teams can spend more time on real threats.
View source version on businesswire.com: https://www.businesswire.com/news/home/20231017359947/en/
For more information, press only:
Walker Banerd, Director of Communications and Content
wbanerd@d3security.com",https://venturebeat.com/wp-content/uploads/2015/10/BusinessWire_FeaturedImage.jpg?w=1200&strip=all,2023-10-17 19:25:55
https://interestingengineering.com/science/energy-crisis-iea-directs-for-50-million-miles-of-new-power-lines,Energy crisis: IEA directs for 50 million miles of new power lines,"The world needs to act fast to improve and expand its electricity grids or risk facing a climate catastrophe and frequent blackouts, a new report by the IEA, aka The International Energy Agency, said recently.Electricity grids are the lifelines of modern societies, powering homes, factories, offices, and hospitals. They are also crucial for the transition to clean energy, as more and more electricity comes from solar, wind, and other low-carbon sources. However, the report titled Electricity Grids and Secure Energy Transitions found that grids must catch up with the pace of change and innovation in the energy sector.The report warned that grids could become a bottleneck for deploying renewables and electrifying transport and heating without more investment and policy support. This could jeopardize the goal of limiting global warming to 1.5 °C and threaten energy security.To meet all national climate and energy targets, the world will need to add or replace 50 million miles (roughly converted from 80 million kilometers) of power lines by 2040 – the same as the length of the existing grid. By 2030, the operation and regulation of grids will require significant reforms, and annual investment in grids will need to be doubled to over USD 600 billion.Sources: IEA analysis The report also highlighted the growing backlog of renewables projects waiting to be connected to the grid. It is estimated that there are 1,500 gigawatts of solar PV and wind projects in advanced stages of development – enough to power over a billion homes – but they are stuck in limbo due to grid constraints.IEA Executive Director Fatih Birol stated that the world is experiencing an unparalleled clean energy transition. However, he warned that this could be at risk unless immediate action is taken to improve our electricity grids. Birol emphasized the importance of investing in grids to avoid potential gridlock and guarantee a stable and sustainable energy future. He also cautioned that failing to invest in grids could result in a much higher cost in the future.The report also stressed the importance of grids for coping with the rising demand for electricity as more people switch to electric cars and heat pumps. These new technologies can help reduce emissions but also require more power lines and innovative distribution networks to ensure reliable supplies. The report also called for more flexibility in grids, such as through demand response and energy storage, to balance the variability of solar and wind power.The report presented a new scenario called the Grid Delay Case, which showed the consequences of failing to upgrade grids in time. It projected that CO2 emissions from the power sector would be almost 60 billion tonnes higher between 2030 and 2050 due to a slower expansion of renewables and a higher reliance on fossil fuels. This would make it impossible to achieve the Paris Agreement goal of limiting global warming to 1.5 °C and increase the likelihood of exceeding two °C by 40%.The report also suggested some strategic actions that can help improve grids, such as building more cross-border and regional interconnections to share power across different areas and increase resilience. It also urged countries to integrate more solar and wind power into their grids by adopting best practices and standards for grid planning, operation, and regulation.The report urged governments to back large-scale transmission projects to ensure that grids are prepared for further strong growth in renewable power. It also encouraged grid developers and operators to embrace digitalization to make future grids more resilient and flexible.Given the long lead times for modernizing and extending grids, the report emphasized the urgency of taking action. It said that new grid infrastructure often takes 5 to 15 years to plan, permit, and complete – compared with 1 to 5 years for new renewables projects and less than two years for new charging infrastructure for electric vehicles.The report also called for more vital international collaboration to improve and expand grid infrastructure in countries worldwide. It noted that emerging and developing economies, excluding China, have seen a decline in grid investments in recent years despite robust electricity demand growth and ongoing efforts to meet energy access goals.The report quoted Birol as saying that ensuring the developing world has the resources it needs to build and modernize electricity grids is essential for the international community. He said that by mobilizing financing, providing access to technology, and sharing best practices on policies, leading economies can help improve people’s lives, strengthen sustainable development, and reduce the risks of climate change. ",https://dnd2oi6izkvoi.cloudfront.net/2023/10/18/image/jpeg/d2lTvJJFbVwiwC3Y77oKEUq7fG6TFmLiftLmQggs.jpg,2023-10-18 00:00:00
https://interestingengineering.com/military/insitu-pacific-innovaero-australian-uas,New all-Australian UAS-loitering munition tag team announced,"Two Australian companies, Innovaero and Boeing subsidiary Insitu Pacific (IPL), intend to collaborate to develop a new loitering munition and intelligence, surveillance, and reconnaissance (ISR) combination for the Australian Department of Defense. The new system will provide Australia with a long-range strike capability using uncrewed aircraft systems (UAS). The combination includes IPL's ""Integrator"" ISR UAS and Perth-based Innovaero’s ""One-Way Loitering"" (OWL) munition.“This unified approach would combine uncrewed intelligence, surveillance, and reconnaissance (ISR) and long-range strike capabilities to rapidly deliver direct effects in the engagement zone without the need for crews in larger air assets being put at risk,” said Andrew Duggan, Managing Director of Insitu Pacific in a press release. “The concept is designed to achieve seamless integration with current Australian Defence Force systems, including the Integrator, and offers great potential to become an integral strike asset,"" he added. The IPL ""Integrator"" is, according to IPL, an advanced version of the UAS and is designed to provide Group 4 and 5 capabilities in a Group 3 UAS. According to the Federal Aviation Administration (FDA), ""Groups 4 and 5 are the largest of DoD UAS, weighing over 1,320 pounds [(598 kg)] and operating at all speeds and altitudes. Group 4 aircraft operate at all altitudes, usually below 18,000 feet [(5,486 meters), mean sea level (MSL)]. Group 5 aircraft typically operate well above 18,000 feet MSL."" Group 3 are UAS that weigh more than 55 pounds [(25 kg)] and less than 1,320 pounds, operate below 18,000 feet, and have a top speed of 250 knots (463 kph). With the addition of satellite-enabled beyond line of sight (SATCOM BLOS), the ""Integrator"" UAS is capable of extended ranges that can help reduce logistical challenges and improve the safety of field personnel. According to IPL, ""Integrator"" has over one million operational hours of experience, making it one of the most innovative and reliable unmanned aircraft systems available in the industry today.Innovaero's ""OWL,"" developed in collaboration with BAE Systems Australia, is an electrically-powered munition with a maximum range of nearly 124 miles (200 km). It can loiter at a range of 62 miles (100 km) for up to 30 minutes. According to Innovaero, precision targeting of stationary and moving targets is achieved using an electro-optical/infrared camera. Additionally, it has a range of anti-armor and fragmentation warheads that can weigh up to 15 pounds (7 kg).""Together, the companies will develop, test, and field the collaborative system using Insitu Pacific’s common ground control station (GCS) and INEXA software to control UAS and long-range OWLs. Operators would command both assets through the common GCS,"" explains Innovaero. The announcement strengthens the partnership between Insitu Pacific and Innovaero to develop Australian technology for uncrewed aerial systems, as outlined in a Memorandum of Agreement established in July 2021.“The versatility of the proposed combined ISR and strike solution provides a significantly shorter ‘sensor to shooter’ loop to engage emerging threats,” said Simon Grosser, Innovaero Group CEO. “Our collaboration with Insitu Pacific builds on our work with Defence in Australia to develop an Australian loitering munitions capability and offers an integrated solution for long-range UAS target detection and effective engagement,"" he added. Development and testing for the Integrator/OWL system will continue through 2023. ",https://dnd2oi6izkvoi.cloudfront.net/2023/10/18/image/jpeg/pLLJ90kKSRqgr37RROZxOrgvkYwsuVnMofRViigP.jpg,2023-10-18 00:00:00
https://interestingengineering.com/innovation/breakthrough-mini-device-converts-molecular-movement-into-electricity,Breakthrough: Mini device converts molecular movement into electricity,"Energy is a critical component of modern human civilization, supplying electricity to houses, factories, and transportation. As the world's population and demands grow, sustainable energy sources and efficient use become critical for the long-term future.In a major development, a tiny device has harnessed the motion of molecules in room-temperature liquid to generate electricity.This innovative technological solution promises to create a clean and readily available energy source for low-power devices, entirely self-sufficient and not reliant on any external energy sources.As per the New Scientist report, this device may find applications in energizing items such as tiny medical implants and even small household gadgets in the future. Molecules are constantly in motion because they have thermal energy — even when they seem stationary to our eyes.For instance, even though a glass of water appears to be still, the individual water molecules continually vibrate and clash with one another, resulting in this seemingly undetectable motion. This underlying molecular mobility is a basic property of matter at every temperature above absolute zero.“We thought it would be interesting and meaningful to see if this motion can be harvested and converted into electricity,” Wei Li at Nankai University in China told New Scientist. The study team created a small energy-harvesting device that is only one square centimeter, called a molecular thermal motion harvester (MTMH). This device has two electrodes, one on top and one on the bottom, each having several 25-nanometer-wide strands of zinc oxide attached to it. Reportedly, zinc oxide was chosen as the material because of its ability to generate an electrical charge when mechanically deformed.The harvesting device was then placed in a container filled with n-octane – a hydrocarbon comparable to propane or butane but with a longer chain of carbon and hydrogen atoms. This process occurred at room temperature.APL materials The experiment results indicated that when the molecules in the liquid came into contact with the microscopic zinc oxide strands, they generated a small voltage of 2.28 millivolts and a current of 2.47 nanoamperes.“The energy of the thermal motion of octane can be converted into electrical energy through the device based on the piezoelectric properties of ZnO and a nano-array structure,” mentioned the study. The team also aims to examine whether different solvents or liquids can efficiently serve as power sources for this device.The researchers believe the gadget might provide energy for nano-scale devices such as implants for medicine delivery and therapeutic purposes. The team hopes to advance this technology further to power more complex applications with high efficiency. The results were reported in the journal APL Materials.Study abstract: Molecular thermal motion has been studied yet never utilized as an energy source. In this work, we demonstrate that the energy of liquid molecular thermal motion can be converted into electrical energy by a novel harvesting device, the molecular thermal motion harvester (MTMH). The MTMH was made by using two ZnO-based nano-arrays and one of which was gold coated to form a Schottky junction. The assembled electrodes were immersed in different liquid phase environments. The device was demonstrated to convert the molecule thermal energy of the liquid into a continuous and stable electric current. The output voltage and current can achieve 2.28 mV and 2.47 nA, respectively, and increase with the liquid temperatures. This strategy opens new insights into the development of mini- and micro-scale energy sources, and it can be expected the MTMH will have broad applications in the future. ",https://dnd2oi6izkvoi.cloudfront.net/2023/10/18/image/jpeg/YIhcH7kUcGmQgkRZysYvOJgv69WXFomxo3rTy8Nv.jpg,2023-10-18 00:00:00
https://interestingengineering.com/innovation/undersea-cables-reshape-earthquake-preparedness,How old undersea cables could reshape earthquake preparedness,"A new study has found a way to use old telecom cables lying under the sea as earthquake sensors, which could save precious seconds in warning people of impending tremors. The researchers used a method called Distributed Acoustic Sensing (DAS) to turn 31 miles (50 kilometers) of fiber optic cable between the US and Chile into thousands of seismic detectors.The study, published in The Seismic Record, was led by Jiuxun Yin, a former Caltech researcher who now works at SLB. He and his colleagues analyzed the seismic data from 8,960 channels along the cable for four days and detected three earthquakes, one on land and two in the ocean.They found that the offshore DAS array could improve the earthquake early warning (EEW) by about three seconds compared to the onshore DAS arrays. They also simulated how multiple offshore DAS arrays spaced 31 miles (50 kilometers) apart could work together to reduce the EEW alert time by five seconds in the subduction zone, where one tectonic plate slides under another.Yin said that the offshore location of the DAS array was the critical advantage, as it eliminated the delay caused by the seismic waves traveling to the land-based stations. He said they were surprised by how much faster the offshore DAS array was than their initial expectations.TSR doi.org/10.1785/0320230018 The study focused on the region off the coast of Chile, which is prone to powerful and frequent earthquakes due to its active subduction zone. The same is true for the Cascadia region off Canada, the US Pacific Northwest, and even Southern California, where many faults have produced strong quakes. In these densely populated coastal areas, offshore EEW could help save lives and property from earthquake damage.Yin explained that they chose the cable off Chile because of its high seismic risk. He said Chile had witnessed several devastating earthquakes of magnitude eight or more in history, including the largest one ever recorded in 1960. He said there was an urgent need for a reliable offshore EEW system in Chile.The researchers used a deep-learning artificial intelligence model to identify the earthquake waves from the DAS data of the offshore cable. Yin said this was a fast and efficient option for real-time applications like EEW, as DAS data was vast in volume. He added, however, that other traditional seismological methods could also work well with DAS data with automation.Yin also revealed that there were more than 1,500 cable landing stations around the globe and that the progress in the technology allowed them to use operational cables and add DAS systems without affecting data transportation. He expressed his belief that this opened up many exciting research opportunities and that he and his colleagues were eager to explore them in future studies. He said they sought close interactions with cable owners, environmental agencies, and policymakers to scale up the DAS-EEW to benefit coastal communities.Yin said more data from significant earthquakes was needed to develop and test EEW algorithms effectively. More information is needed on how DAS instruments behave before building a real-time EEW system that integrates with existing EEW frameworks.He said there were many places worldwide where this research could be continued and expanded.The study was published in The Seismic RecordStudy abstract:We present a real‐data test for offshore earthquake early warning (EEW) with distributed acoustic sensing (DAS) by transforming submarine fiber‐optic cable into a dense seismic array. First, we constrain earthquake locations using the arrival‐time information recorded by the DAS array. Second, with site effects along the cable calibrated using an independent earthquake, we estimate earthquake magnitudes directly from strain rate amplitudes by applying a scaling relation transferred from onshore DAS arrays. Our results indicate that using this single 50 km offshore DAS array can offer ∼3 s improvement in the alert time of EEW compared to onshore seismic stations. Furthermore, we simulate and demonstrate that multiple DAS arrays extending toward the trench placed along the coast can uniformly improve alert times along a subduction zone by more than 5 s. ",https://dnd2oi6izkvoi.cloudfront.net/2023/10/18/image/jpeg/UquRXexee4t7OVFLRXPh7Ao94ZRvIsiMZvG0xPan.jpg,2023-10-18 00:00:00
https://interestingengineering.com/innovation/nvidias-ai-bites-nails-as-us-halts-advanced-chipset-sales-to-china,Nvidia’s AI bites nails as US halts advanced chipset sales to China,"The US administration has gone forward with its objective of limiting China's access to advanced chipsets made in the country by introducing further regulations. A year back, the US announced new laws prohibiting companies operating out of its soil from selling specific chips used in supercomputing and AI to Chinese corporations. The limitations also targeted foreign enterprises that utilize US equipment. The Western superpower is engaged in an arms race with its Eastern counterpart, and such curbs are designed to limit the use of such cutting-edge semiconductors for military uses. According to information accessed initially by Reuters, chips intended for consumer items such as laptop computers would be excluded from the new tariffs. Corporations must notify the Commerce Department when processing orders for the most potent consumer chips to ensure they are not utilized in ways that endanger national security.The new updates to the rule were necessitated as many firms found a way to bypass the restrictions on exporting such chipsets. Nvidia, the world's most valuable chipmaker, was prevented from sending two of its most sophisticated AI chips to Chinese clients last year, processors that have become the industry standard for building chatbots and other AI systems. However, Nvidia quickly created other variations for the Chinese market that were less complex and circumvented US export limits. The H800 processor, for example, has the same computational capability as the company's more powerful but banned H100 device at particular settings used in AI work. Nvidia has now released a filing saying that the new export limitations will prevent the sale of two high-end AI processors explicitly designed for the Chinese market, the A800 and H800. It also stated that one of its gaming chips will be disabled. China accounts for up to 25% of its data center chip sales income. The US has maintained that such curbs are required to ensure that China does not use such advanced chipsets to manufacture weapons that may specifically target the country's cybersecurity initiatives. China has responded by alleging that the US restriction is intended to suppress its firms from advancing their businesses. ""The US needs to stop politicizing and weaponizing trade and tech issues and destabilizing global industrial and supply chains. We will closely follow the developments and firmly safeguard our rights and interests,"" Mao Ning, China's foreign ministry spokesperson, said. The relationship between the superpowers is hitting new lows after the trade war seen under the leadership of President Trump in 2018-19. In retaliation to the US curbs on chipsets last year, China restricted exports of two strategic materials in the semiconductor industry, gallium and germanium. Over the years, China has been moving some of its foreign-goods imports away from the United States. Both are concerned that the other side may suddenly weaponize trade flows, cutting off imports or exports in the name of security. According to statistics from 2022, US exports are lagging behind global counterparts selling into the Chinese market. Once significant, US-manufactured exports, such as automobiles and airplanes, have vanished. Unsurprisingly, the semiconductor sector sales also fell in 2022 and are unlikely to recover owing to a new US export control regime. US service exports plummeted during the epidemic and have yet to recover.According to the Semiconductor Industry Association, the new curbs go a step forward in national security and risk harming the industry. ""Overly broad, unilateral controls risk harming the US semiconductor ecosystem without advancing national security as they encourage overseas customers to look elsewhere. Accordingly, we urge the administration to strengthen coordination with allies to ensure a level playing field for all companies,"" said SIA. ",https://dnd2oi6izkvoi.cloudfront.net/2023/10/18/image/jpeg/guvxqzCIOdZ9bT5RxMPU8S6IxUnUKcou6kgNgu7G.jpg,2023-10-18 00:00:00
https://interestingengineering.com/science/nasa-starts-planning-of-the-roman-telescopes-future-observations,NASA starts planning of the Roman telescope's future observations,"A new sophisticated telescope will soon join the next generation of advanced space observatories. NASA is making preparations for the launch of its next major astronomical observatory, the Nancy Roman Space Telescope, scheduled for 2027.The agency has already begun working with the space community to prepare plans for observations using the Roman telescope.In fact, NASA intends to begin cosmic investigations soon after the successful deployment of the telescope in the Lagrange point. “We’re harnessing the science community at large to lay a foundation, so when we get to launch we’ll be able to do powerful science right out of the gate. There’s a lot of exciting work to do, and many different ways for scientists to get involved,” said Julie McEnery, Roman’s senior project scientist at NASA’s Goddard Space Flight Center in Greenbelt, Maryland, in a NASA blog post. This cutting-edge telescope, originally known as the Wide Field Infrared Survey Telescope (WFIRST), will be critical in advancing our understanding of the cosmos, from the nature of dark energy to the discovery of exoplanets and other astrophysical research.The newly selected infrastructure teams will play a critical role in the initial phase by engaging in activities such as producing simulations, fine-tuning the telescope's components, and more. This will enable scientists to harness the telescope's capabilities as soon as it is launched.In essence, this initiative will equip scientists with the necessary tools to study countless cosmic entities and contribute to solving various enigmas, such as the nature of dark energy.Among the preparatory efforts, telescope simulations are of crucial importance. These simulations will enable the space community to evaluate algorithms, predict the scientific output of the Roman telescope, and refine the strategies employed for observations.“The preparatory work is complex, partly because everything Roman will do is quite interconnected. Each observation is going to be used by multiple teams for very different science cases, so we’re creating an environment that makes it as easy as possible for scientists to collaborate,” said McEnery. Interestingly, one team is developing software for processing and interpreting data from the Roman telescope's Coronagraph Instrument. This instrument will showcase its prowess in directly obtaining images of exoplanets. This development has the potential to be a game-changer for a field that is still relatively young. Furthermore, scientists will simulate numerous stellar processes and occurrences as well. Machine learning algorithms will assess models’ ability to detect these phenomena automatically.Developing quick and practical approaches for discovering underlying patterns is critical for this mission. The telescope is anticipated to accumulate 20,000 terabytes (20 petabytes) of observations, encompassing trillions of individual measurements of stars and galaxies throughout its five-year primary mission.The Nancy Roman Space Telescope will serve the valuable role of identifying intriguing celestial targets. These discoveries will provide observatories like NASA's James Webb Space Telescope with specific areas to focus on for more comprehensive and detailed scientific investigations.These efforts will immensely benefit teams and individuals worldwide who will collaborate to optimize the scientific capabilities of the Roman telescope. ",https://dnd2oi6izkvoi.cloudfront.net/2023/10/18/image/jpeg/GQvbEANLPY8JqGPy0klht3bWkU73stIkWrUklT5L.jpg,2023-10-18 00:00:00
https://interestingengineering.com/innovation/superlensing-microscope-without-superlens,Scientists invent superlensing microscope without a superlens,"Physicists at the University of Sydney Nano Institute in Australia have invented a superlensing microscope that does not actually use a superlens, a press release said. The invention is expected to help advance imaging in areas such as medical diagnostics, archaeology, and forensics. In the 17th century, Dutch microbiologist Antonie van Leeuwenhoek opened up a whole new world of smaller objects and microorganisms with his invention of the microscope. Over the years, scientists have been working to increase the power of these microscopes to peer deeper into this world and understand how it works. However, scientists soon came across the physical limitations of light waves. Objects smaller than half of the wavelength of light could not be observed using the optical approach. This is known as the diffraction limit. To advance, science now needed a superlens that could overcome this hurdle. A superlens is a lens made from metamaterials that can work beyond the diffraction limit. Different materials have been used in the past to make superlenses, and they work by producing a negative refractive index to produce nanometer-sized images. Superlenses typically work in close proximity to the object being examined. This is because the lenses work to capture high-resolution information that decays as it travels further. The low-resolution data does not decay quickly but the close proximity of the superlens distorts the image. In worst-case scenarios, superlenses absorb too much light and render their usage meaningless. A research team led by Alessandro Tuniz at the University of Sydney Nano Institute has found an alternate way to capture images of objects smaller than the diffraction limit by avoiding the superlens altogether. Uni Sydney Tuniz's team approached the issue at hand by placing the light source far away from the object. This way, they could capture both high and low-resolution information coming from it. Previous studies have also shown that keeping the probe further away ensures that it does not interfere with high-resolution data. By moving the probe away, the team was successful in maintaining the integrity of the high-resolution data and filtered out the low-resolution data using a post-processing step on the computer to get a clear final image. ""This produces a ‘truthful’ image of the object through the selective amplification of evanescent, or vanishing light waves,"" said Tuniz in the press release. ""This technique is a first step in allowing high-resolution images while staying at a safe distance from the object without distorting what you see.""The researchers used light at terahertz frequency at millimeter wavelength, in the region between visible and microwave, which is useful for biological imaging such as visualizing protein structures or cancerous cells. However, that's not all. ""Our method could be applied to determine moisture content in leaves with greater resolution, or be useful in advanced microfabrication techniques, such as non-destructive assessment of microchip integrity,"" added Boris Kuhlmey, associated professor at Sydney Nano, who was involved in the work. (It) could even be used to reveal hidden layers in artwork, perhaps proving useful in uncovering art forgery or hidden works.""The research findings were published in the journal Nature Communications. ",https://dnd2oi6izkvoi.cloudfront.net/2023/10/18/image/jpeg/C3ZX11a3hmassAYQQQ21jcDceTzEsXvM8nQS8eaq.jpg,2023-10-18 00:00:00
