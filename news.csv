Link,Title,Text,Image,Date Publish
https://www.forbes.com/sites/paultassi/2023/10/18/here-are-destiny-2s-secret-twilight-triumph-objectives-for-the-lost-memento/,Here Are Destiny 2’s Secret Twilight Triumph Objectives For The Lost Memento,"Destiny 2 Bungie
Destiny 2 has started Festival of the Lost and as soon as it went live, players noticed that there was a new triumph full of question marks in order to acquire the first copy of the Lost Memento from the event, the new black-wrap shader that is so good, it’s causing a few controversies of its own. But more on that later.
Because this is the Destiny community, either through datamining or deduction, these objectives have been found already, and lord knows that you will never randomly figure these out on your own, so you should probably just listen to the instructions below.
Objective 1 – The mystery here is to complete the Fallen SABER strike with the Clovis Bray mask equipped, and yes, you can just launch it manually.
Objective 2 – The 100 here is 100/100 kills on Neomuna with the new Nimbus mask. This is probably the only one I can see you maybe figuring out randomly.
Objective 3 (these can be done in any order, by the way) – You need to perform 25 finishers in Legend Haunted Sectors while wearing the Tormentor mask. Clever.
Destiny 2 Bungie
This will get you your first copy of the Lost Memento, a Festival-only black memento that can be applied to crafted weapons like the Trials and Gambit and other ones before it. Many people thought Bungie forgot about these, but now it appears to be a way to get players to farm holiday events when they may not otherwise.
This is your first copy, but once you unlock this triumph by completing all the steps, you can then start to farm more of these as they are random drops from the event engrams. But apparently they are really, really rare drops, so you will have to go a bit crazy farming in order to actually acquire a bunch of these for your favorite weapons.
The memento system is weird. On the one hand, the shader effect is so good you will wish it was…an actual shader. On the other hand, grinding for at least something you want in Festival of the Lost that isn’t a bad new GL is mildly attractive. But the three week time limit? Yeah, that’s less fun, and I wonder if they’re going to be doing this with each event now.
The hidden challenge is cool, but yeah this whole process is bound to be pretty controversial as the event goes on. I’m out of town now, but yeah, I’ll be hunting for it when I get back.
Follow me on Twitter, Threads, YouTube, and Instagram.
Pick up my sci-fi novels the Herokiller series and The Earthborn Trilogy.",https://imageio.forbes.com/specials-images/imageserve/652fe8de96e4e34363c9b3e7/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds,2023-10-18 10:19:16
https://www.forbes.com/sites/tylerroush/2023/10/18/amazon-will-start-delivering-prescriptions-by-drone/,Amazon Will Start Delivering Prescriptions By Drone,"Topline
Amazon will begin delivering prescriptions for some Texas-based customers by drone, according to an announcement on Wednesday, becoming the latest company to test drone deliveries for medications as Amazon expands its drone delivery service.
The company said customers could receive their prescriptions within an hour of placing their order. picture alliance via Getty Images
Key Facts
Customers in College Station, Texas, will receive their medications within an hour of placing their order with Amazon Pharmacy, the company announced Wednesday. Amazon said College Station residents will be able to request more than 500 medications—including treatment for the flu, asthma and pneumonia, among others—as part of the drone delivery service. Amazon’s drones—which fly at an altitude of up to nearly 400 feet—will check to see whether the delivery zone is clear of pets, children or other obstacles before dropping the package off, the company said. Amazon Pharmacy’s drone delivery service is expected to expand to other markets, according to Amazon, which noted it has no time frame for expansion. Shares for Amazon fell slightly (1.2%) to $129.80 in early trading on Wednesday.
Tangent
Other companies have tested delivering prescriptions via drone in recent years. In a joint statement, UPS announced in 2020 that it would use drones to deliver prescriptions for CVS Health locations in The Villages, Florida, after both companies “successfully” completed their first drone deliveries in Cary, North Carolina, in 2019. That delivery service has since ended, a CVS spokesperson told the Associated Press. Intermountain Healthcare announced last year that it would begin delivering prescriptions in Salt Lake and Utah counties in Utah. The company told the Associated Press that it is continuing to expand the delivery service through Zipline, a logistics company that uses drones to drop packages by parachute. Walmart announced earlier this year that it was expanding its own drone delivery service to Dallas, though it does not provide delivery for prescriptions.
Big Number
10,000. That’s how many drone deliveries Amazon projected to have completed via drone in 2023, according to CNBC, though the company completed just 100 as of May.
Key Background
Amazon launched deliveries through Prime Air—the company’s drone delivery service—for customers in Lockeford, California, last year in an effort to deliver items “quickly” and “cost-effectively.” The launch follows comments by chief executive Jeff Bezos in 2013, after Bezos said he expected “Prime Air vehicles will be as normal as seeing mail trucks on the road.” Bezos noted that he expected the expansion to take “some number of years,” pending approval and possible regulation by the FAA. The agency approved Amazon’s request for a drone delivery fleet in 2020. Some Lockeford and College Station residents have previously expressed concerns about the drone delivery service, though an Amazon spokesperson told Insider that “safety is our top priority.”
Further Reading
Amazon Will Start Testing Drones That Will Drop Prescriptions On Your Doorstep, Literally (Associated Press)",https://imageio.forbes.com/specials-images/imageserve/652fe4c9ae942ba8af2ba1a0/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds,2023-10-18 10:01:32
https://www.forbes.com/sites/garydrenik/2023/10/18/ai--low-code-can-the-two-work-harmoniously-to-democratize-coding-for-developers/,AI & Low Code; Can They Work Together To Match Coding For Developers?,"Artificial Intelligence AdobeStock_245853295
The synergy between AI and low code is transformative, democratizing coding and expanding the horizons of software development. It empowers a diverse group of individuals, from professional developers to business analysts, to participate in and contribute to the software development process, ultimately driving innovation and efficiency in various industries. According to a recent Prosper Insights & Analytics survey, about 8-14% of people across generations use ChatGPT for development.
Prosper - Use ChatGBT For Chatbot Development Prosper Insights & Analytics
To learn how AI and low code can democratize coding, I spoke to Vikram Srivats, Chief Commercial Officer of WaveMaker, a leading Java low-code platform that helps professionals rapidly build modern, scalable, and secure software products and applications.
Gary Drenik: What are the shortcomings of AI-generated code when compared to code created in low-code platforms?
Vikram Srivats: Low Code platforms and AI take different approaches to generating code. Low Code tools have already been vetted by enterprise architects for adoption within their enterprises and many applications created by low code tools have already been deployed for end customer usage.
Right now, inconsistency in responses has plagued ChatGPT. The copilot paradigm has been put to use where a developer asks a copilot to generate code at a function level. Huge swathes of developer cycles are spent in maintaining, upgrading tech stack of solutions after the V1 is created.
This is the problem low code is able to solve better. Low code tools support iterative development and provide tools to debug and improve the code while AI generated code cannot be released without the developer understanding the code and taking ownership of it for maintenance.
Drenik: What steps can developers take, other than working alongside AI, to help scale their coding efforts effectively and accurately?
Srivats: In programming, a lot of productivity gains are made when teams are able to reuse abstractions at component, module level. When code is reused the cycle time needed to implement a customized solution reduces. This is how teams of developers work iteratively to build solutions that best fit the market needs. This process of tinkering, delivering, observing usage and planning improvement is still a very effective way to build software solutions. GitHub developer survey reveals that internal collaboration and gathering customer feedback is where most of the time in software development is spent. Hence embracing agile methodologies, reducing the cycle time needed to push change to production, a well-established feedback loop along is way to scale developer efforts.
Drenik: Analysis shows that, when prompted, 52 percent of ChatGPT answers to programming questions are incorrect and 77 percent are verbose. How can developers work alongside AI knowing they are the only ones who can catch and correct these errors?
Srivats: Working alongside AI can occasionally be a challenging experience, particularly regarding the accuracy and verbosity of responses. It's important to recognize that we are currently in an era of generative AI that is still in the early stages but improving at a faster pace than any other tech in the past. Not all applications of generative AI need to mimic chat-based interaction nor do they have to use ChatGPT only.
However, the adoption of ChatGPT has driven an expectation to build in smartness into many customer interactions. In order to build AI into solutions, developers should invest time in understanding underlying technology advancements that are underpinning the generative AI. New use cases that are not satisfactorily solved yet may become the next big market opportunity.
Drenik: As developers and business users alike dabble into AI-generated code, what use do they have for low-code tools, the original means for making coding faster for developers and accessible for non-developers?
Srivats: AI generated code is still not changing the level of abstraction where developers operate. In this way the productivity gains made are localized to dev teams, while not addressing the skill set gap and time spent in collaboration between product design, implementation, quality analysis.
However, much higher order gains in productivity can be achieved by elevating levels of abstraction and by solving the collaboration problem. This is where low code paradigm outshines simple generation of code from text. Low code tools are addressing both efficiency and skills gaps. Low code tools that also use AI in them further increase productivity of teams and not just individual developers.
Drenik: Will low-code design ever be replaced by AI entirely? Why or why not?
Srivats: As with other tools and processes, we can expect low-code platforms to become AI-infused and become more powerful than they are today. If low-code has been an accelerator for software development, then AI is an accelerator for low-code platforms. Although there will likely be classes of application that can entirely be created by AI at some point without any human intervention or low-code platforms for that matter, this does not mean that all future software development (and developers) will lose the need of low-code development platforms. In fact, there may be a new class of low-code platforms infused with AI that will become the dominant method to design, build, debug and maintain sophisticated, custom, and high-stakes applications.
Drenik: Why won’t AI replace low-code platforms?
Srivats: Even after getting trained on all of the code available in the GitHub and looking at all the answers on StackOverflow, current proficiency of the coding by the AI is at best as a copilot. All interactions to write code from just the text prompt result in frustration. The current state of AI’s proficiency in coding is simply not as good as the hype is making it out to be. We expect this to get better quickly.
A large part of a programmer’s time also goes to fixing bugs and changing the structure of the code in a way that is easier to maintain. This process of fixing a bug or refactoring code is not recorded anywhere for AI to be trained on. Initial versions of AI generated code are usually rewritten or entirely to make it easier to maintain.
Code generation in low-code development platforms is based on a visual declarative model and occurs organically each time a developer starts to build an application. In the case of AI-based code generation, there is the legal/compliance question of not knowing the source of where generated code comes from.
AI could start generating apps with cookie cutter UI atop any given API and a workflow definition. The quality of the code behind this may not matter at all as long as the user interface gets the job done. However, as the world moves more in the direction of software platforms that offer customizability, extensibility, and maintainability at low TCO, The process of development is iterative by building quickly, collecting feedback, and enhancing later. It is impossible that a developer’s mind has a crystal-clear detail of what exactly needs to be built – ahead of such an iterative process. Low code tools are better placed with such iterative development processes. They enable diverse, cross-functional teams to collaborate and iterate quickly, while AI may be used within each iteration to produce snippets of code to be refined, tested and integrated further.
Lastly, in the evolution of modern software development, we see a growing fusion upstream between designers and coders. So far, a lot of the friction, time, and effort between these 2 groups (and worlds) goes into, say, translating a product vision specified in text or a Figma design into real, working frontend and backend code. This process often needs iterative development and collaboration between 2 very different kinds of people. The skills required to ideate, and design are different from skills needed to write code. Low code platforms that integrate upstream with popular design tools and frameworks offer development and design teams to work more closely and, for example, interpret and render fully functional UI (and code) from a design. While such low-code platforms will rely on AI to generate a V1 of the UI or even generate new UI widgets not currently available in their out-of-the-box libraries, the inherent process of iterating between development and design will necessitate the future salience of a standard, robust development platform well-integrated with SDLC practices and built-in collaboration.
Drenik: Thank you for your time, Vikram, and your insights into how professional developers and business analysts can leverage both AI and low code to scale coding, increase innovation, and improve efficiency. It will certainly be interesting to see where coding goes next from here.",https://imageio.forbes.com/specials-images/imageserve/652ee1ff08f740841b955421/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds,2023-10-18 10:00:00
https://www.forbes.com/sites/tomcoughlin/2023/10/18/ocp-2023-announcements-from-jedec-ocp-foundation-kioxia-and-phison/,"OCP 2023 Announcements From JEDEC, OCP Foundation, Kioxia And Phison","Chicklets. getty
Although I wasn’t able to physically attend the Open Compute Project (OCP) Summit I did get information about several storage and memory related developments at the show. Let’s look into these developments on Chiplets, enhanced Ethernet systems, device level security auditing, data center SSDs and SSD and domain specific processor controllers.
The OCP Foundation and JEDEC Solid State Technology Association reported a joint development for automated System in Package (SiP) design and build using Chiplets. This included a Chiplet Description Schema (CDXML) specification which enables standardized Chiplet part descriptions for use with modern EDA tools and allows chiplet builders to provide electronically readable descriptions to their customers. CDML is being integrated into JEDEC JEP30. OCP is granting a compensation free and non-exclusive right to incorporate CDXML into JEP30.
The electronically readable descriptions for chiplets include: Thermal, Physical/Mechanical, Behavioral, Power/Power and Signal Integrity, Electrical test and security information. These new standards are expected to help establish an Open Chiplet economy. The objective is to build an Open Chiplet economy as illustrated below.
OCP and JEDEC Chiplet Ecosystem OCP Summit Announcements
The OCP Foundation and the Ultra Ethernet Consortium announced an alliance to help deliver data center equipment that is optimized for artificial intelligence (AI) and high-performance computing (HPC) applications. This includes solving memory size and AI cluster back-end fabric challenges posed by large language models (LLMs). This will help fast track the integration of UCE-inspired Ethernet enhancements into complete systems. This will enable OCP to support its multi-vendor supply chain to deliver on these enhanced Ethernet systems.
This enables integration of specialized silicon systems developed using Chiplets and large memory pools created with CXL and various memory appliances. The OCP Foundation also announced its Security Appraisal Framework and Enablement (S.A.F.E.) Program to enable standardized device specific security auditing. This is meant to reduce the cost, decrease redundancy and provide common security conformance to device customers.
Kioxia also participated in the OCP Summit highlighting its data center and enterprise SSD portfolio. In particular the company talked about their XD7P data center NVMe SSDs as shown below as well as Kioxia’s LD2-L NVMe SSD (in a EDSFF E1.L 9.5mm form factor) and CD8P Data Center PCIe 5.0 NVMe SSDs (in EDSFF E3.5 and 2.5-inch (U.2) 15mm thickness form factors).
KIOXIA XD7P NVMe Data Center SSDs KIOXIA OCP Summit Announcements
These products also work with Software-Enabled Flash (SEF) data management to control data placement, provide workload isolation, reduce write amplification and optimized latency. This allows advanced queueing, I/O prioritization and customized protocols with open source APIs and SDKs.
Phison introduced high-speed signal enhanced IC products at the OCP Summit to expand its PCIe 5.0 and CXL 2.0 ecosystem for AI-driven data centers. These developments include PCIe 5.0 and CXL 2.0 compatible redriver and retimer data signal conditioning IC products. These products are intended for NAND flash products for AI applications, including machine learning (ML). The company currently has PCIe 4.0 and 5.0 products in mass production and PCIe 6.0 products in design.
Phison's PS7201 and PS7202 retimer solutions are designed to meet the growing demand for data performance, and follow industry standard retimer footprints. In addition to working with NAND flash, these solutions work with accelerator technologies including GPU, CPU, FPGA, ASIC and DPUs. They boost a 5ns latency with pin-to-pin compatibility with competing products. These products are certified by PCI-SIG. Phison also offers it auto tuning tool PHiTUNE for its retimers. This tool enables development engineers to collect signal data and determine the best parameters for signal optimization within 30 minutes.
The OCP Summit introduced new Chiplet enablement, advanced Ethernet and device security auditing. Kioxia highlighted their data center SSD products and Phison announced new controller technology for PCIe 5.0 and CXL 2.0 devices.",https://imageio.forbes.com/specials-images/imageserve/652fe2c576ff253d1be722f7/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds,2023-10-18 09:55:09
https://www.forbes.com/sites/forrester/2023/10/18/what-should-revenue-enablement-do-about-sales-layoffs/,What Should Revenue Enablement Do About Sales Layoffs?,"Layoffs happen in B2B organizations too often and too regularly. For revenue enablement managers who want to be seen as leaders, you might as well be prepared for if, and when, the next one impacts your team. Here are five suggestions to simultaneously come to the aid of your internal customers and to up your enablement game for the long term.
Lead Through The Moment With Professional Change Management
While revenue enablement teams typically cover a wide range of responsibilities, now is the moment to emphasize the human element within your revenue enablement toolkit. After all, enablement staff are increasingly being populated by professionals with skills in change management. During a time when the emotional upheaval that accompanies layoffs is raw, help your colleagues near and far understand the answers to the following questions: Why is this happening, what does it mean for me, and what should I be doing about it? Your internal customers and colleagues will remember your support efforts when the stress diminishes later on and be more attuned to your ongoing efforts to prop up their successes, represent calm during the storm, and be the adult in the room when you …
Help Sellers With Stable, Streamlined Communication
The three questions above are generic reactions to change that should be interpreted more specifically for the revenue team. Follow the lead of the corporate communications and HR folks, by adapting their internal messaging to what matters most to sellers: impact on current deals, territories, accounts, and quotas. Work with HR and sales leadership to rapidly publish an approved FAQ resource, curate relevant communications and assets in a central location, and ramp up your enablement help desk support capabilities to help folks out. Reach out to revenue operations friends, who are certainly mired in seller-specific needs. Consider how product marketing and other teams have been impacted, because now is the time when reps need you all to …
Double Down On Enablement That Uplifts Sellers And Helps Them Make The Next Cut
Without interpreting this recommendation as “push all the surviving reps to the LMS,” the fact is that many departed sellers likely represent folks who didn’t “find the cheese” around newer buyers, products, and selling motions or basically did not adapt their skills quickly enough over time. Most reps who are still on staff will naturally wonder if they have the right competencies to survive the next layoff, real or imagined. New manager/rep relationships need to quickly be built. Enablement teams can leverage the communications channels mentioned above to gently suggest learning experiences that are associated with ongoing, stable, and secure professional outcomes and to identify any tribal knowledge that walked out the door. Don’t imply that “the laid-off folks didn’t take this class, so you should” — focus on the most recently introduced new competencies that management has asked enablement to support. Don’t stop at suggesting; let them see you …
Get Your Hands Dirty With Sudden Coverage Gaps
If you’re like most successful revenue enablers, you’ve carried the bag in the past and also are reasonably familiar with your reps’ basic motions. Their customers and deals are top priority right now, so what’s stopping you from digging in at a time when their support system may have just been diminished? The help desk suggestion above is an ideal way to tangibly contribute during a difficult moment but turn the service from a pull function (responding) to a push mentality (proactive). Ask reps — and managers — what current deals are slowing down as a result of the current cuts or what territories suddenly need more support. If you’re already good or great at enablement, you’ll soon be flooded with grateful requests for short-term help, which lead to long-term value-add for your function. But never forget to …
Balance Short-Term Heroics With Long-Term Value Perception
Without a doubt, this is a moment for enablement teams to shine through the pain. You absolutely need to find ways to pitch in during moments of crisis — see the recommendations above — but conversely can’t risk giving other functions the impression that, until now, you were not delivering 100% effort. This may sound overtly political or shallow, but it’s wise to accompany your short-term support efforts by temporarily scaling back some other deliverables, if not overhauling your entire charter. If enablement itself experienced headcount loss, this is easier for others to understand; otherwise, be sure to communicate your adapted focus as we’ve indicated here.
This blog was written by VP, Research Director Peter Ostrow and it was originally appeared here.",https://imageio.forbes.com/specials-images/imageserve/652fe255a69bf8b95705e82a/0x0.png?format=png&height=900&width=1600&fit=bounds,2023-10-18 09:50:05
https://www.forbes.com/sites/games/2023/10/18/super-mario-wonder-review-wonderfully-mad/,‘Super Mario Wonder’ Review: Wonderfully Mad,"The Wonder Flower is a new and integral part to 'Super Mario Wonder'. Nintendo
Super Mario Wonder is a fascinating mix of what makes classic Super Mario games tick coupled with some thoroughly surreal setpieces. So let’s get into into it.
For all intents and purposes, Super Mario Wonder is a fundamentally traditional 2D Super Mario game. While there are sections of the game where you can pop into a background plane, the game operates in two dimensions much like how the series started out.
That means the level design and platforming has to turn things up a notch and this is where the things start to get more technical than usual.
Just on the basic platforming aspects of the game, Super Mario Wonder is exacting with its demands on the player. This is not to say that it is difficult, although some levels early on can be a surprising challenge, but that you have to keep on your toes to progress smoothly.
The Wonder Flower setpieces are pretty out there. Nintendo
Each level also features a new Wonder Flower, which once touched starts a wacky and reality defying setpiece. Upon successful completion of that section and also on the completion of that level, you are awarded a Wonder Seed.
Wonder Seeds act as your currency in the over world map to unlock more levels, which is a pretty standard setup by this point.
Progressing through the overworld unlocks more levels and a boss level, which gives you a Royal Seed. This Royal Seed then allows you to chip away at Bowser’s Castle, with more areas that you complete weakening its defences further.
Sitting literally atop all of this are new Badges, that seem like a mild homage to Super Mario Odyssey. These Badges give Mario a variety of powers, such as gliding or speeding around underwater.
On top of all this you have a very robust co-operative player mode and an online setup, which at the time of my review was sadly unavailable. However, from my standpoint, I am mostly interested in the singleplayer campaign.
'Super Mario Wonder' is visually pristine throughout. Nintendo
The latter, for all intents and purposes, is one very slick package. Not only in terms of the precision in the level design and abilities at your disposal, but also the pristine visuals and sound design.
You also have these lovely little flowers that talk to you and make comments as you pass by, which is a fun touch.
All this aside though, this may be a very good game, but it doesn’t hit as hard as Super Mario Odyssey did, or even Super Mario 3D World for that matter.
Maybe I am too spoiled on functionally 3D platformers by this point, as even the recent Kirby game was exemplarily good. However, it’s been a while since a traditional 2D Super Mario game really hit home for me.
Overall though, Super Mario Wonder is an excellent 2D platformer. With excellent level design, polished visuals and mad Wonder Flower setpieces. It’s not my favorite Super Mario game in recent years, but it’s definitely worth checking out.
Super Mario Wonder
Platform: Nintendo Switch
Developer: Nintendo
Publisher: Nintendo
Released: 20th October 2023
Price: $59.99
Score: 8.5/10
Disclosure: Nintendo sent me a copy of this game for the purposes of this review.
Follow me on Twitter, Facebook and YouTube. I also manage Mecha Damashii and do toy reviews over at hobbylink.tv.
Read my Forbes blog here.",https://imageio.forbes.com/specials-images/imageserve/652fdb6a09caf398c42a77b3/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds,2023-10-18 09:28:51
https://www.forbes.com/sites/jonathankeane/2023/10/18/real-estate-tech-firm-hqo-secures-50-million-series-d-round/,Real Estate Tech Firm HqO Secures $50 Million Series D Round,"Chase Garbarino HqO
Real estate software company HqO has raised over $50 million to fuel its growth and acquisition strategy.
The Series D round was led by Koch Real Estate Investments, a subsidiary of Koch Industries, with participation from existing investors including Accomplice, Insight Partners and Related.
The round brings HqO’s total funding to date to over $200 million.
HqO develops a software ""experience"" platform for managing how tenants and employees use a building.
Its latest product is the Real Estate Experience (REX) platform, which brings together several tools for building owners and operators to manage tenant and employee experiences in their properties.
The tools include measuring employees’ workstyles, preferences and satisfaction along with marketplaces for services in the building. The company said that this can help with retention and greater efficiency with operating costs.
According to HqO, more than 350,000 users across 700 properties are using REX.
Effectively measuring how buildings are used has become increasingly important, Chase Garbarino, chief executive of HqO, said.
MORE FOR YOU What High Interest Rates Mean For Commercial Real Estate Investors
""The world has dramatically changed over the last few years, especially the way we work, live, and interact with our surroundings. In this environment of digital disruption, data, technology and a focus on the customer are not just options; they’re mission-critical to compete,"" Garbarino said.
The new round of funding will aid HqO in its M&A strategy where it targets other proptech and real estate start-ups for acquisition.
It has already completed a number of acquisitions including Leesman last year, which measures employee experience and has been integrated into HqO’s offering, and Dutch start-up Office App in 2021.
""As the real estate industry continues to radically evolve, we firmly believe that its future lies in the convergence of innovative technology, data and customer-centric experiences,"" said Justin Wilson, managing director at lead investor Koch Real Estate Investments, said.
""By developing cutting-edge technology and tools that prioritize user sentiment, HqO is not only adapting to the rapidly changing real estate industry, but driving its progression. With HqO’s vision and our investment, we are confident that together we are building a more transformative ecosystem.""
As part of the investment, Wilson will be joining HqO’s board of directors.",https://imageio.forbes.com/specials-images/imageserve/652e72fd50f8c81778de316a/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds,2023-10-18 09:07:09
https://www.forbes.com/sites/forbestechcouncil/2023/10/18/a-forward-looking-approach-to-managing-risk-in-an-uncertain-climate/,A Forward-Looking Approach To Managing Risk In An Uncertain Climate,"Ron Dembo is the founder and CEO of RiskThinking.ai.
getty
We are living in a time characterized by unprecedented uncertainty in our environment. Business leaders are paying attention to the risks of climate change and asking important questions more often in boardrooms, leadership summits and conference calls:
• How can we measure the future financial impact of climate change?
• How will factors such as rising temperatures or fuel costs affect our businesses?
• What do we need to know to make good decisions in the future?
It’s impossible to answer these questions with certainty—not just because the future is inherently uncertain but because climate change is an extremely complex problem governed by dynamic and interconnected systems. We know the climate is changing, but we can't predict with certainty what this means for the planet and its people or how it will affect our businesses.
Climate change affects the physical and financial assets of businesses. If your company has a dozen data centers in England, and heat waves force you to temporarily reduce your output or shut down centers, you may take a big financial hit. If you have offices throughout the U.S., and several locations are flooded because of storms in the northeast, you may experience serious economic losses.
I believe the traditional ways people manage uncertainty are fundamentally misguided. Forecasting is the norm in risk management, but it often falls short. Unknown factors can disrupt our plans and predictions, so we must rethink our approach to managing risk.
It is critical to use forward-looking data—aggregating a multitude of perspectives about future outcomes into probability distributions—to better prepare for climate risks and develop a data-based strategy. When there is deep uncertainty, the “form of a solution” should involve taking action but simultaneously including mitigation strategies or hedges. I recommend taking the following steps to cope with risks in an uncertain future.
1. Measure your exposure and risk using forward-looking data.
Without measuring potential risks and impacts, it's hard to plan for the future. Gather as much forward-looking data as possible from various expert sources and weigh their significance. Consider a range of possibilities, not a single forecast. This systematic, future-focused approach can help you deal with unpredictable changes.
For example, in a more carbon-constrained world, the prices of goods and services your company relies on may fluctuate. Investigate potential scenarios that could occur if the cost of raw materials, manufacturing or shipping suddenly rise.
2. Plan for mitigating risks.
Mitigation strategies can vary depending on your business context. For instance, if you run an airline, exploring hydrogen fuel or other alternative sources for planes may help mitigate future risks associated with carbon pricing and environmental concerns. Or if you're in the oil and gas industry, and your company is facing increased pressure as electric vehicles become more popular, diversifying into electric power stations could help hedge against the decline in traditional gas stations.
The key is to think beyond standard risk measurement and explore different scenarios and alternatives. Scenario thinking, or risk thinking, involves considering all possible outcomes and building a strategy that makes sense in an uncertain world. By considering various viewpoints and aggregating them into an actionable plan, you can navigate risks more effectively.
3. Set aside capital.
Setting aside capital is similar to buying insurance against potential losses. A financial buffer can provide your business with a safety net when unexpected events occur.
Perform a cost-benefit analysis to determine how much capital you need, aligning the amount with the level of risk your business is willing to bear. The more you want to eliminate risk, the more expensive this becomes—and you have to balance this tradeoff. Setting aside too much capital can be financially inefficient, just as overinsuring a low-risk event can be costly.
We need to learn to adapt our risk thinking strategies to be effective in an uncertain world. We can't predict the future with 100% accuracy, but we can develop solutions that combine action and mitigation.
Forbes Technology Council is an invitation-only community for world-class CIOs, CTOs and technology executives. Do I qualify?",https://imageio.forbes.com/specials-images/imageserve/652d77c6d6ea174fc78f5c6f/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds,2023-10-18 09:00:00
https://www.forbes.com/sites/forbestechcouncil/2023/10/18/to-find-global-tech-talent-look-to-emerging-markets/,"To Find Global Tech Talent, Look To Emerging Markets","Bui Hoang Tung is the senior executive vice president of Rikkeisoft.
getty
Arguably, now more than ever, companies are strategically diversifying their operations beyond their traditional go-tos.
Geopolitical instabilities and economic concerns amplified by the Covid-19 pandemic have made it so that any organization over-reliant on traditional markets for supply chain networks is putting itself at a significant disadvantage. Moving forward, supply chain diversification will be essential, as will leveraging global tech talent to support vendor diversification.
The Supply Chain Diversification Trend
Globally, more organizations are diversifying their supply chains. According to a 2022 survey by Gartner, 51% of supply chain leaders indicated that they had expanded their network locations in the past two years. The most noteworthy example of this trend is the “China plus one” strategy, where companies are seeking to become less reliant on China. Notably, Nikkei Asia reported in December 2022 about Apple’s shift to Vietnam and India for the production of some of its products. The company’s rival, Samsung, has also relocated some of its operations away from China. And these are just two examples.
Besides mitigating geopolitical risks, diversification has another benefit: It enables companies to localize their manufacturing to serve their core markets nearby. For example, production in India enables companies to accommodate this populous market more easily. Additionally, through diversification, companies can also leverage the competitive labor costs of new locations.
Looking To Emerging Markets To Find Global Tech Talent
Zooming in on the topic, the supply chain diversification trend can be extended to enterprises leveraging a global talent pool to drive innovation outside of traditional markets, especially in light of current challenges.
By tapping into talent in various countries, enterprises can first reduce geopolitical risks, then save on budgets and access a larger talent pool with a wide range of skills and expertise. Amid the global IT talent shortage, this blend of cost-efficiency, talent and resilience can give companies a significant competitive edge.
From my observations, there are three emerging markets in particular to pay attention to for global tech talent: Colombia, Poland and Vietnam. Each of these markets has its pros and cons.
Vietnam
I’ll start with the country I’m most familiar with—Vietnam. Vietnam has several advantages, including relative political and economic stability, a strategic location in the heart of Asia, a highly-emphasized education system and low-cost internet connectivity for its people.
The country also boasts a resourceful IT and tech workforce that is known for its diligent work ethic. According to the Vietnam Software Association (VINASA), as of 2023, there are 1.3 million workers in the country’s software and IT services industry. Vietnam has also been recognized internationally. Notably, as Reuters reported in September 2023, the U.S. and Vietnam entered a “historic partnership” when U.S. President Joe Biden “secured deals with Vietnam on semiconductors and minerals.” Reuters also mentioned Vietnam’s “growing importance as a ‘friendshoring’ destination for U.S. technology companies,” which was indicated by the fact that senior executives from some prominent U.S. technology companies, including Google and Intel, were at the summit between the two countries.
However, Vietnam has some drawbacks as well. For one, the country needs to work on improving its infrastructure. It also needs to improve the enforcement of its intellectual property laws to become a truly ideal development hub for businesses worldwide.
Colombia
Then there’s Colombia. The Latin American country is geographically convenient for U.S.-based companies; if need be, executives can travel there faster than they can to Poland and Vietnam. It has a decent information and communications technology (ICT) market. Per 2022 reporting by La República, there were 152,000 IT job openings in the country in 2021, albeit the country’s Ministry of Information Technologies and Communications estimates that there will be a shortage of between 68,000 to 112,000 software developers. Additionally, as the U.S. Department of Commerce’s International Trade Administration noted, the country is “generally open and business-friendly.” However, the International Trade Administration also identified some drawbacks of doing business in Colombia, including “unpredictable bureaucratic processes” and regulations that can, at times, change “without adequate notification.”
Poland
As for Poland, its location is less geographically convenient than Colombia for U.S. businesses. A more serious issue, however, is that Poland’s economic growth is “expected to be impacted by the Russian war in Ukraine,” as stated by the U.S. International Trade Administration.
On the bright side, the organization also stressed that Poland “ranks favorably when it comes to cross-border trading and credit access,” and corruption is “not a widespread problem” there. What’s more, using BMI Research as a source, the International Trade Administration stated that the forecast for Poland’s IT sector “remains positive, although it varies greatly depending on the market segment.” In fact, a 2023 report by Emerging Europe noted that in Poland, the number of ICT specialists has “been consistently increasing, with 486,000 employed in 2021 compared to 369,000 in 2015.” Additionally, in a 2022 report, international education company EF Education First deemed Poland as a country with very high English proficiency, giving the country an advantage over Vietnam and Colombia.
Best Practices For Talent Acquisition Abroad
Regardless of which country a company sets its sights on for talent acquisition, certain
practices will help its leaders increase their chances of success. From my experience, three steps are particularly crucial.
First, business leaders should conduct in-depth market research, understanding the country’s current and projected economic environment and where a particular industry is headed. As part of their market research, they should conduct site visits and leverage available government support. Before going full-scale into the new country, the company should start a proof-of-concept project to get an idea of what working there is like, and to properly plan for future oversight of operations.
This brings me to my next point: Partnering with local companies is vital, as those leaders will have insider knowledge, including about the talent pool, that will prove advantageous. However, companies must define specific outcomes and measure the progress toward those outcomes, especially after they outsource talent. Keeping track of metrics will maximize the chances of success, as it will keep various team members aligned with the company’s goals.
Finally, keeping an ideal ratio of onshore and offshore engineers in a software project is key. For every nine offshore engineers, I recommend that there be one onshore engineer serving as a bridge between the company and its offshore team. This is my effective practice to ensure all technical requirements are clearly understood and to streamline communication, which eventually translates into timely project completion and overall successful global operations.
If company leaders apply these best practices, they can leverage global talent from potential untapped markets, which can be a crucial opportunity to stay ahead of the competition.
Forbes Technology Council is an invitation-only community for world-class CIOs, CTOs and technology executives. Do I qualify?",https://imageio.forbes.com/specials-images/imageserve/652eece0b198c83bdf70f5d8/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds,2023-10-18 09:00:00
https://interestingengineering.com/science/energy-crisis-iea-directs-for-50-million-miles-of-new-power-lines,Energy crisis: IEA directs for 50 million miles of new power lines,"The world needs to act fast to improve and expand its electricity grids or risk facing a climate catastrophe and frequent blackouts, a new report by the IEA, aka The International Energy Agency, said recently.Electricity grids are the lifelines of modern societies, powering homes, factories, offices, and hospitals. They are also crucial for the transition to clean energy, as more and more electricity comes from solar, wind, and other low-carbon sources. However, the report titled Electricity Grids and Secure Energy Transitions found that grids must catch up with the pace of change and innovation in the energy sector.The report warned that grids could become a bottleneck for deploying renewables and electrifying transport and heating without more investment and policy support. This could jeopardize the goal of limiting global warming to 1.5 °C and threaten energy security.To meet all national climate and energy targets, the world will need to add or replace 50 million miles (roughly converted from 80 million kilometers) of power lines by 2040 – the same as the length of the existing grid. By 2030, the operation and regulation of grids will require significant reforms, and annual investment in grids will need to be doubled to over USD 600 billion.Sources: IEA analysis The report also highlighted the growing backlog of renewables projects waiting to be connected to the grid. It is estimated that there are 1,500 gigawatts of solar PV and wind projects in advanced stages of development – enough to power over a billion homes – but they are stuck in limbo due to grid constraints.IEA Executive Director Fatih Birol stated that the world is experiencing an unparalleled clean energy transition. However, he warned that this could be at risk unless immediate action is taken to improve our electricity grids. Birol emphasized the importance of investing in grids to avoid potential gridlock and guarantee a stable and sustainable energy future. He also cautioned that failing to invest in grids could result in a much higher cost in the future.The report also stressed the importance of grids for coping with the rising demand for electricity as more people switch to electric cars and heat pumps. These new technologies can help reduce emissions but also require more power lines and innovative distribution networks to ensure reliable supplies. The report also called for more flexibility in grids, such as through demand response and energy storage, to balance the variability of solar and wind power.The report presented a new scenario called the Grid Delay Case, which showed the consequences of failing to upgrade grids in time. It projected that CO2 emissions from the power sector would be almost 60 billion tonnes higher between 2030 and 2050 due to a slower expansion of renewables and a higher reliance on fossil fuels. This would make it impossible to achieve the Paris Agreement goal of limiting global warming to 1.5 °C and increase the likelihood of exceeding two °C by 40%.The report also suggested some strategic actions that can help improve grids, such as building more cross-border and regional interconnections to share power across different areas and increase resilience. It also urged countries to integrate more solar and wind power into their grids by adopting best practices and standards for grid planning, operation, and regulation.The report urged governments to back large-scale transmission projects to ensure that grids are prepared for further strong growth in renewable power. It also encouraged grid developers and operators to embrace digitalization to make future grids more resilient and flexible.Given the long lead times for modernizing and extending grids, the report emphasized the urgency of taking action. It said that new grid infrastructure often takes 5 to 15 years to plan, permit, and complete – compared with 1 to 5 years for new renewables projects and less than two years for new charging infrastructure for electric vehicles.The report also called for more vital international collaboration to improve and expand grid infrastructure in countries worldwide. It noted that emerging and developing economies, excluding China, have seen a decline in grid investments in recent years despite robust electricity demand growth and ongoing efforts to meet energy access goals.The report quoted Birol as saying that ensuring the developing world has the resources it needs to build and modernize electricity grids is essential for the international community. He said that by mobilizing financing, providing access to technology, and sharing best practices on policies, leading economies can help improve people’s lives, strengthen sustainable development, and reduce the risks of climate change. ",https://dnd2oi6izkvoi.cloudfront.net/2023/10/18/image/jpeg/d2lTvJJFbVwiwC3Y77oKEUq7fG6TFmLiftLmQggs.jpg,2023-10-18 00:00:00
https://interestingengineering.com/military/insitu-pacific-innovaero-australian-uas,New all-Australian UAS-loitering munition tag team announced,"Two Australian companies, Innovaero and Boeing subsidiary Insitu Pacific (IPL), intend to collaborate to develop a new loitering munition and intelligence, surveillance, and reconnaissance (ISR) combination for the Australian Department of Defense. The new system will provide Australia with a long-range strike capability using uncrewed aircraft systems (UAS). The combination includes IPL's ""Integrator"" ISR UAS and Perth-based Innovaero’s ""One-Way Loitering"" (OWL) munition.“This unified approach would combine uncrewed intelligence, surveillance, and reconnaissance (ISR) and long-range strike capabilities to rapidly deliver direct effects in the engagement zone without the need for crews in larger air assets being put at risk,” said Andrew Duggan, Managing Director of Insitu Pacific in a press release. “The concept is designed to achieve seamless integration with current Australian Defence Force systems, including the Integrator, and offers great potential to become an integral strike asset,"" he added. The IPL ""Integrator"" is, according to IPL, an advanced version of the UAS and is designed to provide Group 4 and 5 capabilities in a Group 3 UAS. According to the Federal Aviation Administration (FDA), ""Groups 4 and 5 are the largest of DoD UAS, weighing over 1,320 pounds [(598 kg)] and operating at all speeds and altitudes. Group 4 aircraft operate at all altitudes, usually below 18,000 feet [(5,486 meters), mean sea level (MSL)]. Group 5 aircraft typically operate well above 18,000 feet MSL."" Group 3 are UAS that weigh more than 55 pounds [(25 kg)] and less than 1,320 pounds, operate below 18,000 feet, and have a top speed of 250 knots (463 kph). With the addition of satellite-enabled beyond line of sight (SATCOM BLOS), the ""Integrator"" UAS is capable of extended ranges that can help reduce logistical challenges and improve the safety of field personnel. According to IPL, ""Integrator"" has over one million operational hours of experience, making it one of the most innovative and reliable unmanned aircraft systems available in the industry today.Innovaero's ""OWL,"" developed in collaboration with BAE Systems Australia, is an electrically-powered munition with a maximum range of nearly 124 miles (200 km). It can loiter at a range of 62 miles (100 km) for up to 30 minutes. According to Innovaero, precision targeting of stationary and moving targets is achieved using an electro-optical/infrared camera. Additionally, it has a range of anti-armor and fragmentation warheads that can weigh up to 15 pounds (7 kg).""Together, the companies will develop, test, and field the collaborative system using Insitu Pacific’s common ground control station (GCS) and INEXA software to control UAS and long-range OWLs. Operators would command both assets through the common GCS,"" explains Innovaero. The announcement strengthens the partnership between Insitu Pacific and Innovaero to develop Australian technology for uncrewed aerial systems, as outlined in a Memorandum of Agreement established in July 2021.“The versatility of the proposed combined ISR and strike solution provides a significantly shorter ‘sensor to shooter’ loop to engage emerging threats,” said Simon Grosser, Innovaero Group CEO. “Our collaboration with Insitu Pacific builds on our work with Defence in Australia to develop an Australian loitering munitions capability and offers an integrated solution for long-range UAS target detection and effective engagement,"" he added. Development and testing for the Integrator/OWL system will continue through 2023. ",https://dnd2oi6izkvoi.cloudfront.net/2023/10/18/image/jpeg/pLLJ90kKSRqgr37RROZxOrgvkYwsuVnMofRViigP.jpg,2023-10-18 00:00:00
https://interestingengineering.com/innovation/breakthrough-mini-device-converts-molecular-movement-into-electricity,Breakthrough: Mini device converts molecular movement into electricity,"Energy is a critical component of modern human civilization, supplying electricity to houses, factories, and transportation. As the world's population and demands grow, sustainable energy sources and efficient use become critical for the long-term future.In a major development, a tiny device has harnessed the motion of molecules in room-temperature liquid to generate electricity.This innovative technological solution promises to create a clean and readily available energy source for low-power devices, entirely self-sufficient and not reliant on any external energy sources.As per the New Scientist report, this device may find applications in energizing items such as tiny medical implants and even small household gadgets in the future. Molecules are constantly in motion because they have thermal energy — even when they seem stationary to our eyes.For instance, even though a glass of water appears to be still, the individual water molecules continually vibrate and clash with one another, resulting in this seemingly undetectable motion. This underlying molecular mobility is a basic property of matter at every temperature above absolute zero.“We thought it would be interesting and meaningful to see if this motion can be harvested and converted into electricity,” Wei Li at Nankai University in China told New Scientist. The study team created a small energy-harvesting device that is only one square centimeter, called a molecular thermal motion harvester (MTMH). This device has two electrodes, one on top and one on the bottom, each having several 25-nanometer-wide strands of zinc oxide attached to it. Reportedly, zinc oxide was chosen as the material because of its ability to generate an electrical charge when mechanically deformed.The harvesting device was then placed in a container filled with n-octane – a hydrocarbon comparable to propane or butane but with a longer chain of carbon and hydrogen atoms. This process occurred at room temperature.APL materials The experiment results indicated that when the molecules in the liquid came into contact with the microscopic zinc oxide strands, they generated a small voltage of 2.28 millivolts and a current of 2.47 nanoamperes.“The energy of the thermal motion of octane can be converted into electrical energy through the device based on the piezoelectric properties of ZnO and a nano-array structure,” mentioned the study. The team also aims to examine whether different solvents or liquids can efficiently serve as power sources for this device.The researchers believe the gadget might provide energy for nano-scale devices such as implants for medicine delivery and therapeutic purposes. The team hopes to advance this technology further to power more complex applications with high efficiency. The results were reported in the journal APL Materials.Study abstract: Molecular thermal motion has been studied yet never utilized as an energy source. In this work, we demonstrate that the energy of liquid molecular thermal motion can be converted into electrical energy by a novel harvesting device, the molecular thermal motion harvester (MTMH). The MTMH was made by using two ZnO-based nano-arrays and one of which was gold coated to form a Schottky junction. The assembled electrodes were immersed in different liquid phase environments. The device was demonstrated to convert the molecule thermal energy of the liquid into a continuous and stable electric current. The output voltage and current can achieve 2.28 mV and 2.47 nA, respectively, and increase with the liquid temperatures. This strategy opens new insights into the development of mini- and micro-scale energy sources, and it can be expected the MTMH will have broad applications in the future. ",https://dnd2oi6izkvoi.cloudfront.net/2023/10/18/image/jpeg/YIhcH7kUcGmQgkRZysYvOJgv69WXFomxo3rTy8Nv.jpg,2023-10-18 00:00:00
https://interestingengineering.com/innovation/undersea-cables-reshape-earthquake-preparedness,How old undersea cables could reshape earthquake preparedness,"A new study has found a way to use old telecom cables lying under the sea as earthquake sensors, which could save precious seconds in warning people of impending tremors. The researchers used a method called Distributed Acoustic Sensing (DAS) to turn 31 miles (50 kilometers) of fiber optic cable between the US and Chile into thousands of seismic detectors.The study, published in The Seismic Record, was led by Jiuxun Yin, a former Caltech researcher who now works at SLB. He and his colleagues analyzed the seismic data from 8,960 channels along the cable for four days and detected three earthquakes, one on land and two in the ocean.They found that the offshore DAS array could improve the earthquake early warning (EEW) by about three seconds compared to the onshore DAS arrays. They also simulated how multiple offshore DAS arrays spaced 31 miles (50 kilometers) apart could work together to reduce the EEW alert time by five seconds in the subduction zone, where one tectonic plate slides under another.Yin said that the offshore location of the DAS array was the critical advantage, as it eliminated the delay caused by the seismic waves traveling to the land-based stations. He said they were surprised by how much faster the offshore DAS array was than their initial expectations.TSR doi.org/10.1785/0320230018 The study focused on the region off the coast of Chile, which is prone to powerful and frequent earthquakes due to its active subduction zone. The same is true for the Cascadia region off Canada, the US Pacific Northwest, and even Southern California, where many faults have produced strong quakes. In these densely populated coastal areas, offshore EEW could help save lives and property from earthquake damage.Yin explained that they chose the cable off Chile because of its high seismic risk. He said Chile had witnessed several devastating earthquakes of magnitude eight or more in history, including the largest one ever recorded in 1960. He said there was an urgent need for a reliable offshore EEW system in Chile.The researchers used a deep-learning artificial intelligence model to identify the earthquake waves from the DAS data of the offshore cable. Yin said this was a fast and efficient option for real-time applications like EEW, as DAS data was vast in volume. He added, however, that other traditional seismological methods could also work well with DAS data with automation.Yin also revealed that there were more than 1,500 cable landing stations around the globe and that the progress in the technology allowed them to use operational cables and add DAS systems without affecting data transportation. He expressed his belief that this opened up many exciting research opportunities and that he and his colleagues were eager to explore them in future studies. He said they sought close interactions with cable owners, environmental agencies, and policymakers to scale up the DAS-EEW to benefit coastal communities.Yin said more data from significant earthquakes was needed to develop and test EEW algorithms effectively. More information is needed on how DAS instruments behave before building a real-time EEW system that integrates with existing EEW frameworks.He said there were many places worldwide where this research could be continued and expanded.The study was published in The Seismic RecordStudy abstract:We present a real‐data test for offshore earthquake early warning (EEW) with distributed acoustic sensing (DAS) by transforming submarine fiber‐optic cable into a dense seismic array. First, we constrain earthquake locations using the arrival‐time information recorded by the DAS array. Second, with site effects along the cable calibrated using an independent earthquake, we estimate earthquake magnitudes directly from strain rate amplitudes by applying a scaling relation transferred from onshore DAS arrays. Our results indicate that using this single 50 km offshore DAS array can offer ∼3 s improvement in the alert time of EEW compared to onshore seismic stations. Furthermore, we simulate and demonstrate that multiple DAS arrays extending toward the trench placed along the coast can uniformly improve alert times along a subduction zone by more than 5 s. ",https://dnd2oi6izkvoi.cloudfront.net/2023/10/18/image/jpeg/UquRXexee4t7OVFLRXPh7Ao94ZRvIsiMZvG0xPan.jpg,2023-10-18 00:00:00
https://interestingengineering.com/innovation/nvidias-ai-bites-nails-as-us-halts-advanced-chipset-sales-to-china,Nvidia’s AI bites nails as US halts advanced chipset sales to China,"The US administration has gone forward with its objective of limiting China's access to advanced chipsets made in the country by introducing further regulations. A year back, the US announced new laws prohibiting companies operating out of its soil from selling specific chips used in supercomputing and AI to Chinese corporations. The limitations also targeted foreign enterprises that utilize US equipment. The Western superpower is engaged in an arms race with its Eastern counterpart, and such curbs are designed to limit the use of such cutting-edge semiconductors for military uses. According to information accessed initially by Reuters, chips intended for consumer items such as laptop computers would be excluded from the new tariffs. Corporations must notify the Commerce Department when processing orders for the most potent consumer chips to ensure they are not utilized in ways that endanger national security.The new updates to the rule were necessitated as many firms found a way to bypass the restrictions on exporting such chipsets. Nvidia, the world's most valuable chipmaker, was prevented from sending two of its most sophisticated AI chips to Chinese clients last year, processors that have become the industry standard for building chatbots and other AI systems. However, Nvidia quickly created other variations for the Chinese market that were less complex and circumvented US export limits. The H800 processor, for example, has the same computational capability as the company's more powerful but banned H100 device at particular settings used in AI work. Nvidia has now released a filing saying that the new export limitations will prevent the sale of two high-end AI processors explicitly designed for the Chinese market, the A800 and H800. It also stated that one of its gaming chips will be disabled. China accounts for up to 25% of its data center chip sales income. The US has maintained that such curbs are required to ensure that China does not use such advanced chipsets to manufacture weapons that may specifically target the country's cybersecurity initiatives. China has responded by alleging that the US restriction is intended to suppress its firms from advancing their businesses. ""The US needs to stop politicizing and weaponizing trade and tech issues and destabilizing global industrial and supply chains. We will closely follow the developments and firmly safeguard our rights and interests,"" Mao Ning, China's foreign ministry spokesperson, said. The relationship between the superpowers is hitting new lows after the trade war seen under the leadership of President Trump in 2018-19. In retaliation to the US curbs on chipsets last year, China restricted exports of two strategic materials in the semiconductor industry, gallium and germanium. Over the years, China has been moving some of its foreign-goods imports away from the United States. Both are concerned that the other side may suddenly weaponize trade flows, cutting off imports or exports in the name of security. According to statistics from 2022, US exports are lagging behind global counterparts selling into the Chinese market. Once significant, US-manufactured exports, such as automobiles and airplanes, have vanished. Unsurprisingly, the semiconductor sector sales also fell in 2022 and are unlikely to recover owing to a new US export control regime. US service exports plummeted during the epidemic and have yet to recover.According to the Semiconductor Industry Association, the new curbs go a step forward in national security and risk harming the industry. ""Overly broad, unilateral controls risk harming the US semiconductor ecosystem without advancing national security as they encourage overseas customers to look elsewhere. Accordingly, we urge the administration to strengthen coordination with allies to ensure a level playing field for all companies,"" said SIA. ",https://dnd2oi6izkvoi.cloudfront.net/2023/10/18/image/jpeg/guvxqzCIOdZ9bT5RxMPU8S6IxUnUKcou6kgNgu7G.jpg,2023-10-18 00:00:00
https://interestingengineering.com/science/nasa-starts-planning-of-the-roman-telescopes-future-observations,NASA starts planning of the Roman telescope's future observations,"A new sophisticated telescope will soon join the next generation of advanced space observatories. NASA is making preparations for the launch of its next major astronomical observatory, the Nancy Roman Space Telescope, scheduled for 2027.The agency has already begun working with the space community to prepare plans for observations using the Roman telescope.In fact, NASA intends to begin cosmic investigations soon after the successful deployment of the telescope in the Lagrange point. “We’re harnessing the science community at large to lay a foundation, so when we get to launch we’ll be able to do powerful science right out of the gate. There’s a lot of exciting work to do, and many different ways for scientists to get involved,” said Julie McEnery, Roman’s senior project scientist at NASA’s Goddard Space Flight Center in Greenbelt, Maryland, in a NASA blog post. This cutting-edge telescope, originally known as the Wide Field Infrared Survey Telescope (WFIRST), will be critical in advancing our understanding of the cosmos, from the nature of dark energy to the discovery of exoplanets and other astrophysical research.The newly selected infrastructure teams will play a critical role in the initial phase by engaging in activities such as producing simulations, fine-tuning the telescope's components, and more. This will enable scientists to harness the telescope's capabilities as soon as it is launched.In essence, this initiative will equip scientists with the necessary tools to study countless cosmic entities and contribute to solving various enigmas, such as the nature of dark energy.Among the preparatory efforts, telescope simulations are of crucial importance. These simulations will enable the space community to evaluate algorithms, predict the scientific output of the Roman telescope, and refine the strategies employed for observations.“The preparatory work is complex, partly because everything Roman will do is quite interconnected. Each observation is going to be used by multiple teams for very different science cases, so we’re creating an environment that makes it as easy as possible for scientists to collaborate,” said McEnery. Interestingly, one team is developing software for processing and interpreting data from the Roman telescope's Coronagraph Instrument. This instrument will showcase its prowess in directly obtaining images of exoplanets. This development has the potential to be a game-changer for a field that is still relatively young. Furthermore, scientists will simulate numerous stellar processes and occurrences as well. Machine learning algorithms will assess models’ ability to detect these phenomena automatically.Developing quick and practical approaches for discovering underlying patterns is critical for this mission. The telescope is anticipated to accumulate 20,000 terabytes (20 petabytes) of observations, encompassing trillions of individual measurements of stars and galaxies throughout its five-year primary mission.The Nancy Roman Space Telescope will serve the valuable role of identifying intriguing celestial targets. These discoveries will provide observatories like NASA's James Webb Space Telescope with specific areas to focus on for more comprehensive and detailed scientific investigations.These efforts will immensely benefit teams and individuals worldwide who will collaborate to optimize the scientific capabilities of the Roman telescope. ",https://dnd2oi6izkvoi.cloudfront.net/2023/10/18/image/jpeg/GQvbEANLPY8JqGPy0klht3bWkU73stIkWrUklT5L.jpg,2023-10-18 00:00:00
https://interestingengineering.com/innovation/superlensing-microscope-without-superlens,Scientists invent superlensing microscope without a superlens,"Physicists at the University of Sydney Nano Institute in Australia have invented a superlensing microscope that does not actually use a superlens, a press release said. The invention is expected to help advance imaging in areas such as medical diagnostics, archaeology, and forensics. In the 17th century, Dutch microbiologist Antonie van Leeuwenhoek opened up a whole new world of smaller objects and microorganisms with his invention of the microscope. Over the years, scientists have been working to increase the power of these microscopes to peer deeper into this world and understand how it works. However, scientists soon came across the physical limitations of light waves. Objects smaller than half of the wavelength of light could not be observed using the optical approach. This is known as the diffraction limit. To advance, science now needed a superlens that could overcome this hurdle. A superlens is a lens made from metamaterials that can work beyond the diffraction limit. Different materials have been used in the past to make superlenses, and they work by producing a negative refractive index to produce nanometer-sized images. Superlenses typically work in close proximity to the object being examined. This is because the lenses work to capture high-resolution information that decays as it travels further. The low-resolution data does not decay quickly but the close proximity of the superlens distorts the image. In worst-case scenarios, superlenses absorb too much light and render their usage meaningless. A research team led by Alessandro Tuniz at the University of Sydney Nano Institute has found an alternate way to capture images of objects smaller than the diffraction limit by avoiding the superlens altogether. Uni Sydney Tuniz's team approached the issue at hand by placing the light source far away from the object. This way, they could capture both high and low-resolution information coming from it. Previous studies have also shown that keeping the probe further away ensures that it does not interfere with high-resolution data. By moving the probe away, the team was successful in maintaining the integrity of the high-resolution data and filtered out the low-resolution data using a post-processing step on the computer to get a clear final image. ""This produces a ‘truthful’ image of the object through the selective amplification of evanescent, or vanishing light waves,"" said Tuniz in the press release. ""This technique is a first step in allowing high-resolution images while staying at a safe distance from the object without distorting what you see.""The researchers used light at terahertz frequency at millimeter wavelength, in the region between visible and microwave, which is useful for biological imaging such as visualizing protein structures or cancerous cells. However, that's not all. ""Our method could be applied to determine moisture content in leaves with greater resolution, or be useful in advanced microfabrication techniques, such as non-destructive assessment of microchip integrity,"" added Boris Kuhlmey, associated professor at Sydney Nano, who was involved in the work. (It) could even be used to reveal hidden layers in artwork, perhaps proving useful in uncovering art forgery or hidden works.""The research findings were published in the journal Nature Communications. ",https://dnd2oi6izkvoi.cloudfront.net/2023/10/18/image/jpeg/C3ZX11a3hmassAYQQQ21jcDceTzEsXvM8nQS8eaq.jpg,2023-10-18 00:00:00
