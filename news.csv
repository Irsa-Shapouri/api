Link,post_title,post_content,featured_image,Date-Publish,post_category,post_tag
https://techxplore.com/news/2024-03-quantum-algorithm-high-quality-solutions.html,Novel quantum algorithm proposed for high-quality solutions to combinatorial optimization problems,"Combinatorial optimization problems (COPs) are prevalent in various fields such as logistics, supply chain management, machine learning, material design, and drug discovery. These problems involve finding the optimal solution to complex issues. However, solving COPs using classical computers can be computationally intensive. This has led to a growing interest in leveraging quantum computers to solve COPs more efficiently.

Quantum computers utilize the quantum property of superposition, utilizing specialized qubits that can exist in multiple states simultaneously. This property allows quantum computers to quickly solve large problems. However, when COPs involve constraints, traditional quantum algorithms face challenges in obtaining near-optimal solutions within the operation time of quantum computers.

Recent advancements in quantum technology have introduced devices such as quantum annealers and gate-type quantum devices, which provide suitable platforms for solving COPs. However, these devices are susceptible to noise, limiting their applicability to quantum algorithms with low computational costs.

To tackle this challenge, Assistant Professor Tatsuhiko Shirai and Professor Nozomu Togawa from Waseda University in Japan have developed a post-processing variationally scheduled quantum algorithm (pVSQA). This algorithm combines variational scheduling with a post-processing method to transform infeasible solutions into feasible ones, enabling the achievement of near-optimal solutions for constrained COPs on both quantum annealers and gate-based quantum computers.

The pVSQA algorithm begins by using a quantum device to generate a variational quantum state through quantum computation. This state then produces a probability distribution function that includes both feasible and infeasible solutions within the constraints of the COP. The post-processing method is then employed to transform the infeasible solutions into feasible ones, resulting in a probability distribution consisting solely of feasible solutions. A classical computer calculates the energy expectation value of the cost function using this new probability distribution. By repeating this calculation, a near-optimal solution is obtained.

The researchers conducted performance analyses of the pVSQA algorithm using both a simulator and real quantum devices, such as a quantum annealer and a gate-type quantum device. The experiments demonstrated that pVSQA achieves near-optimal performance within a predetermined time on the simulator and outperforms conventional quantum algorithms without post-processing on real quantum devices.

Dr. Shirai emphasizes the urgency of addressing social issues and believes that efficient solutions to combinatorial optimization problems are essential for achieving transformative societal goals. Examples of these goals include the realization of a carbon-neutral society to combat climate change and the fulfillment of sustainable development goals to tackle challenges such as increased energy demand and food shortages. The pVSQA algorithm developed through this study is expected to play a significant role in realizing these long-term social transformations.

In conclusion, this research represents a significant advancement in the utilization of quantum computers for solving COPs. It holds great promise for addressing complex real-world problems across various domains. With the pVSQA algorithm, researchers and industries can explore new possibilities and find optimal solutions to intricate combinatorial optimization problems.",https://scx2.b-cdn.net/gfx/news/2024/novel-quantum-algorith.jpg,2024-03-25 12:50:38,Innovation,Innovation
https://www.zdnet.com/article/singapore-university-sets-up-ai-research-facility-for-public-good/,Singapore university sets up AI research facility for 'public good',"The National University of Singapore (NUS) has established the AI Institute to drive research in artificial intelligence (AI) for the public good. The institute aims to advance fundamental research, development, and application of AI technologies in areas such as healthcare, urban sustainability, education, finance, and manufacturing. It will also focus on regulating the use of AI to ensure transparency, accountability, and address ethical concerns. The NUS AI Institute will collaborate with industry partners and government agencies to understand real-world challenges and develop talent and technologies. IBM and Google Cloud are among the initial partners, and discussions with other organizations are ongoing. The institute has secured SG$8 million in external research grants and will receive an additional SG$20 million from the university itself. The funds will be allocated to foundational AI research, policy and societal implications of AI, and real-world domain-specific applications.

The research activities of the NUS AI Institute will cover various areas, including AI hardware and software systems, AI theory and reasoning, and AI models for humanities, social sciences, and science domains. The institute aims to develop real-world applications in logistics, manufacturing, energy distribution, and waste reduction. It will also focus on AI governance frameworks to ensure the adherence of AI development and implementation to societal values, ethical guidelines, and legislation. The NUS AI Institute will establish a common repository of AI tools to support research translation and prototyping efforts. It will also provide learning opportunities, including internships, for undergraduate and graduate students in the education sector.

NUS' deputy president for research and technology, Liu Bin, emphasized the importance of developing, deploying, and governing AI technologies to maximize their benefits while addressing challenges and risks. The institute's partnerships with local and international experts in academia and industry will contribute to driving the ecosystem and aligning capabilities. This initiative comes at a time when businesses in Singapore are prioritizing their IT budget on AI and other emerging technologies. According to a study by Colt Technology Services, one in three organizations in Singapore and Hong Kong plan to invest in AI and emerging technologies this year. Improving security and acquiring AI and machine learning capabilities are among the top priorities for IT investment in these markets.

In conclusion, the establishment of the NUS AI Institute reflects Singapore's commitment to driving AI research and development for societal benefits. By focusing on research, talent development, and collaborations with industry partners, the institute aims to address real-world challenges and ensure the responsible and ethical use of AI. With the support of external research grants and university funding, the NUS AI Institute is poised to make significant contributions to the field of AI and its applications across various sectors.",https://www.zdnet.com/a/img/resize/ac999c32ef35ef0fd15d56a18d2f8ddeea0b7198/2024/03/25/2c32ada3-6917-4f0a-b2dd-9e0474dae73f/ai-accountgettyimages-1405004482.jpg?auto=webp&fit=crop&height=675&width=1200,2024-03-25 00:00:00,Innovation,Innovation
https://techcrunch.com/2024/03/25/can-you-hear-me-now-ai-coustics-to-fight-noisy-audio-with-generative-ai/,Can you hear me now? AI-coustics to fight noisy audio with generative AI,"Can you hear me now? AI-coustics to fight noisy audio with generative AI

Noisy recordings of interviews and speeches can be a real headache for audio engineers. But a German startup called AI-coustics aims to solve this problem using generative AI to enhance the clarity of voices in video. Recently, AI-coustics came out of stealth mode with €1.9 million in funding. According to co-founder and CEO Fabian Seipel, their technology goes beyond standard noise suppression and can work with any device and speaker.

The core mission of AI-coustics is to make every digital interaction, whether it's a conference call, consumer device, or casual social media video, as clear as a broadcast from a professional studio. Seipel, an audio engineer himself, co-founded AI-coustics with Corvin Jaedicke, a machine learning lecturer at the Technical University of Berlin. They were inspired to start the company because they often encountered poor audio quality in their online courses and tutorials.

The market for AI-powered noise-suppressing and voice-enhancing software is already quite robust. AI-coustics' competitors include Insoundz and Veed.io. Insoundz uses generative AI to enhance streamed and pre-recorded speech clips, while Veed.io offers a video editing suite with tools to remove background noise. However, AI-coustics believes it has a unique approach to developing the AI mechanisms for noise reduction.

The startup trains its model on speech samples recorded in its studio in Berlin. People are paid to record these samples, which are then added to the data set used to train AI-coustics' noise-reducing model. What sets AI-coustics apart is its unique approach to simulating audio artifacts and problems during the training process. They simulate noise, reverberation, compression, band-limited microphones, distortion, clipping, and more to ensure their model can handle a wide range of scenarios.

While AI-coustics' compensation scheme for creators might raise some concerns, the company is focused on recruiting diverse speech sample contributors to combat bias. They believe that size and diversity are key to eliminating bias and making the technology work for all languages, speaker identities, ages, accents, and genders.

To put AI-coustics to the test, I uploaded three video clips to their platform: an interview with an 18th-century farmer, a car driving demo, and an Israel-Palestine conflict protest. The processed clips had significantly less ambient background noise, and the speakers' voices were much clearer.

Seipel envisions AI-coustics' technology being used for both real-time and recorded speech enhancement. It could potentially be embedded in devices like soundbars, smartphones, and headphones to automatically boost voice clarity. Currently, AI-coustics offers a web app and API for post-processing audio and video recordings, as well as an SDK for integrating their platform into existing workflows, apps, and hardware.

AI-coustics already has five enterprise customers and 20,000 users, with plans to expand their team and improve their speech-enhancing model in the coming months. They generate revenue through a mix of subscriptions, on-demand pricing, and licensing. The company has also built a substantial network of investors and mentors in Germany and the U.K. for guidance and support.

AI-coustics is on a mission to revolutionize audio quality in digital communications. With their unique approach and innovative technology, they are poised to make a significant impact in the industry. The days of struggling to hear in noisy recordings may soon be over, thanks to AI-coustics' generative AI solution.","https://techcrunch.com/wp-content/uploads/2020/08/GettyImages-1009979808.jpg?resize=1200,801",2024-03-25 18:43:01,Innovation,Innovation
https://www.forbes.com/sites/timtreadgold/2024/03/25/us-and-australia-get-cosy-over-critical-metals/,U.S. And Australia Get Cosy Over Critical Metals,"The U.S. and Australia are forging closer ties in the global search for critical metals used in innovative technologies and renewable energy. This development is creating a gap between these countries and China. Two recent deals highlight this trend, one involving lithium, a crucial battery metal, and the other concerning rare earths, which are vital in various applications, including wind turbines.

Pilbara Minerals, a successful lithium mining company in Australia, has expressed its interest in getting closer to the U.S. and taking advantage of the investment incentives available. This is despite the company's partnership with a Chinese company in an expansion project. Pilbara intends to build a lithium conversion plant outside of China and utilize the U.S. Government's Inflation Reduction Act (IRA). The success of this plan is uncertain, but Pilbara's management remains optimistic about its prospects in new battery material markets and the subsidies offered by the U.S.

The Australian Financial Review published a headline that encapsulated Pilbara's plan: ""Pilbara Minerals mulls building a lithium processing plant anywhere but China."" The specifics of how Pilbara will structure a joint venture with a Chinese partner while still accessing the incentives provided by the IRA are yet to be determined.

The second deal between Australia and the U.S. involves finding a solution to a longstanding challenge of monetizing a unique geological structure abundant in rare earths and other critical minerals. The U.S. Export-Import Bank (EXIM), a trade finance arm of the U.S. Government, has shown interest by providing a $600 million letter-of-interest to Australian Strategic Minerals (ASM). This funding will support the final design and development of the Dubbo project in New South Wales, Australia. Furthermore, ASM has awarded a contract to Bechtel, a prominent U.S. engineering and construction firm, to provide ore processing and infrastructure technical services. The involvement of a government financing agency and a major engineering company adds a significant U.S. influence to the Dubbo project, which has been under evaluation for 30 years.

Bechtel will be handling a variety of minerals at Dubbo, including rare earths neodymium and praseodymium, tantalum, niobium, hafnium, and zirconium. Separating these metals poses the initial challenge for ASM, with the subsequent test being the production of required materials at a competitive price.

The Dubbo project has been a focal point for the Australia-U.S. Taskforce on Critical Minerals, which aims to leverage Australia's geological resources for the benefit of U.S. industry. Rowena Smith, CEO of ASM, believes that the Dubbo project is well-positioned to support the joint objectives of Australia and the U.S. in the rare earths and critical mineral sector.

These recent developments signify the growing collaboration between the U.S. and Australia in securing critical metals and highlight their efforts to reduce dependence on China. As the demand for innovative technologies and renewable energy continues to rise, this partnership will play a crucial role in meeting global needs while ensuring a secure and sustainable supply of critical metals.",https://imageio.forbes.com/specials-images/imageserve/660204347dcbbcbc0ad19587/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds,2024-03-25 21:27:14,Innovation,Innovation
https://techcrunch.com/2024/03/25/large-language-models-can-help-home-robots-recover-from-errors-without-human-help/,Large language models can help home robots recover from errors without human help,"Home robots have faced numerous challenges that have hindered their success. Factors such as pricing, practicality, form factor, and mapping have all contributed to repeated failures in the industry. Even when these issues are addressed, there remains the question of how a robot should handle inevitable mistakes.

This challenge extends to consumers as well. While big companies have the resources to address problems as they arise, it is unreasonable to expect consumers to learn programming or hire someone for assistance every time an issue arises. However, researchers from MIT have found a solution to this problem using large language models (LLMs) in the field of robotics.

A study set to be presented at the International Conference on Learning Representations (ICLR) in May aims to introduce a bit of ""common sense"" into the process of correcting mistakes. The study highlights the fact that robots are excellent mimics but lack the ability to adjust to unexpected situations unless specifically programmed to do so.

Traditionally, when a robot encounters an issue, it will exhaust its pre-programmed options before requiring human intervention. This poses a significant challenge in unstructured environments like homes, where small changes can disrupt a robot's functionality. Imitation learning, which involves learning tasks through observation, is popular in the world of home robotics. However, it often fails to account for the countless small variations in the environment that can affect a robot's performance.

The new research addresses this problem by breaking demonstrations into smaller subsets instead of treating them as a continuous action. This approach eliminates the need for programmers to manually label and assign numerous subactions. LLMs come into play by providing a way to describe each step of a task in natural language. The continuous demonstration by a human represents these steps in physical space, allowing the robot to know its stage in the task and recover on its own.

To demonstrate the effectiveness of this approach, the researchers trained a robot to scoop marbles and pour them into an empty bowl. While this task may seem simple for humans, it requires the robot to perform various small tasks. LLMs are capable of listing and labeling these subtasks. In the demonstrations, researchers intentionally disrupted the activity by bumping the robot off course and knocking marbles out of its spoon. Instead of starting from scratch, the system self-corrected the small tasks.

""With our method, when the robot is making mistakes, we don't need to ask humans to program or provide additional demonstrations on how to recover from failures,"" explains Tsun-Hsuan Wang, a graduate student involved in the study.

This research presents a promising approach to help robots adapt and recover from mistakes without relying on human intervention. By utilizing LLMs and breaking tasks into smaller subsets, robots can overcome challenges and continue functioning effectively. This method offers a practical solution to ensure that robots can operate seamlessly in unstructured environments, ultimately improving their overall performance and usefulness.",https://techcrunch.com/wp-content/uploads/2024/03/CommonSense-01-press_0.jpg?w=900,2024-03-25 20:01:06,Innovation,Innovation
https://techxplore.com/news/2024-03-household-robots-common.html,Engineering household robots to have a little common sense,"Robots are becoming increasingly proficient at performing complex household tasks, from cleaning up spills to serving food. Many of these robots learn through imitation, where they copy the motions guided by a human. However, these robots often struggle to handle unexpected situations that deviate from their trained path. To address this issue, engineers at MIT have developed a method that combines robot motion data with the knowledge of large language models (LLMs) to give robots a sense of common sense when faced with disruptions.

The MIT engineers' approach allows robots to logically break down household tasks into subtasks and adapt to disruptions within each subtask. This enables the robot to continue its task without starting from scratch or requiring explicit programming for every failure. The researchers found that blindly mimicking a human's motion trajectories can lead to cumulative errors, which can eventually derail the robot's execution. With their method, robots can self-correct errors and improve overall task success.

The team's new approach is outlined in a study that will be presented at the International Conference on Learning Representations in May. The study's co-authors include graduate students Tsun-Hsuan Wang and Jiayuan Mao, postdoc Michael Hagenow, and Professor Julie Shah.

To illustrate their approach, the researchers used the example of scooping marbles from one bowl and pouring them into another. Traditionally, engineers would move a robot through the motions of scooping and pouring in a single fluid trajectory, providing multiple demonstrations for the robot to mimic. However, the researchers realized that a human demonstration is a continuous trajectory, while the task itself consists of a sequence of subtasks. For example, before scooping, the robot needs to reach into the bowl, and after scooping, it needs to move to the empty bowl.

If a robot makes a mistake during any of these subtasks, it typically has to start from the beginning. To avoid this, engineers would have to explicitly label each subtask and program or collect new demonstrations for the robot to recover from the failure. This level of planning is time-consuming and tedious.

Instead, the researchers discovered that language models could automate some of this work. Language models process vast amounts of text and can generate new sentences based on what they have learned. The researchers found that language models can also produce a logical list of subtasks for a given task. For example, when asked to list the actions involved in scooping marbles, a language model might generate a sequence of verbs such as ""reach,"" ""scoop,"" ""transport,"" and ""pour.""

By connecting the language model's list of subtasks with the robot's physical position or state, the researchers created an algorithm for grounding. Grounding involves mapping the robot's physical coordinates or an image of its state to a natural language label. This algorithm allows the robot to automatically understand its stage in a task and replan and recover on its own.

The researchers' method offers a promising solution to the challenges of robot learning and adaptation. By combining robot motion data with the knowledge of language models, robots can gain a sense of common sense and improve their performance in household tasks. This approach eliminates the need for explicit programming for every failure and allows robots to self-correct errors, leading to overall task success.",https://scx2.b-cdn.net/gfx/news/2024/engineering-household.jpg,2024-03-25 09:48:20,Innovation,Innovation
https://www.forbes.com/sites/timothypapandreou/2024/03/25/generative-ai-healthcare-from-treatment-to-global-wellness/,Generative AI Healthcare: From Treatment To Global Wellness,"A Radiologist Looks at a Patient's Brain Images on an AI-Based App

We are on the cusp of a revolutionary transformation in healthcare. Traditional healthcare systems are outdated, expensive, and difficult to navigate. However, with the advent of generative AI, healthcare is about to undergo a significant change. This powerful technology has the ability to analyze vast amounts of data, identify patterns, and create innovative solutions. It is poised to revolutionize how we approach health and well-being in our daily lives. The timing could not be better, as the healthcare sector is in desperate need of innovation, efficiency, affordability, and improved customer service. But don't worry, AI will not replace doctors. Instead, it will act as a highly skilled assistant, ushering in an era of global wellness, prevention, and personalized care.

AI's Role in Medical Discovery

Generative AI is rapidly advancing in the field of healthcare. It is now capable of accelerating simulations of drug compounds, tailoring individual treatment plans based on genetic makeup, and even designing custom bio-printed prosthetics. Imagine a future where regular check-ups are replaced by constant monitoring of our cells, enabling early detection of diseases and avoiding costly treatments, surgeries, and complications. This once science-fiction concept is becoming a reality. Companies like Google's MedLM and NVIDIA are already utilizing AI to analyze global datasets, identify patterns for early disease prediction, and optimize non-invasive treatments.

The $10 Trillion Business Case for Generative AI in Healthcare

The health and wellness industry is a nearly $10 trillion dollar economy. Despite its size, the current healthcare systems are outdated and inefficient. Introducing generative AI into healthcare offers benefits beyond improved patient care. It has the potential to reduce administrative burdens, allowing doctors and nurses to spend more time interacting with patients and providing personalized care. Furthermore, it can shift the focus from reactive ""sickcare"" to proactive wellness-based healthcare, emphasizing prevention and early detection. The applications of generative AI are vast, and numerous companies are already working on innovative solutions:

- Wellness: Calm, a mobile app that offers sleep meditation and mindfulness exercises, utilizes AI to personalize content and track user progress.
- Chatbots and Agents: EMed offers AI-powered virtual assistants for symptom checking, triage, and connecting patients with appropriate healthcare services. Ada Health provides personalized health information and guidance, offering symptom assessment and potential causes. Woebot Health provides an AI chatbot for cognitive behavioral therapy (CBT) to support individuals experiencing depression and anxiety.
- Pathology: Paige utilizes generative AI to assist pathologists in cancer diagnosis through pathology slide analysis.
- Drug Discovery: BenevolentAI analyzes vast scientific and patient datasets to discover and develop new drugs. Atomwise uses AI for structure-based drug discovery, simulating potential drug interactions with disease targets.
- Robotic Assisted Surgery: Intuitive Surgical is a leader in robotic-assisted surgical systems, such as the da Vinci Surgical System. Auris Health is developing robotic-assisted surgical platforms for complex procedures, including the Monarch Platform for lung cancer surgery.
- 3D Printers: Stratasys specializes in developing custom prosthetics, surgical models, and bioprinting.

These are just a few examples of how generative AI is being used in healthcare. The possibilities are endless, and the potential for transforming the industry is immense.

In conclusion, the integration of generative AI into healthcare is a game-changer. It has the power to revolutionize patient care, improve efficiency, and enhance the overall well-being of individuals. By harnessing the capabilities of AI, we can shift from a reactive approach to healthcare to a proactive one that prioritizes prevention and personalized care. The future of healthcare is here, and it looks bright with generative AI leading the way.",https://imageio.forbes.com/specials-images/imageserve/6602332557114bec935353fe/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds,2024-03-25 22:42:30,Innovation,Innovation
https://techxplore.com/news/2024-03-large-language-simple-mechanism-knowledge.html,Large language models use a surprisingly simple mechanism to retrieve some stored knowledge,"Large language models (LLMs) are incredibly complex tools used in various areas such as customer support, code generation, and language translation. However, scientists still have limited understanding of how these models work. To gain insight into their mechanisms, researchers from MIT and other institutions conducted a study on how LLMs retrieve stored knowledge. Their surprising finding was that LLMs often employ a simple linear function to decode and recover stored facts. These linear functions capture the straightforward relationship between variables and are used consistently for similar types of facts. By identifying these linear functions, researchers can probe the model to understand its knowledge about new subjects and where that knowledge is stored within the model.

The researchers developed a technique to estimate these simple functions and discovered that even when a model provides incorrect answers, it often retains the correct information. This approach could be useful in identifying and correcting falsehoods within the model, thereby reducing its tendency to provide incorrect or nonsensical responses. Despite their complexity, LLMs occasionally exhibit simple mechanisms that can be understood. Evan Hernandez, an electrical engineering and computer science graduate student at MIT, emphasizes the importance of these findings in shedding light on the inner workings of LLMs.

The study was conducted by Hernandez and Arnab Sharma, a computer science graduate student at Northeastern University, along with their advisors and other researchers from MIT, Harvard University, and the Israeli Institute of Technology. The findings will be presented at the International Conference on Learning Representations in May 2024.

LLMs, also known as transformer models, are neural networks that contain billions of interconnected nodes or neurons. These networks encode and process data, and much of the knowledge stored in a transformer can be represented as relations connecting subjects and objects. For example, the relation ""Miles Davis plays the trumpet"" connects the subject (Miles Davis) to the object (trumpet). As a transformer acquires more knowledge, it stores additional facts about a subject across multiple layers. When a user asks a question related to that subject, the model must decode the most relevant fact to provide an accurate response.

The researchers aimed to understand the mechanism by which LLMs decode relational information. Despite their complexity, the models use a simple linear function for decoding. Each decoding function is specific to the type of fact being retrieved. For instance, one function is used to output the instrument a person plays, while another function is used to output the state where a person was born. The researchers developed a method to estimate these linear functions and computed functions for 47 different relations, such as ""capital city of a country"" and ""lead singer of a band.""

While there are countless possible relations, the researchers focused on a specific subset that represents the types of facts that can be expressed through linear functions. They tested each function by changing the subject and verifying if it correctly recovered the corresponding object information.

The study's findings provide valuable insights into the inner workings of LLMs. Despite their complexity, these models often rely on simple mechanisms to retrieve and decode stored facts. This discovery opens up possibilities for identifying and correcting falsehoods within the models, ultimately improving their accuracy and reducing the occurrence of incorrect or nonsensical answers. By understanding these mechanisms, researchers can further enhance the performance and reliability of LLMs.

In conclusion, large language models are powerful tools that have revolutionized various fields. Although their complexity poses challenges in understanding their functioning, researchers have discovered that LLMs often utilize simple linear functions to decode stored facts. This finding not only enhances our understanding of these models but also offers potential strategies for improving their performance and reducing inaccuracies. As scientists continue to explore the intricacies of LLMs, we can expect further advancements in their capabilities and applications.",https://scx2.b-cdn.net/gfx/news/hires/2024/large-language-models-2.jpg,2024-03-25 09:34:06,Innovation,Innovation
https://techxplore.com/news/2024-03-strategy-suppress-strain-propagation-ultrahigh.html,A strategy to suppress strain propagation in ultrahigh-Ni cathodes during fast charging,"To meet the increasing demand of the electronics industry and support the widespread use of electric vehicles, researchers are working on developing advanced battery technologies. One promising approach is the use of nickel-rich layered oxides as cathode materials in lithium-ion batteries (LiBs). These cathodes have the potential to increase battery capacity, improve charging rates, and lower production costs. However, they also face limitations such as capacity degradation and structural instability during fast-charging and long-term cycling.

To address these limitations, researchers from Argonne National Laboratory and other institutes worldwide have introduced a new strategy outlined in a paper published in Nature Energy. They propose the use of epitaxial entropy-assisted oxide coating to suppress strain propagation, which is the main cause of structural deterioration in cathodes during battery operation.

The researchers designed a specialized oxide coating that aligns with the structure of nickel-rich cathodes. These coatings not only enhance the robustness of the cathode materials' surface but also improve ionic conductivity, enabling faster charging of batteries. The coating is based on Wadsley-Roth crystallographic shear phases, which have been found to enhance the performance of LiB electrodes. These compounds adhere well to nickel-rich cathodes, strengthening their structural stability during operation and fast-charging.

In their experiments, the researchers coated nickel-rich layered cathodes and tested their performance over time and under different conditions. The results were highly promising, as the coating significantly reduced damage to the cathodes, even during fast-charging and after multiple operation cycles.

The researchers believe that this epitaxial entropy-assisted coating strategy opens up new opportunities for surface engineering in the design and development of high-energy and high-power LiBs and beyond.

In conclusion, the use of nickel-rich layered oxides as cathode materials in LiBs shows great promise for boosting battery performance. The application of epitaxial entropy-assisted oxide coating can effectively suppress strain propagation and improve the structural stability of cathodes, leading to enhanced battery performance and durability. This innovative strategy has the potential to revolutionize the design and development of advanced battery technologies, supporting the growing demand for electronics and electric vehicles.",https://scx2.b-cdn.net/gfx/news/hires/2024/a-strategy-to-suppress.jpg,2024-03-25 09:40:01,Innovation,Innovation
https://techcrunch.com/2024/03/25/profluent-spurred-by-salesforce-research-and-backed-by-jeff-dean-uses-ai-to-discover-medicines/,"Profluent, spurred by Salesforce research and backed by Jeff Dean, uses AI to discover medicines","Last year, Salesforce initiated a project called ProGen, which aimed to use generative AI to design proteins. The project showed promising results in creating the 3D structures of artificial proteins. However, it didn't progress beyond the research stage. Now, one of the researchers involved in ProGen, Ali Madani, has launched a company called Profluent. Profluent aims to bring protein-generating technology out of the lab and into the hands of pharmaceutical companies. The company's mission is to reverse the drug development paradigm by starting with patient and therapeutic needs and working backward to create custom-fit treatments.

Proteins play a crucial role in the body as they are involved in various functions, such as hormone production and tissue repair. Madani noticed similarities between the language of proteins and natural language like English. He realized that proteins, like words in a paragraph, could be treated as chains of bonded-together amino acids. By feeding protein data into a generative AI model, it becomes possible to predict entirely new proteins with novel functions.

Profluent aims to take this concept further by applying it to gene editing. Many genetic diseases cannot be treated with proteins or enzymes from nature. Additionally, current gene editing systems have functional tradeoffs that limit their effectiveness. Profluent believes that its technology can optimize multiple attributes simultaneously to create custom-designed gene editors that are a perfect fit for each patient.

Other companies and research groups have also explored the use of generative AI to predict proteins. Nvidia released a generative AI model called MegaMolBART, which was trained on a dataset of millions of molecules to search for potential drug targets and forecast chemical reactions. Meta trained a model called ESM-2 on protein sequences, enabling the prediction of sequences for over 600 million proteins in just two weeks. DeepMind's AlphaFold system predicts complete protein structures with remarkable speed and accuracy.

Profluent is training AI models on massive datasets with over 40 billion protein sequences. The company aims to create new gene-editing and protein-producing systems, as well as fine-tune existing ones. Rather than developing treatments itself, Profluent plans to collaborate with external partners to produce genetic medicines with the most promising paths to regulatory approval.

Madani believes that this approach can significantly reduce the time and cost typically required for drug development. It usually takes 10-15 years to develop a new medicine from initial discovery to regulatory approval, with costs ranging from several hundred million to billions of dollars. Profluent's technology offers the opportunity to move from accidental discoveries to intentional design in the field of biology.

Profluent, based in Berkeley and with 20 employees, has received funding from prominent venture capital firms such as Spark Capital, Insight Partners, Air Street Capital, AIX Ventures, and Convergent Ventures. Google's chief scientist, Jeff Dean, has also contributed to the platform.

In the coming months, Profluent plans to upgrade its AI models by expanding its training datasets. The company also aims to acquire customers and partners to accelerate its growth. The competition in protein-generating models is fierce, with rivals like EvolutionaryScale and Basecamp Research raising significant amounts of venture capital.

According to Madani, Profluent has developed an initial platform and demonstrated scientific breakthroughs in gene editing. Now, the company is ready to scale and collaborate with partners to achieve its ambitious goals for the future.","https://techcrunch.com/wp-content/uploads/2022/01/GettyImages-1288172035.jpg?resize=1200,675",2024-03-25 22:08:51,Innovation,Innovation
https://www.zdnet.com/article/my-favorite-linux-text-editors-and-why-you-should-be-using-one/,My favorite Linux text editors (and why you should be using one),"Linux has a long history of text editors, with past editor wars between emacs and vi causing heated debates among users. However, the role of text editors has evolved over time. While they are still commonly used for configuring Linux and writing code, they have also become versatile tools for various purposes such as note-taking, journaling, and even writing novels. Although I have not personally used a text editor to write a full-length book, I have found them to be efficient for short stories and flash fiction.

In this article, I will introduce a few text editors that are suitable for everyday use and cater to the average user. I won't be including emacs or vi on this list, despite their exceptional power, as I believe they can be overwhelming for most users. However, if you find the editors mentioned here to be too simplistic or lacking flexibility, you can always turn to these two powerhouse tools for coding, configuring, and administrative tasks.

Let's begin with nano, which has been my go-to editor for decades. Nano may be basic, but it gets the job done efficiently. It includes all the essential features I need in an editor, without unnecessary complexities. With nano, you can write simple flat text files without any formatting. It offers interactive search-and-replace, undo/redo, syntax coloring, smooth scrolling, auto-indentation, go-to-line-and-column-number, feature toggles, file locking, and internationalization support.

It's important to note that nano is a terminal application, which means it doesn't have a GUI (Graphical User Interface) app. To use nano, you simply open the terminal and issue the command ""nano filename"" (replace ""filename"" with the name of the file you want to edit or create). Nano provides several options, such as ""--backup"" for creating a backup of the previous version of the file, ""--tabstospaces"" for converting typed tabs to spaces, ""--locking"" for locking the file during editing, ""--smooth"" for smooth scrolling, and many more.

Nano is free and comes pre-installed with most Linux distributions, making it easily accessible to users.

Next on the list is Gedit, the default text editor for the GNOME desktop. Gedit is a basic yet effective GUI application that offers a range of features. These include tabs for easy organization, support for internationalized text with UTF-8, syntax highlighting, markdown support, configurable fonts and colors, print support, auto-save, auto backup creation, keyboard shortcuts, theming options, and full-screen mode.

What sells me on Gedit is its simplicity. While I typically default to nano, when I need a GUI, Gedit is my choice. Additionally, Gedit allows me to open text files with a simple click, unlike nano, which requires opening the terminal first. Another advantage of Gedit is its fullscreen mode, which enables distraction-free editing.

Gedit is free and ships with most GNOME-based desktop distributions, making it readily available to users.

Moving on, let's discuss COSMIC Text Editor. Although it will be the default text editor for System76's COSMIC desktop once it is released, the COSMIC Text Editor is already showing great promise. This editor aims to be the Gedit equivalent for COSMIC and offers a standard feature set. These features include syntax highlighting, standard keyboard shortcuts, find functionality, spellcheck, project support, revert changes, document statistics, and even Git management support.

What stands out about COSMIC Text Editor is its dark theme, which I personally find fitting. Like Gedit, COSMIC Text Editor is simple to use and can handle both basic and more complex tasks, such as writing code. If you use Pop!_OS, you can get a preview of COSMIC Text Editor's look and feel by installing it from the Pop Shop.

COSMIC Text Editor is free and will be officially available when the COSMIC Desktop OS is released.

Lastly, let's explore Kate, which is to KDE Plasma what Gedit is to GNOME. Kate offers a slightly more extensive feature set compared to Gedit. It includes features such as multi-cursor and multi-cursor selection, allowing you to select and manipulate multiple strings of text simultaneously. Additionally, Kate provides project support, syntax highlighting, standard keyboard shortcuts, and plugins. The plugins feature allows you to add functionalities such as SQL query support, GDB debugging, one-click project build, and more. Think of Kate as a supercharged version of Gedit, suitable for creating and editing simple text files.

In conclusion, these text editors offer a range of features and cater to different user preferences. Whether you prefer the simplicity of nano, the user-friendly interface of Gedit, the upcoming COSMIC Text Editor for COSMIC desktop, or the feature-packed Kate for KDE Plasma, there is a text editor that suits your needs. Experiment with these editors and find the one that enhances your productivity and makes your writing experience enjoyable.",https://www.zdnet.com/a/img/resize/feda4ca65eefc13df0e3505780d84330ecd3c713/2024/03/25/d964a97e-9c56-444a-9497-19bc7ca26a56/typingclosegettyimages-1341060766.jpg?auto=webp&fit=crop&height=675&width=1200,2024-03-25 00:00:00,Innovation,Innovation
https://techxplore.com/news/2024-03-method-quantum-mechanics-lithium-metal.html,New method that uses quantum mechanics can lead to improved lithium metal batteries,"In a recent study published in Nature Energy, Dr. Perla Balbuena and Dr. Jorge Seminario, professors in the Artie McFerrin Department of Chemical Engineering at Texas A&M University, introduced a groundbreaking method for understanding the impact of external pressure on lithium-metal batteries. By utilizing quantum mechanics, the researchers aimed to gain a deeper understanding of the behavior of lithium ions under pressure, with the ultimate goal of advancing lithium-metal battery fabrication processes to create longer-lasting and more efficient battery technologies.

Dr. Balbuena described the study as a ""beautiful demonstration of the impact of first-principles ab initio analysis on macroscopic process design."" She explained that similar methods could be used to improve chemical and physical processes in various fields, including chemical engineering, electrical engineering, mechanical engineering, materials science, and biology.

This research is part of the ongoing Battery500 Consortium, a collaboration among national labs and academia led by the Pacific Northwest National Laboratory. The consortium aims to develop more reliable and high-performing batteries for vehicles, in line with the goals set out by the Department of Energy.

Lithium-ion batteries have played a pivotal role in revolutionizing mobile electronics, allowing for the development of nanoelectronics and compact devices that can easily fit in our pockets. Despite their widespread use in smartphones, watches, toys, laptops, electric vehicles, and grids, lithium-ion batteries still face numerous challenges. One of the most significant limitations is their energy density, which is restricted by the battery components.

According to Dr. Seminario, lithium-ion batteries function by utilizing two essential electrodes to convert lithium ions into neutral species, storing their energy as chemical energy. These neutral species can then be transformed back into ions, enabling the transport of their energy as electrical energy.

The anode, or the negative electrode, is where the lithium ions possess maximum energy. On the other hand, the cathode, or the positive electrode, has the minimum energy of the lithium-ion. This energy difference explains why lithium ions naturally migrate from the anode to the cathode during discharge, allowing electrons to follow suit externally and power the intended device.

To overcome the limitations of current lithium-ion batteries, researchers have been exploring alternative materials, specifically replacing the traditional graphite anode with lithium metal. Theoretically, this substitution could increase the energy density of the anode by a factor of ten.

However, lithium metal is highly reactive, necessitating innovative control measures, such as applying external pressure to the battery. While the impact of external pressure on cell performance is known, there are no reports exploring its relationship with the electroplating of lithium in large-format pouch cells to enhance overall performance. Additionally, when the battery is assembled and undergoes cycling, its components may experience volume changes, leading to cell swelling and affecting battery performance and cycle life.

The research conducted by the Texas A&M team focused on understanding why pressure can help achieve a nearly uniform distribution of lithium ions on the anode, thereby preventing the formation of dendrites, which are needle-like structures that could potentially short-circuit the battery. Using theoretical-computational techniques, the researchers meticulously analyzed the effects of pressure on lithium-metal anodes.

Dr. Balbuena explained that they employed quantum mechanical analysis to evaluate the trajectories of lithium ions migrating from the cathode to the anode. By understanding these trajectories, they could predict the subsequent electrodepositions on the anode surface, as the anode surface is modified by the pressure effect.

The key finding of this research is that lithium ions tend to detour towards regions with elevated pressure or a higher concentration of lithium atoms on the surface. This behavior arises due to the electric field generated by the lithium-metal anode.

This discovery holds great potential for predicting the behavior of novel materials proposed as components for advanced applications. Being able to predict ion behavior in these conditions could pave the way for widespread use of lithium-metal batteries, developed with less expensive infrastructure and fabrication processes, resulting in longer battery life and increased functionality.

Dr. Balbuena and Dr. Seminario's research has shed light on the impact of external pressure on lithium-metal batteries, providing valuable insights into the behavior of lithium ions under pressure. This knowledge can significantly contribute to the development of more efficient and longer-lasting battery technologies, with implications for various industries and fields.",https://scx2.b-cdn.net/gfx/news/hires/2024/new-discovery-can-lead.jpg,2024-03-25 17:06:08,Innovation,Innovation
https://www.forbes.com/sites/zakdoffman/2024/03/25/google-update-warning-chrome-windows-11-android-iphone/,Google’s New AI Search Goes Horribly Wrong-M Is For Malware,"Google's new AI search feature, known as Search Generative Experience (SGE), has encountered a major setback as it delivers dangerous malware and scams to users. This unexpected outcome has raised concerns about the transition from traditional search to AI-powered search and the potential risks involved.

The purpose of SGE is to enhance search results using generative AI technology, providing users with a more powerful and contextual search experience. However, an SEO consultant recently discovered obvious scams within the search results. Bleeping Computer confirmed these findings and warned about the presence of scam sites that redirect users to unwanted Chrome extensions, fake iPhone giveaways, browser spam subscriptions, and tech support scams.

One of the challenges with generative AI is that the dangers are disguised in friendly and conversational language, making it difficult for users to identify and defend against them. The fraudulent redirects primarily aim to target personal information, generate adware, or promote unwanted subscriptions for commission payments. Some of the links even pose more severe threats by forcing unwanted browser extensions that hijack searches and potentially engage in other malicious activities.

In response to these issues, Google stated that they continuously update their advanced spam-fighting systems to prevent spam from appearing in search results. They assured users that they employ anti-spam protections to safeguard SGE and have taken action to remove the examples of scams that were reported. However, further comments from Google regarding these issues are still pending.

While SGE was initially an opt-in feature, it is now being expanded to a wider user base. Google has started showing SGE AI-powered overviews to users who have not signed up, but this test is currently limited to a small percentage of search traffic in specific categories and is only available in the United States. It includes users who are not logged into a Google account.

It is important to note that the reported examples of scams were from an opt-in Search Labs user, not a general user seeing AI test results. Hopefully, as SGE becomes more widely available, any such issues will have been resolved through improved filters and defenses.

Despite these initial challenges, AI search undoubtedly represents the future of search technology. However, this serves as a reminder to approach the new AI-powered search with caution and not to overlook the importance of safe searching practices, even with the friendly language used in the new search experience.

As search becomes more integrated into generative AI chatbots without the visual presentation of search results, these problems are likely to worsen. Therefore, it is crucial to enhance filters and defenses before implementing such technology on a larger scale.","https://imageio.forbes.com/specials-images/imageserve/6602155031526c87ed877205/0x0.jpg?format=jpg&crop=3115,2027,x1040,y734,safe&height=900&width=1600&fit=bounds",2024-03-25 21:15:00,Innovation,Innovation
https://techcrunch.com/2024/03/25/dma-first-formal-probes/,"Apple, Google and Meta face first formal investigations under EU's DMA","What’s the collective noun for investigations on Big Tech? Because the European Union has just announced a pile of probes on gatekeepers designated under the Digital Markets Act (DMA). Alphabet/Google, Apple, and Meta are facing the first formal non-compliance investigations under the bloc’s rebooted ex-ante competition rulebook.

Alphabet/Google’s rules on steering in Google Play and its approach to self-preferencing in search results are in the frame. For Apple, the EU is also looking at its rules on steering in the App Store and the design of choice screens for alternatives to its Safari web browser. While Meta’s “pay or consent” model will be scrutinized by the Commission.

In total, five investigations were announced Monday — less than three weeks since the compliance deadline kicked in for the companies earlier this month.

The three gatekeepers, which were designated under the pan-EU market power and contestability regulation last fall, face formal investigation in these areas to determine whether they are breaching the rulebook, as the Commission suspects. Confirmed violations of the DMA can result in fines of up to 10% of global annual turnover, or even 20% for repeat offenses.

The EU will have up to 12 months to conclude the investigations, per recommended timeframes in the DMA. A preliminary report can be produced within six months. Although senior Commission officials noted Monday that the probes may conclude sooner or could take longer than these guidelines.

The enforcement action by the bloc comes as antitrust scrutiny continues to dial up on the three U.S. firms on home turf, too.

Since the three companies unveiled their DMA compliance plans, there has been a range of criticism that the proposals do not comply with the new EU law.

Google has been accused of seeking to avoid the regulation’s ban on self-preferencing by launching new rich features in search results that compete unfairly with rivals. While Apple’s use of notifications to users warning them of risks of stepping outside its walled garden has been attacked by developers as “scare screens”, among a number of criticisms. And Meta’s ‘pay or be tracked’ tactic has been roundly condemned as exploitative abuse by privacy and consumer rights groups. (Earlier this month the Commission sent Meta questions about this under the DMA’s sister regulation, the Digital Services Act, too.)

“The Commission has opened proceedings to assess whether the measures implemented by Alphabet and Apple in relation to their obligations pertaining to app stores are in breach of the DMA. Article 5(4) of the DMA requires gatekeepers to allow app developers to “steer” consumers to offers outside the gatekeepers’ app stores, free of charge,” the Commission wrote, saying it’s concerned the pair’s steering measures “may not be fully compliant as they impose various restrictions and limitations”, pointing, for example, to constraints on developers’ ability to “freely communicate and promote offers and directly conclude contracts”.

On concerns about Google self-preferencing, the EU said the investigation will focus on Google’s vertical search services (e.g., Google Shopping; Google Flights; Google Hotels) and the impact its action may have on similar rival services.

“The Commission is concerned that Alphabet’s measures implemented to comply with the DMA may not ensure that third-party services featuring on Google’s search results page are treated in a fair and non-discriminatory manner in comparison with Alphabet’s own services, as required by Article 6(5) of the DMA,” it wrote.

On Apple, the EU will also look at whether it’s complying with a range of user choice obligations on iOS — including enabling end-users to easily uninstall apps, easily change default settings, and prompt users with choice screens which it says “must effectively and easily allow them to select an alternative default service, such as a browser or search engine on their iPhones”.

“The Commission is concerned that Apple’s measures, including the design of the web browser choice screen, may be preventing users from truly exercising their choice of services within the Apple ecosystem, in contravention of Article 6(3) of the DMA,” it added.

On Meta, the EU said the proceedings will investigate whether its recently introduced “pay or consent” model for EU users complies with Article 5(2) of the DMA, noting that this portion of the regulation “requires gatekeepers to obtain consent from users when they intend to combine or cross-use their personal data across different core platform services”.

“The Commission is concerned that the binary choice imposed by Meta’s ‘pay or consent’ model may not provide a real alternative in case users do not consent, thereby not achieving the objective of preventing the accumulation of personal data by gatekeepers,” it said.

Responding to a question about this probe during Monday’s press conference, the EU’s internal market commissioner, Thierry Breton, said the DMA puts a clear requirement on gatekeepers to offer a free, non-p","https://techcrunch.com/wp-content/uploads/2022/05/GettyImages-1031626648.jpg?resize=1200,799",2024-03-25 12:10:10,Innovation,Innovation
https://www.forbes.com/sites/erikkain/2024/03/25/todays-wordle-1011-hints-clues-and-answer-for-tuesday-march-26th/,"Today’s ‘Wordle’ 1011 Hints, Clues And Answer For Tuesday, March 26th","How to Solve Today's Wordle

It's almost the end of March, and what a strange month it has been. Winter has refused to let go, overpowering the budding spring. Although it's sunny today and the snow is melting, we are expecting more snow over the Easter weekend. And then, just after Easter, comes my least favorite day of the year: April Fool's Day. It's probably best to stay offline that day to avoid pranks and jokes.

Interestingly enough, I got my first Wordle on April Fool's Day. I guessed ""march"" because if I were playing a Wordle-style prank, I would choose the only other month with five letters that isn't just a proper noun (April is only a proper noun and therefore cannot be a Wordle answer).

Speaking of proper nouns, yesterday's Wordle really threw me off!

Now, let's get to today's Wordle.

How to Solve Today’s Wordle

Hint: Politician.
Clue: Today’s Wordle ends with a consonant.

Spoiler alert! The answer is revealed below.

Today's Wordle Can you solve today’s phrase? Play Now Credit: Erik Kain

Wordle Analysis

Every day, I check Wordle Bot to see how well I did. You can also check your Wordles with Wordle Bot right here.

I was so confident on my third guess, only to have victory snatched away from me when the third box turned grey. Oh well, that's life! My initial guess was close but not quite there. I had 196 words remaining and only one yellow 'O'. Crane reduced that to 11 and gave me two more yellow squares to work with. I juggled them around and settled on ""major"" because out of all the words I could think of, two had the letter 'M' in them (other options like ""razor"" and ""tarot"" didn't share enough common letters to narrow down my choices). Unfortunately, it was the ""mayor"" and not the ""major"" that was today's Wordle answer.

Competitive Wordle Score

I lose 1 point because the Bot solved it in just three guesses (crane / tyros / mayor — tyros? Really?), and I get 0 points for guessing in four. A total of -1. Sigh.

Today’s Wordle Etymology

The word 'mayor' comes from the Old French 'maire,' meaning ""head of a city or town government,"" which in turn comes from the Latin 'maior,' meaning ""greater"" or ""superior."" The Latin term was used in the title 'maior domus' or 'major domo,' which meant ""chief steward"" of a noble house, reflecting a position of authority and oversight. Over time, 'maior' evolved into various forms in the Romance languages, eventually leading to the English word 'mayor.' The role of a mayor as the leader of a city or municipal government reflects this historical sense of being a superior or chief official within a local jurisdiction.

Check out today’s Strands guide here.

Make sure to visit my blog for daily Wordle and Strands guides, as well as my other writings on TV shows, streaming guides, movie reviews, video game coverage, and much more. Thanks for stopping by!","https://imageio.forbes.com/specials-images/imageserve/654ac7d9543b3152d167c85e/0x0.jpg?format=jpg&crop=2629,1480,x0,y135,safe&height=900&width=1600&fit=bounds",2024-03-25 19:00:26,Innovation,Innovation
