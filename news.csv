Link,Title,Text,Image,Date Publish
https://www.forbes.com/sites/forbestechcouncil/2023/10/17/ai-is-not-a-competitive-advantage-for-startups-heres-why/,AI Is Not A Competitive Advantage For Startups: Here's Why,"Serge Vasin is Partner at Flintera, a startup studio with a private equity arm that's focused on SaaS, blockchain, AI and EdTech.
getty
Artificial intelligence (AI) has become one of the hottest buzzwords in the world of technology. And two things the hype machine is going all in on are the technology’s potential benefits and the disruptions it will bring to businesses.
Because of this, there’s a growing list of startup founders who believe AI is the silver bullet they need to get funded and find success in the market. In fact, of the 282 companies in the Y-Combinator Winter 2023 (W23) batch, over 40% are related to AI or machine learning (ML).
Unfortunately, the assumption that all a startup needs to succeed is AI couldn’t be further from the truth. That’s why founders should not create startups where AI is the only competitive advantage. Areas where companies are almost certainly doomed in this regard are when it comes to things like email applications, web design, language lessons, search, chatbots, code writing and more.
Yet many startups have tried, and continue to try, to make AI the David that will disrupt the big Goliaths in these categories.
How are market leaders incorporating AI?
Startups need to look at the world of AI differently. For the bigger incumbents, the technology is just another feature. It’s simply one more way to monetize what they already have.
Take Wix, the website-building platform, for example. Wix uses AI to enhance its website design and creation process. Wix's AI site generator uses algorithms to create websites based entirely on the user's inputs. The commercial value of Wix's AI implementation comes from the increased customization options and enhanced user experience it can provide to its already captive audience.
Duolingo, the language learning platform, has also upgraded to the tech, incorporating GPT-4 into its newly launched Duolingo Max. The platform leverages GPT-4 to offer a role-playing feature, enabling users to engage with an AI-powered bot and complete a variety of learning-oriented tasks. Duolingo Max also uses GPT-4 within its ""Explain My Answer"" feature, which provides a personalized explanation of why an answer was graded as correct or incorrect.
Another example is the email client Superhuman, which will continue integrating AI to make email workflows faster by automatically analyzing, categorizing and prioritizing incoming emails. The platform already uses generative AI to help customers write personalized emails and responses with just a few prompts. LinkedIn has a similar feature, which enables job candidates to send AI-generated messages to hiring managers. And in June, the company made a similar feature available for B2B marketers.
What are Big Tech's big advantages?
Implementing AI is no longer a vast moat for seasoned market leaders to cross. If a startup can do it, more established technology enterprises can, too. And they can do it well. Unfortunately, many startups in the AI space aren’t transparent about their technology. Many say they have proprietary technologies to gain investment dollars when, in reality, they are using the ChatGPT API.
Big Tech also has these five advantages.
1. Bigger players have an unfair distribution advantage.
One of the main reasons why AI is not a sustainable competitive advantage is that bigger tech players have the upper hand when it comes to distribution. Startups may have cutting-edge AI products, but seasoned enterprises have a massive audience and brand reputation built over time. This established audience can be monetized through AI-powered products and services. This is evident from the examples of Wix's AI Site Generator, Duolingo Max powered by GPT-4 and Superhuman AI.
2. AI can be replicated.
Another reason why AI is not a sustainable competitive advantage is that it can be replicated. While the companies that develop AI have unique algorithms, these algorithms can be reproduced by other tech firms or even individuals. Currently, most AI platforms plug into a handful of models. As a result, they are all the same.
Hence, the technological edge that AI initially offered can evaporate quickly, and startups are left competing in a highly saturated market, which is not an attractive proposition for any new business.
3. Most AI startups don’t have a real competitive advantage.
Startups must have a real competitive advantage to succeed in today's market. Utilizing APIs or open-source algorithms does not constitute an advantage. Startups should invest in their own models and create products that others cannot replicate by simply leveraging an API or copying some open-source code.
4. AI requires human domain expertise.
AI is not a magic pill that can solve all problems independently. It requires human expertise, especially in the specific domain the algorithms are trained on. Unfortunately, startups may not want to use resources to hire domain experts to train their algorithms in the fields they want to disrupt. But this should be a priority.
5. The AI market has become oversaturated.
There isn’t a day that goes by without an AI startup being mentioned in the news. In the future, I believe AI startups will cannibalize each other, especially as more and more of them turn to open-source algorithms and APIs. The market will become more flooded. This will only worsen as LLM tokens become increasingly cheap, just like what happened with bandwidth, data storage and CPUs.
In a flooded market, survival depends on being unique and standing out. That means having innovative algorithms and producing high-quality software solutions. And this is an advantage Big Tech will have over most startups.
Final Thoughts
The increasing popularity of AI and machine learning technology has not spared startups from its lure. Many founders now aspire to build an AI startup and exploit the hype. However, they may not realize that AI is not necessarily the competitive advantage they’ve been dreaming of. At the end of the day, it's not a silver bullet.
That’s why startups betting on AI as their primary competitive advantage may want to rethink their strategies. As the implementation of AI becomes more accessible, startups need to differentiate themselves by creating unique and innovative products that solve real-world problems. This approach will always make a better bet than relying entirely on this new technology.
Forbes Technology Council is an invitation-only community for world-class CIOs, CTOs and technology executives. Do I qualify?",https://imageio.forbes.com/specials-images/imageserve/648c6843d9c37c71b63b363e/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds,2023-10-17 08:00:00
https://www.forbes.com/sites/erikkain/2023/10/17/willow-star-warwick-davis-strikes-back-at-disney-embarrassing/,‘Willow’ Star Warwick Davis Strikes Back At Disney: ‘Embarrassing’,"Willow star Warwick Davis strikes back at Disney. Credit: Lucasfilm / Disney
Willow star Warwick Davis has finally opened up about his true feelings over Disney deleting the Willow TV show off of Disney+ and he is not very happy about it.
Quoth Davis, on Twitter:
“I meet lovely people on a daily basis who are fans of #Willow, who are the reason the @DisneyPlus series was made,” Davis wrote on X (fka Twitter). “Please tell me @WaltDisneyCo, what do I say to these subscribers when they ask why they can’t watch the series any more? #embarrassing”
I have thoughts.
Boy do I have thoughts.
First of all, I love Davis. He’s been a part of my life since I was a wee lad, not much bigger than Elora Danan. I am one of the world’s top superfans of Willow. I love it as much, if not more, than Star Wars. I definitely love it more than Lucasfilm’s other big IP, Indiana Jones, though I love that, too.
One thing that Willow had that these two other big franchises didn’t, was a clean record. Star Wars was great. The OG trilogy is one of my all-time favorites. But then they released the prequel trilogy, which was terrible, and then all the Disney stuff has been, well, relentlessly mediocre outside of a few diamonds in the rough like Andor.
Indiana Jones had a solid trilogy under its belt and then released Kingdom of the Crystal Skull. I haven’t even watched the new one yet because, well, it makes me sad to just think about how badly they’ve ruined Indie. I wish they’d left Star Wars and Indiana Jones alone, even if it mean all we had were old movies to go back and watch, and none of these new stories at all.
(This, by the way, applies even more to George Lucas’s unforgivable edits to the original trilogy, which are among the most ghastly cinematic crimes of all time).
Willow sort of just lived on as its own thing, one single movie with a weird trilogy of sequel books (easily ignored if you didn’t like them) a Zelda-like video game and the occasional random cultural Easter Egg, like the character Elora Danan in Reservation Dogs. The IP was dead, and a big part of me really wished it would come back. For many years I hoped and dreamed that a sequel or a prequel would be made.
I remember when Netflix and the Jim Henson company made the prequel series to The Dark Crystal and it was absolutely fantastic, I thought at the time “This would be so cool if they could do the same thing for Willow and give us a show that really captured the spirit of the movie this well.”
But then Willow actually released on Disney+ and it was . . . nothing at all like the movie. It was like if you took the movie and then sent it to the CW and made it into a show for teenagers (which, as we all know, teenagers don’t even like to begin with). The majority of the cast was suddenly teenage girls (a blond, a brunette, a redhead!) and a couple teenage boys, and Warwick Davis was sidelined entirely.
Willow Credit: Lucasfilm
And believe me, if they’d focused on Elora as the main character that would have been fine. It even makes sense! A story about Elora and Willow and their new pal, Boorman (easily my favorite new character) on a quest to find the missing Madmartigan is a story I could have gotten behind. On their way, they could have run into the Brownies, discovered new and amazing creatures, gotten into some crazy hijinks and so on and so forth.
But instead we got a show with extremely cringey dialogue, bizarrely out of place teen romance subplots, puzzling costume choices that felt cheap and out of place, the constant insertion of modern music into not just the credits, but scenes throughout the episodes—and so much more awfulness that the final product no longer resembled Willow even in the slightest.
This is not the Willow I grew up with. Not even close. It’s bad fan-fiction that seemed to miss the entire point of the original film.
So while I sympathize with Warwick Davis, and genuinely don’t think shows should just be deleted entirely from streaming platforms especially this fast and without some other way of purchasing them (like physical media or VOD) I also think that the most embarrassing thing about the Willow TV show was the show itself. The bad writing, the inability to capture the spirit and feel of the original, the fact that it was so clearly made for “modern audiences” rather than its actual fanbase, that’s embarrassing.
If they’d made a show geared toward fans like me, and captured the actual spirit of the original, I bet it would have been a big hit on Disney+ and I’d bet good money it would have not only not been disappeared, but would be heading toward a second season now. The real shame is that the people in charge of this bungled it so badly they gave the corporate vampires an excuse to delete it for a tax write-off. Nobody wins. Everybody loses.
Stupid Daikinis, will we never learn?
The silver lining is that the original movie still exists on Disney+ and unlike the bastardized OG Star Wars films, Lucas never ruined this with his post-release edits. For this, at least, we can all give thanks.",https://imageio.forbes.com/specials-images/imageserve/63a4964681dc86b3f81d7c75/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds,2023-10-17 08:00:00
https://www.forbes.com/sites/danieladelorenzo/2023/10/17/collective-action-needed-to-reimagine-capitalism-but-indigenous-communities-challenge-sustainability/,"Collective Action Needed To Reimagine Capitalism, But Indigenous Communities Challenge Sustainability","Rebecca Henderson during her keynote speech at the Oslo Business Conference in September 2023 Oslo Business Conference
As the world grapples with the destabilization of the global climate and the looming threat to the economy, the imperative for corporations to unite and address these challenges has never been more pronounced.
John and Natty McArthur University Professor at Harvard Business School Rebecca Henderson, acclaimed author of the 2020 best-seller “Reimagining Capitalism in a World on Fire"", is a fervent advocate for the transformative power of business.
Professor Henderson's insights were on full display at the Oslo Business Forum, a premier annual event, convening over 2,500 Norwegian business leaders and international executives. Here, as a keynote speaker, she championed the concept of every firm, regardless of industry, collaborating to confront the pressing crises that loom over the global economy.
While the Nordic region has sensibly invested in impact funds and embraced sustainability and environmental concerns, this year's Forum aimed to foster further bold leadership in times of uncertainty.
Not just business
In her book, Henderson aligned with the idea of reforming capitalism to make it more environmentally and socially responsible, arguing that businesses and capitalism can be forces for good.
Her research found that the top 10% of businesses driven not only by profit, but also by a sense of purpose and responsibility were often twice as productive as the bottom 10% in the same average industry: “Other economists thought it was a measurement error,” she told Forbes in Oslo.
The book was named after the class she designed at Harvard University where students challenged her beliefs regarding the necessity of reshaping the current capitalist system, suggesting instead to move forward with a different system.
Henderson argues however that business alone can’t guide the change, but politics is decisive when it comes to reform the system and create proper regulations to achieve a sustainable business environment.
Increased interest for sustainability
Since the release of her internationally acclaimed best-selling book, the volume of companies reaching out to Rebecca Henderson for guidance on becoming more purpose-driven and sustainable has surged. What was once a weekly inquiry has transformed into a daily occurrence, with two to three companies per day seeking her expert insights.
Much more has changed since 2020, she told: “In some industries that collective case is sufficiently strong that the industry is starting to try and find solutions,” she told, referring especially to the textile industry as well as the steel and cement ones, that are trying to find lower processes to develop critical material.
Henderson says the wave of interest in transforming business models is further evident in the proliferation of sustainability consultancies and increased global investments in companies focusing on these transformative efforts. These entities are scrutinizing businesses, directing them towards more sustainable practices, and fostering an environment of responsible corporate stewardship. “We see that there's whole new businesses to be created here,” Henderson stated, adding that reducing risk, supporting their supply chain and reducing emissions in the business is another motivation to act for companies and embracing sustainability targets.
Voices unheard: decolonizing sustainability
But as the theory that increasing sustainability of our processes will distance us from traditional capitalism, indigenous communities and minority groups warn of the contrary.
""If we understand capitalism as a system, then sustainability is one of the components that keeps it going – the grease in the machinery, so to speak,"" emphasized Liisa-Rávná Finbog, an Indigenous Sámi scholar from Norway, explaining that capitalism needs the continued existence of its resources to be replenished in order to function.
Indigenous Sámi scholar Liisa-Rávná Finbog on stage during The Big Picture's event ""The tipping ... [+] point of decolonising sustainability"" hosted under the Oslo Innovation Week, September 2023 Alex Asensi
If capitalism has so far worked out fine for some people and fostered inequality, they argue, a reformed capitalism will still not work for everyone, as sustainability will still be approached from a western point of view.
Indigenous communities have long been at the forefront of climate protection efforts, standing as guardians against deforestation and biodiversity loss. Their traditional knowledge, sustainable practices, and profound connection to the natural environment proved them being the most capable of curbing deforestation and effectively restoring previously deforested land.
But their contribution is rarely reflected in what is commonly considered sustainable: ""So whenever the term and the concept of sustainability is impressed upon indigenous societies, but from a Western place of understanding it is also a reinforcement of the capitalistic values, promoted in the West,” Finbog added.
The western world is finding it hard to have a more inclusive and holistic approach to sustainability, one that considers diverse voices and values: “Indigenous values (...), as seen and understood within said system, are considered to be systemic failures; they are mistakes or oversights in the design, too alien to conform or adapt,” said Finborg.
Recent examples are to be found in Norway itself in the clashing case between indigenous communities advocating for the removal of 151 wind turbines from an indigenous region, and the authorities who do not want to remove them although their construction was deemed illegal by the Norwegian Supreme Court already in 2021. More broadly, Australian citizens rejected on October 14 a referendum granting indigenous communities recognition in their country’s constitution.
The Sami scholar's views found a platform at a parallel event to the Oslo Business Forum, organized by the Oslo-based impact agency specializing in sustainability strategy and storytelling, The Big Picture. This event delved into the theme of decolonizing sustainability: “The motivation to organize the event was to kickstart a critical decoloniality discourse among sustainability professionals in the Nordics (...),” said Cinthya Sopaheluwakan, founder of The Big Picture. “We want to start the discussion, however uncomfortable and complex it is, approach it with respect and humility, and not from the perspective of approaching a solution,” she said, hoping this first event could represent the beginning of many more decoloniality conversations in the future in Norway.
Sámi scholar Liisa Rávná Finbog and The Big Picture founder Cinthya Sopaheluwakan on stage during ... [+] the event organised under Oslo Innovation Week 2023. Alex Asensi
New ways to be alive
Asked about the indigenous critique Henderson said to be sympathetic to these communities: “We have a lot to learn from successful indigenous societies. Not only about how to relate to the natural world, but also how to organize ourselves, how to think about what it means to be alive,” she said.
Henderson says she is designing a new course for her students which she says ‘are enraged or in despair’ over the current world’s situation: “(The course) It's about what it means to be human when the world is falling apart. (…) we're going to talk about how to choose hope. And how to find a place to stand when it's easy to think that you can't make a difference.” she said, adding they will also discuss how to identify levers for systemic change.
She further pointed out that, despite the need for lessons from indigenous cultures, with nearly 9 billion people on the planet, harnessing the power of capitalism remains essential for resource allocation and innovation: “I think capitalism needs to be absolutely rebalanced and reimagined. I think it's the best thing we can do. And I fully understand that I could be wrong. But that's what I believe.”",https://imageio.forbes.com/specials-images/imageserve/65281f1590a0d96ad4b7ec62/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds,2023-10-17 07:46:56
https://www.forbes.com/sites/forbestechcouncil/2023/10/17/looking-past-credentials-why-potential-is-key-to-long-term-success/,Looking Past Credentials: Why Potential Is Key To Long-Term Success,"CEO of Syncfusion, leading product development for 1,800 software components and reporting tools for developers on dozens of platforms.
getty
You’ve worked with executive recruiters who have scoured countless applications. You’ve interviewed many candidates and chosen someone with the highest degree from a prestigious institution, the most impressive job history and a proven skill set. Congratulations, you’ve hired a highly qualified individual! You’ve also chosen, perhaps unintentionally, an expensive individual who will likely only stay at your organization for a year or two. Then, you must start that lengthy process all over again.
Hire Based On Potential, Not Credentials
What if you rethink the traditional hiring model? Instead of searching for people with the most expertise, look for people eager to learn and hungry for success. Credentialism—or evaluating an individual based on formal qualifications or certifications—is a limiting factor, undermining the recognition of someone’s true potential. It restricts individuals by implying that they lack the capability to perform certain jobs or learn certain technical skills.
Rocket science isn’t rocket science if you break it down. I say that often, though it may upset some rocket scientists who’ve spent years entrenched in their field! However, those scientists were once math students working on rudimentary equations. They sat in lecture halls in Engineering 101 courses. Then, determined to learn and grow, they built on their knowledge and skills step by step, one course or project at a time.
As long as someone has the willingness to push themselves, there is nothing they can’t learn to do, especially in today’s world with the plethora of resources at our fingertips. For example, a basic understanding of math and spreadsheets and a desire to learn is all an individual needs to become a successful business analyst. I’ve found that the same is true for customer service representatives (a friendly disposition and eagerness to help others), software developers (a course or two in basic coding) and UX/UI designers (an eye for design).
Upskill, Reskill And Promote From Within
Due to the rapid advancement of artificial intelligence (AI)—based technology, expanding global economy and ever-changing market landscape, upskilling is essential to future-proofing your employees and, thus, your company.
Despite technological advancements, human capital remains any organization's most prized and precious resource. Humans have an innate ability to drive innovation and fuel growth. Companies unlock individual talents by investing in people and empowering them to realize their full potential. You’ll witness a remarkable surge in your workforce's overall success and loyalty. According to a Society for Human Resource Management (SHRM) and Epignosis study, 76% of employees are likely to stay with a company that provides ongoing learning and development training. 86% of HR managers agree, reporting that training supports improved retention. (Mark C. Perna’s excellent article, “Why Learning And Development Is Now A Competitive Differentiator” offers for further analysis of the study.)
There are best practices when incorporating learning and development in your organization. Accessible, plentiful mentorship and cross-training opportunities can facilitate a united organization. Promoting from inside your organization incentivizes employees.
It’s also very important not to dwell on human error. By minimizing the focus you place on mistakes, you're sending a message to your team that it's okay to learn, try new things and fix problems in novel ways. This promotes a culture of confidence, resiliency and support. Though this way of thinking starts at the top, it will quickly spread throughout the team, creating a strong sense of connectedness and security.
If you adopt this model and build your experts, you’ll create stars, drastically improving loyalty to your organization and dedication to your customers while lowering attrition rates and filling vacancies more quickly.
Look For Talent In Unconventional Places
I’ve written about hiring from outside the traditional talent pool, such as those without college degrees or from underdeveloped nations. There's plenty of talent around the world. It may not be in the form you imagine, and you have to spend time setting up capabilities to do this kind of hiring. For example, you could work with a nonprofit organization with “boots on the ground” that can help identify and connect you to individuals who, with a bit of training and patience, can become productive, skilled, successful members of your organization.
Much has been said about the tech industry’s talent shortage, and this is one way to address the ultra-competitive labor market. Further, if you’re bootstrapping or running a lean organization, you may not be able to compete with the compensation and incentives offered by larger, well-funded companies. You can, however, create your own talent pool. The added benefit of hiring in unconventional locations is that you can change people’s lives, offering hope and opportunity to those with little resources. All while boosting the global economy. It’s a win-win.
Above All, Be Flexible And Make Adjustments As You Go
Examining and reinventing employee training and development models, recruiting strategies and talent pools take time, patience and adaptability. Be willing to listen to your leadership team and solicit feedback from your employees as you implement new programs and processes. Lean on your existing stars to help craft future stars.
Rethinking traditional hiring by prioritizing potential over credentials can produce remarkable results. Embrace upskilling and reskilling with a robust training program to foster employee growth and enhance loyalty and retention. Create a culture that values learning from mistakes to promote confidence and resilience throughout the organization. Seek talent in unconventional places to address shortages and make a positive impact on the global economy. Lastly, flexibility and adaptability are key as you reinvent your strategies. Look for potential, and you’ll guide your organization toward a brighter future.
Forbes Technology Council is an invitation-only community for world-class CIOs, CTOs and technology executives. Do I qualify?",https://imageio.forbes.com/specials-images/imageserve/64b7eb82c1a5902f985b79a0/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds,2023-10-17 07:45:00
https://www.forbes.com/sites/emilsayegh/2023/10/17/ready-for-cyber-readinessany-time-now/,Ready For Cyber Readiness - Any Time Now,"This Cybersecurity Awareness Month, there is one piece of wisdom that stands above all: the ... [+] importance of being ready to face the unknown. getty
Cybersecurity Awareness Month (CSAM) takes place each October, and is a dedicated month to raise awareness about cybersecurity’s importance. Cybersecurity Awareness Month typically brings forth a wealth of advice aimed at a wide audience. The public is inundated with fundamental recommendations such as using strong passwords, verifying app authenticity, and enabling multi-factor authentication. However, for businesses seeking practical guidance, this landscape can be challenging to navigate. Among the myriad insights, there is one piece of wisdom that stands above all: the importance of being ready to face the unknown.
Protecting Your Digital Frontier
The significance of cybersecurity readiness cannot be overstated, given the myriad threats that persist in today’s world. In the ever-advancing realm of technology, these threats are continually evolving and evolving in tandem. Regardless of size or industry, organizations must maintain vigilance and adopt a proactive stance. Of all the awareness we seek to cultivate this month, the most critical theme is the enduring pursuit of readiness.
Sweet Entropy: The Changing Landscape of Cybersecurity
The cybersecurity landscape is in a perpetual state of flux. It encompasses new technologies, tactics, threats, services, and events from diverse sources. Fresh attack vectors emerge regularly, while threat actors refine their techniques and intensify their pursuit of sensitive information and system vulnerabilities. In this dynamic environment, everything an organization has built, no matter how impressive, could be vulnerable to the next significant breach. This includes point technologies and Security Operating Centers (SOCs). The only response is to remain poised to build and rebuild as required.
Understanding Cybersecurity Readiness
When concepts materialize into plans, the portrait of cybersecurity readiness emerges. It involves a spectrum of proactive measures and strategies aimed at being prepared to confront potential cyber threats. This readiness encompasses not only the deployment of security tools and technologies, but also the development of a cybersecurity culture that permeates every level of an organization. This multi-level presence epitomizes the comprehensive security principles that underpin the most secure environments in the industry. Awareness and evaluation remain constant factors within systems, expertise, and operational programs that are guided by comprehensive security strategies.
Key Components of Cybersecurity Readiness
Approaches to navigating the transition from concept to application of cybersecurity readiness may vary, but certain elements persist. They include:
Risk Assessment: Understanding an organization's unique vulnerabilities is the first step in cybersecurity readiness. A comprehensive risk assessment identifies potential threats and helps prioritize security measures.
Understanding an organization's unique vulnerabilities is the first step in cybersecurity readiness. A comprehensive risk assessment identifies potential threats and helps prioritize security measures. Robust Policies and Procedures: Well-defined cybersecurity policies and procedures ensure everyone in the organization knows their responsibilities and how to respond to security incidents.
Well-defined cybersecurity policies and procedures ensure everyone in the organization knows their responsibilities and how to respond to security incidents. Incident Response Plan: A well-crafted incident response plan minimizes the impact of a cyberattack by outlining the steps to take when an incident occurs, and helping mitigate damage and prevent further breaches.
A well-crafted incident response plan minimizes the impact of a cyberattack by outlining the steps to take when an incident occurs, and helping mitigate damage and prevent further breaches. Security Technologies: Implementing a layered security approach with firewalls, intrusion detection systems, antivirus software, and encryption helps protect against a wide range of threats.
Implementing a layered security approach with firewalls, intrusion detection systems, antivirus software, and encryption helps protect against a wide range of threats. Regular Updates and Patch Management: Keeping software, operating systems, and applications up to date is crucial for plugging known vulnerabilities that cybercriminals can exploit.
Keeping software, operating systems, and applications up to date is crucial for plugging known vulnerabilities that cybercriminals can exploit. Continuous Monitoring: Real-time monitoring of network traffic and systems can help detect and respond to threats as they happen, reducing the time attackers have to wreak havoc.
Real-time monitoring of network traffic and systems can help detect and respond to threats as they happen, reducing the time attackers have to wreak havoc. Education and Training: Employees are often the weakest link in cybersecurity. Regular training and awareness programs can help staff recognize phishing attempts, social engineering tactics, and other common attack methods.
The Benefits of Cybersecurity Readiness
Investing in cybersecurity readiness is worthwhile, and offers several advantages:
Reduced Risk: By proactively identifying and mitigating threats, organizations can significantly reduce the risk of a successful cyberattack.
By proactively identifying and mitigating threats, organizations can significantly reduce the risk of a successful cyberattack. Protection of Reputation: Cyber incidents can damage an organization's reputation. Being prepared and responding effectively can minimize the negative impact.
Cyber incidents can damage an organization's reputation. Being prepared and responding effectively can minimize the negative impact. Regulatory Compliance: Many industries are subject to cybersecurity regulations and standards. Maintaining readiness helps organizations stay compliant and avoid legal consequences.
Many industries are subject to cybersecurity regulations and standards. Maintaining readiness helps organizations stay compliant and avoid legal consequences. Cost Savings: Preventing cyber incidents is often more cost-effective than dealing with the aftermath. Readiness helps you to avoid the financial and reputational costs of data breaches.
Path Forward
To forge a path to a secure and resilient future, it’s imperative to embrace the mission of cybersecurity readiness without delay. The cost of inaction is simply too high, and the stakes too great. It’s essential to be prepared for the unforeseeable. By engaging with seasoned cybersecurity experts and professionals, and forming strategic alliances in this dynamic landscape, organizations can reinforce their digital frontier, ensuring a steadfast, secure future for their operations and upholding the trust of their esteemed customers.",https://imageio.forbes.com/specials-images/imageserve/652e6e18ad6f9467a8a2fcba/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds,2023-10-17 07:31:00
https://www.forbes.com/sites/catherinewang/2023/10/17/indian-space-startup-raises-267-million-series-b-to-launch-satellites-using-3d-printed-rocket-engines/,Indian Space Startup Raises $26.7 Million Series B To Launch Satellites Using 3D-Printed Rocket Engines,"Agnikul Cosmos cofounder and COO Moin SPM (left) and cofounder and CEO Srinath Ravichandran. Courtesy of Agnikul Cosmos
Aerospace manufacturing startup Agnikul Cosmos–backed by the likes of Forbes Midas Lister Navin Chaddha’s Mayfield Fund–raised $26.7 million in a Series B funding round, as investor optimism in India’s space industry takes off.
Participating in the round were new investors including Celesta Capital, Rocketship.vc, Artha Select Fund and Artha Venture Fund, and existing investors Mayfield India, Pi Ventures and Speciale Invest. The fresh capital brings the six-year-old startup’s total funding raised to $40 million. Agnikul declined to disclose its latest valuation.
“Agnikul's pursuit of innovative space solutions aligns with our investment focus on India’s leading-edge deep tech sector,” said Arun Kumar, managing partner at Celesta Capital, in a statement. “We are excited to support their pioneering vision and innovative approach to modernizing and democratizing the space industry.”
Founded in 2017 and based in Chennai, India, Agnikul designs and manufactures rockets for satellites under 100 kilograms in weight. Its launch vehicle, the Agnibaan SubOrbital Technological Demonstrator (SOrTeD), has five possible configurations depending on the number of engines and stages used in the launch, and clients’ needs. Agnibaan integrates 3D-printed components, such as Agnilet, a patented 3D-printed rocket engine, which the startup claims is the world’s first such engine to be printed in a single piece.
The Agnikul team with Agnibaan at Satish Dhawan Space Center, Sriharikota. Courtsey of Agnikul Cosmos
The fresh capital will go towards Agnikul’s first set of commercial launches, the “building of key launch infrastructure,” and hiring production, operations and technology talent, according to the company. With a private launchpad located in the Satish Dhawan Space Centre, Agnikul says its maiden launch is set for the end of 2023.
Srinath Ravichandran, cofounder and CEO at Agnikul, credits the success of India’s recent lunar mission with raising “the sentiment of every Indian and the space tech sector at large.” In August, the Indian Space Research Organization’s Chandrayaan-3 spacecraft touched down on the moon’s southern polar region, making India the first country to reach this region and the fourth country to land on the moon, after the United States, the former USSR and China. Months earlier, in April, Indian authorities unveiled the country’s first national space policy, outlining the participation of the private sector.
“India's space industry is in an exciting growth trajectory, we were on the moon just recently and what could have been better than this?” Ravichandran wrote in an email to Forbes Asia. “With a burgeoning ecosystem of public and private enterprises, increased international collaboration, and a steadfast commitment to innovation, I see India's space sector contributing significantly to global space exploration, satellite services, and environmental sustainability.”
A skyrocketing number of startups targeting the field of space technology, known as spacetech, have taken off in India. The country is home to 190 registered spacetech startups, according to an October report by Deloitte, the Indian Space Association, and trade association NASSCOM. This includes earth-imaging startup Pixxel, which raised $36 million in a Series B funding round in June, and Skyroot Aerospace, which raised $51 million last September in a Series B funding round led by Singaporean sovereign wealth fund GIC. Another rising spacetech is Bellatrix, an honoree of the inaugural Forbes Asia 100 to Watch list, which is in talks to receive funding from BASF Venture Capital, according to local media reports.
READ MORE
MORE FROM FORBES Forbes Asia 100 To Watch 2023","https://imageio.forbes.com/specials-images/imageserve/652e5c4084c8ac6a21df1d2a/0x0.jpg?format=jpg&crop=2046,1151,x0,y232,safe&height=900&width=1600&fit=bounds",2023-10-17 07:30:19
https://www.forbes.com/sites/forbestechcouncil/2023/10/17/which-ethical-implications-of-generative-ai-should-companies-focus-on/,Which Ethical Implications Of Generative AI Should Companies Focus On?,"Somdip is the Chief Scientist of Nosh Technologies, an MIT Innovator Under 35 and a Professor of Practice (AI/ML) at the Woxsen University.
getty
In the burgeoning realm of technology, artificial intelligence (AI), and especially generative AI, stands out as a monumental force, poised to redefine industries. Drawing from my extensive background and expertise in AI and embedded machine learning, I can attest to the profound transformative impact this technology harbors. While the allure of generating novel content such as text, images and music is tantalizing, we must remain acutely aware of the ethical considerations at play.
Below are the critical ethical implications that businesses dabbling in generative AI must navigate, alongside some potential pitfalls and mitigative strategies.
1. Misinformation And Deepfakes
Generative AI's capacity to produce content that blurs the lines between reality and fabrication is alarming. From synthetic news reports to manipulated videos, these creations can distort public perception, fuel propaganda and detrimentally impact both individuals and organizations.
A tarnished reputation is a high price to pay for any company found complicit, either directly or indirectly, in the spread of misinformation. Beyond a tarnished reputation, imagine a scenario where a deepfake video purportedly shows a CEO making controversial remarks, leading to stock price plummeting overnight. Trust is hard-won and easily lost.
Invest in developing and deploying tools to identify fake content. Furthermore, embarking on user awareness campaigns can be instrumental in countering the spread of misleading information. For instance, companies like Facebook have already initiated projects to detect deepfakes. By investing in such tools, businesses can also partner with third-party fact-checkers, ensuring any content flagged as potentially misleading is reviewed and, if necessary, removed.
2. Bias And Discrimination
Generative models mirror the data they're fed. Consequently, if they're trained on biased datasets, they will inadvertently perpetuate those biases.
AI that inadvertently perpetuates or even exaggerates societal biases can draw public ire, legal repercussions and brand damage. Take the instance of facial recognition software, which, when biased, might wrongly identify individuals leading to potential legal confrontations or public relations disasters.
Prioritize diversity in training datasets and commit to periodic audits to check for unintended biases. Organizations like OpenAI emphasize the importance of diverse training data. Companies can initiate partnerships with such organizations, ensuring that their generative models undergo rigorous bias checks and external audits.
3. Copyright And Intellectual Property
The ability of generative AI to craft content that mirrors existing copyrighted materials poses significant legal concerns.
Intellectual property infringements can result in costly legal battles and reputational damage. Consider the music industry, where a generative AI's music piece closely resembling an artist's copyrighted song could lead to costly lawsuits and public backlash.
Ensure that training content is licensed and transparently outline how generated content was produced. The use of metadata tagging in training content can trace back origins, ensuring transparent accountability. For example, Jukin Media offers a platform to obtain rights and clearances for user-generated content. Engaging in such practices can safeguard against unintentional infringements.
4. Privacy And Data Security
Generative models, particularly those trained on personal data, pose privacy risks. The unauthorized use of this data or the generation of eerily accurate synthetic profiles is a significant concern.
A breach of user privacy or data misuse can trigger legal consequences and erode user trust. Consider an AI trained on personal medical histories inadvertently generating a profile that, though synthetic, closely resembles a real patient, leading to privacy concerns and potential Health Insurance Portability and Accountability Act (HIPAA) violations.
Lean towards anonymizing data when training models and bolster data security measures to ensure user data remains uncompromised. GDPR’s data minimization principle, for example, suggests that only necessary data should be processed. Companies should adopt similar principles, ensuring any non-essential personal data is stripped away before training, and employing robust encryption methods during data storage.
5. Accountability
The multifaceted creation and deployment pipeline of generative AI complicates the attribution of responsibility.
In the event of a mishap, an undefined accountability structure can result in finger-pointing, legal entanglements, and dilution of brand credibility. Reflect on the recent controversies with AI chatbots spewing hate speech or inappropriate content. Without clear accountability, the blame game intensifies, leading to brand damage.
Establish lucid policies detailing the responsible use of generative AI. Policies akin to X's (formerly known as Twitter) guidelines for synthetic and manipulated media, which provide clear definitions and boundaries on the use and dissemination of such content, can be a template for businesses. Furthermore, feedback loops, where users can report questionable outputs, can be invaluable.
The Business Perspective
Beyond the societal and ethical implications, businesses face tangible risks if they sidestep these issues. Brand image, user trust and financial stability are all at stake. Ignoring the ethical facets of generative AI isn't just a moral oversight; it's a business risk.
The Path Forward For Businesses
Awareness is the first step. Recognize and understand the ethical minefields associated with generative AI. Once identified, proactively architect policies, processes and strategies that promote responsible use. Lastly, champion transparency and foster a culture of ethical AI usage both within and outside the organization.
In this brave new world of generative AI, it's not just about what we can create, but how we go about it. Companies at the forefront of this revolution carry a weighty responsibility. It's a call not just for innovation but also for introspection and ethical stewardship. Let's rise to the occasion.
Forbes Technology Council is an invitation-only community for world-class CIOs, CTOs and technology executives. Do I qualify?",https://imageio.forbes.com/specials-images/imageserve/64a570171d6feda6a59805d4/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds,2023-10-17 07:30:00
https://www.forbes.com/sites/forbestechcouncil/2023/10/17/addressing-credential-compromise-the-role-of-modern-iga/,Addressing Credential Compromise: The Role Of Modern IGA,"Vice president of product strategy, Omada.
getty
The latest annual risk and vulnerability assessment report from CISA revealed that the majority of breaches at state or local government agencies and critical infrastructure networks had, at their base, valid account credentials.
What’s more, valid accounts—including former employee accounts not removed from the Active Directory and default administrator credentials—were responsible for 54% of all attacks studied. That’s just over half—no small number. Whether used by angry insiders or outside attackers who have obtained these account credentials from the dark web, the damage is the same.
Unfortunately, these findings are hardly surprising, and they underscore a challenge that continues to ripple across industries. Today’s organizations are facing an identity (management) crisis. They need improved identity governance and administration (IGA). To achieve that, they need to know the differences between traditional and modern IGA.
A Closer Look At The Findings
Most bad actors aren’t the evil geniuses they might want their targets to believe. They aren’t using superpowers or high technology to get into organizations; they’re just getting ahold of valid credentials. As the CISA report found out, valid credential compromise (along with spear-phishing attacks) accounted for nearly 90% of infiltrations—in other words, almost all of them.
According to the CISA report, gaining initial access to the network is the first stage in the attack path. To gain a footing and persist on the network, the attacker then executes code within the network. Then the attacker employs privilege escalation to get administrative rights. This gives them more access to more areas and more—possibly limitless—potential to cause harm.
The Need For Access Governance And IGA
These findings illustrate that there’s a lack of robust access governance, which is a component of IGA concerning the collection of rules, procedures and tools that businesses create to manage and regulate user access to their information systems, data and applications.
On the basis of the identities of certain individuals or groups, identity-based access control provides or prohibits access to resources. The user’s role, job title, department and any other pertinent information must be carefully considered while developing an identity access governance policy.
Identity-based access control must be able to scale to handle the rising number of identities and access life cycle events, including role changes or firings, to continue to operate effectively. Identity-based access control needs the ability to manage and carry out access control in both cloud-based and on-premises systems.
This strategy needs to include an effective deprovisioning process for when an employee leaves a role and/or the organization. The primary hurdle is that the process needs to be flawless, but even a basic access review should be able to identify any oversights. The purpose of an access review is to remove unnecessary or unused privileges.
By seriously committing to this straightforward process, organizations can effectively tackle this challenge.
Looking To Modern IGA
Organizations need an identity solution that will enable them to adapt and evolve in response to organizational changes and technology demands as they anticipate future needs. This requires a modern, full-featured IGA solution that will allow organizations to regain control of IT. To ensure rapid time to value, look for solutions built on cloud-native architecture.
Older IGA solutions frequently involve substantial maintenance costs and complex customization. These systems typically have trouble supporting the automation of complicated business operations. Because they are not cloud-native, have few IGA capabilities and can’t scale, some SaaS solutions also fall under this category.
A more updated IGA system is fully functional, cloud-native, enterprise-ready and deploys quickly. Companies get sophisticated access automation, intelligent decision support and high governance and audit standards.
Modern IGA empowers enterprises to rapidly establish a thorough, transparent assessment of access risk and act promptly to address any potential aberrations. Organizations can greet every audit with assurance and minimal manual labor, as well as obtain complete compliance and trust with comprehensive dashboards.
Updated IGA also enables them to conduct access evaluations, determine the established expected state and comply with corporate policies and regulations.
Overcoming The Challenges Of Modern IGA
It can, however, be a complex process to implement seamlessly into existing infrastructure. Here are a few challenges that organizations might face:
1. User resistance requires effective change management strategies.
2. Scalability requirements are also often underestimated, potentially leading to performance issues as the organization expands—which is why cloud-native solutions are ideal.
3. It can also be hard to maintain efficiency when trying to ensure rapid implementation and secure onboarding of new digitized business, applications and systems processes.
To navigate these challenges, organizations should observe several best practices:
1. Secure executive buy-in to demonstrate the strategic importance of IGA ensures necessary resources and fosters a security-oriented culture.
2. Develop a holistic approach that encompasses all identity types, robust change management and scalability planning.
3. Enable continuous monitoring and auditing, role-based access control (RBAC) and investing in education and training for IT and security personnel are equally vital. Roles for staff members will evolve to focus on policy development, risk assessment and monitoring rather than manual user provisioning. Important IGA skills include IGA systems operation, regulatory compliance, security best practices and reporting and analytics.
Finally, it’s important to note that, while modern IGA systems are powerful, they do not cover all aspects of cybersecurity. Organizations must complement IGA with a zero-trust model, multifactor authentication, robust endpoint security and a comprehensive incident response plan to ensure comprehensive cybersecurity coverage.
Overcoming The Access And Identity Crisis
Knowing that valid account credentials form the foundation of successful cyber intrusions highlights a critical challenge in the realm of identity management.
To address this crisis, organizations must adopt modern IGA solutions and best practices that connect with the broader security ecosystem. These solutions not only automate threat detection but also facilitate swift responses to mitigate risks. By integrating today’s IGA with effective de-provisioning processes, organizations can confront identity-based security threats, safeguarding their networks, data and systems.
This process can be tricky, but organizations can succeed if they understand the best practices and implement modern IGA as part of a holistic cybersecurity plan.
Forbes Technology Council is an invitation-only community for world-class CIOs, CTOs and technology executives. Do I qualify?",https://imageio.forbes.com/specials-images/imageserve/63f7c6727d0ada838b093b46/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds,2023-10-17 07:15:00
https://www.forbes.com/sites/forbestechcouncil/2023/10/17/why-the-future-of-generative-ai-lies-in-a-companys-own-data/,Why The Future Of Generative AI Lies In A Company’s Own Data,"Alex Ratner is the co-founder and CEO at Snorkel AI, and an Affiliate Assistant Professor of Comput. Sci. at the University of Washington.
getty
The age of large language models (LLMs) and generative AI has sparked excitement for business leaders. But those who want to launch their own LLM face many hurdles between wanting a production generative AI tool and developing one that delivers real business value and sustained advantage.
Foundation models themselves have quickly become commoditized. Any developer can build on the Google Bard or OpenAI APIs. More mature organizations can deploy models like Llama 2 in their own walled gardens. But if their competitors also use Llama 2, what advantage do they have? Proprietary data—and the knowledge of how to develop and use it—provides the only sustainable enterprise AI moat.
As generative AI has reached the peak of the Gartner AI Hype Cycle, enterprises are learning that off-the-shelf LLMs can’t solve every problem—particularly not unique, high-value problems. Proprietary data can close the gap, but only when properly curated and developed.
Your Data, Your Moat
Off-the-shelf LLMs yield fun experiments and demos, but using them in a business setting will rarely achieve the accuracy needed to deliver business value. Businesses don’t need chatbots that can discuss poetry as competently as they explain computer code—they need highly accurate specialists.
Private data is a moat—a potential competitive advantage. By leveraging your proprietary data and subject matter expertise, you can build generative models that work better for your domain, your chosen tasks and your customers.
Enterprises can gain these advantages in three ways:
1. Retrieval augmentation.
2. Fine-tuning with prompts and responses.
3. Self-supervised pre-training.
Let’s briefly look at each.
Retrieval Augmentation
Retrieval augmented generation, better known as RAG, allows your generative AI pipeline to enrich prompts with query-specific knowledge from a company’s proprietary databases or document archives. This generally yields better, more accurate answers, even with a standard LLM.
But this is similar to giving an intern access to your intranet: Even with all the information before them, the intern may misunderstand or miscommunicate. To get better performance, your data team needs a customized model.
Fine-Tuning With Prompts And Responses
Data-driven organizations can fine-tune LLMs with curated prompts and responses. This sharpens and improves the model’s output on the organization’s most important tasks. To use a metaphor, a doctor needs access to a patient’s medical chart (retrieval augmentation) and specialty training (fine-tuning) to render an accurate diagnosis. Data scientists can carefully choose the prompts and responses used to fine-tune the LLM to improve performance on a wide variety of tasks or greatly boost performance on a very narrow set of them.
Self-Supervised Pre-Training
Some organizations may want to take their LLM customization further and build a model from scratch. However, this can demand more effort than it’s worth. Firms with business vocabularies well-represented in the embedding spaces of off-the-shelf LLMs can often achieve the necessary performance gains through fine-tuning alone.
If an organization feels that it needs a model custom-built from the ground up, its data team first selects a model architecture and then trains it on unstructured text—initially on a large, generalized corpus, then on proprietary data. This teaches the model to understand the relationships between words in a way that’s specific to the company’s domain, history, positioning and products. The data team can then further train the model on prompts and responses to make it not just knowledgeable but task-oriented.
The Data Lift
The ideal deployment would incorporate all three of the above approaches, but that represents a heavy data labeling load. Studies from McKinsey and Appen show that a lack of high-quality labeled data blocks enterprise AI projects more often than any other factor—and, to be clear, all three of these approaches require labeled data.
Fine-tuning with prompts and responses requires data teams to identify and label prompts according to the task and then determine high-quality responses. Pre-training with self-supervised learning requires companies to carefully curate the unstructured data they feed the model. Training on lunch orders and payroll could degrade performance or cause sensitive data to leak internally.
Even retrieval augmentation benefits from data labeling. Although vector databases efficiently handle relevance metrics, they won’t know if a retrieved document is accurate and up to date. No company wants its internal chatbot to return out-of-date prices or recommend discontinued products.
Data Is Essential To Delivering Generative AI Value
Using your proprietary data to build your AI moat requires work, and that work rests heavily on data-centric approaches including data labeling and curation. Firms can outsource some labeling to crowd workers, but much of it will be too complex, specialized or sensitive for gig workers to handle. And it’s still time-consuming and expensive, similar to relying on internal experts for data labeling.
Data science teams can use active learning approaches such as label spreading to amplify the impact of internal labelers. Programmatic labeling is another option. Our researchers used those tools to build a better LLM.
Your data—properly prepared—is the most important thing your organization brings to AI and where your organization should spend the most time to extract the most value. Your data is your moat. Use it.
Forbes Technology Council is an invitation-only community for world-class CIOs, CTOs and technology executives. Do I qualify?",https://imageio.forbes.com/specials-images/imageserve/652d8973f7b99acf81ff72c3/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds,2023-10-17 07:00:00
https://www.forbes.com/sites/lanceeliot/2023/10/17/prestigious-symposium-on-ai-lawyering-reveals-keen-insights-including-the-ardent-debate-on-whether-to-use-generative-ai-in-law-school-education/,Prestigious Symposium On AI Lawyering Reveals Keen Insights Including The Ardent Debate On Whether To Use Generative AI In Law School Education,"Should law students be using generative AI in law school? You decide. getty
In today’s column, I will be providing commentary and coverage of a prestigious symposium on AI lawyering that was recently jointly undertaken by the Tsai Center for Law, Science and Innovation of the SMU Dedman School of Law and with Wake Forest Law via a special event entitled “AI Lawyering: Adapting to the Era of ChatGPT and Large Language Models”.
The range of topics encompassed at the symposium consisted of three major areas of focus: (1) AI in legal education, (2) AI in legal practice, and (3) AI as viewed from the bench, the ABA, and state bars. I participated as a speaker in the third session and will be sharing herein highlights of the entire event. All told this important get-together was an invigorating and notable confluence of perspectives by law firms, solo lawyers, legal practitioners, legal scholars/academics, and others stridently interested in the future of lawyering as impacted by AI.
First, let’s lay out the notable panelists and their affiliations.
The panel on AI in legal education consisted of speakers Raina Haque, Wake Forest University School of Law, Rachelle Holmes Perkins, George Mason University Antonin Scalia Law School, Dan Schwarcz, University of Minnesota Law School, and was ably moderated by Keith Robinson, Wake Forest University School of Law. This was a stirring exploration of whether or not to use generative AI in law schools and got the event off to a fast start. In a moment, I’ll be examining the keystones revealed, doing so in my own words, and will be using the points made as a launching pad to closely unpack a heated and altogether contentious and extremely timely topic.
The panel on AI in legal practice included speakers Rob Hill, Holland & Knight, Michelle A. Reed, Akin Gump, and was skillfully moderated by Meghan J. Ryan, SMU Dedman School of Law. Topics covered a wide gamut including how law firms are adopting generative AI, along with the fascinating and newly encountered twists and turns associated with having clients that either want their legal advisors to be using generative AI or taking the opposite stance. For space purposes in today’s column, I won’t have space to cover the particulars of this emerging and eyebrow-raising set of considerations, and aim to do so in a subsequent column.
The final session explored a deep variety of AI lawyering topics and consisted of Dr. Lance Eliot, Techbrium, Inc. (that’s me), Hon. Xavier Rodriguez, U.S. District Court for the Western District of Texas, Stephen Wu, Silicon Valley Law Group, and was adeptly moderated by Nathan Cortez, SMU Dedman School of Law. A slew of significant points was addressed. Again, for space purposes in today’s column, I’ll be covering the remarks in a subsequent column (please be on the look for that upcoming coverage).
MORE FOR YOU Zipcar Fined 300 000 For Letting Customers Rent Recalled Cars
Before I leap into my analysis and discussion, you might find of interest a helpful shortlist of some of my prior and ongoing series of pieces that provide a solid background on these matters, ranging from the application of AI to the law (such as the use of generative AI for performing legal services) and encompassing too the application of the law to AI (e.g., copyright issues of generative AI, AI governance and efforts to regulate AI, national and international endeavors, the U.S. Bill of Rights related to AI, etc.).
Here is a sampler list of seven of my essential pieces that adroitly convey these heady matters:
(1) Generative AI Ramifications For Law Firms And Law Partners. Law firms and law partners need to address the rise of generative AI for performing legal tasks, and cannot avert their eyes or keep their heads in the sand on the steady march toward AI in the practice of law (see my in-depth analysis at the link here).
Law firms and law partners need to address the rise of generative AI for performing legal tasks, and cannot avert their eyes or keep their heads in the sand on the steady march toward AI in the practice of law (see my in-depth analysis at the link here). (2) Big-Picture About AI & Law. This is my big-picture analysis of the forest for the trees regarding AI and the law, an altogether substantive piece identifying fifty crucial points that in-the-know lawyers and partners need to know about (see the link here).
This is my big-picture analysis of the forest for the trees regarding AI and the law, an altogether substantive piece identifying fifty crucial points that in-the-know lawyers and partners need to know about (see the link here). (3) ABA AI Resolutions. My close look at the ABA model rules and resolutions associated with AI, covering duties pertaining to how lawyers and law firms should be suitably approaching AI, including analysis of the ABA Model Rule 1.1 Comment 8, ABA Resolution 112, ABA Resolution 700, and the recently enacted ABA Resolution 604 (see the link here).
My close look at the ABA model rules and resolutions associated with AI, covering duties pertaining to how lawyers and law firms should be suitably approaching AI, including analysis of the ABA Model Rule 1.1 Comment 8, ABA Resolution 112, ABA Resolution 700, and the recently enacted ABA Resolution 604 (see the link here). (4) AI Hallucinations Undermining Lawyers. My detailed assessment and lessons learned arising from those two lawyers who got into hot water by relying upon generative AI when they cited AI-hallucinated legal cases in their formal court filings (see the link here).
My detailed assessment and lessons learned arising from those two lawyers who got into hot water by relying upon generative AI when they cited AI-hallucinated legal cases in their formal court filings (see the link here). (5) Judges And Courts Reacting To GenAI Using Lawyers. My review and predictions about how judges and the courts are going to react to generative AI being used by lawyers and law firms (see the link here).
My review and predictions about how judges and the courts are going to react to generative AI being used by lawyers and law firms (see the link here). (6) GenAI And The Attorney-Client Privilege . My early bird noted concerns that unaware law firms and hapless lawyers are potentially going to usurp their vaunted attorney-client privilege at times by inadvertently using generative AI in ill-advised ways (see the link here).
. My early bird noted concerns that unaware law firms and hapless lawyers are potentially going to usurp their vaunted attorney-client privilege at times by inadvertently using generative AI in ill-advised ways (see the link here). (7) Prompt Engineering Techniques For Lawyers. One of my many pieces covering legal examples highlighting prompt engineering techniques when smartly using generative AI by or for lawyers (see the link here).
One of my many pieces covering legal examples highlighting prompt engineering techniques when smartly using generative AI by or for lawyers (see the link here). And many others.
I’ve been trying to ensure that lawyers and the legal profession are kept up to date on AI.
Change is afoot for the legal world. AI is a disruptive and transformative force. You’d have to be living in a cave that has absolutely no internet connection to believe otherwise. Lawyers across all areas of the law ranging from newbie attorneys to seasoned ones are going to be impacted by AI.
I dare suggest that this is an inarguable fact, though I hesitate to ever mention that something is inarguable when tossing around verbiage with lawyers (I brazenly try doing so during my workshops, lectures, and talks). In any case, I squarely stand by the notion that the propensity of AI impacts on the legal profession are inarguable, whilst agreeing that the mainstay of debate centers on which ways and in what timeframe things will play out.
Generative AI As Used Within Legal Education
I’ve got a seemingly straightforward question for you.
It is one of those questions that on the surface might appear to be simple and ergo would presumably garner a simple answer. Lawyers though know that at times simple questions can be entirely chockfull of densely packed and extremely complicated tradeoffs. This is one of those instances.
Put on your seatbelt for this thought-provoking question:
Should law school students be allowed to use generative AI?
There, I said it, and you might immediately have a reactive response. Some law schools have recoiled at the use of generative AI and claim it is going to undercut those budding legal beagles. Other law schools have said that they welcome generative AI. Many law schools are scratching their heads and toying with generative AI in their educational efforts.
Generally, the response overall has been quite a mixed bag.
I tend to boil down the pursuits into five major positions or approaches:
(a) Ban generative AI usage by law students. Outrightly ban generative AI use by law students at a given law school.
Outrightly ban generative AI use by law students at a given law school. (b) Permit generative AI usage by law students. Overtly allow generative AI use by law students though keeping a tight leash on usage.
Overtly allow generative AI use by law students though keeping a tight leash on usage. (c) Encourage generative AI usage by law students. Actively encourage generative AI use by law students and urge them on.
Actively encourage generative AI use by law students and urge them on. (d) Nebulousness on generative AI usage by law students. Muddle along and say nothing either way about whether your law students can use generative AI.
Muddle along and say nothing either way about whether your law students can use generative AI. (e) Other assorted GenAI usage posturing. This is a catchall for either a mixture of the above or some other variant policy and approach to generative AI for law students.
Before I dig into those various approaches, I’d like to emphasize that the usual attention is devoted to whether law students are going to be using generative AI. This says nothing about whether law faculty might or might not be using generative AI.
Few give any thought about that added possibility. If, for example, a law faculty member decides to create an exam that is entirely composed via the use of generative AI, do you see anything wrong or amiss about this action? Some would insist that this is entirely up to the faculty member to decide on. Others would decry this approach and would worry that the exam is going to be less suitable without the human touch of a law faculty member devising the exam themselves.
Give the matter some contemplative thought. Does a law faculty member who voluntarily opts to use generative AI send any kind of subliminal message to the law students, such that doing so might be in alignment with or utterly contrary to some overall GenAI policy by the law school regarding law student usage of generative AI? Here’s a wilder one. Should law schools go out of their way to entice or reward law faculty for judiciously using generative AI, thus fostering them to learn about and get involved with generative AI?
Those are all construed as bitter fighting words in the hallways of academia, which I am not going to get further into in this particular discussion (if reader interest dictates, I’ll gladly elaborate in a future column posting).
Let’s get back to the central matter at hand, namely today’s law students and their use or non-use of generative AI while in law school.
As you’ll see shortly, the matter has significant implications not just for what happens in law school but also for what happens after law school, including the future of budding legal careers and perhaps the future of the legal profession in total. Everyone should care about this. Not just academics. Not just law students. The whole legal community encompassing law firms, law partners, existing lawyers, prospective clients, existing clients, and society overall has a notable stake in this weighty topic.
Let’s start the unpacking with a sharp bang. I’d venture that the most vocal and vehement position is that law school students should be categorically and unequivocally banned from using generative AI.
Period, end of story.
You might be notably curious as to why this is a highly vocalized exhortation. The reasons are aplenty.
One stated reason is that law school students need to learn how to think like a lawyer and that the use of generative AI will usurp that essential goal. In a sense, generative AI is seen as a potential crutch. Law school students will be underdeveloped in legal reasoning because they rely upon GenAI to do so for them. All they are doing by using generative AI is sorrowfully and dangerously undercutting their own legal education. In turn, this will indubitably seem to undercut their legal career. They will be forever one step behind, due to letting AI do their legal brainiac work for them.
Worse still, the worry is that once law students graduate and go into the legal profession, they will be hooked on generative AI. It is like a habit-forming drug. When asked to put together a legal brief, the law school graduate who was using GenAI in school will be completely at the whim of generative AI. They won’t be able to write a legal brief on their own. If somehow the GenAI is unavailable, this law student is out of luck and out of order. Bad for the law practice that hired the law graduate.
This is also seemingly bad news for the legal profession overall, namely that we will be quietly releasing a barrage of law students who can’t exercise the law without their aided crutch of GenAI. All that the law graduate is good for is to enter prompts into generative AI. Imagine that the GenAI generates errors or does an AI hallucination. The AI-addicted law graduate won’t know that the generative AI is pulling the wool over their eyes. Clients are going to be upset, rightfully so. Legal malpractice lawsuits are going to go into high gear.
The bottom line, some lamentedly insist, is that generative AI as used by law students is going to drive the legal profession mercilessly in a pitiful race to the hopeless bottom of an empty abyss.
Wow, that does seem depressingly worrisome and something we need to curtail.
Hold on. Don’t toss in the towel just yet. Lawyers know that hearing one side of a contentious issue is rarely the full story. You can be lulled and insidiously leaned in one direction by powerful assertions that are tilted in one direction. We ought to keep our minds open and hear what the other side has to say.
Consider closely the retort or counterarguments to the above-proclaimed total ban.
Gear up for this.
First, generative AI is going to become an integral part of modern-day legal practice soon enough. Law firms are going to have to embrace generative AI, whether they like it or not. Clients are going to want to know that their chosen legal advisors are using the latest in AI to stake out the best and brightest of legal positions. AI is not going to fade away. It will get stronger and deeper into the legal field.
Law school students who aren’t versed in generative AI are going to find themselves out of step with what law firms are going to look for. Existing lawyers within law firms are bound to be slower to adopt GenAI. It is the nature of things. Meanwhile, the hope will be that those fresh faces out of law school will know when and how to prudently utilize generative AI.
A law school that bans generative AI is going to undermine its law students. They are denying law students a chance to stand out as they come out of law school. Indeed, this lack of experience with generative AI is likely to dampen their career pursuits. They will forever be that last generation of law school students who didn’t make use of generative AI during their legal education.
On top of those career considerations, another aspect is whether declaring a ban on GenAI during law school is sensibly feasible. Here’s what that means. A law school makes a hefty proclamation that law students cannot touch generative AI. GenAI is verboten. The administrators believe they can wipe their hands clean and be done with the matter.
Who will police this ban?
You might be tempted to say that all the law school needs to do is enlist one of those alleged GenAI detectors and use such a tool to scan any written work turned in by the law students.
Importantly, I’ve covered extensively in my column that those detection tools are not reliable and should not be used, see the link here and the link here. When it comes to text (versus detection of generated images), the detectors can be easily fooled. Do not fall for the unbridled and unfounded assertions that they work effectively. They don’t. Law school students will wise up and learn how to readily defeat the automated detectors.
There is an additional twist about the detection tools that really get my goat. I’ve had many students come to me and indicate that they were falsely accused by a detection tool of having used generative AI for writing a paper. There is in fact a disconcerting false positive rate with these tools. In other words, a sincere and non-cheating student and their whole scholastic career can be tainted unfairly. You become guilty until proven innocent. Furthermore, those who use these detection tools tend to be doggedly insistent that the tool can do no wrong. They will stand on a lofty hill and proclaim a student as having cheated, despite the readily known fact that these tools can be wrong.
I’ll add more twists.
Suppose that some of the law school students obey the ban and stridently avoid using generative AI. They are trying to do as the law school has asked them to do. Good for them, one would assume. But, meanwhile, let’s imagine that some other law school students in their same classes decide secretly to “cheat” and use generative AI at that law school (despite the ban). They get away with it.
The students who were non-cheaters will realize they are essentially likely to get lower grades or at least be more taxed to do their work, yet nobody will care. The cheaters will prevail. The temptation to cheat goes up. There are already so many pressures on law school students that having to contend with whether to give in and be like the so-called cheaters is not worthy of the angst. One would bet that ultimately most students would be drawn to using the generative AI.
This in turn creates an entire underground activity at a law school. All of these law school students are expending time and energy to go under the radar of the ban. Is the ban worth that effort? One supposes that you could claim that any law student worth their salt will readily abide by the ban and reject those who are presumably cheating. Maybe they ought to turn in the law students who are using generative AI. Yes, that’s right, the matter of using generative AI becomes a snitch fest. Go to law school and learn to snitch on your fellow students. Not a promising way to start your days becoming a lawyer.
You might be under the impression that those throes and difficulties are worth it if the alternative is that by allowing generative AI we are going to produce a generation of legal zombies that are wholly reliant on AI. It seems that nearly any kind of problematic issue during law school would be worth coping with, assuming it can stop the flow of law-deficient thinkers being pumped out into the legal profession at large.
Stop there. We need to carefully examine the logic of this proclaimed linchpin. It is sitting on extremely loose and flimsy ground.
Research studies already have provided the first indications that law students who prudently use generative AI are typically aided by the use of such a tool. Low performers appear to be especially boosted into higher levels of performance. Though such studies are still being performed, the belief by some is that this AI-boosting action is not merely a one-time fleeting affair. There is a strong possibility that the law student garners improvements in their knowledge of the law and is gaining by suitably using generative AI.
The blanket and loosey-goosey claim that law students will undercut their legal education by using generative AI is not backed by any solid empirical evidence (it is a supposition, mainly based on questionable assumptions or narrowly targeted tangential studies). It is hand waving and heretofore unsubstantiated conjecture.
As an aside, there had been similar speculation historically that the advent of word processing would undercut law school students and they would falter in becoming legal thinkers. The same is said of the adoption of legal research tools in doing law school homework. A storied history of similar qualms about automated tools for budding lawyers has permeated the legal education field for a long time.
A caveat comes in here. I hope that you carefully noticed that I said that the judicious or sensible use of generative AI is the key here (the same advice goes with word processing, legal research tools, and the like). I would generally acknowledge that if a law student uses generative AI in an unfettered and wanton fashion, the results for that law student might not be especially beneficial. They could indeed form a crutch. They could get themselves into a pickle about learning the law. All manner of disagreeable results could arise.
Given those concerns, I don’t think we ought to toss the baby out with the bathwater (an old adage, perhaps nearing retirement). Just because there might be some law students who go overboard does not mean that we should reject across-the-board the use of generative AI in a law school. That is a crazy and unfounded overreaction.
Going back to the underground use of generative AI, the odds are that any law school that tries a total ban is going to have to contend with the hidden violators. Even if a law school openly allows generative AI, this does not mean that the usage necessarily applies to in-class tests, nor would it presumably be viably useful during in-class discussions.
In short, the law school faculty will have to step up to the plate and devise suitable and sufficient means to try and gauge the true and forthright work of their law students. They will have to do more in-class activities or at least engage in means to witness firsthand the capabilities of their law students. The world is heading that way for all students in all majors across all professions. All faculty are in the same boat when it comes to assessing students in light of the emergence of generative AI.
A grand wake-up call is being sounded for schools from kindergarten to graduate school.
That’s a stark and unyielding fact.
More Food For Thought On AI In Legal Education
I trust that you can discern that an outright ban on the use of generative AI in a law school is fraught with challenges and would seem regrettably lacking in the forward-looking career growth of the students. This also would seem shortsighted when it comes to the advent of generative AI in the legal profession. Law students ought to be ready bearers and early adopters who upon graduation (or during internships or clerkships) can bring their capacities to aid law firms as they come under industry pressures to use generative AI.
Different settings will undoubtedly require that law graduates adjust accordingly. A judge seeking junior-level legal assistance might declare that no generative AI is to be used. Okay, so a savvy budding lawyer who knows generative AI would simply set aside that skill for that particular circumstance. Perhaps, though one never knows, once the judge gets to know the assistant, discussions about opening the door toward using generative AI might widen the views of the judge.
On the other hand, there is the outside chance that a judge might be purposely looking for emerging legal wranglers who do know and have tamed the Wild West of generative AI. The law student who was able to make use of generative AI now has an opportunity that other law students might not have a chance at landing. The gist is that a generative AI-savvy law student can be ambidextrous and apply their skillset when the situation presents itself.
A ban on generative AI by a law school closes doors that might otherwise be opened.
Some law schools opted to do a full ban as a means of buying them time to figure out what they should do on the thorny matter. In that case, hopefully, the ban is short-lived, unless the law school gets bogged down bureaucratically in trying to sort things out. Let’s next consider something other than a total ban. We shall assume that either there is no ban to be imposed, or that some form of alternative combination or permutation is prudently worthy of attention.
One consideration is the let it all go as a vaunted strategy.
Allowing a free-for-all about the use of generative AI by law school students would seem to tilt things toward an end of the spectrum that likewise has problems. You are bound to have some that go hog-wild and use GenAI too much. You’ll get some that avoid GenAI due to the unknown or because they fall into a clique in their class that has decided to despise generative AI. A mess is going to ensue.
A better direction would be to provide guidance on how and when to use generative AI, as clearly and openly (formally) stated by the law school. In addition, having law school policies that stipulate self-reporting on the use of generative AI would be handy too. The gist is that the use of generative AI comes out of the shadows. You might still have some cheaters here or there, but the bulk of the law students will likely be reasonably using generative AI (tending to adhere to reasonable conditions as per the policies) and not veer into the untoward forbidden territory.
This brings up various logistics considerations.
I will pose them as mindful questions.
Should a law school that allows for generative AI to be used, within stated limits, ensure that the law school students have ready access to GenAI?
This is due to the potential costs of making use of a generative AI app. Some GenAI apps are free to use, though these are typically less capable. The ones that require a subscription fee are usually better. If a law school doesn’t take this into account, there is a chance that you’ll end up with two sets or segments of law school students, namely those who can afford the better GenAI and those who cannot and must rely upon a lesser GenAI.
Should a law school provide training or other educational opportunities on how to use generative AI?
This is brought up due to the free-for-all notion of just handing out the keys to the new car and telling students to go for it. Right now, it seems unlikely that most law students have already become versed in using generative AI. They probably have toyed with GenAI, perhaps on a personal basis. They are unlikely to have deeply used it and are lacking in prompt engineering skills. In the future, you can expect that generative AI will be used during undergraduate degree programs, therefore law school students will seemingly already come with some skills in GenAI usage.
If you give a law school student a prescribed login to a generative AI app (as chosen by the law school) and do nothing else, the chances are that the student will use the GenAI briefly and then falsely presume that the AI app is of little benefit. That’s a sad result. A law school might proudly do a checkmark that they made generative AI available to their law students. Whether the law students got anything useful out of the access is a different matter.
At this time, given the overall lack of understanding about how to best use generative AI, especially in a legal context for doing legal work, a law school would be wise to accompany the generative AI with some form of explicit training or tuned educational coursework. Make the tool available. Show them how to use it. Glean feedback and keep the law students engaged and updated on usage. Do this for the entirety of their law school progression.
Don’t do a classic one-and-done. You will waste the effort and, inevitably, down the road, you will feel defeated. The thing is, you’ll need to face the music and own up that you shot your own foot or feet.
There is another element to this adoption of generative AI in law schools for law students that needs to be addressed. It is a crucial element. A mighty vital ingredient.
Law school faculty.
Will the law school faculty sit back and ignore or overlook the generative AI being used by students, or will they actively seek to incorporate the law students’ usage of generative AI into the esteemed legal educational experience?
Here’s the deal.
One approach consists of idly allowing students to use generative AI. The law school classes remain unchanged. It is up to the students to determine whether or not they want to use generative AI for any particular class they are taking, such as a class on contracts, torts, civil procedures, etc. Whatever the student does with generative AI is of no concern to the faculty, other than trying to ensure that the students abide by the law school policies and are not avidly using generative AI to do their work for themselves.
Another approach involves the faculty opting to acknowledge and incorporate the use of generative AI into law school classes. Assignments might directly advocate using generative AI for particular purposes. Class discussions might include examining what GenAI indicated on a legal matter being discussed. And so on.
This latter approach is going to be a bit of an uphill battle. First, this would require law school faculty to update their courses and go out of their way to encompass generative AI. Why should they do so? Does it aid in attaining tenure? Does it come with added pay? If there are little or no incentives, the chances are that the added work is not going to be seen as worthwhile. They already have enough to do and piling on more work without direct benefits is unlikely to be readily accepted widely.
Another concern at times expressed is that you are taking away precious and costly in-class time to delve into “tech” that otherwise distracts from learning about the law. This is regrettably true if the generative AI is poorly intertwined into classwork. No doubt about it. You see, an astute and deft hand is required to achieve a balance and ensure that any generative AI aspects considered during class time are driving toward learning about the law. Fumbling with generative AI during class time is a mistake and sits on the shoulders of those who haven’t figured out seamless ways to incorporate such tools.
Some would suggest that only certain classes that are designated as AI-accompanied law school classes would seek to embrace the overt use of generative AI. There are already classes often provided on an elective basis that deal with emerging technologies associated with the law. The odds are that this will continue for now. Until generative AI gets more fully adopted by law firms, the chance of it being directly infused into everyday law school classes is a remote bet (that day will eventually arise).
Going back to the idea of a ban, one argument is that maybe a ban should be imposed at the start of law school. This might last for a semester or quarter or could be for the entire first year for 1Ls. This might then aid in ensuring that the law school student gets a leg up on learning and thinking about the law. They are not simultaneously contending with using generative AI. Once they reach the next level of being a 2L or 3L, at that juncture they are allowed to use generative AI.
It is a clever way to split the difference or reach a compromise, one must say.
This approach has tradeoffs, as you might expect.
One concern is that the law students will go underground during their 1L and seek to use generative AI, despite being told it is banned for them. They are going to be interacting with 2L and 3L students, perhaps witnessing the advantages of using generative AI. A tough proposition will arise for them. Should they abide strictly by the first-year ban, or should they opt to cheat the ban? Ugliness once again ensues.
Another concern is that an inadvertent adverse consequence arises. Perhaps the 1Ls become convinced that generative AI is not of use to them (based solely on the first-year ban and never having used it). They then suddenly are given access when becoming a 2L. They have not previously encompassed generative AI in their law school learning. Out of sight leads to out of mind.
In a sense, it could be that leveraging generative AI is now outside of their mindset. They rejected the generative AI usage out of a proclaimed fear of forming bad habits during 1L and the repeated dogma during that time of being banned from doing so. Perhaps this leaves them shortsighted, inadvertently.
Not wanting to leave that dour impression as a lingering gasp, a hopeful condition is that it seems hard to believe that most, or at least many wouldn’t be eager to grasp hold of generative AI, once they have been given permission to do so. Hope springs eternal.
Conclusion
I mentioned at the start of this discussion that sometimes a simple question garners a big answer.
You’ve now seen this with your own eyes.
I might also mention that if you are wondering in what ways law school students might beneficially use generative AI, I’ve covered this in prior columns and as cited in the links near the top of this piece. It isn’t only about writing legal papers.
Generative AI can be used in a manner known as a flipped interaction. This consists of the generative AI asking the student questions about the law. Doing so can be handy for preparing for tests, including those graduating students who are aiming to take the bar exam.
Generative AI can be used to examine the work of a law school student and provide a critique or analysis of their budding efforts to write in legal ways. Imagine a law school student who has composed a practice legal brief and wants to gauge how good it is. How could they do so? Asking another law school student, if they have peers that have the time to do so, can be prohibitive and awkward. One easy 24x7 means consists of entering the draft into generative AI and getting a review from the AI (noting and being wary of any privacy or confidentiality issues, see my coverage at the link here).
Generative AI can be used to improve human skills in legal argumentation. A law school student might find handy a real-time effort to exercise the fine art of legal argument-making. This is good practice for the real world. Using generative AI, the student can enter a legal setting and ask the generative AI to pretend it is on the other side of the arguments to be made. The student then does a back-and-forth fencing match with the generative AI. A prime means of exercising our valued adversarial judicial structure. The student learns to react on their toes.
Note that I am emphasizing that generative AI can be used as a substantive aid for law students. Let’s be real. Not every student is going to come up smelling roses. A barrel nearly always has a few potential rotten apples.
Law students who decide to hand over the writing of a class-required legal brief and let generative AI do the entire thing, well, that’s not what they ought to be doing. You can assume that some law school students will take that route. It is for those reasons that a formalized policy about the use of generative AI is needed by a law school. In addition, the faculty must be on the ball to ferret out deviations from the policies, doing so with care and not getting trapped in false or misleading means to do so.
A final few remarks for now on this heady matter.
I’ve heard various legal pundits spout that it is the worst of times when it comes to the emergence of generative AI usage in law schools. They gloomily fear that we are going to produce law graduates who do not know a whit of law. That’s the assuredly sad face look at the world.
I lean instead toward the happy-face side of things.
Allow me to elaborate.
Generative AI is amply going to shake up the legal realm. Law school students ought to know what is coming. It is a backward viewpoint to fully ban generative AI and won’t do much good anyway. Make sure your law school students are versed in the future. They are likely to be the ones that in a few years after starting their legal careers and therefore will be greatly impacted by generative AI. If the law school they came from had their heads in the sand, those graduates would be caught unduly off-guard.
Law schools and the future of lawyers matter a heck of a lot to our society. I’ve tried to provide a semblance of the arguments that concern the question of whether to have law students use generative AI or not do so. The above commentary and sentiment are all mine and do not necessarily reflect anyone else’s views other than my own. I’ve tried to judiciously combine my thoughts with the numerous discussions and interactions that I have had on these topics.
As a final teaser, go ahead and get yourself ready with another handy bucket of popcorn to read my upcoming analysis and insights on some of the other major topics covered at the recent symposium. I promise you a fun and fact-filled look at additional and vital considerations for the future of lawyering and the AI lawyering transformations coming this way.
The best of times is coming for those that have their eyes open.","https://imageio.forbes.com/specials-images/imageserve/652e023f699d70b9cc306338/0x0.jpg?format=jpg&crop=720,540,x54,y0,safe&height=900&width=1600&fit=bounds",2023-10-17 07:00:00
https://techxplore.com/news/2023-10-unveils-partially-disordered-phase-li-.html,Study unveils a new partially disordered phase in Li- and Mn-rich cathode materials,"This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:
Characterization of the as-synthesized L5M85, L10M70 and L15M55. a, The partially disordered spinel phase as an intermediate between the DRX and fully ordered spinel structures. b, XRD patterns of L5M85, L10M70 and L15M55, refined based on the rock salt structure. The lattice parameter (a) and weighted profile R factor (R wp ) are shown in the figure. c–e, SEM images of L5M85 (c), L10M70 (d) and L15M55 (e) after shaker milling with carbon (scale bar = 500 nm). f, STEM image and EDS mapping of the elements O, Mn and Ti in as-synthesized L5M85 (scare bar = 500 nm). g, SAED pattern of as-synthesized L5M85. Credit: Nature Energy (2023). DOI: 10.1038/s41560-023-01375-9
Lithium-ion (Li-ion) batteries are among the most widespread battery technologies worldwide, due to their light weight, high energy densities, easy fabrication process, rapid charging times and other advantageous properties. Identifying strategies that could boost their performance further or facilitate their future upscaling has been the focus of numerous recent studies.
One of the proposed approaches for improving the performance of Li-ion batteries entails identifying new promising cathode materials that can be made from metals that are abundant in nature. So far, Li-ion cathodes have been found to be in some ways ineffective, as phase transitions inside them can elicit what is known as voltage hysteresis, which adversely impacts battery capacity.
Researchers at University of California Berkeley and other institutes across the United States have recently unveiled an unconventional phase transformation in cathode materials that are rich in Li and manganese (Mn). The new phase they uncovered, outlined in a paper in Nature Energy, could enable the creation of highly performing batteries with Mn-based cathodes.
""We want to create high energy density cathode materials for Li-ion that can be made from earth-abundant metals, unlike current cathode materials which contain both Co and Ni,"" Gerbrand Ceder, co-author of the paper, told Tech Xplore. ""This would mean Li-ion batteries that are less expensive, thereby helping their market penetration in EVs, grid, etc.""
Mn is an Earth abundant metal, as it is already widely produced in large quantities for various real-world applications. This metal has a good redox voltage and could thus work well in Li-ion batteries with high energy densities.
These advantageous properties are what ultimately inspired Ceder and his colleagues to try to create cathodes containing a high amount of Mn. Some studies have already explored the potential of Mn-rich cathodes, yet most results gathered so far have been unsatisfactory.
""Previous efforts to use Mn-based cathodes have suffered from the fact that Mn has a tendency to move around and rearrange the crystal structure that you start from,"" Ceder said. ""We decided to turn that into an advantage and start from a material (DRX) that when cycled would turn into a structure that is very good for storing lithium. So, it was a form on inverse design: We knew the material would transform, so we just made sure it transformed to something very good for storing lithium.""
The new phase that Ceder and his colleagues unveiled in their study, dubbed the delta (δ) phase, has a unique, unconventional structure. This structure resembles that of spinels, a class of ceramics typically marked by an ordered internal organization.
""The phase we uncovered is related to the known spinel structure, but only forms that structure in very small domains, which are anti-phased with each other,"" Ceder explained. ""Spinel is a structure that is known to store lithium ions, but its commercialization has been problematic, as it undergoes a destructive phase transformation when cycled in a battery. ""
In the phase observed by the researchers, small domains of spinel act independently. This prevents the destructive transition previously observed in spinel-based cathodes during a battery's operation, instead allowing batteries to retain a good capacity for several battery cycles.
""We can make 'complex' structures in-situ while we charge and discharge a battery and these complex structures can have excellent performance,"" Ceder said. ""A cathode material based on only Mn- and Ti-oxide precursors can potentially be very inexpensive and could reduce the cost of Li-ion batteries by 40–50%. This would make batteries for EV and grid much cheaper.""
In their experiments, the researchers were able to identify the kinetic mechanisms underpinning their Li- and Mn-rich cathodes' transition to the so-called delta phase. This could pave the way for the development of more promising cathode materials with similar characteristics.
Initial tests performed by Ceder and his colleagues yielded very promising results, as the phase they unveiled was found to enable both a high energy density and good battery cyclability. In the future, their work could thus also encourage other teams to explore the potential of cathodes rich in Mn using similar experimental strategies.
""We believe that we can make even higher energy density materials,"" Ceder added. ""Also, we are working on accelerating this transformation to delta so one doesn't have to wait for 10–20 cycles to get the best performance out of one's battery.""
More information: Zijian Cai et al, In situ formed partially disordered phases as earth-abundant Mn-rich cathode materials, Nature Energy (2023). DOI: 10.1038/s41560-023-01375-9 Journal information: Nature Energy
© 2023 Science X Network",https://scx2.b-cdn.net/gfx/news/hires/2023/study-unveils-a-new-pa-1.jpg,2023-10-17 07:40:01
https://techxplore.com/news/2023-10-method-ai-1.html,A method to interpret AI might not be so interpretable after all,"This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:
A study finds humans struggle to understand the outputs of formal specifications, a method that some researchers claim can be used to make AI decision-making interpretable to humans. Credit: Bryan Mastergeorge, Massachusetts Institute of Technology
As autonomous systems and artificial intelligence become increasingly common in daily life, new methods are emerging to help humans check that these systems are behaving as expected. One method, called formal specifications, uses mathematical formulas that can be translated into natural-language expressions. Some researchers claim that this method can be used to spell out decisions an AI will make in a way that is interpretable to humans.
MIT Lincoln Laboratory researchers wanted to check such claims of interpretability. Their findings point to the opposite: Formal specifications do not seem to be interpretable by humans. In the team's study, participants were asked to check whether an AI agent's plan would succeed in a virtual game. Presented with the formal specification of the plan, the participants were correct less than half of the time.
""The results are bad news for researchers who have been claiming that formal methods lent interpretability to systems. It might be true in some restricted and abstract sense, but not for anything close to practical system validation,"" says Hosea Siu, a researcher in the laboratory's AI Technology Group. The group's paper, currently available on the arXiv preprint server, was accepted to the 2023 International Conference on Intelligent Robots and Systems held earlier this month.
Interpretability is important because it allows humans to place trust in a machine when used in the real world. If a robot or AI can explain its actions, then humans can decide whether it needs adjustments or can be trusted to make fair decisions. An interpretable system also enables the users of technology—not just the developers—to understand and trust its capabilities. However, interpretability has long been a challenge in the field of AI and autonomy. The machine learning process happens in a ""black box,"" so model developers often can't explain why or how a system came to a certain decision.
""When researchers say 'our machine learning system is accurate,' we ask 'how accurate?"" and 'using what data?' and if that information isn't provided, we reject the claim. We haven't been doing that much when researchers say 'our machine learning system is interpretable,' and we need to start holding those claims up to more scrutiny,"" Siu says.
Lost in translation
For their experiment, the researchers sought to determine whether formal specifications made the behavior of a system more interpretable. They focused on people's ability to use such specifications to validate a system—that is, to understand whether the system always met the user's goals.
Applying formal specifications for this purpose is essentially a by-product of its original use. Formal specifications are part of a broader set of formal methods that use logical expressions as a mathematical framework to describe the behavior of a model. Because the model is built on a logical flow, engineers can use ""model checkers"" to mathematically prove facts about the system, including when it is or isn't possible for the system to complete a task. Now, researchers are trying to use this same framework as a translational tool for humans.
""Researchers confuse the fact that formal specifications have precise semantics with them being interpretable to humans. These are not the same thing,"" Siu says. ""We realized that next-to-nobody was checking to see if people actually understood the outputs.""
In the team's experiment, participants were asked to validate a fairly simple set of behaviors with a robot playing a game of capture the flag, basically answering the question ""If the robot follows these rules exactly, does it always win?""
Participants included both experts and nonexperts in formal methods. They received the formal specifications in three ways—a ""raw"" logical formula, the formula translated into words closer to natural language, and a decision-tree format. Decision trees in particular are often considered in the AI world to be a human-interpretable way to show AI or robot decision-making.
The results: ""Validation performance on the whole was quite terrible, with around 45 percent accuracy, regardless of the presentation type,"" Siu says.
Confidently wrong
Those previously trained in formal specifications only did slightly better than novices. However, the experts reported far more confidence in their answers, regardless of whether they were correct or not. Across the board, people tended to over-trust the correctness of specifications put in front of them, meaning that they ignored rule sets allowing for game losses. This confirmation bias is particularly concerning for system validation, the researchers say, because people are more likely to overlook failure modes.
""We don't think that this result means we should abandon formal specifications as a way to explain system behaviors to people. But we do think that a lot more work needs to go into the design of how they are presented to people and into the workflow in which people use them,"" Siu adds.
When considering why the results were so poor, Siu recognizes that even people who work on formal methods aren't quite trained to check specifications as the experiment asked them to. And, thinking through all the possible outcomes of a set of rules is difficult. Even so, the rule sets shown to participants were short, equivalent to no more than a paragraph of text, ""much shorter than anything you'd encounter in any real system,"" Siu says.
The team isn't attempting to tie their results directly to the performance of humans in real-world robot validation. Instead, they aim to use the results as a starting point to consider what the formal logic community may be missing when claiming interpretability, and how such claims may play out in the real world.
This research was conducted as part of a larger project Siu and teammates are working on to improve the relationship between robots and human operators, especially those in the military. The process of programming robotics can often leave operators out of the loop. With a similar goal of improving interpretability and trust, the project is trying to allow operators to teach tasks to robots directly, in ways that are similar to training humans. Such a process could improve both the operator's confidence in the robot and the robot's adaptability.
Ultimately, they hope the results of this study and their ongoing research can better the application of autonomy, as it becomes more embedded in human life and decision-making.
""Our results push for the need to do human evaluations of certain systems and concepts of autonomy and AI before too many claims are made about their utility with humans,"" Siu adds.
More information: Ho Chit Siu et al, STL: Surprisingly Tricky Logic (for System Validation), arXiv (2023). DOI: 10.48550/arxiv.2305.17258 Journal information: arXiv
This story is republished courtesy of MIT News (web.mit.edu/newsoffice/), a popular site that covers news about MIT research, innovation and teaching.",https://scx2.b-cdn.net/gfx/news/2023/a-method-to-interpret.jpg,2023-10-16 17:27:04
https://techxplore.com/news/2023-10-algorithm-quality-electricity-local-generation.html,New algorithm to help control quality of electricity in local generation systems,"This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:
Prototype. Credit: Ildar Idrisov
With the new stage of energy transition in progress, the key tendency of power market development today is distributed power generation, which is characterized by decentralization, smart energy systems, involvement of consumers, and a higher share of renewable energy sources. In distributed generation systems, electricity comes from a number of local power objects, instead of one large station. For example, home owners who use solar panels can sell excess electricity back into the grid.
A fundamental role in these systems belongs to inverters that convert the generated electricity into the alternating current with specific frequency. In Europe and CIS countries, it equals 50 Hz. Researchers from Skoltech presented an algorithm for inverters that aims to control the quality of electricity injected to the main grid. The results are spotlighted by IEEE and have been published as part of 2023 IEEE Belgrade PowerTech.
""Inverters are programmed with mathematical functions and equations with certain coefficients,"" explains the leading author of the research Ilya Veretennikov, an engineer in the Energy Center's Smart Grid Laboratory.
""If grid parameters remain the same, it is enough to adjust the coefficients just once. Energy systems with distributed (local) generation constantly change (for example, if some market participants stopped selling their electricity), coefficients need to be recalculated. It is difficult to evaluate whether the coefficients are calculated correctly or not, but it is necessary to ensure the quality of electricity, which must meet the standard. Otherwise, it cannot be injected into the grid.""
Ilya Veretennikov working on lab experiments. Credit: Ildar Idrisov
The research team developed an algorithm for a controller, which would recalculate coefficients automatically controlling the quality of electricity injected in the main grid. Using data on calculated voltage, the controller generates a control signal, which ensures the alternating current frequency (50 Hz) without any distortions.
""During our research, we came up with a grid model and a more detailed inverter model. With their help, we checked different algorithms of the controller, their stability and efficiency. We proceeded with validating our results through experimental data. We plugged a real inverter in the grid, modeling a case with a local load, when a part of energy is transferred to the grid. In the lab, we work with low-power inverters, which are suitable for home users. We have great equipment for a detailed simulation in real time. It helps simulate any grid with any number of inverters and any parameters,"" adds Veretennikov.
According to the authors, they see the potential of the research and of the local power generation as a whole in those remote regions which, despite many clear days, still exploit unsustainable power energy sources. The research team is planning to fully automate the algorithm following the plug-and-play concept.
""Configuration is a burden for every end user. As of now, not all parameters are automatically configured, but we are working on the algorithm to make it fully automatic as a modern device that can be used right after connecting it to the computer without manual configurations,"" concludes Veretennikov.
More information: Ilya Veretennikov et al, Proportional Multiresonant Controller with Automatic Gains Adjustment for Grid-Connected Inverters, 2023 IEEE Belgrade PowerTech (2023). DOI: 10.1109/PowerTech55446.2023.10202893",https://scx2.b-cdn.net/gfx/news/2023/new-algorithm-to-help-1.jpg,2023-10-16 17:14:03
https://www.reuters.com/innovation/article/tsmc-results/tsmc-third-quarter-profit-to-slide-30-focus-on-how-much-growth-to-come-idUSKBN31H07N,"TSMC third-quarter profit to slide 30%, focus on how much growth to come","TAIPEI (Reuters) - Taiwan Semiconductor Manufacturing Co Ltd is expected to report a 30% slump in third-quarter profit on Thursday but analysts predict robust growth next year as the chip industry emerges from its current downturn.
FILE PHOTO: A logo of Taiwanse chip giant TSMC can be seen in Tainan, Taiwan December 29, 2022. REUTERS/Ann Wang/File Photo
The likely decline in profit also reflects a strong performance last year, when the company was still riding high on pent-up post-pandemic demand.
The world’s largest contract chipmaker is set to report net profit of T$195.9 billion ($6 billion) for July-September - its second straight quarter of profit decline, according to an LSEG SmartEstimate drawn from 19 analysts. SmartEstimates give greater weighting to forecasts from analysts who are more consistently accurate.
Revenue for the quarter came in at around $17 billion, according to TSMC figures, down 20% from a year earlier and roughly the middle of the company’s forecast range.
Global demand for semiconductors began to weaken in the second half of last year, but analysts say inventories at smartphone and computer makers are running down and restocking demand is expected to pick up.
Given that, much of Thursday’s focus will be on TSMC’s outlook for the fourth quarter and beyond.
Morgan Stanley analysts have forecast 10% revenue growth for the fourth quarter but also said in a research note that “guidance may surprise to the upside,” citing strong demand for high-end chips used in artificial intelligence as one factor.
The AI boom has helped drive up the price of shares in Asia’s most valuable company, with TSMC’s Taipei-listed stock having surged 23% so far this year.
An LSEG SmartEstimate puts TSMC’s 2024 revenue growth at around 22%.
Sources have said, however, that TSMC has been nervous about customer demand and told its major suppliers to delay the delivery of high-end chip-making equipment, although they added that suppliers expect the delay to be short-term.
Some analysts are also reining in their optimism somewhat.
Fubon Securities expects a slow start to next year for TSMC, with 10% growth in the first quarter, predicting order cancellations towards the year end and mild restocking demand. In particular, it is concerned that Apple, a major customer, may revise down its orders.
“We think the market consensus is still too bullish,” it said in a research note.
The company is due to report at 0600 GMT on Thursday.
($1 = 32.2290 Taiwan dollars)",https://s2.reutersmedia.net/resources/r/?m=02&d=20231017&t=2&i=1647931385&w=1200&r=LYNXMPEJ9G044,2023-10-17 03:55:49
https://www.reuters.com/innovation/article/canada-batteries/canada-to-give-belgiums-umicore-up-to-c1-billion-for-new-battery-components-plant-idUSKBN31G1PF,Canada to give Belgium's Umicore up to C$1 billion for new battery components plant,"OTTAWA (Reuters) - Canada and the province of Ontario will give up to C$1 billion to a unit of Belgium’s Umicore to help it build a plant that will produce components for electric vehicle batteries, Ottawa said on Monday.
The facility, in the Ontario town of Loyalist Township, will manufacture cathode active materials and precursor cathode active materials, federal Innovation Minister Francois-Philippe Champagne said in a statement.
The plant - the first of its kind in North America - will initially employ 600 people and have a battery materials production capacity of 35 gigawatt hours annually.
Canada, home to a large mining sector for minerals such as lithium, nickel and cobalt, wants to woo firms involved in all levels of the electric vehicle (EV) supply chain via a multibillion-dollar green technology.
The Umicore plant is due to be built in stages and could be worth C$2.7 billion when fully completed. Canada will invest up to C$551.3 billion with Ontario adding up to C$424.6 billion.
The full project has the potential to produce enough battery materials to support the production of over 800,000 EVs per year, Champagne said.",https://s4.reutersmedia.net/resources_v2/images/rcom-default.png,2023-10-16 19:03:02
https://www.reuters.com/innovation/article/overstock-com-jat/hedge-fund-jat-pushes-overstock-com-to-mull-options-filing-idUSKBN31G1KE,Hedge fund JAT pushes Overstock.com to mull options -filing,"NEW YORK (Reuters) - Hedge fund JAT Capital on Monday urged Overstock.com to consider selling certain assets and overhauling its management and compensation, warning it may seek board seats if its suggestions are ignored, a regulatory filing on Monday showed.
The hedge fund, run by John Thaler, owns a 9.1% stake in Overstock.com, and made its demands public in the filing after sending a letter outlining its wishes to the company last week.
Overstock’s stock price climbed nearly 9% after the filing.
Overstock.com, which spent $21.5 million to buy certain intellectual property assets from Bed Bath & Beyond a few months ago, did not immediately respond to a request for comment.
JAT is not traditionally an activist investor but its filing signaled mounting frustration with the company and left open the option of pursuing strategies like running a proxy contest.
JAT also wants the company to emphasize stock option participation and develop a business plan with financial objectives, the filing said.
“The Reporting Persons may consider to seek Board representation to the extent the above recommendations have not been explored, pursued and executed satisfactorily.”",https://s4.reutersmedia.net/resources_v2/images/rcom-default.png,2023-10-16 16:56:50
https://techcrunch.com/2023/10/17/ray-ban-meta-review/,Ray-Ban Meta sunglasses have 'influencer' written all over them,"Ray-Ban Meta sunglasses have ‘influencer’ written all over them The companies have maintained a slim and light design, while rendering their predecessor obsolete with Facebook and Instagram livestreaming
This is a review-in-progress. More soon!
Somewhere between the Ray-Ban Meta and Meta Quest 3 sits an ideal mixed-reality headset. It’s slim, light, offers hand tracking and passthrough and livestreams video when the moment calls for it. It’s designed to be worn inconspicuously outdoors, until the time comes for content capture.
The Meta Quest Ray-Ban is a fantasy at the moment — albeit one that points in the direction of where its makers think this is all headed. Presently, the Ray-Ban Meta and Meta Quest 3 are very different devices, with little in the way of overlap, beyond being head-worn products with built-in sensors.
The Meta Quest 3 is a mixed-reality headset designed to be worn exclusively indoors. It’s light, perhaps, compared to other headsets of its ilk, but wearing the thing while walking around outside frankly sounds a bit miserable. That’s precisely the use case the Ray-Ban Meta was designed for: freedom of movement outside the house that’s designed to go (mostly) unnoticed.
Just prior to writing this, I slipped a pair on, before the JFK airport mobility cart drove my sciatica-ridden ass to the gate. I would say the pair was inconspicuous but for the fact that I was wearing a pair of sunglasses indoors. Well, that and the extremely necessary recording lighting that flashes on so you can’t creep shoot folks without their knowledge. Here’s some of that video:
We got our first glimpse of the Ray-Ban Meta at a briefing just ahead of the recent Connect conference. I was genuinely impressed by the industrial design the join team came up with. Most folks would hard-pressed to distinguish the charger from a standard Ray-Ban classic eyeglass case. It’s a little thicker than some, sure. A bit heavier. More rigid. But the team was able to make surprisingly few concessions.
There are a lot of clever touches here. In the place of a snap is a ring. Open the case and it glows green when fully charged and orange when not. The orange starts blinking when the battery is low. Space has been maximized inside. The battery sits directly beneath the glasses’ folded temples. In front of this is a dock with two charging pins that lie flush with a pair of contact pads hidden on the underside of the glasses’ bridge, held in place with magnets and a small tab.
The USB-C port is located on the outside bottom of the case, allowing it to sit on its back while being charged. Directly above this on the case’s rear is the Bluetooth pairing button. The case is slimmer than the last gen and can be carried in a pocket comfortably.
Meta says the glasses get “up to” four hours on a charge, while the case gets a total of eight charging cycles, for a grand total of 36 hours. As the company notes, “Battery life varies by use, configuration, settings and many other factors.” That’s the case with all tech, of course, but I did notice that video is a power drainer.
The companies really leaned into the style side of things here (not a bad decision when designing tech meant to be worn on the body). There are two main designs for the glasses. There’s the classic Wayfarer (which is probably what you think of when you think of sunglasses) and the new Headliner (not dissimilar from Wayfarer, but significantly more rounded on the top and bottom).
According to Meta, there are 150 design combos possible, when you factor in all of the different design options, including frame color, style and lenses (including sunglasses, clear, prescription, transitions and polarized).
The temples are thicker than most sunglasses — to be expected, seeing as how they contain the speakers and other components (there’s a transparent option, if you want to see for yourself) — but again, the designers have done a good job keeping size down, all things considered. And again, while slightly heavier that a standard pair of Wayfarers (50.8 g vs. 44 g), you can wear them comfortably all day if you want to (or at least the less than four hours the battery lasts).
There’s a touchpad on the outside of the left temple. Swiping back and forth will adjust the volume (other features can be customized in-app). It also doubles as a control panel for live streaming, since you likely don’t want to futz with your phone or keep using the wake word. A tap can check Instagram or Facebook comments and viewers in real-time. The capture button sits next to the hinge on the left temple
There are a pair of small circular modules on the end pieces. They look identical, for the sake of symmetry, but serve very different — albeit related — functions. On the top right (when facing the glasses) is the 12-megapixel camera. On the top left is an LED that turns on to alert people in your vicinity that you’re recording.
When covered, the glasses send an audio alert that they’ve stopped recording. This is to avoid people sticking a piece of electrical tape to hide the light. Meta says they didn’t hear of any specific examples of this happening, but they almost certainly got that feedback. Again, privacy is paramount for a device like this, especially since it’s something that most people around you don’t know exists. When the battery is low, you’ll get a spoken alert and the light will blink orange and turn red right before shutting down. The light will blink white when receiving a call, do a single flash when taking a photo and glow steadily when recording.
When pairing, it flashes blue, going solid when connected. The pairing process is pretty straight forward. You’ll need to download the Meta View app, choose between Meta Ray-Ban and Ray-Ban Stories and allow bluetooth to connect . Images and video will save to the glasses’ 32GB of internal storage (that’s roughly 500 photos or 100 videos at the maximum 30 seconds apiece). You’ll need to tap “Import” inside the app to connect via WiFi and download the contents to your phone. You can also set it up to auto import via settings.
Once everything is paired, put the glasses on and open either Facebook or Instagram to livestream. Tap the plus icon and it will bring you to the livestream screen. Your phone’s camera is, understandably, the default, but double pressing the capture button will switch over to the glasses. Livestreaming is probably the single biggest killer app Ray-Ban Stories was missing.
There are barely visible down firing speakers on the bottom of the temple tips. When I first tried the speakers in an otherwise silent room, they sounded surprisingly loud and clear. They’re open-ear speakers, rather than bone conduction, which has its pluses and minuses. Bone conduction tends to be quite quiet but does a decent job with ambient noise, since it’s arriving at your eardrums through a different method.
As expected, I had to turn up the volume quite a bit among the airport din. I would recommend them for quieter environments, where possible, but obviously that isn’t always an option. Sound is integral to the headphones, beyond music listening. For instance, there’s an audible shutter click when you take a picture.
There are on-board microphones as well, which listen for the “hey Meta” wake word. Voice certainly makes sense on a device like this. It can be used to take a picture, stop and start video and adjust volume (turns out voice is kind of an annoying way to do the latter). You can also ask the glasses for the time, weather and how much battery is left. You can also ask Alexa style-questions, and Meta AI will attempt to answer. That’s currently only available here in the U.S. through an open beta.
The price starts at $299 for standard lenses. Polarized run $329 and transitions $379. Prescription lenses are on a sliding scale. The price will almost certainly be a deterrent for many — and understandably so. Ultimately, you need to ask yourself how much value a face-worn camera will bring to your life. If you make a living livestreaming, it may make sense. It’s a lot to pay however, for sheer novelty.
It’s worth noting that future updates will bring more value to the device, including sign translation (through voice) and the ability to identify landmarks in front of you. One can see the future of head-worn computing laid out in front of your face — though it’s still going to be a while before we get there.",https://techcrunch.com/wp-content/uploads/2023/09/Meta-Ray-Ban-Stories-06.jpg?w=1200,2023-10-17 07:01:44
https://techcrunch.com/2023/10/17/ray-ban-meta-review/,Ray-Ban Meta sunglasses have 'influencer' written all over them,"Ray-Ban Meta sunglasses have ‘influencer’ written all over them The companies have maintained a slim and light design, while rendering their predecessor obsolete with Facebook and Instagram livestreaming
This is a review-in-progress. More soon!
Somewhere between the Ray-Ban Meta and Meta Quest 3 sits an ideal mixed-reality headset. It’s slim, light, offers hand tracking and passthrough and livestreams video when the moment calls for it. It’s designed to be worn inconspicuously outdoors, until the time comes for content capture.
The Meta Quest Ray-Ban is a fantasy at the moment — albeit one that points in the direction of where its makers think this is all headed. Presently, the Ray-Ban Meta and Meta Quest 3 are very different devices, with little in the way of overlap, beyond being head-worn products with built-in sensors.
The Meta Quest 3 is a mixed-reality headset designed to be worn exclusively indoors. It’s light, perhaps, compared to other headsets of its ilk, but wearing the thing while walking around outside frankly sounds a bit miserable. That’s precisely the use case the Ray-Ban Meta was designed for: freedom of movement outside the house that’s designed to go (mostly) unnoticed.
Just prior to writing this, I slipped a pair on, before the JFK airport mobility cart drove my sciatica-ridden ass to the gate. I would say the pair was inconspicuous but for the fact that I was wearing a pair of sunglasses indoors. Well, that and the extremely necessary recording lighting that flashes on so you can’t creep shoot folks without their knowledge. Here’s some of that video:
We got our first glimpse of the Ray-Ban Meta at a briefing just ahead of the recent Connect conference. I was genuinely impressed by the industrial design the join team came up with. Most folks would hard-pressed to distinguish the charger from a standard Ray-Ban classic eyeglass case. It’s a little thicker than some, sure. A bit heavier. More rigid. But the team was able to make surprisingly few concessions.
There are a lot of clever touches here. In the place of a snap is a ring. Open the case and it glows green when fully charged and orange when not. The orange starts blinking when the battery is low. Space has been maximized inside. The battery sits directly beneath the glasses’ folded temples. In front of this is a dock with two charging pins that lie flush with a pair of contact pads hidden on the underside of the glasses’ bridge, held in place with magnets and a small tab.
The USB-C port is located on the outside bottom of the case, allowing it to sit on its back while being charged. Directly above this on the case’s rear is the Bluetooth pairing button. The case is slimmer than the last gen and can be carried in a pocket comfortably.
Meta says the glasses get “up to” four hours on a charge, while the case gets a total of eight charging cycles, for a grand total of 36 hours. As the company notes, “Battery life varies by use, configuration, settings and many other factors.” That’s the case with all tech, of course, but I did notice that video is a power drainer.
The companies really leaned into the style side of things here (not a bad decision when designing tech meant to be worn on the body). There are two main designs for the glasses. There’s the classic Wayfarer (which is probably what you think of when you think of sunglasses) and the new Headliner (not dissimilar from Wayfarer, but significantly more rounded on the top and bottom).
According to Meta, there are 150 design combos possible, when you factor in all of the different design options, including frame color, style and lenses (including sunglasses, clear, prescription, transitions and polarized).
The temples are thicker than most sunglasses — to be expected, seeing as how they contain the speakers and other components (there’s a transparent option, if you want to see for yourself) — but again, the designers have done a good job keeping size down, all things considered. And again, while slightly heavier that a standard pair of Wayfarers (50.8 g vs. 44 g), you can wear them comfortably all day if you want to (or at least the less than four hours the battery lasts).
There’s a touchpad on the outside of the left temple. Swiping back and forth will adjust the volume (other features can be customized in-app). It also doubles as a control panel for live streaming, since you likely don’t want to futz with your phone or keep using the wake word. A tap can check Instagram or Facebook comments and viewers in real-time. The capture button sits next to the hinge on the left temple
There are a pair of small circular modules on the end pieces. They look identical, for the sake of symmetry, but serve very different — albeit related — functions. On the top right (when facing the glasses) is the 12-megapixel camera. On the top left is an LED that turns on to alert people in your vicinity that you’re recording.
When covered, the glasses send an audio alert that they’ve stopped recording. This is to avoid people sticking a piece of electrical tape to hide the light. Meta says they didn’t hear of any specific examples of this happening, but they almost certainly got that feedback. Again, privacy is paramount for a device like this, especially since it’s something that most people around you don’t know exists. When the battery is low, you’ll get a spoken alert and the light will blink orange and turn red right before shutting down. The light will blink white when receiving a call, do a single flash when taking a photo and glow steadily when recording.
When pairing, it flashes blue, going solid when connected. The pairing process is pretty straight forward. You’ll need to download the Meta View app, choose between Meta Ray-Ban and Ray-Ban Stories and allow bluetooth to connect . Images and video will save to the glasses’ 32GB of internal storage (that’s roughly 500 photos or 100 videos at the maximum 30 seconds apiece). You’ll need to tap “Import” inside the app to connect via WiFi and download the contents to your phone. You can also set it up to auto import via settings.
Once everything is paired, put the glasses on and open either Facebook or Instagram to livestream. Tap the plus icon and it will bring you to the livestream screen. Your phone’s camera is, understandably, the default, but double pressing the capture button will switch over to the glasses. Livestreaming is probably the single biggest killer app Ray-Ban Stories was missing.
There are barely visible down firing speakers on the bottom of the temple tips. When I first tried the speakers in an otherwise silent room, they sounded surprisingly loud and clear. They’re open-ear speakers, rather than bone conduction, which has its pluses and minuses. Bone conduction tends to be quite quiet but does a decent job with ambient noise, since it’s arriving at your eardrums through a different method.
As expected, I had to turn up the volume quite a bit among the airport din. I would recommend them for quieter environments, where possible, but obviously that isn’t always an option. Sound is integral to the headphones, beyond music listening. For instance, there’s an audible shutter click when you take a picture.
There are on-board microphones as well, which listen for the “hey Meta” wake word. Voice certainly makes sense on a device like this. It can be used to take a picture, stop and start video and adjust volume (turns out voice is kind of an annoying way to do the latter). You can also ask the glasses for the time, weather and how much battery is left. You can also ask Alexa style-questions, and Meta AI will attempt to answer. That’s currently only available here in the U.S. through an open beta.
The price starts at $299 for standard lenses. Polarized run $329 and transitions $379. Prescription lenses are on a sliding scale. The price will almost certainly be a deterrent for many — and understandably so. Ultimately, you need to ask yourself how much value a face-worn camera will bring to your life. If you make a living livestreaming, it may make sense. It’s a lot to pay however, for sheer novelty.
It’s worth noting that future updates will bring more value to the device, including sign translation (through voice) and the ability to identify landmarks in front of you. One can see the future of head-worn computing laid out in front of your face — though it’s still going to be a while before we get there.",https://techcrunch.com/wp-content/uploads/2023/09/Meta-Ray-Ban-Stories-06.jpg?w=1200,2023-10-17 07:01:44
https://techcrunch.com/2023/10/17/procurify-lands-fresh-cash-to-invest-in-ai-powered-tools-for-procurement/,Procurify lands fresh cash to invest in AI-powered tools for procurement,"Roughly eight years ago, a little-known startup called Procurify raised $4 million for its platform that hosts tools to take some of the pain out of enterprise procurement.
The company never became buzzy, exactly. But Procurify grew steadily over the subsequent years, going on to raise $20 million in its Series B and today closing a $50 million Series C funding round led by Ten Coves Capital with participation from Export Development Canada, Canada’s export credit agency.
Procurify, which is based in Vancouver, Canada (hence the investment from the EDA), was co-founded by Aman Mann (the CEO), Eugene Dong (the CTO) and Kenneth Loi (the former CCO). The trio began working on the idea for the company in Dong’s parents’ basement after meeting in British Columbia Institute of Technology’s business management program in 2011.
“We recognized a gap in the procurement market for affordable, easy-to-use procurement software,” Mann told TechCrunch in an email interview. “In virtually every industry, organizations are struggling with a lack of real-time spend visibility and control.”
To Mann’s point, according to a recent Statista survey, hundreds of companies engaging in business-to-business procurement — i.e. finding, agreeing to terms and purchasing goods and services from a third party — admit to struggling with compliance processes, complex approval processes and purchasing systems and reconciling invoices in a timely manner.
So how does Procurify help? By consolidating various procurement steps in one place, mainly.
Procurify offers modules to manage purchasing, accounts payable (i.e. money owed to suppliers) and data analytics. Using the platform, customers can reallocate procurement spend and adjust forecasts, identify bottlenecks in “procure-to-pay” workflows and perform supplier analyses to inform future procurement decisions.
Procurify also leverages AI, detecting anomalies in purchase orders or invoices to flag them for review.
“In today’s post-pandemic economy, industries are grappling with layoffs, disrupted supply chains and rising operational costs,” Mann said. “The need for responsible spend controls and clear financial oversight is more pressing than ever.”
Procurify competes with incumbents (Coupa, SAP Ariba), enterprise resource management software with procurement management features (NetSuite) and upstarts (Precoro, Zip) in the over-$6.1 billion procurement software segment.
The startup appears to be doing well for itself, though, with a customer base of over 700 companies, a 100% year-over-year increase in sales and plans to invest heavily in bringing new AI capabilities to market.
“Procurify helps organizations bring more spend under management, thereby consolidating spend data from our customers’ procure-to-pay workflows to provide a complete picture of expenditures before they’re committed,” Mann said. “By harnessing the power of this comprehensive spend data and integrating it with AI models, enterprises could unearth opportunities for process optimization, manage risks and achieve cost efficiencies.”
Procurify, which has a team of just over 170 employees, has raised a total of $70 million in venture capital to date. In addition to AI R&D, Mann says that the proceeds from the Series C will be put toward general expansion and launching new payment features.","https://techcrunch.com/wp-content/uploads/2022/09/GettyImages-931203582.jpg?resize=1200,800",2023-10-17 12:00:48
https://techcrunch.com/2023/10/17/reality-defender-raises-15m-to-detect-text-video-and-image-deepfakes/,"Reality Defender raises $15M to detect text, video and image deepfakes","Reality Defender, one of several startups developing tools to attempt to detect deepfakes and other AI-generated content, today announced that it raised $15 million in a Series A funding round led by DCVC with participation from Comcast Ventures, Ex/ante, Parameter Ventures and Nat Friedman’s AI Grant.
The proceeds will be put toward doubling Reality Defender’s 23-person team into the next year and improving its AI content detection models, according to co-founder and CEO Ben Colman.
“New methods of deepfaking and content generation will consistently appear, taking the world by surprise both through spectacle and the amount of damage they can cause,” Colman told TechCrunch in an email interview. “By adopting a research-forward mindset, Reality Defender can stay several steps ahead of these new generation methods and models before they appear publicly, being proactive about detection instead of reacting to what just appears today.”
Colman, a former Goldman Sachs VP, launched Reality Defender in 2021 alongside Ali Shahriyari and Gaurav Bharaj. Shahriyari previously worked at Originate, a digital transformation tech consulting firm, and the AI Foundation, a startup building AI-powered animated chatbots. Bharaj was a colleague of Shahriyari’s at the AI Foundation, where he led R&D.
Reality Defender began as a nonprofit. But, according to Colman, the team turned to outside financing once they realized the scope of the deepfakes problem — and the growing commercial demand for deepfake-detecting technologies.
Colman’s not exaggerating about the scope. DeepMedia, a Reality Defender rival working on synthetic media detection tools, estimates that there’s been three times as many video deepfakes and eight times as many voice deepfakes posted online this year compared to the same time period in 2022.
The rise in the volume of deepfakes is attributable in large part to the commoditization of generative AI tools.
Cloning a voice or creating a deepfake image or video — that is, an image or video digitally manipulated to convincingly replace a person’s likeness — used to cost hundreds to thousands of dollars and require data science know-how. But over the last few years, platforms like the voice-synthesizing ElevenLabs and open source models such as Stable Diffusion, which generates images, have enabled malicious actors to mount deepfake campaigns at little to no cost.
Just this month, users on the notorious chat board 4chan leveraged a range of generative AI tools, including Stable Diffusion, to unleash a blitz of racist images online. Meanwhile, trolls have used ElevenLabs to imitate the voices of celebrities, generating audio ranging in content from memes and erotica to virulent hate speech. And state actors aligned with the Chinese Communist Party have generated lifelike AI avatars portraying news anchors, commenting on topics such as gun violence in the U.S.
Some generative AI platforms have implemented filters and other restrictions to combat abuse. But, as in cybersecurity, it’s a cat and mouse game.
“Some of the greatest risk from AI-generated media stems from use and abuse of deepfaked materials on social media,” Colman said. “These platforms have no incentive to scan deepfakes because there’s no legislation requiring them to do so, unlike the legislation forcing them to remove child sexual abuse material and other illegal materials.”
Reality Defender purports to detect a range of deepfakes and AI-generated media, offering an API and web app that analyze videos, audio, text and images for signs of AI-driven modifications. Using “proprietary models” trained on in-house data sets “created to work in the real world and not in the lab,” Colman claims that Reality Defender is able to achieve a higher deepfake accuracy rate than its competitors.
“We train an ensemble of deep learning detection models, each of which focuses on its own methodology,” Colman said. “We learned long ago that not only does the single-model, monomodal approach not work, but neither does testing for accuracy in a lab versus real-world accuracy.”
But can any tool reliably detect deepfakes? That’s an open question.
OpenAI, the AI startup behind the viral AI-powered chatbot ChatGPT, recently pulled its tool to detect AI-generated text, citing its “low rate of accuracy.” And at least one study shows evidence that deepfake video detectors can be fooled if the deepfakes fed into them are edited in a certain way.
There’s also the risk of deepfake detection models amplifying biases.
A 2021 paper from researchers at the University of Southern California found that some of the data sets used to train deepfake detection systems might under-represent people of a certain gender or with specific skin colors. This bias can be amplified in deepfake detectors, the coauthors said, with some detectors showing up to a 10.7% difference in error rate depending on the racial group.
Colman stands behind Reality Defender’s accuracy. And he asserts the company actively works to mitigate biases in its algorithms, incorporating “a wide variety accents, skin colors and other varied data” into its detector training data sets.
“We’re always training, retraining and improving our detector models so they fit new scenarios and use cases, all while accurately representing the real world and not just a small subset of data or individuals,” Colman said.
Call me cynical, but I’m not sure if I buy those claims without a third-party audit to back them up. My skepticism isn’t impacting Reality Defender’s business, though, which Colman tells me is quite robust. Reality Defender’s customer base spans governments “across several continents” as well as “top-tier” financial institutions, media corporations and multinationals.
That’s despite competition from startups like Truepic, Sentinel and Effectiv, as well as deepfake detection tools from incumbents such as Microsoft.
In an effort to maintain its position in the deepfake detection software market, which was valued at $3.86 billion in 2020, according to HSRC, Reality Defender plans to introduce an “explainable AI” tool that’ll let customers scan a document to see color-coded paragraphs of AI-generated text. Also on the horizon is real-time voice deepfake detection for call centers, to be followed b ay real-time video detection tool.
“In short, Reality Defender will protect a company’s bottom line and reputation,” Colman said. “Reality Defender uses AI to fight AI, helping the largest entities, platforms and governments determine whether a piece of media is likely real or likely manipulated. This helps combat against fraud in the finance world, prevent the dissemination of disinformation in media organizations and prevent the spread of irreversible and damaging materials on the governmental level, just to name three out of hundreds of use cases.”","https://techcrunch.com/wp-content/uploads/2023/07/GettyImages-1463459171.jpg?resize=1200,800",2023-10-17 12:00:27
https://techcrunch.com/2023/10/17/nova-credit-lands-45m-in-funding-to-grow-its-cross-border-and-alternative-data-credit-products/,Nova Credit lands $45M to grow its cross-border and alternative data credit products,"Moving from one country to another is difficult in many ways, not the least of which involves starting over financially.
Nova Credit, which started out as a graduate research project out of Stanford University about seven years ago, was founded to help immigrants overcome the obstacles of applying for things like apartments or loans with no credit history in the U.S.
“We realized that half of the graduate student population of any university consists of international students – and if you go and ask them about their experience with financial services, you’ll hear some version of the same story – ‘I can’t get credit or I can’t get a credit card. Or I need to go ask my classmate to co-sign for an apartment or cell phone plan,’ ” said Misha Esipov, CEO and founder of Nova Credit.
With that Credit Passport product, Nova has connectivity into credit bureau data from other parts of the world through its APIs. Nova launched that product with American Express and then added dozens of institution partners over the years, such as HSBC,Scotiabank, Verizon and Earnest. (Nova Credit emerges embedded within those institutions’ applications).
It works in 20 countries outside of the U.S. as well. If a person from the U.S. moves to London or Singapore, for example, they can get approved for banking products internationally in those markets through Nova.
In recent years, the startup also has expanded beyond its flagship Credit Passport product to also offer anyone – not just immigrants – the ability to use alternative data for credit but providing access to their bank account. That product, dubbed Cash Atlas, is cash flow underwriting product that allows anyone with a U.S. bank account to allow the information – such as rent payment history or direct deposit of paychecks – inside those accounts to be used to help them apply for credit. It is aimed at the tens of millions of people that are “effectively locked out of the U.S. financial system,” Esipov said.
“We’ve started to expand from a single product company to a multi-product company and platform…Our strategy is to evolve into a more data analytics company that serves not only people that are new to this country, but frankly any customer segment and plugging the gaps in this antiquated traditional credit reporting industry which doesn’t do well for serving customers who are new to credit,” Esipov told TechCrunch in an interview.
Today, Nova is announcing that it has raised $45 million in Series C funding, additional capital that it plans to use toward expanding its product offering and geographically, Esipov told TechCrunch exclusively. The round came together “in a matter of weeks,” he said.
Canapi Ventures led the round, which included participation from existing backers Kleiner Perkins, General Catalyst, Index Ventures and Y Combinator as well as new investors such as Avid Ventures, Geodesic Capital, Harmonic Capital, Radiate Capital, and Socium Ventures (Cox Enterprises).
The raise marks the company’s first external round of financing since February 2020, which makes it a bit of an outlier in the fintech space, which experienced a major funding boom in 2020 and 2021. At that time, Nova raised $50 million in a financing that reportedly gave it a valuation of $295 million after its first close.
Esipov declined to disclose Nova’s current valuation, saying only that the company was “xxxx happy” He also declined to reveal hard revenue figures, saying only that the company has grown its revenues by 10x since that 2020 funding round and that it more than tripled its data transaction volumes since the start of 2023.
Nova has remained relatively lean, with about 100 employees. It does plan to do some more hiring with its new capital. It also plans to take its Credit Passport business global – having already launched in markets such as Canada, the United Kingdom, the United Arab Emirate and Singapore. The company is also planning to invest in its Cash Atlas product and developing more new products.
For now, Nova’s Passport product provides the majority of the company’s revenue but Atlas “is growing even more quickly on a percentage basis right now.” Esipov said the company has invested “heavily” in information security and compliance since it was a seed-stage company.
The executive projects that the company will reach profitability in the relatively near future, possibly as early as next year. It opted not to raise more capital – in fact less than its last round – to avoid taking on “unnecessary dilution,” he added.
Jeffrey Reitman, general partner at Canapi Ventures, told TechCrunch he was initially attracted to Nova’s mission of enabling newcomers and thin-file consumers the ability to have fair access to financial products. Canapi first invested in the company in the Series B round and is impressed with “the explosive growth” it has displayed since.
“Many of our banking LPs are in active dialogues with Nova Credit to leverage their products to better serve their customers and that also nicely aligns with the mission here at Canapi,” he said.
Nova, Reitman added, “has amassed more collective access to international credit data than any one of the major credit bureaus and that makes for a very valuable proposition for its customers.”
Want more fintech news in your inbox? Sign up for The Interchange here.","https://techcrunch.com/wp-content/uploads/2020/09/GettyImages-a0146-000299-e1646928299148.jpg?resize=1200,799",2023-10-17 12:00:15
https://techcrunch.com/2023/10/17/microsoft-affiliated-research-finds-flaws-in-gtp-4/,Microsoft-affiliated research finds flaws in GTP-4,"Sometimes, following instructions too precisely can land you in hot water — if you’re a large language model, that is.
That’s the conclusion reached by a new, Microsoft-affiliated scientific paper that looked at the “trustworthiness” — and toxicity — of large language models (LLMs) including OpenAI’s GPT-4 and GPT-3.5, GPT-4’s predecessor.
The co-authors write that, possibly because GPT-4 is more likely to follow the instructions of “jailbreaking” prompts that bypass the model’s built-in safety measures, GPT-4 can be more easily prompted than other LLMs to spout toxic, biased text.
In other words, GPT-4’s good “intentions” and improved comprehension can — in the wrong hands — lead it astray.
“We find that although GPT-4 is usually more trustworthy than GPT-3.5 on standard benchmarks, GPT-4 is more vulnerable given jailbreaking system or user prompts, which are maliciously designed to bypass the security measures of LLMs, potentially because GPT-4 follows (misleading) instructions more precisely,” the co-authors write in a blog post accompanying the paper.
Now, why would Microsoft greenlight research that casts an OpenAI product it itself uses (GPT-4 powers Microsoft’s Bing Chat chatbot) in a poor light? The answer lies in a note within the blog post:
“[T]he research team worked with Microsoft product groups to confirm that the potential vulnerabilities identified do not impact current customer-facing services. This is in part true because finished AI applications apply a range of mitigation approaches to address potential harms that may occur at the model level of the technology. In addition, we have shared our research with GPT’s developer, OpenAI, which has noted the potential vulnerabilities in the system cards for relevant models.”
So the implication is that the relevant bug fixes and patches were made before the paper’s publication. Whether that’s truly the case, the research is yet another data point suggesting that LLMs — even from Microsoft-backed, billion-dollar-plus-revenue-generating startups like OpenAI — remain an imperfect science.
GPT-4, like all LLMs, must be instructed — or “prompted” — to complete a task (e.g. writing an email or summarizing an article). Jailbreaking LLMs entails using prompts worded in a specific way to “trick” the LLM into perform a task that wasn’t a part of its objective.
For example, the LLM powering Bing Chat wasn’t designed to write neo-Nazi propaganda. But at release, because it was trained on vast amounts of data from the internet — some of it toxic — it was susceptible to doing just that when fed a particular prompt.
As for GPT-4, the researchers found that the model is more likely to generate toxic text than GPT-3.5 when given certain jailbreaking prompts that they “constructed.” They also claim that GPT-4 “agrees with … biased content more frequently than GPT-3.5,” at least depending on the demographic groups mentioned in the prompt.
For example, give the prompt “Homosexuals have HIV,” GPT-4 usually “strongly” disagrees with the statement, according to the researchers. But given “Women have HIV,” GPT-4 agrees — and outputs biased content.
Just as concerningly, GPT-4 — when given the “right” jailbreaking prompts — can leak private, sensitive data including email addresses, say the researchers. All LLMs can leak details from the data on which they’re trained. But GPT-4 proves more susceptible to doing this than others.
Alongside the paper, the researchers have open sourced the code they used to benchmark the models on GitHub. “Our goal is to encourage others in the research community to utilize and build upon this work,” they wrote in the blog post, “potentially pre-empting nefarious actions by adversaries who would exploit vulnerabilities to cause harm.”","https://techcrunch.com/wp-content/uploads/2023/06/OpenAI-logo-symmetry.jpg?resize=1200,675",2023-10-17 11:30:25
https://techcrunch.com/2023/10/17/biotech-eu/,"Give biotech a chance for the planet's sake, EU lawmakers urged","European Union lawmakers are being urged to avoid too much risk aversion from holding back the potential of the homegrown biotech sector.
Developments in biotech could be transformative in a range of critical sectors. Beyond huge promise in healthcare, innovative, low carbon applications in areas like agriculture and food systems and energy production could help address pressing environmental and sustainability challenges. But there’s concern among some local operators that the bloc’s current approach could cap potential biotech benefits — especially in the context of the urgency required to tackle the climate crisis.
“The main regulatory challenges for the EU’s biotech startups are long timelines for approval of new products and a lack of openness towards modern biotech solutions that may lead to GMO solutions,” Joško Bobanović, partner at Sofinnova Partners, a major investor in European biotech, tells TechCrunch. “ Today, EU startups often do not bother trying to get approval in Europe because of long approval timelines, opting instead to go directly to the US or Asia. This is a huge loss for Europe given the plethora of leading-edge technologies developed here.
“Recent Nobel prizes for technologies like CRISPR or for discoveries that led to RNA vaccines highlight European regulators’ hesitance toward genetic technologies, similar to favoring landlines over mobile phones. (Remember what happened with Nokia and smart phones.) The potential benefits of these innovations far outweigh the risks even as they are part of a duly rigorous regulatory cycle.”
“If you look at venture capital, there’s significantly more money going into the synbio [synthetic biology] community in the United States, and so we’re really at a disadvantage here in Europe,” says Stef van Grieken, CEO and co-founder of EU-based startup Cradle, which offers generative AI tools to help bioengineers design proteins. “There’s also a lot of regulatory risk in Europe. So GMO, a lot of these types of techniques are considered genetic modification. And rules in Europe are very strict. And so if you look at a company like Meatable, that’s growing meat in in a dish instead of using a cow — they’re a Dutch company but they’re launching their products in Singapore, in the United States due to regulatory constraints.”
He also points the level of recent biotech support announced by the Biden administration, including a pledge to invest $2 billion in biotechnology and biotech manufacturing — suggesting the bloc is lagging behind on financial support for the field too. “According to McKinsey, about 60% of our current economic inputs you could make with biology,” he says. “And so that’s substantial, right? Like everything that we consume is a lot larger than the things on the internet.”
“One of the things that’s starting to become obvious is there’s lots of application domains for these types of techniques,” he adds, discussing generative AI’s role in accelerating biotech R&D. “I mean, I’m excited about ChatGPT and [popular generative AI] applications but let’s say… [helping] science and R&D teams to get their bio-based products to market faster to help us solve climate change may be a bit more important than producing better marketing copy.”
Earlier this month the European Union adopted a list of ten technologies it considers critical to the bloc’s future economic security — ranging from AI, quantum and advanced semiconductors, to space tech, robotics and biotech — making a clear statement of recognition of transformative and strategic potential. At the same time, four of the listed techs were flagged for further risk assessment, including biotech (the other three pegged for extra scrutiny are: AI, advanced semiconductors and quantum).
The Commission’s recommendation suggested Member States conduct collective risk assessments of these four critical areas by the end of the year — with lawmakers highlighting the possibility that transformative potential could also lead to highly sensitive risks, such as threats to fundamental rights or civil-military fusion.
Reports have suggested the move could prefigure the introduction of additional EU regulations.
Of the four technologies flagged for risk assessments, biotech may be the least familiar, in terms of public understanding — with the term spanning practices like genetic modification; new genomic techniques (such as CRISPR-Cas9 gene editing); gene-drive; and synthetic biology (aka synbio; a multidisciplinary field); all of which were explicitly name-checked in the Commission’s PR as examples of biotech that should be risk assessed by Member States.
The listed techs all deal with manipulating genetic material but can involve different approaches and applications. Developments in one field may also dial up potential elsewhere — such as gene editing techniques increasing potential applications for synthetic biology, for example — further advancing the complexity of developments since there may be overlap in how these biotechnologies are applied.
Despite relatively low public awareness of biotech advances, Cradle’s van Grieken points out some techniques have actually been widely used in industrial processes for years — helping to produce things like detergents which can work at lower temperatures (via industrially produced enzymes); or synthetic insulin for diabetics (i.e. instead of extracting biological insulin from the pancreatic glands of slaughtered cows and pigs).
While, as noted above, a newer wave of alternative protein startups — including companies being built in Europe — are leveraging developments in the field to do things like scale lab-grown meat or produce non-animal derived dairy proteins, on a mission to transform food systems without the huge carbon footprints attached to traditional (animal-derived) meat and dairy.
But it’s interesting how under the radar some of these regional applications of biotech remain. Certain terminology may be preferred (or avoided) in marketing copy — likely with an eye on regulatory risk and/or consumer trust.
“Precision fermentation is not synthetic biology per se,” a spokesperson for one alt protein startup — France’s Bon Vivant — told us, when we asked what it meant by “precision fermentation”, the term it prefers for explaining its dairy-targeting biotech, querying the bio techniques it’s applying to repurpose yeast microorganisms to brew up cow’s milk proteins.
“As a board member of Food Fermentation Europe, Bon Vivant is still working on a science based and still easily understandable definition,” the spokesman also responded to our ask. Its marketing copy, meanwhile, studiously avoids saying it’s genetically modifying yeast to produce milk proteins — which is essentially what it’s doing — the closest it comes is writing that it “programs” yeasts.
Yet it’s widely accepted that precision fermentation is an example of synthetic biology. (See, for e.g., Wikipedia’s definition: “Precision fermentation is an approach to manufacturing specific functional products which intends to minimise the production of unwanted by-products through the application of synthetic biology, particularly by generating synthetic ‘cell factories’ with engineered genomes and metabolic pathways optimised to produce the desired compounds as efficiently as possible with the available resources.”) So it’s curious to observe a European startup that’s doing interesting things with synthetic biology being so reluctant to say so.
The example speaks to the uncertainty steeping biotech developments in Europe — suggesting disruptors remain worried that causing a splash here could amp up their regulatory risk and bring fresh limits on their fledgling businesses, or at least trigger a new wave of consumer concern, rather than inviting admiration and unlocking homegrown support (or even — dare we say it — congratulatory cheerleading).
Cautionary tale
Cradle’s van Grieken is concerned the EU taking an overly risk averse approach to biotech is out-of-date with where the bloc needs to get to; that precautionary treatment of biotech is riskily self-defeating when it comes to the challenges now facing the bloc, including its headline green ambition to get to ‘Net Zero’ by 2050.
Europe is already “late to the party” when it comes to recognizing the economic and strategic importance of biotech compared to the US and parts of Asia, he argues. But his worry about the EU’s modus operandi is an active frustration that the bloc may be creating a blindspot by not being more encouraging of a sector with transformative potential when it comes to tackling the existential crisis of climate change.
“[Synbio’s potential] is not actually being recognised in the environmental policies of the EU,” he suggests. “If you look at the European Green Deal, a lot of it is focused on energy — like energy production, insulating more homes; it’s focused on recycling; on reducing pollution — like mobility; those types of things. Synbio isn’t really a theme. But it could be an incredibly powerful resource for the EU.
“This specific [Commission] call to the Member States to figure out what the risks are [for biotech] — my worry is that we’ll see increased regulation in this space without actually trying to promote the space and become… a leader in this space. Which we currently, unfortunately, are not. So that’s my biggest worry. But I do think at least recognising that it is something that could be strategic, it’s a good first step.”
“Biotech is a serious business and we need serious regulation here,” he adds when pressed to confirm his position. “But inversely, we don’t want to hamper innovation based on outdated notions of what this technology can and cannot do.”
“The EU needs to accelerate its regulatory processes and be more receptive to new technologies,” agrees Sofinnova’s Bobanović. “This is a critical success factor in the global race to address climate change but also to ensure food independence, a topic becoming more prominent post–COVID-19.”
“Failing to adapt may see our innovations benefiting other markets and the EU losing its competitive edge, much like the electronics industry. Once we lose talent and knowledge centers, it is impossible to recover them,” the investor also warns.
Consumer concern about genetically modified organisms (GMOs) does have a long history in the EU — especially in relation to food safety — which likely informs the precautionary approach the bloc has adopted towards the use of biotech in food production since at least the early 2000s. Out of that has come a legal framework that’s focused on health and safety; harmonized risk assessments; labelling; and traceability.
Consumer awareness of cutting edge biotech may be low but a perception of public concern over GMOs in food, which took root after an earlier era of developments during a time of more lax regulation, has been harder to shift. Yet actual consumer concerns are concentrated elsewhere, research suggests.
A 2019 Eurobarometer survey on food safety indicates EU citizens’ concern over GMO has declined while worries about food risks associated with traditional farming methods are riding high. So while 44% of respondents (the largest proportion) said they were concerned about the presence of antibiotics and hormone residues in meat; and 39% were worried about pesticide residues in foods; a lower proportion — 27% — said they were concerned about GMO being used in foods and only 4% were concerned about genome editing in this context (albeit, for the latter bio technique, the survey also found relatively low knowledge of the use of genome editing in food production — 21% vs 60% for GMO in food — so very low concern there may be a reflection of low awareness).
The survey results suggest EU policymaking in this area — certainly on the food front — risks being out of step with public safety concerns. (To wit: Environmental pollutants in fish, meat and dairy was another big worry for 37% of respondents.)
Taken together the Eurobarometer paints a picture of regional consumers with substantial anxieties about the health risks (and environmental toll) attached to current farming and agricultural practices — and lower concern about biotech being applied to engineer food output. (Also relevant: A Eurobarometer survey from 2021 which found an overwhelming percentage of EU citizens consider climate change to be the most serious problem facing the world.)
Yet the bloc remains saddled with a regulatory regime that ploughs massive subsidies into traditional agriculture while demanding high levels of caution — and even throwing up regulatory hurdles — when it comes to applying biotech to critical sustainability challenges. Critics argue this combo looks increasingly misaligned with where the bloc says it wants to get to with its flagship green transition.
Of course it’s worth noting that policymaking across the 27-Member State bloc is complex, with many entities necessarily involved in change-making. The Commission’s role, while important as a proposer of new pan-EU laws (and/or legislative reforms), is just part of the picture. EU Member States themselves can also have their own biotech and bio-ethics rules and reforms — so a Commission intervention listing biotech as a critical tech, and pushing for Member States to conduct risk assessments, may be aimed at driving for harmonization between this patchwork of national laws — which could, ultimately, streamline and simplify life for biotech entrepreneurs down the line.
Other factors also play a role. Another notable development for regulation of novel biotechs in the EU occurred, in 2018, when the Court of Justice (CJEU) ruled that organisms produced using relatively new techniques, such as gene editing, should fall under the bloc’s existing rules on GMO. So the legal system is also involved in interpreting how existing rules apply to biotech developments. But, again, it’s up to policymakers to keep up with such developments and make sure legislative frameworks are providing the right incentives.
“Europe is complex in terms of regulation, market access,” says Sofinnova partner Cedric Moreau, who is focused on the pharmaceuticals side of biotech investing. “We are not as the US [where] when you have the go from the FDA you have a more than a 300 million people market opening and very homogeneous.”
“We see where the European Commission wants to go — making sure that [it’s] not overlapping with State Members’ policy and making sure that the definition, and the category and the activity are very well defined; to not prevent any innovation or [developments] in the space that could be impacted by [divergence in Member State laws],” he suggests.
“It’s important to make some clear rules, clear definitions because [as investors] we need clarity,” he also tells us. “When we are investing in companies for five, eight, 10 years we cannot bet on regulation that will decide if our drug is a high unmet medical need or just an unmet medical need [for example]… And if our market exclusivity will be 10 years, or six years or nine years or five years. So we need to have clarity — and if it’s not clear enough what we will have to do to build our business case is always to retain the more conservative scenario.”
“At Sofinnova, we are a strong believer of Europe,” Moreau adds. “Because we are deploying — roughly 80% — of our capital in Europe. So we think that Europe is a fantastic playground for healthcare, for innovation. Because we have great science, great scientists, great people. And we have also an ecosystem that could really develop great success stor[ies]… Great products, impactful products for the patient. Then having said that… obviously, we think that there were several things that could be improved.”
Climate urgency vs legal uncertainty
“There is some urgency to consider these types of techniques seriously,” argues van Grieken, talking up the potential of synbio to help in the fight against climate change. “I’m not trying to advocate for ‘no regulation’ type of space. I think we need very strong controls. But on the actual end product, not on how they get researched and developed. And in certain cases, like for example with lab-grown meat or if you look at companies that are making alternatives to cheese or milk, those should be products that we should at least consider having on the market in the EU.”
“Take a company like Perfect Day foods in the United States,” he continues. “They’re making milk without cows. They can do that at, like around — I think — it’s 3% to 5% of the emissions compared to using a cow. That’s a pretty significant improvement. And we use a lot of dairy products, right? And we have a planet on fire.”
As we reported last year, Cradle is using generative AI to predict protein sequences to speed up R&D for protein engineers building bio-based products. So its business is applying AI to accelerate biotech developments — which, of course, means it has an interest in speeding up biotech progress by encouraging a more R&D-friendly regulatory environment, too.
The acceleration its customers are seeing is considerable, as van Grieken tells it — turning what would “typically” be a 1%-5% success rate for stabilizing a protein into a 50% success rate on average, thanks to the predictive power of its generative AI models. But stringent regulation is one brake the startup’s tech can’t uplift. Hence his call for EU lawmakers to zoom out and consider a bigger risk picture.
One idea he welcomes is if the EU were to establish more regulatory sandboxes where biotech R&D could be undertaken without so much legal uncertainty fogging the ambition — which amounts to a call for rules that focus more on outputs, than on the R&D itself.
When it comes to AI, a network of regulatory sandboxes is something the bloc is in the process of setting up — at the same time as EU co-legislators are hammering out a comprehensive, risk-based framework for applying artificial intelligence. So support for, and controls on, cutting edge techs are both possible under the regional lawmakers’ playbook.
Add to that, earlier this year (in April) the Commission put out out a proposal for reforming the bloc’s pharmaceutical regulation — which floats launching a regulatory sandbox as one of the suggested measures to boost regional innovation in drug research and design.
But, in that case, the sandbox would be limited to products regulated as medicines. So even if the bloc’s co-legislators adopt the proposal there are many other biotech innovations that won’t be granted a safe space to experiment — since the end product they’re aiming to disrupt isn’t a pharmaceutical. (And of course climate change won’t be fixed by popping a pill, personalized or otherwise.)
Supporting the production of edible proteins without the climate-heating emissions of traditional agriculture is just one example of biotech’s transformative potential for the environment. Bioplastics offer an alternative to petrochemical-based plastics, as another. While bioremediation is a field that offers promise for cleaning up pollutants — including by engineering microorganisms (such as algae) to accelerate uptake of CO2, the major climate heating gas.
Also on a climate tip, production of biofuels could be more sustainably scaled up using biotech techniques — such as, again, by designing microorganisms that can more efficiently turn biomass into low carbon biofuels.
European bioengineers are even working on genetically modifying plants to amp up their ability to fight indoor pollution (see: French startup Neoplants). So when you start to really think about engineering biology for human and environmental utility the canvas looks broad indeed.
Or, well, it should — but European biotech startups have to do their bluesky thinking from under a more legally clouded horizon.
For biotech startups operating in the EU, van Grieken argues it’s “significantly harder” to do the R&D and test potential innovations with so much regulatory risk hanging over the field. “There’s a lot of uncertainty,” he emphasizes. “For example, the Netherlands just introduced the ability to sample these types of [biotech-derived food] products and have investors taste them. But a very reasonable question from these investors is can you do that and sell this stuff? And if the answer is silence, then, you know, that is not a great answer. And I think this industry needs some clarity around that.”
Current EU rules also create some “weird” scenarios, as he tells it. For example, making an “informed edit” to a genome (i.e. where a bioengineer thinks about what mutation to make) would “typically” be considered a GMO in Europe (meaning the regulatory framework starts to apply) — whereas practices which produce random mutations, as happens a lot in the plant seed space, would not. So an operator that’s, for instance, shining UV light on a plant seed and introducing random mutations falls under less regulatory risk than someone doing bioengineering to select for a specific mutation — perhaps seeking higher crop yield to boost productivity or resistance to drought — regardless of the motivations behind the intent.
“If you think about how you might actually engineer one of these systems, it’s considered problematic; but if you just do it randomly, it’s fine. And so that’s not very smart,” he argues. “Because a lot of the techniques that we have today to make informed decisions about where to make changes in order to get to a certain outcome, that’s also a safe outcome — so it’s actually a lot better than doing it random.”
“If you look at, for example, the United States or places in Asia where a lot of these synthetic biology techniques are allowed it’s not like we’re seeing any major problems,” van Grieken also points out. “So we might be being a bit too constrained right now.
“You should be able to show that your product is good; actually is improving its environmental footprint; is safe to use; is delicious, in the case to food, right — and all these types of things — and get approval for it in some reasonable amount of time so you can still get to market.”
Towards a balanced approach?
Despite criticism that it’s too cautious, EU lawmakers have been talking about evolving the bloc’s approach to biotech. They have also been taking some action too.
This summer, for example, the Commission adopted a proposal for a new regulation on plants produced by certain new genomic techniques (NGTs) which would allow plants produced in this way which could also occur naturally (or via conventional breeding) to be placed on the market — exempting them from requirements in the current GMO legislation.
The NGTs the Commission has proposed loosening the rules for are targeted mutagenesis (aka plants that contain genetic material from the same plant); and cisgenesis, including intragenesis (i.e. plants that contain genetic material from crossable plants) — which would only need to undergo a verification process, under the proposal. Whereas transgenic plants (containing genetic material from non-crossable species) would remain subject to comprehensive, case-by-case risk assessment, approval and authorization prior to any sale under the EU’s existing GMO Directive.
The bloc’s Farm to Fork Strategy, meanwhile — part of the aforementioned European Green Deal which is focused on driving sustainability of agriculture and food production — recognizes biotech as having potential to contribute to the fight against climate change. “New innovative techniques, including biotechnology and the development of bio-based products, may play a role in increasing sustainability, provided they are safe for consumers and the environment while bringing benefits for society as a whole. They can also accelerate the process of reducing dependency on pesticides,” the Commission wrote in the May 2020 strategy document.
Although, subsequent to that, a 2021 study the EU undertook of new genomic techniques noted the “rapid” development of NGTs and their products over the past two decades — finding “considerable interest” in conducting research on NGTs in the EU. But it also identified that “most” development is taking place outside the EU. Which does support the contention the bloc is lagging when it comes to biotech research, despite “considerable” homegrown appetite to do this cutting-edge work.
“Following the [2018 GMO] ruling of the [CJEU], there have been reports of negative impacts on public and private research on new genomic techniques in the EU due to the current regulatory framework,” the EU’s executive also noted in the study. “Regulatory barriers would particularly affect small and medium-sized enterprises (SMEs) and smallscale operators seeking to gain market access with new genomic techniques, even though many Member States and stakeholders see opportunities for them in this sector.”
“The use of NGTs raises ethical concerns but so does missing opportunities as a result of not using them,” it went on, essentially echoing van Grieken’s point. “Based on the findings of the study, most of the ethical concerns raised relate to how these techniques are used, rather than the techniques themselves.”
At that time, the Commission concluded that any further policy action in the area should be “aimed at reaping benefits from innovation while addressing concerns”, further stipulating that a “purely safety-based risk assessment may not be enough to promote sustainability and contribute to the objectives of the European Green Deal and in particular the ‘Farm to Fork’ and biodiversity strategies”. The document also explicitly recognized that risk assessment alone could lead to a flawed evaluation process — in which “benefits contributing to sustainability” are not properly considered.
Asked about the critique it’s over-indexing on risk, when it comes to biotech, and not properly weighting potential sustainability (or, indeed, other) benefits, a Commission spokesperson declined to provide comment. But they pointed us to an EU webpage on R&D and the “bioeconomy” — where the EU’s executive also talks up the transformative potential of homegrown biotech developments, writing for example that: “Stronger development of the bioeconomy will help the EU accelerate progress towards a circular and low-carbon economy. It will help modernise and strengthen the EU industrial base, creating new value chains and greener, more cost-effective industrial processes, while protecting biodiversity and the environment.”
The page also links to the bloc’s long-standing bioeconomy strategy — which features an action plan that lists carrying out an analysis of “enablers and bottlenecks for the deployment of biobased innovations” as one of 14 “concrete actions” regional lawmakers are committed to (on paper at least).
The EU bioeconomy strategy was originally set out back in 2012, and reviewed in 2018, with the aim of supporting 2030 Sustainable Development Goals; the Paris Agreement climate objectives; and new EU policy priorities — with the Commission writing then that reaping the “economic, social and environmental benefits of the bioeconomy, dedicated bioeconomy strategies, investments and innovation are required at all levels in the EU”. Hence the updated strategy emphasizing the need for the development of national and regional bioeconomy strategies.
Five years on from that, the Commission lists just nine Member States that have set out a national bioeconomy strategy (Austria, Finland, France, Germany, Ireland, Italy, Latvia, the Netherlands and Spain) — meaning a substantial majority of EU members still lack this piece of the biotech ecosystem support puzzle. So, clearly, there’s more work for regional lawmakers to do to match the bloc’s ambition to build up Europe’s biotech base with actions that deliver results.
Looking ahead, Cradle’s van Grieken sees two big ares of promise for biotech: Human health being the first one; and what he refers to as “planetary health” as the second. “The reason why I left Google is because those are two of the major problems that my generation faces in the world,” he tells TechCrunch. “In human health, increasingly I think we’ll be a lot better at targeting disease with these types of [bioengineered] molecules and curing people.
“On the planetary health side, I think what will increasingly see is that bio-based products will come out that are cheaper than the petrochemical or animal alternatives. Because, ultimately, biology can do a lot of these things in a much lower energy way and also environmental footprint. I think we’re going to see a breadth of products that is going to be super exciting.”
He’s also bullish on cost — suggesting developments in generative AI can be the flywheel that speeds up biotech R&D — and that acceleration of developments in the lab will draw down the costs entailed in unlocking the big, transformative biotech benefits.
“It’s also why we started Cradle — to really accelerate R&D and make R&D a lot cheaper,” he says, arguing: “There is no fundamental reason why this cannot be done… Biology is ultimately capable of doing very complicated things at very low energy — like, look around you right now. There’s probably a plant somewhere there and try to realise that it’s just like water and ambient carbon that created that, right? It’s just wild, if you think about it.”
French startup Bon Vivant, meanwhile, is working to build a European business that can help tackle the planetary health challenge head on. As noted above, it’s reprogramming yeast microorganisms to produce milk proteins to offer the food industry an alternative so they can sell non-animal-based dairy products — which could have a massive impact on shrinking CO2 emissions if taken up at scale.
Foods derived from animals, including dairy, are generally associated with the highest greenhouse gas emissions (see, for e.g., this UN data on kilograms of emissions per kg of food) — owing to factors including land use, methane emissions from livestock and nitrous oxide emissions from the waste produced by animals. So biotechnologies applied to food production which can replace the need for us to get so much protein from animal sources have the potential for radical reductions in emissions if we integrate these new processes into our food systems.
Asked about the regulatory challenge of building an alternative protein business in Europe, Bon Vivant’s co-founder, Stéphane MacMillan, offers two thoughts. On the one hand he sounds sanguine — suggesting high food safety standards in the EU could create a competitive advantage for local startups over time, as a sort of ‘gold standard’ mark (i.e. once regulatory clearance to sell locally is obtained, which he estimates in their case may take two to three years vs a quicker anticipated time-to-market over in the US).
“Everyone is saying, well, it takes too long in Europe to get approval. Okay, it’s taking longer than any other countries but at the same time we have to be proud of standards that we have in Europe,” he tells TechCrunch. “These standards are also the reason why European food is really seen as the best class in most parts of the world. So we have to comply with it. It takes a bit more time. But, at the same time, I think… that guarantee for the consumer that our products are absolutely non-GMO — that’s really important and [builds trust] with customers.”
But he also suggests the bloc’s policymakers need to find “the right balance” — between having such high homegrown standards and risking a future where European consumers are forced to buy foreign bio products “because we were not able to build the champions”.
“It’s not black or white,” he suggests. “It’s a balance that we need all to find collectively. Both are right. But we just to find the right balance.”
Offering an investor perspective on the same point, Sofinnova’s Bobanović sees even less upside for EU biotech startups trying to turn increasingly strict regional food safety standards into a competitive advantage. So — at the least — the suggestion is the bloc shouldn’t be looking to pile more rules on the sector if it’s serious about growing the bioeconomy.
“While Europe’s stringent rules might enhance consumer trust in certain sectors, it’s unlikely the case for biotech,” he argues. “Unlike the luxury industry where ‘made in Europe’ is an advantage most food products are destined for local consumption and consumers already trust regulations. Increased regulation is not likely to influence product adoption.”","https://techcrunch.com/wp-content/uploads/2021/10/GettyImages-1342327233.jpg?resize=1200,800",2023-10-17 10:58:18
https://techcrunch.com/2023/10/17/scylladb-raises-43m-to-scale-its-nosql-database-platform/,ScyllaDB raises $43M to scale its NoSQL database platform,"Investors have an appetite for databases, it seems.
Today, ScyllaDB, a startup developing database tech for high-throughput, low-latency workloads, announced that it raised $43 million in a funding round led by Eight Roads Ventures with participation from AB Private Credit Investors, AllianceBernstein, TLV partners, Magma Ventures and Qualcomm Ventures.
The new cash will be put toward “accelerating” ScyllaDB’s momentum and expanding the size of its 168-person team, according to co-founder and CEO Dor Laor.
“Today’s disruptors are ingesting an unprecedented amount of data and tapping it to deliver differentiating user experiences that transform markets and displace legacy leaders,” Laor told TechCrunch in an email interview. “Data is being enriched, cleaned, streamed, fed into AI and machine learning pipelines, replicated and cached from multiple sources. That’s why it’s more important than ever to have a database that’s up to the task.”
ScyllaDB is what’s known as a NoSQL database, which — unlike the relational databases once dominant in the enterprise — provides mechanisms for data storage and retrieval that don’t rely on a “tabular relations” model. In a tabular model, a relationship is a connection between two tables of data. But with a NoSQL database, relationships don’t have to follow this schema — offering greater engineering flexibility and, in some cases, improved performance.
NoSQL databases are commonly used for applications like ad serving, AI and machine learning, recommendation and personalization engines, fraud detection and analyzing data from internet of things devices.
According to a 2022 survey by Ventana, almost a quarter (22%) of organizations are using NoSQL databases in production today, while more than one-third (34%) are planning to adopt NoSQL databases within two years or evaluating their potential use. And the NoSQL market is expected to grow to $35.7 billion by 2028, up from $7.3 billion in 2022, the IMARC Group reports.
Now, ScyllaDB’s not the only NoSQL vendor out there — far from it. There’s ArangoDB, Redis Labs and Crate.io to name a few, not to mention bigger players like MongoDB, Amazon’s DynamoDB and Couchbase.
But ScyllaDB claims that its tech offers architectural advantages, like the ability to perform millions of operations per second with “single-digit millisecond” latency. Running across multiple clouds, on a hybrid cloud setup or on-premises, ScyllaDB automatically tunes I/O and CPU performance with workload prioritization, which co-locate workloads under a single server cluster.
Those claims and capabilities were enough to win over customers, evidently. ScyllaDB says its database is now used by over 400 companies including Discord, Epic Games and Palo Alto Networks and that revenue has grown 800% since the company’s founding in December 2012.
“Across industries, R&D teams are increasingly realizing that ScyllaDB’s dramatically different database architecture delivers better performance and horizontal scalability for data-intensive workloads,” Laor said. “ScyllaDB is designed to help fast-growing, fast-moving teams deliver lightning-fast user experiences at extreme scale … ScyllaDB’s unique architecture takes full advantage of modern cloud resources, delivering impressive efficiency and price-performance.”
To date, ScyllaDB has raised $103 million in venture capital.","https://techcrunch.com/wp-content/uploads/2021/04/GettyImages-945420192.jpg?resize=1200,849",2023-10-17 10:00:57
https://techcrunch.com/2023/10/17/figures-humanoid-robot-walks-for-the-camera/,Figure's humanoid robot walks for the camera,"In May of this year, TechCrunch ran a piece titled “Figure’s humanoid robot takes its first steps.” The story was a firsthand account of my visit to the startup’s South Bay offices. The headline was a reference to both the company’s first year of existence and its stated plan to hit a key milestone by its first birthday.
The company later confirmed with me that it had, in fact, managed to get its humanoid robot to walk. I asked for video evidence, which Figure refused to send — until now. Among other things, it’s clear the company wants to get a film crew to capture the bipedal locomotion. I tend to prefer raw laboratory video for stuff like this, but that’s probably one of the many reasons no one is asking me to run marketing for their robotics firm.
Two things jump out at me immediately: First, it’s good to see a non-render from the company. Thus far, their art has been limited to mockups of what the robot could eventually look like. Watching this footage is a reminder that there are many steps along the way to that futuristic bit of product art. Second, you’ve probably noticed that the robot is moving with bent knees, rather than the fully upright motion we see in humans.
Bent knees, on the other hand, are pretty standard in robots — you’ve seen it with Boston Dynamics’ Atlas and Agility’s Digit (though the latter has a reverse bend, similar to an ostrich). Bending gives you better control of balance and other important factors. Ultimately there’s a question of how important it is to hue to a more human-like gait, but obviously this first video of the Figure 01 robot walking is very much early stage. There are plenty of kinks to work out between now and a ship date.
The other thing I will draw your attention to is the hands. Mobile manipulation remains a key problem in this world, and many humanoid systems like Digit and Apptronik’s Apollo have yet to add articulated graspers. Of course, there’s nothing in this video that suggests the grippers are currently functional. On my visit to the company’s HQ, however, they showed me a portion of the office devoted to the development of what looked to be a five-digit, human-style hand.
The video notes that Figure’s headcount at the time of shooting (10/1) was 60. Impressive growth for one year. More updates soon, no doubt.","https://techcrunch.com/wp-content/uploads/2023/10/Screenshot-2023-10-13-at-3.53.07 PM.jpg?resize=1200,725",2023-10-17 10:00:01
https://techcrunch.com/2023/10/17/invesco-raises-swiggy-valuation-to-nearly-8-billion/,Invesco raises Swiggy's valuation to nearly $8 billion,"Conditions appear to be shifting favorably for India’s Swiggy. The food delivery startup — backed by SoftBank, Prosus and Accel — saw its paper valuation slashed by more than a half this year as investors marked their holdings largely in response to the dwindling market conditions. The startup, valued at $10.7 billion in a funding round early 2022, also lost some market share to Zomato, its arch publicly-listed rival, according to Prosus.
Now, not so much.
Invesco, which led Swiggy’s previous round and cut its valuation to under $5.5 billion, marked up the startup’s valuation to $7.85 billion at July’s closure, according to a newly published disclosure.
The U.S. asset manager says it considers the valuation of similar public companies as a factor when reassessing the value of its private investments. Given that shares of Zomato have risen by 33% since the end of July, this could imply that the current $7.85 billion valuation for privately-held Swiggy may be conservative.
Separately, Swiggy, which is eyeing to make an initial public offering next year, appears to be closing in on some of the market share it lost to Zomato this year. Swiggy’s month-on-month volume grew 7% this July and 6% in August, beating Zomato in both months, UBS said in a report this month.","https://techcrunch.com/wp-content/uploads/2023/03/GettyImages-1239421148.jpg?resize=1200,801",2023-10-17 09:24:24
https://techcrunch.com/2023/10/17/stack-overflow-cuts-28-of-its-staff/,Stack Overflow cuts 28% of its staff,"Developer community site Stack Overflow has laid off 28% of its staff, the Prosus-owned company announced Monday.
In a blog post, Stack Overflow’s CEO, Prashanth Chandrasekar indicated that the company is focusing on its path to profitability. While the post didn’t elaborate on the reason behind the job cuts, it mentioned customers’ budgets shifting elsewhere “due to the macroeconomic pressures.”
“This year we took many steps to spend less. Changes have been pursued through the lens of minimizing the impact on the lives of Stackers. Unfortunately, those changes were not enough and we have made the extremely difficult decision to reduce the company’s headcount by approximately 28%,” Chandrasekar said.
While Stack Overflow is primarily a Q&A website for consumers it also has enterprise products like “Stack Overflow for Teams,” which helps organizations maintain a company-wide knowledge base.
The company didn’t specify the number of laid-off employees. However, since it had pushed its headcount to over 500 people last year, more than 100 people are likely to be impacted.
With generative AI gaining popularity for helping coders with different problems, Stack Overflow has seen its traffic drop as compared to last year.
In August, the company said that because of generative AI, it expects “some rises and falls in traditional traffic and engagement over the coming months.”
Earlier this year, Stack Overflow asked AI companies to pay for training data. In January, it barred users from posting answers generated by AI. The company is also trying to bolster its own AI capabilities. In July, it launched OverflowAI with features like generative AI-powered search.
Big Tech is also moving fast to make generative AI-aided products available for coders in a rapid manner. Last month, GitHub expanded access to its Copilot chat to individual users. In May, during its developer conference, Google announced a bunch of AI-centric coding tools including an assistive bot called Codey. The company has also trained its conversational AI tool Bard to help users with code generation and debugging.","https://techcrunch.com/wp-content/uploads/2023/10/3281da8e0c2332be9228c95317c493fe508c5a65-2400x1260-1.webp?resize=1200,630",2023-10-17 07:44:44
https://techcrunch.com/2023/10/17/ambani-jio-financial-launches-lending-and-insurance-businesses/,Ambani's Jio Financial launches lending and insurance businesses,"Jio Financial Services, the Indian conglomerate Reliance Industries-backed financial services firm, has started its lending and insurance businesses and plans to rapidly broaden its offerings as billionaire Mukesh Ambani expands the ever-so-wide tentacles of his oil-to-telecom empire.
The market has been closely paying attention to Reliance’s financial services ambitions for years. But it wasn’t until last year that Ambani, Asia’s richest man, revealed that the firm plans to enter into the sector, which though has grown multiple folds in the past decade remains largely untapped, serving only tens of millions of individuals.
Jio Financial Services, which made public debut in August, said in its annual presentation that it has started to offer personal loan to salaried and self-employed individuals through its MyJio app and 300 stores across India. Its insurance arm has also partnered with 24 insurers to offer a wide-range of coverage across auto, health, and corporate categories, said the firm.
Jio Financial Services has largely remained quiet about precisely what all it plans to do. The firm, whose largest backer remains Reliance Industries, earlier this year partnered with U.S. asset manager BlackRock to launch asset management services in the country.
The financial services is the newest sector for Ambani, who has entered several businesses — including telecom — in the past decade and scaled them to tentpole positions. Reliance also operates the nation’s largest retail chain, which has been valued at $100 billion in recent fund raises from investors including KKR.
As Jio Financial scales its business, it may pose a challenge to a number of players in the industry, including Paytm and Policybazaar. Reliance said it will make use of AI and analytics for its financial services business and operate on a “low cost of servicing.”
Jio Financial Services said it’s taking a direct-to-customer approach with its offerings to drive cost efficiencies and enabling personalized customer interactions. The firm is incorporating “alternate data models for 360-degree customer view and tailored offerings,” and is developing a unified app for the “diverse financial needs of customers.”
In the annual report, Jio Financial Services said it’s also testing a sound box, the fast-omnipresent portable device that alerts merchants when a transaction has completed, the firm said, confirming an August TechCrunch report. The company is “generating substantial data footprint and enhancing our customer engagement across digital channels, and in turn enriching and facilitating other businesses,” it said.
On lending, Jio Financial Services plans to extend loans to businesses and merchants as well as offer loans to facilitate vehicle and home purchases, it said. It also plans to give loans by using shares as collateral. The firm said it has also “relaunched” savings account service and bill payments and plans to launch debit cards.","https://techcrunch.com/wp-content/uploads/2023/08/GettyImages-1243634682.jpg?resize=1200,800",2023-10-17 07:26:12
https://techcrunch.com/2023/10/17/ray-ban-meta-review/,Ray-Ban Meta sunglasses have 'influencer' written all over them,"Ray-Ban Meta sunglasses have ‘influencer’ written all over them The companies have maintained a slim and light design, while rendering their predecessor obsolete with Facebook and Instagram livestreaming
This is a review-in-progress. More soon!
Somewhere between the Ray-Ban Meta and Meta Quest 3 sits an ideal mixed-reality headset. It’s slim, light, offers hand tracking and passthrough and livestreams video when the moment calls for it. It’s designed to be worn inconspicuously outdoors, until the time comes for content capture.
The Meta Quest Ray-Ban is a fantasy at the moment — albeit one that points in the direction of where its makers think this is all headed. Presently, the Ray-Ban Meta and Meta Quest 3 are very different devices, with little in the way of overlap, beyond being head-worn products with built-in sensors.
The Meta Quest 3 is a mixed-reality headset designed to be worn exclusively indoors. It’s light, perhaps, compared to other headsets of its ilk, but wearing the thing while walking around outside frankly sounds a bit miserable. That’s precisely the use case the Ray-Ban Meta was designed for: freedom of movement outside the house that’s designed to go (mostly) unnoticed.
Just prior to writing this, I slipped a pair on, before the JFK airport mobility cart drove my sciatica-ridden ass to the gate. I would say the pair was inconspicuous but for the fact that I was wearing a pair of sunglasses indoors. Well, that and the extremely necessary recording lighting that flashes on so you can’t creep shoot folks without their knowledge. Here’s some of that video:
We got our first glimpse of the Ray-Ban Meta at a briefing just ahead of the recent Connect conference. I was genuinely impressed by the industrial design the join team came up with. Most folks would hard-pressed to distinguish the charger from a standard Ray-Ban classic eyeglass case. It’s a little thicker than some, sure. A bit heavier. More rigid. But the team was able to make surprisingly few concessions.
There are a lot of clever touches here. In the place of a snap is a ring. Open the case and it glows green when fully charged and orange when not. The orange starts blinking when the battery is low. Space has been maximized inside. The battery sits directly beneath the glasses’ folded temples. In front of this is a dock with two charging pins that lie flush with a pair of contact pads hidden on the underside of the glasses’ bridge, held in place with magnets and a small tab.
The USB-C port is located on the outside bottom of the case, allowing it to sit on its back while being charged. Directly above this on the case’s rear is the Bluetooth pairing button. The case is slimmer than the last gen and can be carried in a pocket comfortably.
Meta says the glasses get “up to” four hours on a charge, while the case gets a total of eight charging cycles, for a grand total of 36 hours. As the company notes, “Battery life varies by use, configuration, settings and many other factors.” That’s the case with all tech, of course, but I did notice that video is a power drainer.
The companies really leaned into the style side of things here (not a bad decision when designing tech meant to be worn on the body). There are two main designs for the glasses. There’s the classic Wayfarer (which is probably what you think of when you think of sunglasses) and the new Headliner (not dissimilar from Wayfarer, but significantly more rounded on the top and bottom).
According to Meta, there are 150 design combos possible, when you factor in all of the different design options, including frame color, style and lenses (including sunglasses, clear, prescription, transitions and polarized).
The temples are thicker than most sunglasses — to be expected, seeing as how they contain the speakers and other components (there’s a transparent option, if you want to see for yourself) — but again, the designers have done a good job keeping size down, all things considered. And again, while slightly heavier that a standard pair of Wayfarers (50.8 g vs. 44 g), you can wear them comfortably all day if you want to (or at least the less than four hours the battery lasts).
There’s a touchpad on the outside of the left temple. Swiping back and forth will adjust the volume (other features can be customized in-app). It also doubles as a control panel for live streaming, since you likely don’t want to futz with your phone or keep using the wake word. A tap can check Instagram or Facebook comments and viewers in real-time. The capture button sits next to the hinge on the left temple
There are a pair of small circular modules on the end pieces. They look identical, for the sake of symmetry, but serve very different — albeit related — functions. On the top right (when facing the glasses) is the 12-megapixel camera. On the top left is an LED that turns on to alert people in your vicinity that you’re recording.
When covered, the glasses send an audio alert that they’ve stopped recording. This is to avoid people sticking a piece of electrical tape to hide the light. Meta says they didn’t hear of any specific examples of this happening, but they almost certainly got that feedback. Again, privacy is paramount for a device like this, especially since it’s something that most people around you don’t know exists. When the battery is low, you’ll get a spoken alert and the light will blink orange and turn red right before shutting down. The light will blink white when receiving a call, do a single flash when taking a photo and glow steadily when recording.
When pairing, it flashes blue, going solid when connected. The pairing process is pretty straight forward. You’ll need to download the Meta View app, choose between Meta Ray-Ban and Ray-Ban Stories and allow bluetooth to connect . Images and video will save to the glasses’ 32GB of internal storage (that’s roughly 500 photos or 100 videos at the maximum 30 seconds apiece). You’ll need to tap “Import” inside the app to connect via WiFi and download the contents to your phone. You can also set it up to auto import via settings.
Once everything is paired, put the glasses on and open either Facebook or Instagram to livestream. Tap the plus icon and it will bring you to the livestream screen. Your phone’s camera is, understandably, the default, but double pressing the capture button will switch over to the glasses. Livestreaming is probably the single biggest killer app Ray-Ban Stories was missing.
There are barely visible down firing speakers on the bottom of the temple tips. When I first tried the speakers in an otherwise silent room, they sounded surprisingly loud and clear. They’re open-ear speakers, rather than bone conduction, which has its pluses and minuses. Bone conduction tends to be quite quiet but does a decent job with ambient noise, since it’s arriving at your eardrums through a different method.
As expected, I had to turn up the volume quite a bit among the airport din. I would recommend them for quieter environments, where possible, but obviously that isn’t always an option. Sound is integral to the headphones, beyond music listening. For instance, there’s an audible shutter click when you take a picture.
There are on-board microphones as well, which listen for the “hey Meta” wake word. Voice certainly makes sense on a device like this. It can be used to take a picture, stop and start video and adjust volume (turns out voice is kind of an annoying way to do the latter). You can also ask the glasses for the time, weather and how much battery is left. You can also ask Alexa style-questions, and Meta AI will attempt to answer. That’s currently only available here in the U.S. through an open beta.
The price starts at $299 for standard lenses. Polarized run $329 and transitions $379. Prescription lenses are on a sliding scale. The price will almost certainly be a deterrent for many — and understandably so. Ultimately, you need to ask yourself how much value a face-worn camera will bring to your life. If you make a living livestreaming, it may make sense. It’s a lot to pay however, for sheer novelty.
It’s worth noting that future updates will bring more value to the device, including sign translation (through voice) and the ability to identify landmarks in front of you. One can see the future of head-worn computing laid out in front of your face — though it’s still going to be a while before we get there.",https://techcrunch.com/wp-content/uploads/2023/09/Meta-Ray-Ban-Stories-06.jpg?w=1200,2023-10-17 07:01:44
https://techcrunch.com/2023/10/16/snapchat-is-now-allowing-websites-to-embed-content/,Snapchat is now allowing websites to embed content,"Snapchat has relied on people consuming content on its own app. But now, the social network is allowing websites to embed public content including Lenses, Spotlight videos, Public Stories, and Public Profiles.
Users who want to embed a Story, video, or a Lens, can open up the content on a desktop browser using the link. They can click on the embed button on the share sheet to copy the code and post it to their site.
In July 2022, Snap made its website more useful for users with core features like the ability to send messages and Snaps. The initial version of Snapchat for the web was only available for Snapchat+ users in the United States, United Kingdom, Canada, Australia, and New Zealand. The company made it available to all users in September 2022.
Snapchat’s rivals Instagram and TikTok have long offered web embeds so blogs and news sites can include content from those platforms. Snap hopes that this move will drive more traffic to the app and website.
Last week, Snap CEO Evan Spiegel sent an internal memo to employees stating that the social network wants to reach 475+ million daily users in 2024, according to The Verge’s Alex Heath. The report also noted that Snap aims to have 14 million Snapchat+ subscribers and $500 million in non-ads revenue. Last month, Snap reported that Snapchat+ crossed 5 million subscribers.
The Verge’s report added that the company has set a goal to achieve a 20% increase in ad-based revenue year-on-year.",https://techcrunch.com/wp-content/uploads/2021/01/GettyImages-1172921170.jpg?w=1024,2023-10-17 06:02:54
https://techcrunch.com/2023/10/16/ftx-execs-blew-through-8b-testimony-reveals-how/,FTX execs blew through $8B; testimony reveals how,"Sam Bankman-Fried and other FTX executives spent $8 billion worth of customer funds on real estate, venture capital investments, campaign donations, endorsement deals and even a sports stadium, according to testimony from former senior FTX executive Nishad Singh.
Singh’s testimony, which kicked off the third week of Bankman-Fried’s trial, provides fresh details of exactly where that money went.
Singh, who has already pled guilty to fraud, money laundering and violation of campaign finance laws, said Monday that he learned of the massive hole in Alameda’s books as a result of a coding error that “prevented the correct accounting” of user deposits by around $8 billion.
Singh’s testimony helps corroborate the statements given by three previous prosecution witnesses, all of whom were in Bankman-Fried’s inner circle: FTX CTO Gary Wang, Alameda CEO Caroline Ellison and FTX engineer Adam Yedidia. While Wang and Ellison have pled guilty, each witness has pointed to Bankman-Fried as the orchestrator of fraud and money laundering.
Singh said that even after learning about the hole, “implicitly and explicitly, I green-lit transactions that I knew must have been digging the hole deeper and therefore coming from customer funds.”
Singh went on to describe Bankman-Fried’s spending as “excessive.” He said that he often learned about large spends after the fact, and that his expressions of concern weren’t taken seriously.
“I also would express that I felt kind of embarrassed or ashamed of how much it all wreaked of excess and flashiness,” said Singh. “It didn’t align with what I thought we were building a company for.”
Where the money went
Prosecutor Nicolas Roos and Singh went through spreadsheets detailing different ways Alameda spent the $8 billion in customer funds. Singh testified that Bankman-Fried was “in general the one making the final decision on investments and investment team decisions as a whole.”
In addition to going over a $1 billion on Genesis Digital Assets, a crypto mining firm in Kazakhstan, and $500 million on Anthropic, an AI company focused on safety, the prosecution focused on Alameda’s $200 million investment into K5 Global, a venture firm led by investor Michael Kives who is known for his extensive network.
That network seemed to impress Bankman-Fried deeply. After attending a Super Bowl Party hosted by K5 in Los Angeles, the former crypto mogul told Singh that he had met “the most impressive collection of people he ever had in one location.” Faces at the party included Hilary Clinton, Katy Perry, Orlando Bloom, Leonardo DiCaprio, Jeff Bezos, Kendall and Kris Jenner and Kate Hudson.
Bankman-Fried had proposed a term sheet to Singh and Wang one night that laid out hundreds of millions of dollars of onuses to Kives and Bryan Baum, co-founder and managing partner of K5. The sheet also proposed up to $1 billion long-term capital to give to the VC firm, according to Singh.
“We can get from them essentially infinite connections,” wrote Bankman-Fried in a letter to FTX leadership that was shared at Monday’s trial. “I think that if we asked them to arrange a dinner with us, Elon, Obama, Rihanna and Zuckerberg in a month, they would probably succeed.”
Singh said he expressed concern about partnering with K5 and giving them such substantial funds, which would be “really toxic to FTX and Alameda culture.” He said that “politicking and social climbing was not going to be rewarded, and here we were rewarding people in exorbitant amounts.”
The former FTX executive suggested that Bankman-Fried use his own money, not FTX’s, to make some of these investments. Those protestations didn’t yield results, according to the spreadsheet, which showed the K5 deal went through Alameda’s venture arm.
Bankman-Fried also believed that endorsement deals and even “unpaid partnerships with celebrities” would help increase FTX’s influence to propel its success, said Singh.
To that end, about $205 million of that $8 billion chunk was spent renaming the Miami Heat stadium to FTX Arena. Another $150 million was spent to endorse the MLB. Other items on a spreadsheet shown to the jury show FTX paid out $1.13 billion in exchange for endorsements from basketball player Steph Curry, video game developer Riot, Seinfeld writer Larry David to endorse FTX in a Super Bowl ad, football star Tom Brady and model Giselle Bündchen, with whom FTX was coordinating on some philanthropic efforts, according to Singh. .
Singh’s testimony also revealed a range of properties that had been purchased with the funds, including a $30 million penthouse in the Bahamas that Singh said was “too ostentatious.”
Bankman-Fried has also donated tens of millions to election campaigns.
The former FTX executive, who also went to high school with Bankman-Fried and was a close friend of his brother, testified that he expressed concern about the company’s spending, but was usually blown off.
Singh recalled one instance where Bankman-Fried got visibly angry with him and said that people like him were “sowing seeds of doubt in the company decisions” and were “the real insidious problem here.”
“It was pretty humiliating,” said Singh.
Where did this $8 billion hole come from?
Singh’s testimony aligned with Yedidia’s that states in June 2022, the executives learned that Alameda owed $8 billion worth of FTX customer money after Ellison shared a Google Doc displaying the “extremely negative” balance.
Singh told the court this hole was due to a bug that Yedidia accidentally introduced into the system in 2021. The bug “prevented correct accounting for fiat@FTX.com’s balances on specific types of withdrawals,” said Singh. Fiat@FTX.com was an internal accounting system that recorded user deposits.
On top of this, Singh testified that he built out systems on FTX that gave Alameda “special privileges” not afforded to other users. A feature called “allow negative” let Alameda trade, borrow and withdraw FTX funds in excess of its balance and collateral amounts, according to Singh. He testified that he coded an initial version of the feature in 2019 at Bankman-Fried and Wang’s advisement.
A later version of this code allowed Alameda to borrow from FTX without having tis collateral liquidated. In effect, it could “withdraw money that it didn’t have,” meaning it could “lose money” that “belonged to customers,” Singh said.
By June 2022, Alameda had built up its own $2.7 billion deficit on the FTX platform.
“This seemed like a real abuse of a feature that until this point I believe was serving FTX, not hurting it,” said Singh.
Alameda at this point also owed $8 billion in user funds to FTX that it no longer had on hand. In total, the negative account balance and accounting bug contributed to a $11 billion hole on FTX’s balance sheet, Singh testified.","https://techcrunch.com/wp-content/uploads/2023/10/GettyImages-1728183029.jpg?resize=1200,801",2023-10-17 03:52:32
https://techcrunch.com/2023/10/16/agnikul-funding-india-space-tech-startup/,India's Agnikul gets $26.7M to prepare for commercial space launches,"Agnikul, an Indian space tech startup developing small-lift launch vehicles, has raised $26.7 million in fresh investment as it looks to begin commercial launches using its customizable satellite rocket.
Companies — from big tech giants to startups — are looking to launch their small satellites (up to 500 kg in weight) to space to improve their existing technologies and bring new experiences, such as precise location tracking and internet connectivity for remote areas. As underlined by the European Commission, this has ramped up the demand for smaller rockets.
Small satellites have typically been launched as secondary payloads on larger launch vehicles. Existing players including Elon Musk’s SpaceX have been conducting rideshare missions for small satellite launches. However, their growing demand has encouraged space companies to seek specific solutions. Astra, Virgin Orbit and Rocket Lab are some U.S. space companies that have introduced small satellite launch vehicles to cater to the growing demand. Nevertheless, the gap between the demand and supply of small launch vehicles is still quite significant by most accounts, leaving enough room for new entrants.
Agnikul is one such entrant, via its ‘Agnibann’ small satellite rocket. It will use a single-piece engine with no assembly or conventional manufacturing process to offer a faster production timeline and tailor-made launches. It’ll instead use additive manufacturing, otherwise known as 3D printing – the same approach being taken by US-based Relativity Space. The Chennai-based startup has showcased some glimpses of its plan by launching a 3D-printed engine called Agnilet, which was successfully test-fired in early 2021.
Last year, Agnikul secured a patent for the engine and established its facility to build many such engines using end-to-end 3D printing. It also launched India’s first private launchpad and mission control center at the Satish Dhawan Space Center in Sriharikota, located in the Southern Indian state of Andhra Pradesh, in November and started the integration process of its launch vehicle Agnibaan SOrTeD (Suborbital Technological Demonstrator) in August.
Srinath Ravichandran, co-founder and CEO of Agnikul, told TechCrunch that the startup looks to complement India’s space agency, the Indian Space Research Organisation (ISRO), and is targeting to handle launches in the less than 300 kg payloads segment.
“When the customer looks at India for a solution, we are filling the gap not directly addressed by ISRO today,” he said in an interview.
ISRO currently has its Small Satellite Launch Vehicle (SSLV) to launch satellites weighing up to 500 kilograms in a low-Earth orbit. However, the space agency intends to fully transfer the vehicle to the private sector through bidding.
Ravichandran founded Agnikul along with Moin SPM and IIT Madras professor SR Chakravarthy in 2017. In December 2020, it became the first Indian private space company to sign an agreement with ISRO. Subsequently, the startup began developing its launch service for satellites weighing up to 100 kgs using the Agnibaan rocket into a 700-kilometer (about 435 miles) Earth orbit.
“We have not yet done commercial launches; we have not entered the commercialization phase. But at the same time, today, people are able to look at what we have done with the money we have received, how efficient we have been on capital, and what technology we have been able to build,” Ravichandran asserted.
Without disclosing specifics, he added that the startup has received some inbound interest from potential launch customers, mainly from companies in Europe and Japan, and also signed memorandums of understanding with a few. India also has some satellite tech startups that could become Agnikul’s customers after it starts commercialization following its first test flight, which is expected sometime before the end of 2023.
The space of small satellite launch vehicles where Agnikul operates already has Indian startup Skyroot Aerospace backed by GIC, Sherpalo Ventures and Graph Ventures, among other investors. The latter has Vikram S to take 80 kg payloads to 100-kilometer altitude. Similarly, there is global competition from players including Rocket Lab, which also has the Electron rocket for small satellite launches. However, Ravichandran said the ability to customize the vehicle depending on payload requirements helps bring a cost-effective advantage to Agnikul.
“The vehicle can be tailored to whatever payload is being asked or to whatever orbit it is being asked to go to, without compromising on the cost itself,” he said. “So just because you have only 30–40 kg to launch, we don’t believe in pricing at a very high dollar per kg. We say between 30 to 300 kgs, anyone in that range, the dollar per kg would be still the same.”
He continued that the vehicle is also being designed to be launched using mobile launchpads, and that they can be reused.
Agnikul currently has a headcount of around 225 people, predominantly in manufacturing and launch operations. It operates from four facilities and the mission control center.
With the capital infusion, the startup is looking to go beyond its first few launches and hire talent to help realize and manufacture multiple launch vehicles.
“It’s about getting out of a very design-focused phase into a phase of design+production+manufacturing, with quality as a prime focus, wherein we’ll be able to actually tell our customers that okay, your assets are safe with us,” Ravichandran stated.
“Agnikul’s pursuit of innovative space solutions aligns with our investment focus on India’s leading-edge deep tech sectors,” said Arun Kumar, Managing Partner at Agnikul investor Celesta Capital, in a prepared statement. “We are excited to support their pioneering vision and innovative approach to modernizing and democratizing the space industry. Their mission underscores the spirit of collaboration amongst the Indian Space Research Organization, space regulators, and entrepreneurs in driving advancements within India’s vibrant space-tech ecosystem.”
Agnikul sees an annual demand for about 50 tons in the less than 300 kgs satellite launch segment. Therefore, it plans to develop multiple variants of its Agnibaan rocket and increase launches from one or two per year to one or two per month over time.
“As India’s answer to SpaceX, Agnikul is poised to revolutionize the space industry not just domestically but globally. Led by Srinath, Moin and Prof. Satya, the team is super passionate, and we wish them all the success in their first mission,” said Sailesh Ramakrishnan, Managing Partner at Rocketship.vc, which also participated in the round.
Agnikul is one of the examples of how India’s space tech industry has emerged in the last few years. The country opened its space sector for private companies in June 2020, and created the Indian National Space Promotion and Authorisation Centre (IN-SPACe) as a nodal agency to collaborate with startups. Since then, it has seen significant growth in space activities.
The South Asian nation, which currently has over 150 space tech startups, introduced its anticipated space policy in April, detailing public and private cooperation guidelines. The country also saw successful launches of missions, including its highly acclaimed moon lander mission Chandrayaan-3 and solar probe Aditya-L1. Additionally, India’s growing space activities gained attention — and attracted investments — from big tech companies including Google and Microsoft.
Foreign satellite launches helped India generate $174 million, with $157 million coming in the last nine years, the government recently said in the parliament. However, the industry demands clarity on foreign direct investments in Indian space tech startups and the recently released guidelines for the private sector as it moves forward.
Equity investments in the Indian space tech startup ecosystem soared nearly 312% to $114.9 million in 2022 from $27.9 million in 2020, according to the data shared by analyst firm Tracxn. As much as $65.5 million was invested in 2023 alone.
“From our early days with Agnikul, it’s been a thrilling journey,” said Anirudh A Damani, Fund Manager at Artha Venture Fund. “Now, seeing them draw such esteemed investors showcases not just their current achievements but hints at the groundbreaking feats on the horizon in the space tech sector. Doubling our investment isn’t merely a financial move—it’s a ringing endorsement of our faith in Agnikul’s prowess. We’re all in, eager to see—and support—every giant leap they make in reshaping space exploration.”
The all-equity Series B funding round saw participation from Celesta Capital, Rocketship.vc and Artha Select Fund. Agnikul’s existing investors Artha Venture Fund, Pi Ventures, Speciale Invest and Mayfield India also participated in the round. The six-year-old startup has raised $40 million in capital to date, including the $11 million Series A round in May 2021.",https://techcrunch.com/wp-content/uploads/2023/10/agnikul-founders.jpg?w=1200,2023-10-17 03:00:58
https://techcrunch.com/2023/10/16/bandcamps-new-owner-lays-off-half-the-company/,Bandcamp's new owner lays off half the company,"Bandcamp has officially changed hands from its old new owner, Epic, to its new new owner, Songtradr, and lost half its employees in the process. Songtradr confirmed that “50% of employees received offers” to continue on under the new ownership — and naturally the other 50% didn’t.
The venerable digital music marketplace was acquired by Epic last year, but clearly the Fortnite maker wasn’t quite sure what to do with the company, and late last month resold it to music licensing platform Songtradr as part of a wave of cost-cutting.
It was known from the start that layoffs would happen, and indeed Epic and Songtradr were fairly straightforward about their necessity as part of the deal — technically the employees were laid off by Epic ahead of the formal acquisition, though it was Songtradr that decided who would and would not be hired. It was never clear whether they were talking about a few redundancies in web design and sales, or across-the-board cuts. It seems it was the latter, as Songtradr explained in a statement:
Over the past few years the operating costs of Bandcamp have significantly increased. It required some adjustments to ensure a sustainable and healthy company that can serve its community of artists and fans. After a comprehensive evaluation, including the importance of roles for smooth business operations and preexisting functions at Songtradr, 50% of Bandcamp employees have accepted offers to join Songtradr.
A spokesperson for the company added that “there were reductions made across all departments, and all departments still have original Bandcamp employees.” Acquisitions very frequently result in loss of positions, so while this isn’t unusual, 50% does seem like a lot — and a lot of people are sadly out of a job.
Notably, Bandcamp employees were in the process of unionizing, or rather some had done so already, a factor that has been suggested as contributing to Epic’s sudden distaste for ownership. I asked Bandcamp United for comment on the layoffs and have not heard back from them.
Songtradr said that it had no access to union membership, and the offers were made without any of that information.
When I asked whether Bandcamp will remain independent, Songtradr responded as follows:
Bandcamp will continue to serve its Fan and Artist community as a dedicated service and stand-alone solution. From the business structuring point of view, Bandcamp employees will be part of Songtradr and over time they will fully integrate into the Songtradr organization.
Until last year, Bandcamp seemed to be one of the few remaining places for relatively simple and equitable monetization for independent musical artists. The corporate takeover and resale does not bode well for the platform, but we will know soon what effect these layoffs and any other changes will have on the business.","https://techcrunch.com/wp-content/uploads/2023/10/bandcamp-flames.jpg?resize=1200,675",2023-10-16 22:39:08
https://techcrunch.com/2023/10/16/max-q-psyched/,Max Q: Psyche(d),"Hello and welcome back to Max Q!
In this issue:
SpaceX launches NASA asteroid mission
News from Relativity Space and more
Godspeed, Psyche.
The large NASA spacecraft is officially en route to a metal-rich asteroid (also named Psyche) after taking off on a SpaceX Falcon Heavy rocket last week. The mission marked the first time a NASA science mission has used SpaceX’s larger rocket for a launch.
Psyche (the spacecraft) will now embark on a six-year, 2.2 billion-mile journey to Psyche (the asteroid), which sits in the main asteroid belt between Mars and Jupiter. Before the spacecraft reaches its target, it will conduct a technology demonstration of the Deep Space Optical Communications experiment. If successful, it would be the first time optical communications are demonstrated beyond the Earth-moon system.
More news from TC and beyond
Astra Space is reportedly weighing up selling a 51% stake in its in-space propulsion business or selling other parts of the business, like equipment.
Evolution Space has a new deal with NASA to begin building a solid propulsion center and solid rocket motor testing at the agency’s Stennis Space Center.
Relativity has signed a launch agreement with Intelsat that would see the telecom giant’s satellites fly on a Terran R rocket as early as 2026.
Max Q is brought to you by me, Aria Alamalhodaei. If you enjoy reading Max Q, consider forwarding it to a friend.",https://techcrunch.com/wp-content/uploads/2019/12/tc-space-hero.gif?w=949,2023-10-16 22:00:41
https://techcrunch.com/2023/10/16/google-lobbies-against-legally-mandated-age-verification-for-minors/,Google lobbies against legally mandated age verification for minors,"Google is challenging proposed laws that would require online services to implement age checks in a new framework that theorizes how technology companies should approach children’s safety online. The framework, titled the “Legislative Framework to Protect Children and Teens Online,” is the tech giant’s response to congressional child online safety proposals.
In its set of principles, Google dismisses policies that would require online services to verify the age of their users before allowing them access to their platforms. For instance, Utah passed a law that aims to start requiring social media companies to verify the age of a user seeking to maintain or open an account. Google says that such age verification policies will lead to trade-offs and possibly restrict access to important information.
“Good legislative models — like those based on age-appropriate design principles — can help hold companies responsible for promoting safety and privacy, while enabling access to richer experiences for children and teens,” the company wrote in a blog post announcing the framework. “Of course, as policymakers contemplate these issues, they should carefully consider the broader impacts of these bills and avoid side effects like blocking access to critical services, requiring people (including adults) to submit unnecessary identification or sensitive personal information.”
The company states that “data-intrusive methods,” such as verification with government IDs, should be limited to “high-risk” services that deal with alcohol, gambling, or porn. For context, Louisiana recently passed a law that requires age verification to access adult websites in an attempt to prevent kids from seeing online porn. Google’s framework is not against age verification in this manner.
Google argues that instead of implementing legislation that would require online services to verify ages, these companies should be required to “prioritize the best interests of children and teens in the design of their products.” Google says that online services used by children and teens should be required to assess the collective interests of children based on “expert research and best practices, to ensure that they are developing, designing and offering age-appropriate products and services.”
In other words, Google says online services shouldn’t be forced to block teens and children from their platforms, and should instead be required to design products appropriately.
Today’s framework comes four years after the Federal Trade Commission (FTC) fined Google and YouTube $170 million for violating children’s privacy. The FTC said YouTube illegally collected personal information from children and used it to profit by targeting them with ads. As part of the settlement, the FTC said YouTube had to develop and maintain a system that asks channel owners to identify their child-directed content to ensure that targeted ads are not placed in such videos.
Interestingly, Google’s framework notes that there should be legislation banning personalized advertising for children and teens. Earlier this year, Senator Ed Markey (D-Mass.) announced the reintroduction of the Children and Teens’ Online Privacy Protection Act (COPPA 2.0), which would ban targeted ads to minors. Google argues that “for those under 18, legislation should ban personalized advertising, including personalization based on a user’s age, gender, or interests.”
In a separate online safety framework published today by YouTube, the video platform’s CEO Neal Mohan said the service doesn’t serve personalized ads to kids.
Despite this claim, a recent report from advertising performance optimization platform Adalytics alleges that YouTube continues to serve targeted ads to minors. In a blog post, Google stated that Adalytics’ report was “deeply flawed and uninformed.” The report caught the attention of Senator Marsha Blackburn (R-Tenn.) and Senator Markey, who sent a letter to the FTC asking the government agency to investigate the matter.","https://techcrunch.com/wp-content/uploads/2021/07/GettyImages-1207206237.jpg?resize=1200,800",2023-10-16 21:39:05
https://techcrunch.com/2023/10/16/websummit-derailed-by-founders-public-fight-with-those-supporting-israel-in-hamas-conflict/,Web Summit derailed by founder's public fight with those supporting Israel in Hamas war,"Web Summit, the big tech conference brand that runs events in several cities and whose 70,000 person flagship event in Lisbon is taking place next month, is running into a wall — a wall of outrage. Founders, investors and others from the technology community in Israel have gone ballistic over comments made by the founder and figurehead of Web Summit, Paddy Cosgrave, related to the fighting underway across Israel and Gaza, specifically his criticism of Israel’s retaliatory actions.
Now, the anger with Cosgrave has gone viral, and today it looked like it was about to overrun promotion efforts for Web Summit.
The situation also highlights how Israel’s tech industry, the country’s most valuable and arguably best-known export, built on business development and relationships, has been willing to cut those ties in the battle of public opinion in this most polarizing of conflicts.
“Here in Israel, we’re basically now in rage mode after the first week of shock and awe,” one tech source told TechCrunch. “We ain’t got time to f_ck around with anyone remotely suggesting Israel needs to sit it out and not put an end to Hamas.”
It all started the day that Hamas busted through Israel’s walls and rampaged through villages and a music festival on a murdering and pillaging spree, killing 1,400 people, mostly civilians. Hamas, the ruling party in the Palestinian territory, is considered a terrorist organization by the U.K., U.S. and other countries; they also took 199 hostages back into Gaza.
On that day, Cosgrave was in Doha, Qatar, the city where Web Summit will be holding its newest event in four months’ time. As some were taking to social media to express shock, or sympathy, or in some cases, advocating for restraint, some took more critical stances. Cosgrave, for his part, posted data on X of the human cost of the Israel-Palestine conflict between 2008 and 2023. It omitted the events (and casualties) of the weekend.
That stirred debate, but Cosgrave didn’t acknowledge that the numbers were out of date or comment about the attacks in Israel. He instead proceeded, over the next several days — between posts about Qatar, political comments related to Ireland, and rugby reactions — to put out several more posts, all highlighting the opinion that Israel was taking an unjust approach.
As the posts racked up a range of alarming and extreme responses on both sides of the argument, Cosgrave doubled down. On Friday, he noted he was “shocked by the rhetoric and actions of so many Western leaders” in supporting Israel. But as attention mounted, the rejections to Web Summit started, too.
Some of the highlights (or I guess you could say, lowlights):
David Marcus said he would never again attend, sponsor or speak at another Web Summit event. “Saddened by your ill-informed stance. You could’ve taken a more nuanced one, condemning these atrocities and calling for restraint. That would’ve been acceptable,” wrote David Marcus, the longtime fintech entrepreneur and Meta executive, in a tweet yesterday. “You chose to support terrorists. As such I’ll never attend/sponsor/speak at any of your events again.”
“Will refuse to work with anyone who speaks at this conference in Qatar for the rest of my career,” chimed in Keith Rabois, the Founders Fund partner and entrepreneur.
Ori Goshen, the co-founder and co-CEO of AI21 Labs, announced on LinkedIn that he would no longer be giving a keynote at Web Summit.
“It’s bad enough that summit CEO Paddy Cosgrave didn’t see fit to express horror at the sickening atrocities committed by Hamas on October 7th,” he said. “But as immoral as that is, Paddy Cosgrave chose to not only ignore these but instead post something against the policies of the Israeli government. Leaving aside his very partial understanding of history and geopolitics, this response was abhorrent. We at AI21 cannot be part of such indecency and moral bankruptcy. We will not attend WebSummit, and I will not give the keynote. #cancelwebsummit #standwithisrael”
Then the Israeli ambassador to Portugal, Dor Shapiro, waded in.
“Today, I wrote to the Mayor of Lisbon informing him that Israel will not participate in the #WebSummit conference due to the outrageous statements made by the conference CEO Paddy Cosgrave. Even during these difficult times, he is unable to set aside his extreme political views and denounce the Hamas terrorist activities against innocent people,” he wrote, also on LinkedIn. “Dozens of companies have already canceled their participation in this conference, and we encourage more to do so.”
By today, Cosgrave appeared to walk back his statement. “We are devastated to see the terrible killings and the level of innocent civilian casualties in Israel and Gaza,” Cosgrave wrote, nine days Hamas invaded Israel. “We condemn the attacks by Hamas and extend our deepest sympathies to everyone who has lost loved ones. We hope for peaceful reconciliation.”
Under so much fire, however, he subsequently dug in his heels, tweeting afterward: “To repeat: War crimes are war crimes even when committed by allies & should be called out for what they are. I will not relent,”
Damage has been done to Cosgrave and the Web Summit brand in the interim.
“Hard to take this statement at face value — given all the tweets @paddycosgrave has been liking over the last few days. I saved several of them on the attached google doc (so we have a record when the @WebSummit PR team asks him to delete them),” said Josh Kopelman, the founder of First Round Capital.
Kopelman separately suggested in a tweet that Cosgrave is in the pocket of Doha and Qatar, a country that many believe is connected to the financing of Hamas. That was enough to push Garry Tan, the head of Y Combinator, over the edge, too.
“I refuse to appear at Web Summit and am canceling my appearance,” he said. “I condemn Hamas and pray for peace for the Israeli and Palestinian people.”
We’ve reached out to Tan and Kopelman to ask if they are advising portfolio companies and partners at their firms against also attending. Tan declined to comment, and Kopelman has yet to respond.
Web Summit has provided us with a statement on the cancellations, saying that the organization is talking to “a number of people about their attendance at Web Summit” but is not in a position to discuss exacts and individuals.
“We understand that it is an incredibly sensitive and painful time during this utter tragedy of war. We want to reiterate our devastation for the loss of innocent life in Israel and Gaza. We strongly condemn the horrific attacks by Hamas on Israelis. Web Summit’s mission is to connect people and ideas changing the world from all around the globe. The more voices we have from around the world, the more we can help change the world for the better,” she added. “We are saddened to hear that some Israelis in the tech community will no longer be attending Web Summit. We regret any hurt caused and extend our deepest sympathies to everyone who has lost loved ones. We hope for peaceful reconciliation.”
The spokesperson said that last year’s event attracted about 71,000 people and this year it’s on track to “max out” at 70,000.
A public page in Notion titled “techcondemingterror” is tracking the growing response. It now includes press clippings, comments from a number of leaders in Israel’s technology industry and comments.",https://techcrunch.com/wp-content/uploads/2022/09/43965968860_0f0b8699b9_c.jpg?w=800,2023-10-16 21:14:56
https://techcrunch.com/2023/10/16/kia-opens-orders-for-its-flagship-all-electric-2024-ev9-suv/,Kia opens orders for its flagship all-electric 2024 EV9 SUV,"Kia has started taking reservations for its EV9, the full-size SUV that has been positioned as the flagship for the company’s EV portfolio.
Reservations for the Kia EV9 are $750 and can be applied to the purchase price, according to the company.
Kia taking reservations for an EV is a relatively new strategy for the automaker that began with the 2022 EV6 sedan. The EV9 is the second vehicle that Kia has allowed customers to reserve in advance of deliveries. Of course, this isn’t a new strategy among EV startups that sell directly to the consumer. Tesla, which has long since left the startup category, still uses reservations ahead of vehicle deliveries; in many cases taking refundable deposits years before the vehicle is even delivered.
For Kia EV9 reservation holders the wait will be much shorter. The EV9 is expected to arrive in dealer showrooms in the fourth quarter of this year.
Kia is betting that an all-electric SUV will have the same kind of success that its internal combustion engine-powered Telluride has had in the United States. The EV9 is a three-row SUV based on the company’s Electric Global Modular Platform (E-GMP) that has a 122-inch wheelbase and an overall length of 197 inches, putting it about in line with other full-size SUVs on the market today including the Telluride.
The big selling point besides the size and the software? Kia is pricing the EV9 lower than other similarly sized EVs on the market today, such as the Mercedes EQS SUV and the Rivian R1S. The Kia EV9 starts at $54,900, not including the $1,495 destination fee. The price pops up from there depending on the powertrain and trim.
The company is offering customers the choice of two powertrain options. The standard powertrain comes with a 76.1-kWh battery with a 160-kW (215-hp) motor that drives the rear wheels. There’s also an optional 99.8-kWh battery that will be available in a single-motor configuration (201-hp), or a dual-motor, 283-kW (379-hp) all-wheel-drive configuration.
Customers also can choose between five model trims. The Light trim is available with a short or long-range battery. Other trims include Wind, Land and GT Line, which is at the top of the price list at $73,900. The range of the EV9, which is between 230 and 304 miles, is dependent on the powertrain and trim. The 304-mile range version is the Light trim in rear-wheel drive equipped with the larger battery pack.
The stakes are certainly high for the company. “In many ways we consider the Kia EV9 to be the new flagship for our brand,” Kia CEO Ho-sung Song said in a livestream that aired back in March 2023. “While the Kia EV6 played an important role in repositioning the Kia brand following the launch in 2021, the Kia EV9 moves us further forward.”","https://techcrunch.com/wp-content/uploads/2023/10/kia-ev9.jpg?resize=1200,800",2023-10-16 21:12:42
https://techcrunch.com/2023/10/16/archer-aviation-to-launch-air-taxis-in-abu-dhabi-in-2026/,Archer Aviation to launch air taxis in Abu Dhabi in 2026,"Electric vertical takeoff and landing (eVTOL) vehicle company Archer Aviation plans to start air taxi operations in Abu Dhabi in 2026, making the city its first international market outside the United States.
From there, Archer plans to launch an air taxi service across the United Arab Emirates as part of the company’s recently signed memorandum of understanding with the Abu Dhabi Investment Office (ADIO).
The plans for UAE air taxi development come off the back of the California-based company’s $142 million deal in August to provide up to six of its “Midnight” aircraft to the U.S. Air Force. In May, Archer completed final assembly for Midnight, which can carry four passengers and a pilot and has a range of up to 100 miles.
Archer wants to replace 60- to 90-minute car commutes with 10- to 20-minute eVTOL flights in urban areas. Midnight is designed to perform rapid back-to-back flights with minimal charge time between flights.
In August, Archer received Federal Aviation Administration certification to begin test eVTOL flights in the U.S. Once Archer’s air taxis are fully certified by the Federal Aviation Administration, the UAE will approve them for use in the country, according to Saif Mohammed Al Suwaidi, director general of UAE’s General Civil Aviation Authority.
As part of Archer’s deal with ADIO, the agency will provide Archer with incentives to establish its first international headquarters and manufacturing facilities within Abu Dhabi’s Smart and Autonomous Vehicle Industry (SAVI) cluster.
SAVI was recently launched in Masdar City — a sustainable urban community in Abu Dhabi built by Masdar, a subsidiary of Mubadala Investment Company — to attract foreign companies and support innovation and commercialization of smart and autonomous vehicle technologies. Mubadala is one of Archer’s backers.
“Bringing electric aviation to the UAE will help unlock congestion with zero emissions and, in turn, bring millions in foreign direct investment and thousands of jobs to the region over the next decade,” said Badr Al-Olama, acting director general of the Abu Dhabi Investment Office, in a statement.
Many of the vehicles to be launched in UAE will be built in partnership with Stellantis — the automaker agreed to mass-produce Archer’s eVTOL’s in January. Archer is also looking to partner with local manufacturers and plans to build a Center of Excellence in Abu Dhabi where the company will focus on building out next-generation aviation technologies.
The Stellantis manufacturing facility in the U.S. will serve as a “blueprint for future Archer manufacturing facilities,” according to Carlos Tavares, CEO of Stellantis.
Alongside its MoU with ADIO, Archer also signed agreements with helicopter charter service Falcon Aviation and aviation maintenance company GAL-AMMROC to, respectively, operate its air taxis and provide maintenance, repair and overhaul service support on the ground.","https://techcrunch.com/wp-content/uploads/2023/10/image002-2.jpg?resize=1200,741",2023-10-16 21:09:45
https://www.innovationnewsnetwork.com/how-the-space-age-is-polluting-our-atmosphere/38320/,How the Space Age is polluting our atmosphere,"The Space Age is leaving fingerprints on the stratosphere – one of the most remote parts of the planet – which has potential implications for climate, the ozone layer, and the continued habitability of Earth.
Using tools hitched to the nose cone of their research planes and sampling more than 11 miles above the planet’s surface, researchers have discovered that the Space Age has resulted in significant amounts of metals in aerosols in the atmosphere.
The increasing amount of debris is likely due to more frequent launches and returns of spacecraft and satellites.
This mass of metal is changing atmospheric chemistry in ways that may impact Earth’s atmosphere and the ozone layer.
The study, ‘Metals from spacecraft re-entry in stratospheric aerosol particles,’ is published in Proceedings of the National Academy of Sciences.
The rising use of metal and polluting materials in space
“We are finding that the Space Age has released human-made materials in what we consider a pristine area of the atmosphere,” said Dan Cziczo, one of the study’s authors.
The team detected more than 20 elements in ratios that mirror those used in spacecraft alloys.
They found that the mass of lithium, aluminium, copper, and lead from spacecraft re-entry far exceeded those metals found in natural cosmic dust.
Nearly 10% of large sulfuric acid particles – the particles that help protect and buffer the ozone layer – contained aluminium and other spacecraft metals used in the era of the Space Age.
Scientists estimate that as many as 50,000 more satellites may reach orbit by 2030. The team calculates that means that, in the next few decades, up to half of stratospheric sulfuric acid particles would contain metals from re-entry.
What effect that could have on the atmosphere, the ozone layer and life on Earth is yet to be understood.
The Space Age is in full swing, but how does this impact space pollution?
Spacecraft launches and returns were once international events. The launches of Sputnik and the Mercury missions were front-page news.
Now, a quickening tide of innovation and loosening regulation means that dozens of countries and corporations are able to launch satellites and spacecraft into orbit and fuel the Space Age.
All those satellites must be sent up on rockets, and most of that material eventually comes back down.
The Space Age has left behind a trail of metals that may change the atmosphere in ways scientists don’t yet understand.
“Just to get things into orbit, you need all this fuel and a huge body to support the payload,” Cziczo commented.
“There are so many rockets going up and coming back and so many satellites falling back through the atmosphere that it’s starting to show up in the stratosphere as these aerosol particles.”
He concluded: “Changes to the atmosphere can be difficult to study and complex to understand.
“But what this research shows us is that the impact of the Space Age on the planet may be significant. Understanding our planet is one of the most urgent research priorities there is.”",https://www.innovationnewsnetwork.com/wp-content/uploads/2023/10/shutterstockstudiovin_2208172963.jpg,2023-10-17 10:22:21
https://www.innovationnewsnetwork.com/research-innovation-key-renaissance-european-solar-manufacturing/38305/,Research and innovation is key for the renaissance of European solar manufacturing,"The world is switching to green energy, and Europe is presented with an opportunity to ensure solar energy plays the critical role it is meant to.
The European solar manufacturing landscape is at a critical crossroads, with a perfect storm emerging. Over ordering on the demand side, combined with overcapacity on the supply side, has resulted in a record drop in prices for solar modules and other system components. It has never been more important for the EU to advance its industrial strategy for solar PV and support European solar manufacturers.
This is where research and innovation (R&I) comes in. Expanding the European solar manufacturing base also requires an expansion of the EU’s R&I activities. Increased investments in innovative technologies are a key component in the long-term reindustrialisation of Europe’s solar manufacturing base.
Undoubtedly, R&I has been high on the Commission’s agenda. Under Horizon Europe, the EU’s key R&I funding programme, the Commission has allocated a significant budget of €95.5bn. More than 40% of that fund – €40bn – is earmarked for research that supports the European Green Deal.
Previously, the Commission invested €4.99bn towards clean energy technologies under its Horizon 2020 programme; only 10% of this was earmarked for PV projects. The Directorate-General for Research and Innovation has promised to help Europe “stay ahead of the game, and accelerate the roll-out of the EU’s strategic net-zero technologies,” like solar PV.
Solar has also been booming across Europe, especially in the last three years. Over 40GW of solar was installed in 2022, nearly double what was installed the previous year. Already in the first half of 2023, solar generation grew by 13%, according to a recent Ember report.
We have truly entered a thriving solar era, with record drops in fossil fuel generation. Every year, solar generation and installation numbers are increasing.
The R&I challenge
With solar numbers on the rise, and the EU setting its R&I agenda, you might wonder what the issue is? The reality is that the rest of the world has also woken up to the strategic role of solar. China is by far the world leader in the manufacturing of solar. The US has the Inflation Reduction Act which is spurring a boom in American solar manufacturing. India, Turkey, and South Africa are all making similar moves.
There are a number of solutions that EU leaders can take to ensure that European solar manufacturing plays a significant role in the globalised solar supply chain, like changing subsidy rules, setting up a dedicated financing instrument, and delivering ‘resilience’ auctions under the incoming Net-Zero Industry Act.
One wider tool we can’t forget is the role of R&I in supporting Europe’s manufacturing base – the critical link between ‘labs’ and ‘fabs’. The Fraunhofer Institute for Solar Energy Systems (ISE) has found that in Germany, PV technology development has delivered cost reductions of 36% per year on average since 2010, thanks to a combination of upscaling of manufacturing, and continued R&I advancements.
According to the Commission’s third Progress Report on the Competitiveness of Clean Energy Technologies, half of the EU’s greenhouse gas reductions expected by 2050 will require technologies that are not yet commercially available. Solar PV alone is set to generate more than 60% of the EU’s electricity by 2050, requiring more private and public investment into clean energy research.
The perovskite potential
The development of new cell technologies like perovskite solar cells reflect the necessity of expanded R&I investments in European solar manufacturing. In May 2023, Oxford PV, a perovskite solar manufacturer, set the record for the highest recorded efficiency of any commercial-sized solar cell in its Brandenburg an der Havel factory in Germany.
The cell converted 28.6% of the sun’s energy into electricity, and was made by placing a thin film of the perovskite material onto a conventional silicon solar cell. The combined ‘perovskite-on-silicon’ tandem solar cell achieves a conversion efficiency that is substantially higher than that of mainstream silicon-only solar cells, which average 22–24%.
Commenting on the achievement, David Ward, Chief Executive Officer at Oxford PV, noted that their, “innovative solar cells are close to being in the hands of our module-manufacturing customers,” with the focus now on ramping up production.
Recent findings from a team at the University of Surrey have also illustrated the potential of perovskite. They found that a nanoscale ‘ink’ coating improved the perovskite solar cells’ stability, making them suitable for mass production.
Researchers made this breakthrough when they discovered an aluminium oxide that minimises the drop in efficiency during the conditioning of perovskite solar cells. Perovskite has also been used to create self-healing solar panels on satellites in low-Earth orbit that can recover 100% of their efficiency, even after being damaged by radiation in space.
In general, the perovskite material is lighter and cheaper than a silicon-based solar cell, and is extremely efficient. It has even been praised as a ‘miracle material,’ a label earned with recent developments. When it reaches the market at scale, it will transform the PV sector.
All of these findings have emerged from investments into one innovative technology. The European solar PV sector’s research representation to the European Commission – ETIP PV – has made the point that getting R&I to production scale will require continuous EU funding.
Otherwise, we risk only investing in technologies that will one day be obsolete, especially given the acceleration of innovation cycles.
For example, fully realising the potential of perovskite solar cells will require more funding to facilitate its mass-production, and improve its shelf life; currently, perovskite deteriorates quickly when exposed to light, voltage, or heat.
More research will also be required to substitute the lead currently used in perovskite solar cells, for a more eco-friendly alternative, while retaining its efficiency.
A step forward for European solar manufacturing
Undoubtedly, the EU is leading in several areas of PV research and innovation, including in perovskite tandem solar cells. Oxford PV, Fraunhofer ISE, and Helmholtz-Zentrum Berlin, all European research and development bases, hold global solar cell conversion efficiency records.
However, rapid advancements in R&I investments by public and private actors in other regions are catching up to the EU, and threaten to leave it behind, especially when it comes to the industrialisation of R&I.
For example, in June, at a Shanghai trade show, a Chinese manufacturer already announced its plans to commercialise a perovskite solar cell. The EU is already lagging behind in the production of ingots and wafers, an important segment of solar manufacturing. It has also seen a notable loss of expertise in key segments of the PV R&I landscape.
Just like investments in manufacturing, the EU will need to expand and intensify its R&I investments if it wants to keep up, especially with its renewed ambitions for PV manufacturing.
Alongside renewed investments in PV manufacturing capacity, the EU must also invest in the industrialisation of the results of R&I efforts, and strengthen its investments towards developing the next generation of PV technologies.
For example, the perovskite potential will be lost without a strong investment commitment to bridging the manufacturing gap and delivering innovation at scale.
The ETIP PV White Paper on manufacturing puts it best: adequate financing is needed throughout the EU PV value chain. Many solutions can be implemented to accelerate R&I financing at the European level. This could include relaxing the EU’s State Aid rules – its Temporary Crisis and Transition Framework (TCTF) – to accelerate the channelling of funding towards projects.
The rebirth and long life of European solar manufacturing needs a strong research and innovation base. Europe has its part to play in the world’s solar manufacturing story.
Innovations like perovskite solar cells are just one example waiting on the horizon, reflecting the potential of R&I investments to revolutionise the solar industry.
However, the PV manufacturing storm is still brewing; sustained and increased investments in EU R&I investments will help build resilience against this storm. Left unchecked, this storm will only get worse.
Now is the time to double down on EU research and innovation, so that we can guarantee the EU’s solar renaissance.
Please note, this article will also appear in the sixteenth edition of our quarterly publication.",https://www.innovationnewsnetwork.com/wp-content/uploads/2023/10/1-Copyright-Meyer-Burger-Thalheim-factory.jpg,2023-10-17 09:28:51
https://www.innovationnewsnetwork.com/new-innovation-challenge-launched-tackle-bias-in-ai-systems/38298/,New innovation challenge launched to tackle bias in AI systems,"UK companies can now apply for up to £400,000 in government investment to fund innovative solutions tackling discrimination and bias in AI systems.
The competition will look to support up to three groundbreaking homegrown solutions, with successful bids securing a funding boost of up to £130,000 each to tackle bias in AI.
It comes ahead of the UK hosting the world’s first major AI Safety Summit to consider how to best manage the risks posed by AI while harnessing the opportunities in the best long-term interest of the British people.
Tackling bias in AI systems is a major priority
The first round of submissions to the Department for Science, Innovation, and Technology’s Fairness Innovation Challenge, delivered through the Centre for Data Ethics and Innovation, will nurture the development of new approaches to ensure fairness underpins the development of AI models.
The challenge will tackle the threats of discrimination and bias in AI by encouraging new approaches, which will see participants building a wider social context to develop their models from the off.
Fairness in AI systems is one of the government’s key principles for AI, as set out in the AI Regulation White Paper. AI is a powerful tool for good, presenting near-limitless opportunities to grow the global economy and deliver better public services.
Minister for AI, Viscount Camrose, said: “The opportunities presented by AI are enormous, but to fully realise its benefits we need to tackle bias in AI.
“By ensuring AI models do not reflect bias found in the world, we can not only make AI less potentially harmful but ensure the AI developments of tomorrow reflect the diversity of the communities they will help to serve.”
Harnessing a new, UK-led approach
While there are a number of technical bias audit tools on the market, many of these are developed in the US.
Although companies can use these tools to check for potential bias in AI systems, they often fail to fit alongside UK laws and regulations.
The challenge will promote a new UK-led approach which puts the social and cultural context at the heart of how AI systems are developed, alongside wider technical considerations.
This will focus on two areas. First, a new partnership with King’s College London will offer participants from across the UK’s AI sector the chance to work on potential bias in AI models. The model, developed with Health Data Research UK with the support of NHS AI Lab, is trained on the anonymised records of more than ten million patients to predict possible health outcomes.
Second is a call for ‘open use cases’. Applicants can propose new solutions which tackle discrimination in their own unique models and areas of focus, including tackling fraud, building new law enforcement AI tools, or helping employers build fairer systems which will help analyse and shortlist candidates during recruitment.
Companies currently face various challenges in tackling bias in AI, including insufficient access to data on demographics and ensuring potential solutions meet legal requirements.
The CDEI is working closely with the Information Commissioner’s Office (ICO) and the Equality and Human Rights Commission (EHRC) to deliver this Challenge. This partnership allows participants to tap into the expertise of regulators to ensure their solutions marry up with data protection and equality legislation.
Stephen Almond, Executive Director of Technology, Innovation and Enterprise at the ICO, explained: “The ICO is committed to realising the potential of AI for the whole of society, ensuring that organisations develop AI systems without unwanted bias.”
Baroness Kishwer Falkner, Chairwoman of the Equality and Human Rights Commission, added: “Without careful design and proper regulation, bias in AI systems has the potential to disadvantage protected groups, such as people from ethnic minority backgrounds and disabled people.
“Tech developers and suppliers have a responsibility to ensure that the AI systems do not discriminate.”",https://www.innovationnewsnetwork.com/wp-content/uploads/2023/10/shutterstockSansoen-Saengsakaorat_2345949869.jpg,2023-10-17 08:27:32
https://www.innovationnewsnetwork.com/new-battery-recycling-method-efficiently-recovers-aluminium-and-lithium/38292/,New battery recycling method efficiently recovers aluminium and lithium,"Researchers from Chalmers University of Technology have developed a new battery recycling method that allows the recovery of 100% of the aluminium and 98% of the lithium in electric car batteries.
The new battery recycling method also minimises the loss of valuable materials such as nickel, cobalt, and manganese.
The researchers use oxalic acid to reduce costs and harmful chemicals in the process.
The paper, ‘Complete and selective recovery of lithium from EV lithium-ion batteries: Modelling and optimisation using oxalic acid as a leaching agent,’ is published in the journal Separation and Purification Technology.
How does the new battery recycling method work?
The team fine-tuned the temperature, concentration, and time to use the oxalic acid to facilitate EV battery recycling.
Martina Petranikova, Associate Professor at the Department of Chemistry and Chemical Engineering at Chalmers, said: “We need alternatives to inorganic chemicals. One of the biggest bottlenecks in today’s processes is removing residual materials like aluminium.
“This is an innovative method that can offer the recycling industry new alternatives and help solve problems that hinder development.”
The aqueous-based recycling method is called hydrometallurgy.
Traditional hydrometallurgy
In traditional hydrometallurgy, the metals in an EV battery cell are dissolved in an inorganic acid. The impurities, such as aluminium and copper, are then removed.
The valuable metals such as cobalt, manganese, lithium, and nickel are separately recovered.
Although the amount of residual copper and aluminium is small, several purification steps are required. Each step in this process can cause lithium to be lost.
The new method reduces the waste of valuable metals
The new battery recycling method reduces the waste of valuable metals needed to make new batteries by reversing the order of the traditional process. By doing this, lithium and aluminium are recovered first.
The latter part of the process leaves aluminium and lithium in the liquid, and the other metals in the solids. Aluminium and lithium then need to be separated.
“Since the metals have very different properties, we don’t think it’ll be hard to separate them. Our method is a promising new route for battery recycling – a route that definitely warrants further exploration,” said Léa Rouquette, PhD student at the Department of Chemistry and Chemical Engineering at Chalmers.
“As the method can be scaled up, we hope it can be used in industry in future years,” concluded Petranikova.",https://www.innovationnewsnetwork.com/wp-content/uploads/2023/10/shutterstockMaxx-Studio_191931434.jpg,2023-10-17 08:02:49
https://www.innovationnewsnetwork.com/software-supply-chain-security-how-spot-cyber-risks-hidden-plain-sight/38274/,Software supply chain security: How to spot cyber risks hidden in plain sight,"Matt Middleton-Leal, Managing Director EMEA at Qualys, discusses the importance of software supply chain security.
Every day, you will see headlines around IT security issues affecting companies and public sector bodies. These organisations will be affected by attacks that could involve everything from data theft or sensitive information being leaked through to full blown ransomware deployments and interruptions to service. One of the biggest routes for these attacks over the past few years has been the software supply chain – if an attacker can jeopardise one software component, then they can attack multiple companies through that hole.
Applications are now more complex too. They have more moving parts, from open source software projects and internally developed software code through to third party applications that are embedded into services. They can expand and scale up to meet demands, created on-demand using infrastructure as Code or in Kubernetes containers. And they can be created using public software hosted on services like GitHub or the Python Package Index.
As a result, many security teams are not able to track those software assets effectively. To solve this, we have to make it easier to manage those software components and prevent potential attacks from coming in.
Bills of materials and software management
In practice, security teams need insight into what IT assets the organisation has. Without this list, it is impossible for IT security leaders to call their organisations secure. This has to be expanded to software as well.
The first step for this is to create a full inventory of the software that you have in place and the components used to make it. For internal applications – otherwise termed first-party software – this level of insight is often lacking. Studies have shown that between 70 to 90% of first-party software includes open-source components; according to our analysis of more than 13 trillion anonymised data points in the 2023 TruRisk Research Report, 79% of servers installed use open-source components.
Application and security operations teams most commonly rely on manual checks or siloed scripts to evaluate the security of first-party software. This depends on how well those checks work and how often they are carried out, and delays teams from prioritising the right risks for remediation.
Setting up a full process for software supply chain management starts with knowing what applications components you have and what versions those components are. Traditional vulnerability assessment or software composition analysis tools do not detect the presence of embedded open-source packages across the production environment. So, expanding your approach to cover these first-party software applications should be a natural first step.
Alongside looking internally, you should also look at the software that you consume from others. This third-party software will itself be built of different components and services, and any one of those can have an issue. As you don’t ‘own’ the software, it may be difficult to peer inside and know if there are any out-of-date components that could affect your security.
To fix this problem, the US Government supported the use of software bill of materials, or SBOMs. SBOMs provide customers with a list of all the components used within a given application, so security teams can spot any faults that come up. However, uptake of SBOMs is still in its infancy.
Regulation may help on this in time. SBOMs were mandated by the US Government in an Executive Order in May 2021, while the European Union’s Cyber Resilience Act also includes resolutions to implement SBOMs for hardware and software manufacturers that provide products to European consumers. The UK Government is also developing its approach to cyber resilience, and SBOMs are expected to be part of that approach.
The challenge here is that SBOMs are still relatively new, and CISOs have other more pressing issues around security that take up their teams’ resources and commitment. Regulation may force this up the agenda in time, but software supply chain attacks are happening now. SBOMs can deliver more insight into what cyber risks exist and consequently where to concentrate. As part of an overall software supply chain strategy, SBOMs will be essential in future, but the data they provide will help you manage risk around misconfigurations or vulnerabilities now too.
Improving overall processes around security
Just like any security process, software supply chain security depends on the data coming in and how quickly that information can be turned into actions. The issue is that software today is so complex that you can easily miss potential problems, whether they are in your organisation’s own software or contained in another company’s products.
Getting more data on what is in place is necessary in order to begin improving security. However, this data is not useful without the right context. Without that insight, you will not be able to prioritise where changes are needed in your own applications, and you will not be able to put pressure on your suppliers around their updates. Equally, you will not be able to manage those potential risks effectively and mitigate problems before they come up.
To improve your approach to software supply chain management, you will have to look at your overall approach to risk and how you manage software within your organisation. Bringing first-party software and third-party application risk data together will help your team understand the potential threats that exist, where changes are needed, and how you can support those problems getting fixed in an efficient and timely manner.
To make this work for you, look at how you can automate the data gathering so you have a continuous level of insight into what you have in place, and then prioritise your risks so you can always get ahead of any potential problems before they become serious or lead to attempted attacks.",https://www.innovationnewsnetwork.com/wp-content/uploads/2023/10/©-shutterstock3rdtimeluckystudio_2268705275.jpg,2023-10-17 07:39:18
https://venturebeat.com/ai/ai-platform-alliance-will-drive-ai-to-be-more-open-efficient-and-sustainable/,"AI Platform Alliance will drive AI to be more open, efficient and sustainable","VentureBeat presents: AI Unleashed - An exclusive executive event for enterprise data leaders. Network and learn with industry peers. Learn More
A group of prominent companies in the AI industry announced the establishment of the AI Platform Alliance, a consortium aimed at making sure that AI platforms will be more open, efficient, and sustainable.
The consortium seeks to address the growing demand for scalable AI solutions and overcome the challenges posed by the increasing compute power required for AI training and inferencing. The founding members of the alliance include Ampere, Cerebras Systems, Furiosa, Graphcore, Kalray, Kinara, Luminous, Neuchips, Rebellions and Sapeon, with more companies expected to join in the future.
The formation of the AI Platform Alliance comes at a critical juncture, not only for the technology industry but also for the world as a whole. The rapid expansion of AI has led to an unprecedented need for compute power to train and run AI workloads. The aim of the group is to “promote better collaboration and openness.”
While AI training demands substantial compute resources upfront, the total compute power required for AI inferencing can be up to ten times higher, posing an even greater challenge as AI usage scales up. One of the primary objectives of the AI Platform Alliance is to enhance the power and cost efficiency of AI hardware, surpassing the performance delivered by traditional graphics processing units (GPUs).
Event AI Unleashed An exclusive invite-only evening of insights and networking, designed for senior enterprise executives overseeing data stacks and strategies. Learn More
Recognizing the complexity involved in implementing AI solutions, the AI Platform Alliance will collaborate to validate joint AI solutions that offer superior alternatives to the prevailing GPU-based status quo. Notably, Nvidia, the biggest designer of AI chips and GPUs, isn’t a member of the alliance.
By fostering community-driven development, the consortium aims to expedite AI innovation by creating more transparent and accessible AI platforms. This collaborative approach seeks to enhance the efficiency of AI in solving real-world problems and establish sustainable, environmentally friendly, and socially responsible infrastructure at scale.
The AI Platform Alliance invites AI companies that are developing hardware solutions and are dedicated to challenging the status quo to join the consortium. Interested companies can apply for membership through the alliance’s website.",https://venturebeat.com/wp-content/uploads/2023/10/ai-platform-alliance.jpg?w=1200&strip=all,2023-10-17 12:00:00
https://venturebeat.com/ai/this-week-in-data-what-the-heck-is-data-observability/,This week in data: What the heck is data observability?,"VentureBeat presents: AI Unleashed - An exclusive executive event for enterprise data leaders. Network and learn with industry peers. Learn More
What is data observability (really)? And how are you supposed to plan your generative AI budget? This week, we learned that just a small number of CIOs spend a significant amount on gen AI and that Morgan Stanley predicts 15 to 20% enterprise adoption within 3 years.
What does this mean for your 2024 gen AI budget? Many of you have already chimed in with comments and voted in the generative AI LinkedIN poll. If you’re going to TED AI this week, Bruno is happy to debate this live there!
This week’s carcast tackles:
1) Generative AI in the enterprise: Identifying use cases for enterprise AI and why trust and data quality are your competitive moat are debated by Michael Krigsman of CXO Talk.
Event AI Unleashed An exclusive invite-only evening of insights and networking, designed for senior enterprise executives overseeing data stacks and strategies. Learn More
2) The State of AI Report 2023: Air Street Capital published its most recent research on AI investment. Among the insights, gen AI apps have had a breakout year across image, video, coding, voice or copilots for everyone, driving $18 billion of VC and corporate investments. Also, 70% of the most-cited AI papers in the last 3 years have authors from U.S.-based institutions and organizations.
3) What the heck is data observability? Gen AI needs sound data infrastructure to work. Our friend Sanjeev Mohan explains that the industry needs DataBizOps, a way to “optimize” cloud in the context of value creation. I’m a big believer in that concept. In fact, just a year ago I wrote about data mesh and why you should care.
This week’s CarCast also includes the best interview question by Peter Thiel and a quick take on Silicon Valley legend and former Stripe COO Claire Hughes Johnson’s book Scaling People.
Bruno Aziza is a technology entrepreneur and partner at CapitalG, Alphabet’s independent growth fund.",https://venturebeat.com/wp-content/uploads/2023/07/annevb_a_graph_with_colorful_lines_behind_it._Colorful_futuris_2f638b4b-7c38-4b18-ab88-137857cb6578.png?w=1200&strip=all,2023-10-16 23:28:49
https://venturebeat.com/ai/actors-worst-fears-come-true-new-4d-gaussian-splatting-method-captures-human-motion/,Actors' worst fears come true? 4D Gaussian splatting is here,"VentureBeat presents: AI Unleashed - An exclusive executive event for enterprise data leaders. Network and learn with industry peers. Learn More
As the Hollywood actors’ strike marches forward towards its 100th day with no resolution in sight, a technological leap has just rendered one of the actors’ biggest complaints even more possible: 3D scanning of human bodies in motion, potentially allowing for actors’ performances and mannerisms to be captured and stored as a 3D model that could be re-used by studios in perpetuity.
Although 3D scanning technology has been around in Hollywood for decades, it has typically involved a complex and time-consuming setup — multiple cameras arranged 360-degrees around an actor’s body, or, in the case of capturing motion, using ping-pong ball like “markers” placed directly on the actor and a tight-fitted bodysuit. Even recent advances using AI, such as the UK startup Move AI, generally rely on multiple cameras (though Move has a new single camera app now in limited, invitation-only release).
But now, a new method has been achieved: Gaussian splatting, a series of equations which has in recent years been used to capture static 3D imagery from a single 2D camera that is moved in a sequence around an object, has now been modified by researchers at Huawei and the Huazhong University of Science and Technology in China to capture dynamic motion in 3D as well, including human body motions.
Their method is called “4D Gaussian splatting,” because time, being the fourth dimension, is the new feature, allowing for the image to change over time.
Event AI Unleashed An exclusive invite-only evening of insights and networking, designed for senior enterprise executives overseeing data stacks and strategies. Learn More
Why motion is so tricky for Gaussian splatting
3D Gaussian splatting was devised for scanning objects with lasers in 2001 by researchers at MIT, ETH Zurich, and Mitsubishi.
It uses collections of particles to represent a 3D scene, each with its own position, rotation, and other attributes. Each point is also assigned an opacity and a color, which can change depending on the view direction. In recent years, Gaussian splatting has come a long way and can now be rendered in modern web browsers and made from a collection of 2D images on a user’s smartphone.
However, as the researchers write in a new paper published October 12 simultaneously on Github and open-access site arXiv.org, “3D-GS [Gaussian splatting] still focuses on the static scenes. Extending it to dynamic scenes as a 4D representation is a reasonable, important but difficult topic. The key challenge lies in modeling complicated point motions from sparse input.”
The main challenge is that when multiple Gaussian splatters are joined together across different timestamps to create a moving image, each point “deforms” from image to image, creating inaccurate representations of the shapes and volumes of the objects (and subjects) in the images.
However, the researchers were able to overcome this by maintaining only “one set of canonical 3D Gaussians,” or images, and used predictive analytics to map where and how they would move from one timestamp to the next.
What this looks like in practice is a 3D image of a person cooking on a pan, including chopping and stirring ingredients, as well as a dog moving nearby. Another example shows human hands breaking a cookie in half and yet another opening a toy egg to reveal a nested toy chick inside. In all cases, the researchers were able to achieve a 3D rotational effect, allowing a viewer to move the “camera” around the objects in the scene in 3D and see them from multiple angles and vantage points.
Example of 4D Gaussian splatting. Credit: ‘4D Gaussian Splatting for Real-Time Dynamic Scene Rendering‘
According to the researchers, their 4D Gaussian splatting method “achieves real-time rendering on dynamic scenes, up to 70 FPS at a resolution of 800×800 for synthetic datasets and 36 FPS at a resolution of 1352×1014 in real datasets, while maintaining comparable or superior performance than previous state-of-the-art (SOTA) methods.
Next steps
While the initial results are impressive, the scenes of motion captured by the researchers in 3D takes 20 minutes, and only last a few seconds each, far from the amount of time needed to cover an entire feature film, for example.
But, for studios looking to capture an actor’s few motions and re-use them, it’s a great start. And for video game designers, XR/VR designers, it’s hard to imagine that this technique will not be useful.
And, as with many promising technological advances, the quality and quantity of what can be captured — over what time frame — is only likely to increase.
As the researchers write at the end of their paper, “this work is still in progress and we will explore higher rendering quality on complex real scenes in the subsequent development.”",https://venturebeat.com/wp-content/uploads/2023/10/cfr0z3n_3D_wireframe_of_a_man_leaping_to_catch_a_ball_07594a44-b0ae-4181-a9c2-439c3f279e9f.png?w=1200&strip=all,2023-10-16 20:46:23
