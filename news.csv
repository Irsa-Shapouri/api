Link,post_title,post_content,featured_image,Date-Publish,post_category,post_tag
https://www.zdnet.com/article/saving-hours-of-work-with-ai-how-chatgpt-became-my-virtual-assistant-for-a-data-project/,Saving hours of work with AI: How ChatGPT became my virtual assistant for a data project,"There has been a lot of hype and excitement surrounding generative artificial intelligence (AI) lately. Tools like ChatGPT have gained a lot of attention and are often seen as these revolutionary AI systems. While it's true that they are powerful tools, it's important to remember that they are just that – tools. They can be used to assist with various projects, much like other productivity software.

In this article, I want to share a project where ChatGPT proved to be incredibly helpful and saved me a significant amount of time. Although this specific project may not be relevant to everyone, I hope that my approach and thought process behind using ChatGPT will inspire you to consider it as a valuable tool for your own projects.

The project I worked on involved creating what I like to call a ""stunt article."" These articles are meant to be fun and captivating for readers. The specific article I focused on was a breakdown of how much computer gear I could purchase from Temu for under $100. I managed to come in at a total of $99.77.

To put this article together, I needed to browse the Temu website and find various items to feature. For example, I discovered an iPad keyboard and mouse combo that cost roughly $6. However, to stay within my $100 budget, I needed to organize all the Temu links in a spreadsheet, find the price for each item, and rearrange things until I reached my desired total budget.

The challenge I faced was converting the Temu links into a usable format. This is where ChatGPT came in handy.

Phase 1: Gathering the links
The first step was to gather all the links from the Temu website. For each product, I copied the link and pasted it into a Notion page. Notion provides an option to create bookmark blocks when pasting a URL, which not only includes the link but also crucial product information such as the name. I then selected all the blocks and copied them into a text editor, resulting in a messy but useful page.

Phase 2: Identifying the data
Each data block contains three key elements: the product name, the base URL, and unnecessary tracking data. I needed to extract the relevant information and discard the rest. To teach ChatGPT how to recognize this data, I described the elements and their formatting.

Phase 3: Teaching ChatGPT to recognize the data
I fed ChatGPT a prompt to accept the given data and await further instructions. Next, I copied the information from the text editor and pasted it into ChatGPT. At this point, ChatGPT knew to wait for more details.

The crucial step was instructing ChatGPT to extract the titles and links while disregarding the rest. I provided a prompt that explained this process, allowing me to name the data for future reference and test ChatGPT's understanding of the task. ChatGPT successfully completed the assignment but stopped midway due to buffer limitations. I instructed it to continue, and it provided the remaining data within a minute. This process would have been much more time-consuming if done manually.

Phase 4: Cleaning up Temu's overly complex titles
Temu's product titles were unnecessarily long and complex for my project. I wanted simpler and more concise titles. I assigned this task to ChatGPT as well, reminding it of the previous step where it parsed and identified the data. I find that reminding ChatGPT about previous steps helps ensure better results.

By leveraging ChatGPT's capabilities, I was able to streamline the process and save hours of work. It demonstrated its efficiency and effectiveness in handling complex tasks. While it may not be suitable for every project, ChatGPT can be a valuable asset when used correctly. Its ability to understand instructions and generate accurate outputs is truly impressive.

So, the next time you find yourself faced with a similar project or need assistance with data processing, consider giving ChatGPT a try. You might be surprised by how much time and effort it can save you.",https://www.zdnet.com/a/img/resize/70d8814af33b190ff84b8faa5f9bafe13d3586e2/2024/03/25/7d1cb1ff-3bb7-4972-a6cd-33d04da76bc1/cover.jpg?auto=webp&fit=crop&height=675&width=1200,2024-03-25 00:00:00,Innovation,Innovation
https://techcrunch.com/2024/03/25/boeing-ceo-to-leave-company-by-year-end-after-a-wave-of-safety-incidents/,Boeing CEO to leave company by year-end after a wave of safety incidents,"Boeing CEO Dave Calhoun is set to leave the company by the end of 2024 following a series of safety incidents that have plagued the aircraft manufacturer. One of these incidents involved a cabin panel blowout on one of Boeing's planes, which raised concerns about the company's commitment to safety. The departure of Calhoun raises questions about the future of Boeing's innovation acceleration program, Aerospace Xelerated, which aims to collaborate with startups in the aerospace industry. The company has not yet released a statement regarding the impact of Calhoun's departure on this program.

In a company statement, Calhoun expressed his intention to focus on stabilizing and positioning the company for the future in the coming months. This comes after an incident in January where an Alaska Airlines 737 Max 9 jet was forced into an emergency landing, leading to the grounding of 171 Max 9 jets for several weeks. This incident has been described as Boeing's largest safety crisis since the crashes of two Max 8 jets in 2018 and 2019, resulting in the tragic deaths of 346 individuals.

Alongside Calhoun, Stan Deal, who leads Boeing's commercial airplanes business (BCA), will also be leaving the company. Stephanie Pope has been appointed to take over BCA. Previously serving as the chief operating officer of Boeing since January of this year, Pope brings extensive experience to her new role. She was also the president and CEO of Boeing Global Services, responsible for overseeing the company's aerospace services for commercial, government, and aviation industry customers worldwide.

As this story continues to develop, more information will be provided to shed light on the situation and its implications.","https://techcrunch.com/wp-content/uploads/2024/01/GettyImages-1910140688.jpg?resize=1200,800",2024-03-25 12:48:28,Innovation,Innovation
https://www.forbes.com/sites/lesliekatz/2024/03/25/heres-proof-that-spiders-pretend-to-be-ants/,Here’s Fossilized Proof That Spiders Pretend To Be Ants,"In the world of nature, survival is a game of avoiding predators, and some species have developed ingenious ways to stay alive. Take spiders, for example, who have mastered the art of disguising themselves as ants.

You might wonder, why ants? Well, ants are known for their aggressive defense mechanisms, making them less appealing to other creatures looking for a quick meal. They have strong bites, stinging venom, and the ability to call in reinforcements from their nestmates. On the other hand, spiders lack chemical defenses and are solitary creatures, making them vulnerable to larger spiders, wasps, and birds. By mimicking ants, spiders are more likely to go unnoticed and unbothered by potential predators.

Recently, a new species of ant-mimicking spider was discovered entombed in fossilized resin. The study, conducted by paleobiologist George Poinar Jr., a professor emeritus in the College of Integrative Biology at Oregon State University, sheds light on the fascinating world of spiders that impersonate ants. While ant-mimicking spiders can be found all over the world, they have managed to escape the attention of both fossil researchers and predators. This study, published in the journal Historical Biology, provides a rare glimpse into this remarkable adaptive behavior.

The spider in question was found in a copal block from Medellin, Colombia. Copal, a less mature form of amber, can date back up to 3 million years. The small size of the copal block presented a challenge for age-testing the material without damaging the spider inside. Despite not knowing the exact timeframe of when the spider attempted to pass as an ant, the fossilized sample offers valuable insights into this unique behavior.

Mimicry is a common strategy used by various creatures in nature to avoid predators. Some change colors to blend into their surroundings, while others take on the appearance of different species altogether. For spiders, which have eight legs and no antennae, making themselves look like ants with six legs and two long antennae is quite a feat.

To achieve this disguise, ant-mimicking spiders reposition their front legs to resemble antennae. However, this is not the only transformation they undergo to outwit their predators. The abdomen and cephalothorax of spiders are closely attached, whereas ants have a narrow segment called the petiole separating these body parts. Numerous other structures also need to be modified for spiders to closely resemble ants.

Scientists believe this morphing process begins with spider mutation, adaptation, and natural selection. However, Poinar suggests that there could be more to it. He believes that spiders use reasoning and intelligence, modeling their body changes after specific ants in their environment. This challenges the notion that all insect behavior is solely driven by instincts.

While ant-mimicking spiders are undoubtedly skilled contortionists, their abilities come at a cost. Other studies have shown that the extensive transformations required for disguise can impair the spiders' own hunting capabilities. It's a trade-off they must make to survive in a world where predators are always on the lookout.

In conclusion, the discovery of the ant-mimicking spider trapped in fossilized resin offers a fascinating glimpse into the world of nature's masterful disguises. By imitating ants, spiders are able to avoid predators that would otherwise see them as easy prey. This intricate adaptive behavior showcases the remarkable ingenuity found in the animal kingdom. While these spiders may pay a price for their disguise, their ability to survive and thrive in hostile environments is a testament to the wonders of evolution.","https://imageio.forbes.com/specials-images/imageserve/6601d75147f6aaf277e73ba1/0x0.jpg?format=jpg&crop=527,297,x0,y132,safe&height=900&width=1600&fit=bounds",2024-03-25 15:28:10,Innovation,Innovation
https://www.forbes.com/sites/petersuciu/2024/03/25/social-media-could-counter-putin-claim-of-kyivs-involvement-in-terrorist-attack/,Social Media Could Counter Putin Claim Of Kyiv’s Involvement In Terrorist Attack,"Russian President Vladimir Putin has alleged a link between the recent terrorist attack in Moscow and Ukraine, despite the Islamic State group claiming responsibility for the attack. Putin's allegations seem to be a page out of his old playbook, reminiscent of when he blamed Chechens for apartment building bombings 25 years ago. The Kremlin, controlled by Putin, is using the attack to push a narrative that elements of the Ukrainian government supported the attackers. This strategy aims to mix truth and misinformation, making it difficult for people to distinguish between the two.

While the majority of Russians may not hear about Kyiv's denials, the flow of information from the rest of the world, especially through social media, may set the record straight. However, the Kremlin may ramp up its propaganda machine to counter this. Disinformation campaigns often use flooding, which involves flooding social media channels with a range of information to confuse and discourage people from sorting out the truth. While flooding has been effective in hindering social media as a venue for alternative information, it may not be as effective as the Great Firewall employed by other authoritarian states.

One mistake Putin made was not locking down the Russian Internet, unlike China and Iran. The Russian Internet is connected to the world, allowing Russians to access foreign social media platforms and engage via the Telegram messaging app. While Telegram allows some information to come in, it is also used by military bloggers and officials for propaganda, employing techniques similar to the liar's dividend. However, Putin's attempt to blame Kyiv could backfire, calling into question the rationale for the invasion two years ago and the conduct of the war.

The Russian government has used social media channels in the past to shape the narrative to its advantage. Telegram, specifically the 'War on Fakes' channel, spreads disinformation to counter what it calls ""Ukrainian disinformation."" This channel has amassed a significant number of subscribers and spreads Russian propaganda. However, there are other Telegram channels that share factual news on the war, providing an alternative perspective.

In conclusion, Putin's response to the terrorist attack in Moscow, alleging a link to Ukraine, follows a familiar pattern of using crises to push his narrative. While social media may help set the record straight, the Kremlin's propaganda machine may intensify its efforts. The Russian Internet, unlike China and Iran, remains connected to the world, allowing access to foreign platforms and the spread of information. However, this strategy could backfire, raising questions about the invasion and the conduct of the war. As the situation unfolds, it is crucial to remain vigilant in evaluating information and seeking diverse perspectives.",https://imageio.forbes.com/specials-images/imageserve/6601e0acedb5ad5a83d52887/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds,2024-03-25 16:43:51,Innovation,Innovation
https://techcrunch.com/2024/03/25/large-language-models-can-help-home-robots-recover-from-errors-without-human-help/,Large language models can help home robots recover from errors without human help,"Home robots have struggled to gain popularity and success beyond the Roomba due to various factors such as pricing, practicality, form factor, and mapping. Even when these issues are addressed, there is still the challenge of what happens when a robot makes a mistake. This problem exists not only on an industrial level but also for consumers who may not have the programming skills or resources to address these issues. However, new research from MIT suggests that large language models (LLMs) could be the solution.

A study set to be presented at the International Conference on Learning Representations (ICLR) in May aims to bring ""common sense"" into the process of correcting mistakes. The research highlights that robots are excellent mimics but lack the ability to adjust to unexpected situations without being programmed to do so. Traditionally, robots exhaust their pre-programmed options before requiring human intervention, which can be a significant issue in an unstructured environment like a home.

Imitation learning, which involves learning tasks through observation, is popular in the field of home robotics. However, it often fails to account for the countless small environmental variations that can disrupt a robot's regular operation. Therefore, the new research proposes breaking demonstrations into smaller subsets, rather than treating them as part of a continuous action. This is where LLMs come into play, eliminating the need for individual labeling and assignment of subactions by the programmer.

LLMs can provide instructions for each step of a task in natural language. These instructions align with a human's continuous demonstration in physical space, allowing the robot to automatically understand its progress in a task and recover on its own. The study demonstrates this concept by training a robot to scoop marbles and pour them into a bowl. While this may seem like a simple task for humans, it involves multiple small tasks for robots. LLMs can list and label these subtasks, and when the robot encounters disruptions like being bumped off course or dropping marbles, it can self-correct the specific subtasks instead of starting over.

This method eliminates the need for humans to program or provide additional demonstrations to help the robot recover from failures. By leveraging LLMs and breaking tasks into smaller subsets, robots can adapt and adjust to unexpected situations, improving their overall performance and reducing the need for human intervention.

In conclusion, the use of LLMs in home robotics research shows promise in addressing the challenges robots face when encountering mistakes or disruptions. By breaking tasks into smaller subsets and using natural language instructions, robots can self-correct and recover without requiring extensive programming or human intervention. This advancement could potentially revolutionize the home robotics industry and pave the way for more practical and capable robots in our everyday lives.",https://techcrunch.com/wp-content/uploads/2024/03/CommonSense-01-press_0.jpg?w=900,2024-03-25 20:01:06,Innovation,Innovation
https://techcrunch.com/2024/03/25/ticktock-5-days-left-to-nest-your-early-bird-savings-for-tc-early-stage/,Ticktock: 5 days left to nest your early-bird savings for TC Early Stage,"Startup visionaries, time is running out! You only have 5 days left to take advantage of the early-bird savings for TechCrunch Early Stage 2024. This is an opportunity you don't want to miss, so secure your ticket now and save big before it's too late! The savings will end on Friday, March 29 at 11:59pm PT.

Let's take a sneak peek at what awaits you at TechCrunch Early Stage. We have a lineup of exciting sessions that will provide you with valuable insights and knowledge to propel your startup to success.

One of the sessions, titled ""Selecting the Right Accelerator or Incubator,"" will be led by Emily Knight, the president of the Engine Accelerator. Emily will guide you through the world of incubators and accelerators and how they can provide vital support structures for early-stage startups. You will learn about tailored programs designed to assist founders transitioning from academia and national labs, ensuring a smooth navigation through post-formation challenges.

Another session, titled ""How to Find Product-Market Fit When You Need It Most,"" will be presented by Jess Lee, a partner at Sequoia. Jess is a seasoned professional with extensive experience in building and scaling popular products. She will share her insights on the quest for product-market fit and how to achieve it. Her expertise in investing in companies like yours that are on the hunt for the ideal fit will prove invaluable.

James Currier, the general partner at NFX, will lead a session titled ""How to Build an MVP and Navigate the Startup-Industrial Complex."" James will delve into the art of crafting the perfect minimum viable product (MVP). He will provide valuable insights into striking the right balance between meeting user needs and avoiding the trap of excessive features and polish in the startup-industrial complex.

These sessions are just a taste of what you can expect at TechCrunch Early Stage 2024. Don't miss out on these enlightening sessions and more! Secure your early-bird ticket today and position yourself for startup success.

If your company is interested in sponsoring or exhibiting at TechCrunch Early Stage 2024, we encourage you to reach out to our sponsorship sales team. Simply complete the form provided, and our team will be in touch with you.

Don't let this opportunity slip through your fingers. Join us at TechCrunch Early Stage 2024 and unlock the potential of your startup.",https://techcrunch.com/wp-content/uploads/2024/02/5DaysLeft_EarlyStage24_1200x628.png?w=1200,2024-03-25 13:00:22,Innovation,Innovation
https://techxplore.com/news/2024-03-household-robots-common.html,Engineering household robots to have a little common sense,"Robots are becoming increasingly capable of performing complex household tasks, from cleaning up spills to serving food. Many of these robots learn through imitation, copying the motions of a human who guides them. However, robots often struggle to handle unexpected situations or disruptions unless explicitly programmed to do so. To address this issue, engineers at MIT have developed a method that combines robot motion data with the ""common sense knowledge"" of large language models (LLMs). This approach allows robots to parse household tasks into subtasks and adjust to disruptions within a subtask, eliminating the need to start from scratch or program fixes for every failure.

The researchers demonstrate their method using the example of scooping marbles from one bowl and pouring them into another. Traditionally, engineers would physically guide a robot through the motions of scooping and pouring, providing multiple demonstrations for the robot to mimic. However, the team realized that these tasks consist of a sequence of subtasks. For example, the robot must first reach into the bowl before scooping, and it must scoop before moving to the empty bowl. If a robot makes a mistake during any of these subtasks, it typically has to start over unless engineers explicitly label each subtask and program new demonstrations for recovery. This process is time-consuming and tedious.

Instead, the researchers found that certain aspects of this work can be automated using LLMs. These deep learning models process vast amounts of text and can generate new sentences based on what they have learned. By prompting an LLM to produce a logical list of subtasks for a given task, the researchers can establish a connection between the natural language labels and the robot's physical position or state. This mapping process, known as ""grounding,"" enables the robot to know what stage it is in a task and allows it to replan and recover autonomously.

The team's approach offers a more efficient and flexible way for robots to handle unexpected situations and errors. Instead of relying solely on explicit programming, the robots can leverage the knowledge stored in LLMs to self-correct and improve overall task success. This method has the potential to make household robots more adaptable and capable of handling a wider range of tasks.

In conclusion, MIT engineers have developed a method that combines robot motion data with large language models to enhance the ability of robots to handle unexpected situations and errors. By connecting the natural language labels of subtasks with the robot's physical position or state, the researchers enable the robot to self-correct and continue its task without starting from scratch. This approach offers a more efficient and flexible way for robots to learn and adapt to various household tasks. With further advancements, this technology could revolutionize the capabilities of household robots and make them more useful and reliable in our daily lives.",https://scx2.b-cdn.net/gfx/news/2024/engineering-household.jpg,2024-03-25 09:48:20,Innovation,Innovation
https://techxplore.com/news/2024-03-large-language-simple-mechanism-knowledge.html,Large language models use a surprisingly simple mechanism to retrieve some stored knowledge,"Large language models (LLMs), like ChatGPT, are incredibly complex and widely used in various fields. Despite their widespread use, scientists still don't fully understand how these models work. To gain insights into their inner workings, researchers at MIT and other institutions conducted a study to investigate how these machine-learning models retrieve and decode stored knowledge.

Surprisingly, the researchers discovered that LLMs often use simple linear functions to recover and decode facts. Linear functions, which involve two variables and no exponents, capture the straightforward relationship between these variables. They found that the model employs the same decoding function for similar types of facts. By identifying linear functions for different facts, researchers can probe the model to understand its knowledge about new subjects and where that knowledge is stored within the model.

Using a novel technique they developed, the researchers estimated these simple functions. They observed that even when a model provides incorrect answers, it often retains the correct information. In the future, this approach could be used to identify and correct falsehoods within the model, reducing the occurrence of incorrect or nonsensical answers.

Evan Hernandez, an electrical engineering and computer science graduate student at MIT and co-lead author of the study, explains, ""Even though these models are really complicated and trained on lots of data, there are sometimes really simple mechanisms working inside them. This is one instance of that.""

The paper detailing these findings was authored by Evan Hernandez, Arnab Sharma (a computer science graduate student at Northeastern University), Jacob Andreas (associate professor in EECS at MIT), David Bau (assistant professor of computer science at Northeastern), and other researchers from MIT, Harvard University, and the Israeli Institute of Technology. The research will be presented at the International Conference on Learning Representations (ICLR 2024) in Vienna.

LLMs, also known as transformer models, are neural networks composed of interconnected nodes or neurons. These networks encode and process data, resembling the structure of the human brain. Much of the knowledge stored within a transformer model can be represented through relations that connect subjects and objects. For example, the relation ""Miles Davis plays the trumpet"" connects the subject (Miles Davis) to the object (trumpet).

As a transformer model acquires more knowledge, it stores additional facts about a particular subject across multiple layers. When a user poses a question about that subject, the model must decode the most relevant fact to provide an accurate response. For instance, if someone prompts the model with ""Miles Davis plays the..."", the model should respond with ""trumpet"" rather than ""Illinois"" (the state where Miles Davis was born).

The researchers conducted experiments to investigate LLMs and found that, despite their complexity, these models use simple linear functions to decode relational information. Each decoding function is specific to the type of fact being retrieved. For example, the model utilizes one decoding function to output the instrument a person plays and a different function to output the state where a person was born.

To estimate these simple functions, the researchers developed a method and computed functions for 47 different relations, such as ""capital city of a country"" and ""lead singer of a band."" Although there are countless possible relations, the researchers focused on this subset as they are representative of the types of facts that can be expressed using linear functions.

To evaluate the functions, the researchers tested them by altering the subject to see if they could recover the correct object information. The results showed that the linear functions were effective in decoding and retrieving the necessary facts.

This study sheds light on the inner workings of large language models and highlights the presence of simple mechanisms within complex models. By understanding these mechanisms, researchers can explore ways to improve model performance and accuracy, ultimately enhancing the reliability and usefulness of large language models.",https://scx2.b-cdn.net/gfx/news/hires/2024/large-language-models-2.jpg,2024-03-25 09:34:06,Innovation,Innovation
https://www.zdnet.com/home-and-office/networking/grab-a-free-nintendo-switch-and-200-target-gift-card-when-you-sign-up-for-verizon-home-internet/,Get a free Nintendo Switch and $200 Target gift card when you sign up for Verizon Home Internet now,"'ZDNET Recommends': What exactly does it mean?

When you come across the label 'ZDNET Recommends,' you might be wondering what it signifies. Allow us to shed some light on this for you.

At ZDNET, our recommendations are not made lightly. We take great care in evaluating and testing various products and services to provide you with accurate and reliable information. Our process involves extensive research, hours of testing, and thorough comparison shopping. We gather data from reputable sources, including vendor and retailer listings, as well as independent review sites. Additionally, we place high value on the opinions of real people who have already purchased and utilized the products and services we assess. By analyzing customer reviews, we gain valuable insights into what matters most to consumers like you.

Now, you may be wondering how we fund our work. When you click through from our site to a retailer and make a purchase, we may earn affiliate commissions. These commissions help support our team's efforts without affecting the content we cover or how we cover it. Rest assured, our recommendations remain unbiased and unaffected by any financial incentives. We hold ourselves to strict guidelines to ensure that our editorial content is never influenced by advertisers. Your trust is of utmost importance to us, and we strive to maintain the highest standards of integrity and transparency.

At ZDNET, our dedicated editorial team works tirelessly on your behalf. Our primary goal is to provide you with the most accurate information and the most knowledgeable advice possible. We want to empower you to make informed decisions when it comes to purchasing tech gear and a wide range of products and services. To achieve this, our editors meticulously review and fact-check every article before publication. We hold ourselves accountable for any errors or misleading information, and if such instances occur, we promptly correct or clarify the article. We value your feedback, so if you come across any inaccuracies in our content, please let us know through this form.

In summary, when you see 'ZDNET Recommends,' it signifies our commitment to delivering reliable, well-researched, and unbiased recommendations. We strive to be your trusted source of information, helping you make smarter buying decisions. With our extensive testing, careful analysis of data, and consideration of real user experiences, you can rely on our recommendations to guide you towards the best products and services available.",https://www.zdnet.com/a/img/resize/d14c505f8c3172cf99c3baabc760a34861982b25/2022/08/03/c69c9d98-18fd-4a49-89a8-db4716d578ac/nintendo-switch-oled-model.jpg?auto=webp&fit=crop&height=675&width=1200,2024-03-24 08:53:00,Innovation,Innovation
https://techcrunch.com/2024/03/25/fisker-nissan-deal-dead-funding-bankruptcy/,"Fisker loses potential Nissan deal, putting rescue funds at risk","The negotiations between Fisker and a large automaker, rumored to be Nissan, have come to an end, jeopardizing the company's near-term rescue funding efforts. Fisker made this announcement in a regulatory filing on Monday, stating that the automaker terminated the negotiations on March 22. The reason for this termination was not explained. However, Fisker was required to continue the negotiations as part of the closing conditions for a potential $150 million convertible note that was announced last week. In response to this development, Fisker plans to ask the unnamed investor to waive the closing condition. 

Following this news, Fisker's stock plummeted by 28% and trading was halted. This is just the latest setback for the struggling electric vehicle (EV) startup. Fisker has been facing challenges in selling its Ocean SUV, falling short of its own sales goals. The company has also faced difficulties in resolving quality issues with some of the cars that have been delivered. These problems have forced Fisker to shift away from its direct sales model. 

In an effort to cut costs, Fisker laid off 15% of its staff in February, which amounted to around 200 people. Additionally, the company recently reported having only $121 million in the bank and warned investors that it would not survive without a fresh injection of cash within a year. Fisker has been in talks with other automakers, including Mazda, but it seems that only Nissan was still considering a potential partnership. 

Despite the termination of negotiations with Nissan, Fisker remains optimistic and is exploring other options. The company is evaluating various ""strategic alternatives,"" which include potential tie-ups with other companies, in or out of court restructurings, capital market transactions subject to market conditions, repurchases, redemptions, exchanges, or refinancings of existing debt, issuance of equity securities, sale of assets and businesses, and other strategic measures. 

This latest development is undoubtedly a blow to Fisker, but the company is determined to find a way forward. It remains to be seen what the future holds for this EV startup, but one thing is certain - the road ahead will not be easy. Fisker will need to navigate these challenges and make the right decisions to secure its survival and success in the competitive electric vehicle market.","https://techcrunch.com/wp-content/uploads/2024/03/GettyImages-1236611991.jpg?resize=1200,759",2024-03-25 13:52:11,Innovation,Innovation
https://techcrunch.com/2024/03/25/elon-musk-x-ccdh-california-lawsuit-dismissed/,A judge just killed Elon Musk's lawsuit against an anti-hate research org,"A federal judge has dismissed a lawsuit brought by Elon Musk and his company, X, against the Center for Countering Digital Hate (CCDH). The lawsuit was filed last year, with X accusing CCDH of spreading misleading claims through unflattering reports about hate and extremism on the platform. X claimed to have lost ""tens of millions of dollars"" as a result of CCDH's research. Musk and X also accused CCDH of illegally scraping data and breaking platform rules by using a third-party social media monitoring tool called Brandwatch.

However, the United States District Judge of the Northern District of California, Charles R. Breyer, sided with CCDH and dismissed the lawsuit. The judge also denied Musk and X the opportunity to relitigate the case. In his ruling, Judge Breyer stated that the purpose of the lawsuit was to punish CCDH for criticizing X and to dissuade others from engaging in such criticism.

The CCDH is a nonprofit organization that was formed in 2018. It conducts research on hate speech, extremism, and misinformation on major social networks. Its research exposes disturbing content on platforms like TikTok, YouTube, and Instagram, including reports on eating disorder content, climate denial, and violent misogynistic threats. The organization aims to hold social media companies accountable for their decisions that impact democracy, human rights, and civil liberties.

CCDH's victory in California is seen as a significant win for researchers who monitor online extremism. However, Elon Musk is pursuing a similar lawsuit against the left-leaning media watchdog Media Matters for America. Unlike the CCDH lawsuit, Musk's lawsuit against Media Matters is taking place in Texas, which does not have the same protections against frivolous lawsuits that stifle free speech.

The ruling in favor of CCDH is a blow to Musk's attempts to silence critics and demonstrates that even the wealthiest individuals cannot bend the rule of law to their will. CCDH's legal team, which includes Roberta Kaplan, who recently won a defamation suit against former President Donald Trump, celebrated the decision as a reaffirmation of the right to research, speak out, and hold social media companies accountable.

While this victory is significant, the battle against online extremism and misinformation continues. It is crucial to support organizations like CCDH that work tirelessly to expose and combat hate speech and extremism on social media platforms. By holding these platforms accountable, we can protect our democracy, human rights, and civil liberties.","https://techcrunch.com/wp-content/uploads/2023/08/twitter-x-logo-musk-pattern.jpg?resize=1200,675",2024-03-25 20:33:17,Innovation,Innovation
https://www.zdnet.com/article/upgrade-to-windows-11-pro-for-just-25-right-now/,Upgrade to Windows 11 Pro for just $25 right now,"'ZDNET Recommends': What does it mean?

When you come across the tagline 'ZDNET Recommends' on our website, it signifies that our recommendations are the result of extensive testing, research, and comparison shopping. We dedicate many hours to gathering data from the best available sources, including vendor and retailer listings, as well as other relevant and independent review sites. Moreover, we carefully examine customer reviews to understand what matters to real people who already own and use the products and services we assess.

It's important to note that when you click through from our site to a retailer and make a purchase, we may earn affiliate commissions. This helps support our work, but it has no influence on what we cover, how we cover it, or the price you pay. We want to emphasize that neither ZDNET nor the author receive any compensation for these independent reviews. In fact, we adhere to strict guidelines that ensure our editorial content is never influenced by advertisers.

At ZDNET, our editorial team writes on your behalf, the reader. Our primary goal is to provide you with the most accurate information and the most knowledgeable advice possible. We aim to assist you in making smarter buying decisions, whether it's related to tech gear or a wide array of products and services. To ensure the highest quality of content, our editors thoroughly review and fact-check every article. If we make an error or publish misleading information, we are committed to correcting or clarifying the article. We value your feedback and encourage you to report any inaccuracies in our content via the provided form.

In conclusion, when you see the 'ZDNET Recommends' label, you can trust that our recommendations are the result of rigorous research and analysis. We strive to provide you with valuable insights and guidance in order to help you navigate the ever-changing world of technology and make informed purchasing decisions.",https://www.zdnet.com/a/img/resize/210bc66f7f72578d128c268bf78cbcf817209402/2023/10/03/e02665e0-f9de-434f-99f7-45a3cde856fa/windowspro-stack-social.jpg?auto=webp&fit=crop&height=675&width=1200,2024-03-25 10:30:00,Innovation,Innovation
https://techcrunch.com/2024/03/25/london-regtech-gss-raises-47m-to-help-banks-screen-for-global-sanctions/,London regtech GSS raises $47M to help banks screen for global sanctions,"Global Screening Services (GSS), a London-based regulatory compliance platform, has successfully raised $47 million in funding. This comes at a time when economic sanctions are on the rise, with the United States imposing trade restrictions and asset blocking against countries such as Russia, China, and Iran.

GSS was founded by Tom Scampion, who previously served as the head of financial crime for Deloitte's EMEA arm. In 2020, Scampion became a general partner at consulting firm AlixPartner, where GSS was initially incubated before becoming an independent entity in 2021.

Last year, GSS secured a similar amount of funding from prominent investors, including Japan's Mitsubishi UFJ Financial Group (MUFG), one of the world's largest banks. For its latest funding round, GSS has attracted the support of the Commonwealth Bank of Australia (CBA), as well as Cynosure Group and AlixPartner.

Financial institutions, particularly banks, often face challenges in enforcing sanctions due to their crucial role in global money flow. However, identifying the parties involved in financial transactions can be a complex task. In recent years, major banks like Standard Chartered and BNP Paribas have faced hefty fines for breaching sanctions and lacking adequate money-laundering controls.

Given the increasing importance of regulatory compliance in the financial sector, investors have shown continued interest in supporting businesses like GSS. Last year, New York-based Droit raised $23 million, while London's SteelEye secured $21 million in financing.

GSS offers a sanctions-screening platform that helps banks and other financial institutions comply with regulations. Users can input transaction data into GSS's cloud-based platform, which then checks for matches against a comprehensive set of sanctions lists from around the world. GSS also adds additional data points, such as dates of birth and International Maritime Organization (IMO) numbers for ships, as well as data from the financial transfer systems of sanctioned countries.

Furthermore, GSS provides ""enhanced"" lists for screening, which include companies that are partially owned by individuals, companies, or governments that have been sanctioned by authorities such as the Office of Foreign Assets Control (OFAC), the European Union (EU), or the United Kingdom (U.K.).

With the new funding, GSS is now transitioning from the development phase to becoming fully operational. The company is preparing to launch its services for its first customers. This significant milestone marks an important step forward for GSS as it continues to play a vital role in helping financial institutions meet their global sanctions obligations.","https://techcrunch.com/wp-content/uploads/2024/03/GettyImages-1770041999-e1711386339681.jpg?resize=1200,677",2024-03-25 18:36:37,Innovation,Innovation
https://techcrunch.com/2024/03/25/spotify-courses-learning/,Spotify tests video courses to teach everything from music production to Excel,"Spotify, known for its music streaming and podcast services, is now venturing into the world of e-learning. The company is testing an online education offering in the U.K., partnering with organizations like the BBC and Skillshare to provide freemium video courses. While at least two lessons will be free, the full courses will cost between £20 and £80 on average. The pricing structure is the same for both basic and premium users, as Spotify is currently testing demand before considering wider rollout.

The courses will be accessible through Spotify's home and browse tabs, as well as the web and mobile app. The content covers a wide range of subjects, from music production to Excel skills, and even includes lessons on creating online learning content. Unlike many online learning platforms that offer interactive content, Spotify's courses revolve around one-directional, on-demand video.

Spotify has partnered with Skillshare, PLAYvirtuoso, BBC Maestro, and Thinkific to provide courses in various domains. The company plans to curate the courses based on user interests and preferences, leveraging its data on what people are already listening to and searching for on the platform. While third-party publishers own the videos, they will be hosted and purchased on Spotify. Revenue from course sales will be shared among the creators, publishers, and Spotify, with content partners handling payments to creators.

This move by Spotify aligns with its strategy to diversify its business and boost profitability. By expanding into education, Spotify aims to leverage its podcasting business and the data it collects on user preferences. The company has observed a strong correlation between popular podcasts and education content, with around half of Spotify Premium subscribers listening to education or self-help podcasts. Spotify plans to use its recommendation algorithms to cross-promote podcasts and courses, offering users a holistic learning experience.

The decision to launch in the U.K. is strategic, as it is one of Spotify's largest and most engaged markets. While the company has faced financial challenges in recent years, including layoffs and net losses, its foray into education presents an opportunity for consistent profitability and stronger margins. By capitalizing on the growing market for online learning and professional development, Spotify aims to tap into the demand for educational content among its user base.

In conclusion, Spotify's entry into the e-learning space marks a new chapter for the company. With its vast user base and data-driven approach, Spotify has the potential to disrupt the online education market. By curating courses based on user preferences and cross-promoting them with podcasts, Spotify aims to create a seamless learning experience for its users. As the company continues to diversify its offerings, it will be interesting to see how it navigates the competitive landscape of online education and establishes itself as a key player in the industry.","https://techcrunch.com/wp-content/uploads/2024/03/Courses-on-Spotify-PR-Image-6-2.png?resize=1200,683",2024-03-25 08:59:18,Innovation,Innovation
