Link,Title,Text,Image,Date Publish
https://www.forbes.com/sites/forbestechcouncil/2023/10/06/implementing-it-solutions-in-retail-how-to-avoid-frustration/,Implementing IT Solutions In Retail: How To Avoid Frustration,"Co-founder at LEAFIO AI Retail Solutions, a supply chain optimization and automation expert for retail, distribution, and CPG manufacturing.
getty
In today’s fast-paced retail landscape, adopting innovative software solutions has become a critical factor in staying competitive and meeting evolving customer expectations. However, this is often a daunting endeavor. The task can become much more difficult if there are unrealistic expectations or unpreparedness for possible challenges. Let’s shed some light on the problem and its solution.
Don’t Get Trapped In False Expectations
Unfortunately, retailers sometimes face unmet expectations from the implementation of IT products. A vivid example is the trend of adopting artificial intelligence solutions in retail. Undoubtedly, this is a breakthrough and powerful technology. However, some believe that it will become a panacea because AI can make the most accurate forecasts, for example.
But you can have the most accurate predictions and fail to meet critical metrics because the rest of the supply chain processes are failing. Thus, you’ll be disappointed in the software, as it won’t give you the expected business results.
To avoid frustration and the needless waste of time and money on cutting-edge software implementation, a retailer needs to follow simple steps:
• Define The Needs And Goals Of Your Business: The first step in implementing software is to understand the unique needs and objectives of the company. It is vital to analyze pains, inefficiencies and opportunities for improvement.
• Set Desired Results And Project KPIs: You must define the expected results from the software implementation and set project success indicators. Regularly tracking and analyzing project metrics will allow retailers to evaluate the impact of the software and make data-driven decisions for further optimization.
• Predict The Impact On Employees And Processes: A retailer needs to consider the impact of software on employees and processes, with a focus on change management. Proactive communication, comprehensive training and problem-solving ensure smooth adaptation and engagement of everyone involved.
• Assess The Need For Scalability And Adaptability: The software to be implemented must meet the future needs of the business. To stay flexible, retailers evaluate long-term growth plans and integration with new technologies. In addition, it is essential to consider the product’s development plans and the frequency of updates.
Be Ready For Challenges
Innovations bring many benefits, but it is not without issues. Here are some of the common challenges retailers face during the software implementation process:
• Integration Difficulties: Legacy or custom systems may have difficulty combining with new software, so integration may take more time and money than expected. It’s essential to be prepared for this. Careful planning and implementation of integration strategies are necessary to ensure smooth data flow and optimal performance.
• Resistance From Employees: Successful implementation depends on employee readiness and acceptance. Resistance to change and lack of training can hinder the process. It is essential to provide comprehensive training, create a positive attitude and involve employees in the decision-making process to increase ownership and engagement. One top regional operator recently adopted our modern solution to optimize merchandising operations. The company recognized that the implementation process requires a great deal of team cohesiveness and involvement.
• Ensuring Data Security And Privacy Compliance: Compliance with industry standards and regulatory requirements is a must. Strong encryption, access controls and security assessments ensure protection against leaks and unauthorized access.
• Managing Costs And Meeting ROI Expectations: Implementing innovative software requires significant licensing, upgrade, consulting and maintenance costs. Retailers must manage costs and set realistic ROI expectations. Realizing that benefits may take time will adjust expectations accordingly.
How Do We Mitigate Challenges And Maximize Success?
The following strategies will help retailers navigate the complexities of the implementation process:
• Ensure Collaboration Between IT And Business Units: It is critical to establish close collaboration between IT and business units to ensure a common understanding of project goals and requirements. Involving stakeholders from different business units allows you to gain information, align expectations and identify potential obstacles early on.
• Choose Software Vendors Carefully: You’d better carefully evaluate potential partners’ experience, reputation and ability to meet specific business needs. By choosing reputable vendors with a proven history of successful implementations, you increase the likelihood of project success. For instance, one supermarket chain we worked with shared that they rejected solutions too complex to implement and use.
• Conduct Pilot Phases And Testing Before Full-Scale Implementation: Such an approach allows potential problems to be identified and addressed on a smaller scale, minimizing disruption to the entire enterprise. This allows for adjustments and fine-tuning before implementing the software on a larger scale.
• Dedicated And Involved Leadership Is Key: It is essential for managers not only to monitor project KPIs constantly but also to ensure continuous collection and provision of feedback from all sides. This way, you will know if the project is on track and will be able to discuss and approve necessary adjustments with the vendor and the team on time.
With a complete understanding of their expectations, careful planning, attentive collaboration and user decision-making, retailers can turn their software adoption endeavors into resounding successes that increase their competitiveness in the dynamic world of retail.
Forbes Technology Council is an invitation-only community for world-class CIOs, CTOs and technology executives. Do I qualify?",https://imageio.forbes.com/specials-images/imageserve/651edfb180be4ced8c04d59b/0x0.jpg?format=jpg&width=1200,2023-10-06 07:00:00
https://www.forbes.com/sites/forbestechcouncil/2023/10/06/the-importance-of-unlocking-ai-for-the-retailer-and-why-digitalization-is-the-first-step/,The Importance Of Unlocking AI For The Retailer,"CEO at JOOR.
getty
In the last 15 years, we’ve seen slow but significant advances in AI when it comes to retail. We can all remember when AI-powered “bots,” or virtual assistants, began showing up on most major retail websites to assist with consumer questions and complaints. Soon after, AI began to assist with proactive recommendations for the consumer.
Today, most of us are aware of the potential for AI to disrupt the retail industry, but much of this has focused on the customer-facing elements. What often gets missed in this conversation is the potential for the same technology to accelerate retailers’ digital transformation journeys.
Many brands first invested in their B2C e-commerce experience, but they’re now recognizing the importance of investing in an elegant B2B experience to facilitate and grow their wholesale business. Retailers can benefit from a digital transformation of their wholesale process in myriad ways. Let’s take a closer look at a few of the main perks that digital transformation can unlock.
• Increased Efficiency: Often, teams are located across several different cities or even countries. Digital tools allow you to work seamlessly from anywhere in the world, without having to catch up with your team hours or days later. That means reduced waste and spend on travel.
• Elimination Of Manual Errors: Just like you wouldn’t want to write by hand every email you send nowadays, no one wants to rely on pen and paper notes after a client meeting. Digital tools encompass all the important parts of a meeting in the showroom as they happen. Furthermore, the massive amounts of time and energy spent manually inputting information into a digitalized system can now be spent on more productive tasks.
• Reduction Of Operational Spend: A digital wholesale experience provides flexibility for brands and buyers to collaborate without the constraints of time and geography. Digital buying and selling also creates increased efficiency, allowing retailers to reduce time-to-site and helping brands and buyers decrease travel and time spent in appointments. It also reduces wasted resources like excess samples and inefficient travel.
• Real-time Data To Inform Decision-Making: Access to real-time sales data enables more informed business decision-making to drive growth.
In this nascent phase of retail AI, we can foresee the benefits of digitalization multiplying and having an even greater impact on both business success and, ultimately, the consumer experience. The most impactful applications of AI include predictive analytics, inventory optimization, proactive recommendations and product recommendations that will appeal to the customer.
Forecasting has historically been a tricky practice for retailers to navigate. AI can analyze sell-through data to predict precisely which quantities and styles a buyer needs for the upcoming season.
The pandemic proved to all of us that forecasting is necessary in order to stay ahead. Manually inputting data into enterprise resource planning (ERP) systems can take days or weeks, and by that time, the data itself isn’t current. AI can allow retailers to analyze all their data in real time and automatically keep ERP systems current.
Inventory optimization has also been an easy way for retailers to make mistakes as the economy fluctuates. Instead of wasting precious hours on manual entry and counting, AI can manage this task in a fraction of that time. This can not only save costs but reduce waste in an era when more and more retailers want to be eco-conscious. If the past few years have shown us anything, retailers will thrive only once they’ve mastered their supply and demand.
There may be additional brand partnership opportunities you don’t even know exist yet, but AI does, and it can recommend what would complement your current assortment for the season. Just look at several examples in recent months to see why these are so important, particularly for beauty retailers. Ulta Beauty sought out Google for virtual try-ons, and L’Oréal announced a partnership with Verily to more effectively research skin issues and reimagine new product development.
In the not-so-distant future, we can expect to see virtual try-ons, authentication of counterfeit accessories and more become commonplace. Advertisements could be completely personalized using AI. Maybe we’ll finally get access to that Clueless outfit creator that Cher Horowitz showed us so many years ago. For now, we have a ways to go.
But I do know one thing: Taking advantage of AI to optimize business processes not only benefits the retailer but also the end consumer, due to more tailored assortments on the selling floor and an overall superior customer experience. But to leverage AI and take advantage of these advancements, you need to have already digitalized your processes.
Forbes Technology Council is an invitation-only community for world-class CIOs, CTOs and technology executives. Do I qualify?",https://imageio.forbes.com/specials-images/imageserve/651ede92879f17197035ad11/0x0.jpg?format=jpg&width=1200,2023-10-06 06:45:00
https://www.forbes.com/sites/katherinehignett/2023/10/06/englands-kids-will-never-be-able-to-buy-cigarettes-under-new-policy/,England’s Kids Will Never Be Able To Buy Cigarettes Under New Policy,"A couple smoke cigarettes in a public house in Bath, Somerset, England. (Photo by Matt Cardy/Getty ... [+] Images) Getty Images
Children aged 14 or younger will never be able to legally buy tobacco products in England under a policy proposed this week by prime minister Rishi Sunak.
Sunak wants to ban the sale of cigarettes to anyone born before January 1 2009, mirroring a law announced in New Zealand last year.
If successful, the move could theoretically eliminate smoking in under-30s by 2040.
However, it would not actually prevent young people from smoking, with the burden of the law falling on sellers rather than smokers themselves. Smoking itself would not become a criminal act.
The law would not cover Scotland, Wales or Northern Ireland. But the government says it wants to work with the devolved nations to introduce similar public health measures.
The idea of the rule is to de-normalize smoking — rates of which have already fallen enormously in the country in recent decades.
Over time, it’s hoped this will reduce pressure on the country’s public health service, with fewer people getting sick from smoking-related diseases like lung cancer.
The government estimates that, under the law, up to 1.7 million fewer Brits would be smoking by 2075, saving billions for the country’s public health system by reducing cases of stroke, heart disease and lung disease by up to 115,000.
The economy, ministers say, would benefit from up to £85 billion over the same period, partly in increased productivity from a healthier, longer-living workforce.
The country will also launch a consultation on vaping, which is promoted by its public health services as a useful tool to help people quit smoking.
Previous reports suggested the government would ban disposible vapes altogether in an effort to reduce rates of youth vaping, in a similar move to France.
But for now, the government just says it will seek advice on whether limiting flavored vapes and the display of the devices at shop tills — as well as changing the packaging they are sold in — would “reduce the appeal and availability of vapes to children.”
National Health Service medical director Professor Sir Stephen Powis said in a statement: “Smoking is the single biggest cause of preventable death and costs the NHS billions of pounds each year. Almost every minute of every day someone is admitted to hospital because of smoking.
“This is a momentous public health intervention and we welcome the government’s bold and ambitious action which will lead to longer and healthier lives.”
He said smoking cessation services would also recieve some £140 million ($170 million) in extra funding.
But experts say previous gaps in funding have seen many local stop smoking services shrink in recent years.
Local councils, which provide many such schemes, have experienced major cuts in recent years, for example.
University of East Anglia addiction expert Prof Caitlin Notley told the BBC that people living in the poorest areas were most affected by smoking, and that innovatie solutions were needed to help reach them.
She said: “It is the poorest and most deprived people in our society who continue to smoke tobacco at the highest rates. Tobacco smoking is an inequalities issue.”",https://imageio.forbes.com/specials-images/imageserve/651fc89599bd80dcda0779d4/0x0.jpg?format=jpg&width=1200,2023-10-06 06:41:03
https://www.forbes.com/sites/forbestechcouncil/2023/10/06/modernizing-banking-compliance-with-ai-unlocking-the-potential/,Modernizing Banking Compliance With AI: Unlocking The Potential,"Asif Alam is Chief Executive Officer at Compliance.ai, a disruptive AI company combining natural language processing and expert insights.
getty
In an era defined by rapid technological advancement, the banking landscape stands at the brink of a transformative revolution. At the heart of the shift lies artificial intelligence. The latest strides in AI research have propelled us into a realm of unprecedented possibilities, with the opportunity to redefine large sectors of the financial sector. The convergence of AI and automation in financial services is rewriting the industry's playbook, and an increasing number of financial institutions are introducing new technological solutions.
Caution has always been a hallmark of the financial sector. Even now, despite AI's many advantages, including efficiency and cost reduction, better security and regulatory adherence and overall enhanced product offerings, the banking sector exercises caution in AI adoption. A survey from KPMG found that 3 in 4 financial services business leaders polled believe AI is more hype than reality.
How Is AI Used In Banking?
AI can inject a great deal of innovation into the financial sector, and modern banking has been reshaped by advancements in big data, cloud computing and natural language processing (NLP).
On the customer-facing front, there are chatbots utilizing neural language processing to provide a more sophisticated and round-the-clock customer service experience. NLP also enhances customer relationship management as AI can now address client queries promptly and offer customer-tailored solutions.
Security-wise, AI proves indispensable in the battle against fraud. AI-driven anti-money laundering (AML) solutions now offer a dynamic approach to fraud detection and prevention. By employing complex algorithms, AI AML solutions can swiftly identify data anomalies and suspicious activities in real time, allowing banks to stay ahead of evolving fraud tactics. Meanwhile, AI's predictive analysis capabilities enable banks to predict market trends and make informed decisions, enhancing operational efficiency.
Potential Opportunities Presented By AI And Automation
• Efficiency And Cost Savings: Automation eliminates manual tasks, such as data entry and document processing, significantly reducing the time needed for routine operations. This allows banking staff to focus on more complex and strategic tasks.
• Error Reduction: Automation minimizes human errors inherent in repetitive tasks. This is particularly crucial in financial operations where accuracy is paramount, such as in transaction processing and accounting.
• 24/7 Operations And Enhanced Customer Experience: Automated systems can work around the clock, providing continuous services to customers regardless of time zones or business hours.
• Risk Management: Automation can improve risk assessment and fraud detection by swiftly analyzing large data sets for irregularities and patterns that might go unnoticed by humans.
• Regulatory Compliance: Automation can help to ensure that operations adhere to regulatory standards by implementing consistent and accurate processes, reducing the risk of noncompliance. It also has the potential to extend to internal policies and procedures, as well as regulatory advice from third parties to highlight inconsistencies.
Keeping Experts In The Loop To Reap The Rewards
Compliance remains one of the biggest priorities for the banking and financial institutions. Following the 2023 bank collapse, when we witnessed the collapse of three banks: Silicon Valley Bank, Signature Bank and Silvergate, financial institutions can expect closer scrutiny from financial watchdogs. The U.S. Federal Reserve and Federal Deposit Insurance Corporation have announced stricter oversight over large banks, while the European Banking Authority has announced its plans for liquidity checks.
That's where modernizing banking compliance with AI can help. However, while AI can help with automation, it is far from omnipotent. To ensure AI decisions align with regulations, it is best to foster collaboration between AI systems and compliance experts so that AI decisions align with regulatory change nuances. If you wish to make the most out of AI solutions, human oversight is key.
• The Human-In-The-Loop Approach: Keeping compliance experts in the loop is a vital part of the development and deployment of artificial intelligence. Instead of relying solely on machine learning, compliance experts should continuously monitor and participate in the decision-making process to correct any mistakes as they occur.
• Clear Objectives And Performance Monitoring: Define the objectives and goals of the AI system. By implementing key performance indicators, you can better measure whether the system accomplishes its role, measure its performance and modify the outcomes if necessary.
• Regular Audits: Conduct regular audits of the AI system's operations, data sources and model performance to maintain accountability and identify potential issues as they emerge.
• Contingency Plans: Create emergency protocols for when the AI tools malfunction or have errors to prevent harm and minimize potential disruption to the business.
• Bias Detection And Mitigation: Even the best of bias-aware algorithms need oversight. Regularly assess AI's fairness to ensure there is no disparity in AI's decision-making across various demographics.
Integrating AI into regulatory compliance processes may offer increased efficiency and accuracy when done right. It should complement your expert team rather than replace it, so when designing a new solution, or picking an already-existing tool, ensure it ticks all the right boxes for your organization.
Since data is the cornerstone of any great AI system, your AI system should use only high-quality, up-to-date data from reliable sources. Meanwhile, when dealing with customer information, keep data privacy and security at the forefront—data privacy violations can be costly to your company if GDPR or HIPAA regulations are broken.
As AI continues to change banking, institutions that embrace these changes could be positioned to thrive in a rapidly evolving landscape. The collaboration between human expertise and AI's analytical capabilities can help provide a technologically advanced, secure and customer-focused banking experience.
By properly combining AI technologies with expert knowledge and a deep understanding of regulatory compliance requirements, modernizing banking compliance can become a strategic initiative that could enhance operational efficiency, reduce risks and strengthen your institution's overall regulatory position.
Forbes Technology Council is an invitation-only community for world-class CIOs, CTOs and technology executives. Do I qualify?",https://imageio.forbes.com/specials-images/imageserve/6290d2ae6085acdb167f39fc/0x0.jpg?format=jpg&width=1200,2023-10-06 06:30:00
https://www.forbes.com/sites/michaelbarnard/2023/10/06/easy--cheap-climate-wins-for-politicians/,Easy & Cheap Climate Wins For Politicians,"3D illustration of a conceptual maze. Shortcut between points A and B or finding the shortest path ... [+] concept. getty
Co-authored with Tony Bishop, Cofounder and Director of UK-based electric aviation firm FLIMAX
Political parties have a bunch of problems, and climate change is definitely one of them. Climate impacts are rising, not falling. Carbon emissions aren’t being cut back enough. It takes time and money to fix things that spew greenhouse gasses and fix homes and buildings that are in the way of climate impacts like flooding.
Many of the necessary changes take a long time to have effect. Others cost a lot of money. And a bunch of them impact voters and special interest groups in ways that become unpleasant for the political parties.
To that end, we have assembled a list of easy and cheap things politicians can do now to move the needle on climate action and to please voters. It’s a subset of the short list of climate actions that will work.
For national leaders, an easy one is to stop subsidies for oil and gas. The International Monetary Fund found that direct subsidies rose to US$1.3 trillion in 2022, up from an average of $0.6 trillion in preceding years. 2022 also saw record profits of $4 trillion in 2022, up from an average of $1.5 trillion globally.
It’s a pretty easy sell to voters that governments giving lots of money to very profitable corporations is a bad policy. And that $1.5 trillion can be used for a lot of better things. With peak fossil fuel demand looming this decade per the International Energy Agency, the industry is a special interest group that’s going to be waning, so it’s time to forge new alliances.
Hydrogen for energy and carbon capture funding are mostly fossil fuel industry subsidies in disguise, so make sure any money spent in that space does just enhance industry profits.
It’s easy to stop new oil and gas exploration. The world already has discovered and operational reserves of coal, oil and gas sufficient to put us well over 3° Celsius of warming. Some of the subsidies mentioned above are tax breaks for exploration. No exploration, no tax breaks and no subsidies.
Operating nuclear power plants are good sources of low-carbon, low-pollution electricity, and despite some perspectives are safe as well. Keeping them going despite political pressure to close them prematurely makes sense. Keeping a close eye on the risks of a Fukushima-scale event which will end up costing Japan’s economy in the range of $1 trillion is a good idea. We do need to cope with reducing reliability; they need cooling water, and as the French have discovered, climate change is causing critical droughts.
For most countries building new nuclear plants is not a solution to climate change or energy requirements. They are expensive, inflexible and have economic risks that renewables, storage and transmission just don’t have. Nuclear is a distraction, and an expensive one. It commits billions to something which won’t be operational until well after 2030 when electricity has to decarbonize before that. Small modular reactors, despite what you may have heard, are unlikely to be cheap and don’t exist right now.
It’s fairly easy to assemble support for a policy to maintain existing plants, consider refurbishment and intentionally sideline efforts to build new ones. Don’t waste money and human time on new nuclear.
Regulations often require local transmission, limit existing generation to inflexible roles (the legacy concept of baseload power) and try to pretend that generating all energy inside the country is key. The grid of the future crosses country borders much more than today and leans into big high-voltage direct current (HVDC) interconnections across continents.
The private money Xlinks project linking Morocco to the UK has just been declared a project of national significance by the government, supplying a reliable 8% of the UK’s electrical power. There are no political downsides to building transmission interconnects with well-behaved neighbors which have lots of other trade ties with your country or province.
One of the biggest slowdowns for getting low-carbon energy added to the grid is regulatory approval. Reform the rules around networks to increase interconnects and speed up connections for new renewables.
Eliminating sub-national barriers to electricity transmission is something most national governments can do. In the USA, HVDC lines from wind farms on the Great Plains to the major population centers on the east and west coasts were blocked because state regulations required transmission to be built by utilities which sold electricity inside the state. The amount of effort and time to get and HVDC line built from Canada’s hydro to New York’s demand had to overcome similar challenges.
Onshore wind and solar are the cheapest form of electricity we’ve ever invented. Rural areas have put up barriers to them, but mostly not because of voters. It’s the elite in their country estates who are annoyed that their rural agrarian fantasy landscapes are changing who are the problem. It’s fairly easy to sell the bottom 80% of rural dwellers on the advantages of local economic development, direct payments for local facilities, new jobs and ongoing revenue. Eliminate national policies inhibiting wind and solar and lean into policies which allow them.
For gas utilities, direct them to create a plan for the strategic and careful shut down of their gas distribution grids. They are entering into a utility death spiral where they will have fewer and fewer customers as heat pumps and induction stoves eat their market, yet they’ll have to maintain the entire network of understreet pipes. Utrecht in the Netherlands is a great example of how to do it, so talk with leaders there.
Businesses know two things very well. As much as they might rail against it, things are changing rapidly and they need more certainty than they are getting. The end of internal combustion engines, gas-fired boilers and similar things is coming. Many countries already have clear deadlines and while automotive and heating manufacturers are grumbling and pushing back, they are moving.
Setting transition targets and sticking to them is key. Not flipflopping is inexpensive, but the alternative is dear. An example of what not to do is Ontario in Canada. When a new administration came in, they killed the carbon pricing scheme the province was using. That didn’t kill carbon pricing, it just meant that all of the regulatory compliance work businesses had already done was thrown out the window and they had to comply with the federal approach. Even Ford is pushing back against the UK’s change in internal combustion sales bans.
There’s a lot of unnecessary paperwork in the way of onshore wind, solar and storage projects. Closed-loop, off-river pumped hydro has huge storage capacities with small, low-impact reservoirs. Anywhere you have hills over a couple of hundred meters high is a candidate for it, and the water just gets reused. Put regulatory resources applied to new nuclear onto those real, near term requirements.
Most countries have regulations for electricity that are very local. Getting markets to work effectively for trading electricity much more freely across much greater distances is something national governments can do. Assembling coalitions around freer and larger markets for electricity and other grid needs like storage is fairly easy.
National jurisdictions set housing and building standards for new development. It’s cheap and easy to update those to include better insulation and a requirement that they have heat pumps instead of gas connections and are ready for EV charging with connections at parking spots. Depending on where you are, ensuring that they are solar ready might be an idea too. Those national standards will flow down through existing channels to cities across the country. It’s cheap and easy to extend them for major renovations of existing buildings as well, so that heat pumps and EV charging spread quickly. Preventing local residential organizations from banning visible rooftop solar panels is also easy nationally.
The chemicals we use in heat pumps, refrigerators and air conditioners are amazing. But they are also climate change bombs, with impacts thousands of times worse than carbon dioxide. Countries have mostly signed onto the Kigali Amendment of 2016 to eliminate them, but countries can do more and cheaply. Global manufacturers need to know that governments are forcing the market in order to change their products and export them. In the same national building codes, put low global warming potential refrigerants as a requirement.
Carbon-dioxide based hot water heat pumps are amazing, but hard to buy in many countries. Propane-based minisplit heat pumps have a climate impact about 100,000 times smaller when they leak than current ones in most countries. In BC, a climate leader otherwise, the Vancouver Economic Commission identified this problem and is trying to get new heat pumps to market. But despite its relative affluence, it’s a tiny part of North America. Put fixed standards on refrigerants and let international manufacturers know what they are. Put the standards into the national building codes.
Electric cars are here and selling rapidly. And cities already have electricity running all over the streets to street lights, traffic lights and sensors. Cities like London have installed EV charging points in existing street light poles. Others have installed EV chargers in many parking spots. Everyone who lives in an older apartment or condo building has some problems with charging, especially if the building doesn’t have a garage of its own. Require an increasing percentage of all street parking to have basic electrical connections for EV charging. It’s simple and a good vote getter in towns and cities across the country.
Cities and regional jurisdictions love to build new infrastructure. New bridges, new highways and new streets are always good local vote getters. But they don’t work to reduce congestion, as every country in the world has established time and again globally. All they do is provide more room for cars, so people buy more cars. At a national level, cities and provinces typically come looking for taxpayer money for these new construction projects.
Don’t give cities and provinces money to build new infrastructure for cars. Make that a policy. All infrastructure money from the national level must be spent on things which get people out of cars, like subways, electric buses, bike lanes, 15 minute cities and the like. Spend the same money, but spend it wisely.
Drones are changing rural work rapidly, but run into problems from national agencies like the Federal Aviation Authority. Big drones are being used to rapidly replant areas burnt out by wildfires, and used for much more efficient and effective spraying of crops. Removing national barriers to big drones flying out of line of sight, supporting firms and organizations doing this work and removing regulatory thickets from them has big advantages.
Similarly, civil aviation regulators are wasting time and money on certification of electric vertical take off and landing passenger aircraft instead of real solutions to aviation’s climate issues. Direct them to stop wasting precious resources on evtol certification.
These actions are easy to do. They are not expensive to do. They are easy to sell to voters. They lean into the special interest groups of the future, not the interest groups of the past. And they are the right things to do. As a political party, make these part of your platform and action plan. As a politician, pick the ones that you are most capable of moving forward.",https://imageio.forbes.com/specials-images/imageserve/651ee90575a6663a07194b44/0x0.jpg?format=jpg&width=1200,2023-10-06 06:30:00
https://www.forbes.com/sites/forbestechcouncil/2023/10/06/the-limits-of-customer-loyalty-and-what-retailers-can-do-about-it/,The Limits Of Customer Loyalty-And What Retailers Can Do About It,"By Alexandre de Vigan, CEO, Nfinite.
getty
Customer loyalty is still alive and well, but it isn’t blind. Consumers have limits and will only stick around if their needs and rising expectations are met. In fact, 63% of consumers say they would leave a brand they were loyal to after a negative experience and 86% would leave after two to three negative experiences.
In an unsteady economy marked by inflation and high interest rates, consumers will also make changes for a better deal. As of March 2023, 56% of shoppers had switched at least some of their spending to lower-cost brands and retailers.
The Keys To Loyalty
So, what exactly, besides lower prices, are consumers looking for? After speaking to many retail executives, all of whom seemed concerned about the fragility of customer loyalty in today’s market, I knew this topic was important to dig into further.
I firmly believe every interaction with a brand or retailer should be coherent, consistent and immersive for the consumer. If a retailer can succeed at that, they can hold on to precious customer relationships.
• Coherent Interactions: Every touchpoint with the brand or retailer should convey a clear and unified message. Every interaction that aligns with the brand’s identity and values builds trust and familiarity.
• Consistent Experiences: Consistency goes beyond branding—it’s about having a smooth experience for customers, whether shopping in a physical store or online. They want the same level of service and convenience. This consistency enhances convenience and reliability, driving loyalty.
• Immersive Engagement: Immersive interactions go beyond transactions—they create memorable experiences that resonate with customers. Retailers can achieve this by personalizing the shopping journey, offering engaging content and utilizing technology like augmented reality or virtual reality to enhance the shopping process. Customers who feel engaged and emotionally connected to a brand’s storytelling are more likely to remain loyal.
The Path Ahead
The risks are clear and so is the value of customer loyalty. My advice to retail executives as they look for solutions is to “nail the basics,” which fits into two buckets: understanding your customers and ensuring their experiences with your brand match their needs.
Understanding Your Customers
Expectations aren’t static, so it’s imperative to do consumer research and ask your customers what they’re looking for. Don’t be afraid to reward customers who answer surveys or agree to interviews—their opinions are everything. Put yourselves in their shoes, understanding what challenges they’re facing, what their goals are and what’s kept them coming back thus far. Keeping tabs on changing wants and needs will enable you to be one step ahead of the competition.
One way to gauge customer needs is to deploy regular surveys to get a pulse of what they want. Here are some questions I’d suggest asking them:
• How satisfied are you with our products or services? What aspects do you like the most, and what could be improved?
• What challenges or pain points have you encountered while using our products or services?
• How do we compare to our competitors in terms of value and service?
A vivid picture can emerge through customer research, allowing you to understand their needs and gain insights into their aspirations and preferences.
To incentivize customer input, consider offering rewards that resonate with your audience. Popular options include discounts or coupons for future purchases, exclusive early access to new products or services, or even small but meaningful gifts like branded merchandise or trendy tech gadgets. Implementing a loyalty points system in which customers accumulate points for each survey or interview and then can later redeem them for rewards can instill a sense of achievement and value. Additionally, making charitable donations on their behalf is a gracious gesture that can foster goodwill and further engage your customers in meaningful ways.
Ensuring Customer Experiences With Your Brand Match Their Needs
Next up is auditing your customer experiences. This process often starts with customer journey mapping, which visually represents the touchpoints from initial awareness to post-purchase engagement. My team recently held an off-site meeting during which we discussed every step a prospect goes through to become a customer. This exercise was valuable in understanding our current process and opened up fruitful discussions about how we can improve the customer experience in the future.
Once you’ve listed these interactions, the next step is evaluation. This involves assessing whether you’re meeting the needs identified through your research. Gathering customer feedback through surveys, interviews and social media listening tools is essential. Additionally, data analytics can provide insights into customer behavior and engagement patterns. Through these evaluations, you can determine where adjustments are needed to better align touchpoints with customer expectations.
Your branding and messaging should maintain uniformity, with visual consistency verified by checking brand colors, fonts and imagery. Content evaluation should ascertain whether the information presented at each touchpoint is engaging, relevant and consistent with the brand’s narrative. A thorough user experience assessment, especially for digital interactions, can uncover navigation challenges or usability issues that require attention. Visual storytelling through images, videos and infographics should align seamlessly with the brand’s story and resonate with consumers.
The final phase involves making necessary adjustments and improvements. Prioritize areas for enhancement based on your evaluations, and adopt an iterative approach to refine interactions that fall short. A/B testing can be a valuable tool for digital touchpoints, allowing you to measure the impact of changes before fully committing. Continuous monitoring and analysis should become part of your process, ensuring your interactions align with customer needs and market trends. Ultimately, this holistic approach to auditing customer experiences will help you create a more engaging and satisfying journey for your customers, driving loyalty and success.
Fostering Customer Loyalty In An Ever-Evolving Market
Customer loyalty is both precious and fragile in today’s marketplace. Negative experiences can quickly erode it, and economic uncertainties drive consumers toward better deals. To drive loyalty, brands must prioritize coherent, consistent and immersive interactions that resonate with customers. By delivering on these fronts, brands can secure lasting customer loyalty and thrive in a dynamic market.
Forbes Technology Council is an invitation-only community for world-class CIOs, CTOs and technology executives. Do I qualify?",https://imageio.forbes.com/specials-images/imageserve/651edb4007a7047e4a20afb4/0x0.jpg?format=jpg&width=1200,2023-10-06 06:15:00
https://www.forbes.com/sites/forbestechcouncil/2023/10/06/brand-protection-is-the-new/,Brand Protection Is The New Rule,"Karan Rai is Chief Technology Officer at Ennoventure Inc.
getty
Most high-end brands have one common enemy—brand identity theft. They are a part of the $11.36 billion industry, and the market doesn’t seem to slow down.
In the world of AI, where creating (fake) products takes only a couple of hours, it is easy for brands to lose business. From product synthesizing to implementing vocal mannerisms, it is easy for fraudsters to steal a brand’s product and overall identity. Unfortunately, this is not a one-time default either—fraudsters can easily deploy recurrent neural networks to learn the product features, its advertising elements, brand colors and others to create a brand new product and fake that is eerily similar to the original one.
This fake product and overall brand identity can lead to a drop in customer loyalty, recall and, ultimately, revenue loss. Having a counterfeit in the market makes the brand less trustworthy and valuable and can be an imminent threat to the brand perception, which may take years to remedy.
While high-end brands have the monetary bandwidth to be identity gatekeepers and curtail losses, brand identity theft spells disaster for small- to medium-sized businesses looking to make a mark in the consumer-driven industry.
The calculated process of brand theft can be countered with a proactive approach to brand protection.
Ways To Ensure Proactive Brand Protection
AI-image Recognition: AI-driven image recognition is a great way to optimize surveillance of counterfeit products across the digital space. ML models can be trained to find product images similar to original products and detect discrepancies such as incorrect fonts, wrong visual placement and wrong listing, to name a few.
Cryptographic Signature: Brands can strengthen their protection with cryptographic signatures. These can be applied as invisible signatures all over the packaging of the original brands’ products. These signatures cannot be replicated and can be authenticated within seconds using a smartphone. An additional advantage of these signatures is that they do not disrupt the production or printing process.
Social Listening: AI applications such as sentiment analysis and NLP for detecting intents and context can monitor conversations around the product and track any adverse comments signaling a potential link to copies or counterfeit manufacturers. Noted fashion brands have taken the help of NLP to track communication related to their original products across social media or online review platforms and get real-time alerts against violations.
How AI Is Contributing To Brand Protection
Brand protection has traditionally comprised labels, holograms and QR codes, which are all easy to copy. Al is leveling up the game, making it harder for counterfeiters and increasing product traceability. With AI models acquiring the capability to be run on edge devices, the technology is going to become as ubiquitous as QR scanners and will power our smartphones with faster, reliable and accurate brand protection tools, leading to a safer environment for customers to buy their products with confidence.
Brand protection should be integral to a brand's strategy from the early stages rather than just an afterthought, as it's harder and more expensive to apply it when the product has already scaled and, therefore, more vulnerable to counterfeiting. Better safe than sorry.
Forbes Technology Council is an invitation-only community for world-class CIOs, CTOs and technology executives. Do I qualify?",https://imageio.forbes.com/specials-images/imageserve/651eda5e4c294b155a900db4/0x0.jpg?format=jpg&width=1200,2023-10-06 06:00:00
https://www.forbes.com/sites/marksparrow/2023/10/06/upgrade-your-laptop-with-the-fast-and-affordable-lexar-790-nvme-ssd/,Upgrade Your Laptop With The Fast And Affordable Lexar 790 NVMe SSD,"The Lexar NM790 NVMe SSD is a fast and affordable way to upgrade the storage on a laptop. Lexar
One of the quickest and easiest ways of perking up a computer’s performance in terms of speed or storage is to upgrade its hard drive or SSD (Solid State Storage). This month, I decided to carry out a little project to show how to upgrade a laptop’s internal storage with a more efficient NVMe SSD, which will boot up faster and hold lots more data.
The Lexar NM790 is a new high-performance NVMe SSD with M.2 format and is very affordable. It offers breakneck speeds thanks to the latest PCIe Gen 4 standards. This blisteringly fast SSD can read at speeds up to 7400MB/s and write at speeds up to 6500MB/s.
Another advantage of upgrading the NVMe SSD in your laptop is the lower power consumption of newer SSDs like the Lexar 790. The 790’s power consumption is 40% lower than DRAM-cached PCIe Gen 4 SSDs, meaning the battery charge in your laptop will last longer.
The M.2 format Lexar NMN790 NVMe SSD is an affordable upgrade or makes an excellent external hard ... [+] drive with an appropriate SSD housing. Lexar
The Lexar 790 NVMe also supports Host Memory Buffer 3.0, activating the DRAM cache function on the host laptop and providing a smoother transfer speed. With this performance boost, the Lexar 790 SSD is suitable for high-performance gamers or inside a gaming console like the Sony PlayStation 5.
Opening a laptop and changing over to an SSD is something that most people can manage for themselves. Many laptops are designed for this kind of user upgrade and there are lots of detailed guides on YouTube. Unfortunately, Apple doesn’t allow this sort of upgrade on its MacBook laptops, but many Windows computers do.
To get the maximum performance out of the Lexar 790 SSD, you will need a computer that supports PCIe Gen 4, but even if your laptop doesn’t support the latest standard, it will still benefit from the performance upgrade and provide better battery performance thanks to the lower power draw of the Lexar 790.
You can put your old SSD in an external housing or even buy yourself an NM790 and pout that in a ... [+] housing like this high-speed NVMe enclosure from Ugreen. Ugreen
And what do you do with the old SSD that was removed from your laptop? That’s an easy question. Whenever I have a spare NVMe SSD, I order a Ugreen M.2 NVMe Gen 3.2 enclosure from Amazon to put my old SSD in and turn it into a handy external hard drive for backing up my computer or for storing photos or other data files that take up a lot of space.
The Ugreen M.2 NVMe enclosure can be turned into an external hard drive. Open it with the supplied screwdriver and slot in an SSD like the new Lexar 790. It takes just a few seconds to do. Once the cover is replaced, you have a handy external hard drive that can be used to store anything you like.
I particularly like the Ugreen M.2 NVMe enclosure. This latest variant from Ugreen efficiently dissipates any heat the SSD produces under stress. The Ugreen enclosure has a rubber bumper that protects its aluminum casing should it be dropped. The Ugreen M.2 NVMe doesn’t support SATA SSDs but can handle NVMe SSDs in all available formats. The enclosure ships with a high-speed USB cable for plugging into any computer.
An SSD enclosure like this one from Ugreen is a great way of recycling an old SSD or housing a new ... [+] one like the Lexar NM790. Ugreen
Verdict: The new Lexar 790 NVMe SSD is a high-performance drive that makes an excellent upgrade for a laptop or Sony PlayStation 5. It’s sufficiently affordable to use as an external storage drive in an enclosure like the Ugreen NVMe. The price and performance offered by the Lexar 790 make it an excellent choice for upgrading a laptop with an NVMe slot.
Pricing & Availability: The Lexar 790 is available now in capacities 512GB, 1TB, 2TB and 4TB. A 1TB SSD costs $59.99 / £56.99 / €65.99 from Amazon. The Ugreen M.2 NVMe enclosure is available from Amazon or Ugreen and costs $24.99 / £20.24 / €23.99.
More info: Lexar.com and Ugreen.com",https://imageio.forbes.com/specials-images/imageserve/651fb0d075a614819d473dd0/0x0.jpg?format=jpg&width=1200,2023-10-06 05:00:53
https://www.forbes.com/sites/jamiehailstone/2023/10/06/private-sector-coalition-to-build-water-resilience-gathers-pace/,Private-Sector Coalition To Build Water Resilience Gathers Pace,"Long Island, N.Y.: Water being poured into a glass from a faucet on Long Island, New York on Oct. 4, ... [+] 2022. (Photo by Steve Pfost/Newsday RM via Getty Images) Newsday via Getty Images
A chief executive-led initiative that aims to put water stress at the top of corporate agendas has revealed it has signed up 35 global companies across multiple sectors.
In its latest update, the Water Resilience Coalition said it now has 21 collective action projects now underway to build water resilience in 15 water-stressed river basins across Asia, Africa, South America, and North America.
Since the coalition’s launch in 2020, 35 global companies across multiple sectors with a combined market cap of US $4.8 trillion and operations in more than 140 countries have joined the initiative.
It aims to recruit 150 of the world’s most influential companies by 2030 with the potential to influence one-third of the world's water withdrawals.
The coalition also announced its 2030 ambition—for businesses to build water resilience in operations, supply chains, and 100 water-stressed basins.
Several new companies, including Ecolaband ABInBev have stepped forward as “basin champions” to serve as convening agents for collective action in specific basins.
The collation is also an initiative of the CEO Water Mandate, a partnership between the United Nations Global Compact and the Pacific Institute.
Jason Morrison, president of the Pacific Institute, a global water think tank, and head of the CEO Water Mandate, said in an interview that most companies have known for some time that the impacts of climate change will manifest through water.
He added the extremely hot and dry heatwave conditions experienced by many, as well as freak floods, have highlighted how climate change can manifest itself in different ways.
“We’ve moved past the ideological divide of whether climate change is real or not. Businesses are realizing that you have to take action.
“There’s also an expression that goes ‘if climate change were a shark, then water would be its teeth’,” Morrison told me.
Morrison said some companies are being driven by the financial costs of climate change and the need to deal with those costs. While others are motivated by the need to show they are a socially responsible brand to their customers.
He added there is also a growing realization in the business community that no company can manage water-related risk or achieve water resilience working by itself.
“They need the architecture of working together,” Morrison told me.
“We want to mobilise the entire business community on this issue,” he added. “There are 18,000 business members in the United Nations Global Compact and they are rolling out this initiative across their membership.
“There are going to be a lot of folks that will be joining our efforts and that will really help us gain momentum and have that impact at scale that we're seeking.”
Coalition member companies include 3M, Microsoft and Heineken.
Heineken’s senior director of global sustainability, Sonia Thimmiah, said in a statement water security is “key for building resilience and future proofing our businesses”.
“That's why as part of our 'Towards Healthy Watersheds' strategy, we are focused on water efficiency and the long-term restoration of critical water basins – it matters to us as a business and the communities where we source and operate,” she added.",https://imageio.forbes.com/specials-images/imageserve/651fc76963f83d214cda7605/0x0.jpg?format=jpg&width=1200,2023-10-06 04:39:57
https://www.forbes.com/sites/bernardmarr/2023/10/06/how-generative-ai-is-used-to-fight-miscarriages-of-justice-at-the-california-innocence-project/,How Generative AI Is Used To Fight Miscarriages Of Justice At The California Innocence Project,"According to the National Registry of Exonerations, since 1989, the wrongly-convicted have lost 29,950 years of their lives thanks to miscarriages of justice in the US legal system.
How Generative AI Is Used To Fight Miscarriages of Justice At The California Innocence Project Adobe Stock
In an attempt to tackle this, the California Western School of Law established the California Innocence Project (CIP), which aims to assist in cases where compelling evidence indicates that people have been locked up unfairly.
This is often highly complex, labor-intensive work requiring many hours of dedication by professional lawyers and researchers. However, an innovative artificial intelligence (AI) partnership is helping to hugely speed up the painstaking work, giving hope that it will lead to a reduction in time spent behind bars by innocent people.
In this piece, I’ll take a look at the partnership and the technology behind it, as well as consider the potential impact that generative AI tools can have on the legal profession in general.
What is the California Innocence Project?
The project was founded in 1999 with the aim of freeing the wrongfully convicted, advocating for reform in the justice system and training lawyers and students to deal with miscarriages of justice.
Students are selected from the California Western School of Law to work alongside qualified attorneys on cases where there is evidence of wrongful convictions and incarceration.
It’s one of a number of legal organizations dedicated to overturning wrongful convictions, which, between them, have played a part in securing close to 4,000 exonerations.
Examples of high-profile wins include the overturning of the conviction of Timothy Atkins, who spent 23 years in prison after being wrongfully imprisoned for a murder carried out during a carjacking, and the conviction of Kimberly Long in 2016 for murdering her boyfriend. In both cases, lawyers working with the project uncovered new evidence that persuaded judges that the convictions were unsafe.
How is the California Innocence Project using Generative AI?
To assist with the time-consuming and highly technical work of reviewing mountains of evidence and case law connected to their investigations, CIP lawyers deployed a generative AI model developed by CaseText in partnership with ChatGPT creators OpenAI.
Billed as an AI legal assistant, the platform – known as CoCounsel, is capable of reviewing and summarizing legal documents, preparing depositions and drafting reports. It's based on a large language model (LLM) of the same type used by the OpenAI’s groundbreaking chatbot but specifically trained on legal documents, case law and court proceedings.
According to CIP attorney Michael Semanchik, the time saved by using the tool for these essential but mundane tasks frees the legal team to spend time on tasks that require human interaction. For example, drafting a letter to send to a client traditionally takes around 15 minutes but can now be achieved in under one minute. Complex documents can be summarized in plain English, reducing the time taken by a human to digest and comprehend them.
Of course, working in such a sensitive field means it’s critical that the AI produces accurate output and isn’t affected by bias, hallucinations and other issues that can affect generative AI.
In order to minimize this risk, CoCounsel was beta-tested by lawyers from 400 firms, including multinational law firms, solo practitioners and Fortune 500 companies. Care is also taken that the sensitive information often entered into the system by those using it isn't stored or fed back into the platform for training to mitigate the risk of “leaking” confidential data.
While it’s too early to measure the precise impact that generative AI will have on the work of the CIP, Semanchik expects that in the future, it will mean they are able to take on more clients and potentially overturn greater numbers of wrongful convictions.
As reported by the California Western School of Law Campus News, he believes “There’s no question it can make for better lawyering. I would argue that in the long-term, failure to embrace and utilize AI may result in a lawyer not being the best and most competent advocate for their client.”
How Will Generative AI Impact Lawyers and the Legal System?
Generative AI has the potential to transform the legal profession by automating many routine and time-consuming tasks, aiding in research and helping lawyers to make better decisions.
As an information-intensive field of work, AI companies have been quick to build and bring products to market.
One leading provider of consumer legal services, LegalZoom, has said that AI will help it to streamline its operations and eliminate inefficiencies in drafting and reviewing contracts.
ThoughtRiver has developed an AI platform designed to automate the process of reviewing contracts and highlighting risks, and Lex Machina offers a product that aims to predict the behavior of courts and judges, forecasting the likely lengthiness of litigation and potential costs and outcomes.
As well as helping lawyers to work more quickly and productively, innovation in this field has the potential to benefit society as a whole by reducing the cost of accessing justice and legal redress.
There are still barriers to be overcome, in particular around data quality and privacy. However, the potential time and money savings will undoubtedly create incentives for these to be tackled. Overall, it's hard to overstate the opportunities that generative AI creates for driving transformative change in the field of law, and it’s an area where I’m confident we’ll see more exciting developments in the future.
You can read more about future tech and business trends in my books, The Future Internet: How the Metaverse, Web 3.0, and Blockchain Will Transform Business and Society, Future Skills: The 20 Skills And Competencies Everyone Needs To Succeed In A Digital World and Business Trends in Practice, which won the 2022 Business Book of the Year award. And don’t forget to subscribe to my newsletter and follow me on X (Twitter), LinkedIn, and YouTube for more on the future trends in business and technology.",https://imageio.forbes.com/specials-images/imageserve/651fada175a614819d473dce/0x0.jpg?format=jpg&width=1200,2023-10-06 02:49:06
https://www.reuters.com/innovation/article/usa-china-chips-riscv/exclusive-us-china-tech-war-risc-v-chip-technology-emerges-as-new-battleground-idUSKBN3160RG,Exclusive-US-China tech war: RISC-V chip technology emerges as new battleground,"(Reuters) - In a new front in the U.S.-China tech war, President Joe Biden’s administration is facing pressure from some lawmakers to restrict American companies from working on a freely available chip technology widely used in China - a move that could upend how the global technology industry collaborates across borders.
FILE PHOTO: A Chinese flag is displayed next to a ""Made in China"" sign seen on a printed circuit board with semiconductor chips, in this illustration picture taken February 17, 2023. REUTERS/Florence Lo/Illustration/File Photo
At issue is RISC-V, pronounced “risk five,” an open-source technology that competes with costly proprietary technology from British semiconductor and software design company Arm Holdings. RISC-V can be used as a key ingredient for anything from a smartphone chip to advanced processors for artificial intelligence.
Some lawmakers - including two Republican House of Representatives committee chairmen, Republican Senator Marco Rubio and Democratic Senator Mark Warner - are urging Biden’s administration to take action regarding RISC-V, citing national security grounds.
The lawmakers expressed concerns that Beijing is exploiting a culture of open collaboration among American companies to advance its own semiconductor industry, which could erode the current U.S. lead in the chip field and help China modernize its military. Their comments represent the first major effort to put constraints on work by U.S. companies on RISC-V.
Representative Mike Gallagher, chairman of the House select committee on China, said in a statement to Reuters that the Commerce Department needs to “require any American person or company to receive an export license prior to engaging with PRC (People’s Republic of China) entities on RISC-V technology.”
Such calls to regulate RISC-V are the latest in the U.S.-China battle over chip technology that escalated last year with sweeping export restrictions that the Biden administration has told China it will update this month.
“The CCP (Chinese Communist Party) is abusing RISC-V to get around U.S. dominance of the intellectual property needed to design chips. U.S. persons should not be supporting a PRC tech transfer strategy that serves to degrade U.S. export control laws,” Representative Michael McCaul, chairman of the House Foreign Affairs Committee, said in a statement to Reuters.
McCaul said he wants action from the Bureau of Industry and Security, the part of the Commerce Department that oversees export-control regulations, and would pursue legislation if that does not materialize.
The bureau “is constantly reviewing the technology landscape and threat environment, and continually assessing how best to apply our export control policies to protect national security and safeguard core technologies,” a Commerce Department spokesperson said in a statement.
“Communist China is developing open-source chip architecture to dodge our sanctions and grow its chip industry,” Rubio said in a statement to Reuters. “If we don’t broaden our export controls to include this threat, China will one day surpass us as the global leader in chip design.”
“I fear that our export-control laws are not equipped to deal with the challenge of open-source software - whether in advanced semiconductor designs like RISC-V or in the area of AI - and a dramatic paradigm shift is needed,” Warner said in a statement to Reuters.
RISC-V is overseen by a Swiss-based nonprofit foundation that coordinates efforts among for-profit companies to develop the technology.
The RISC-V technology came from labs at the University of California, Berkeley, and later benefited from funding by the Pentagon’s Defense Advanced Research Projects Agency (DARPA). Its creators have compared it to Ethernet, USB and even the internet, which are freely available and draw on contributions from around the world to make innovation faster and cheaper.
HUAWEI TECHNOLOGIES
Executives from China’s Huawei Technologies have embraced RISC-V as a pillar of that nation’s progress in developing its own chips. But the United States and its allies also have jumped on the technology, with chip giant Qualcomm working with a group of European automotive firms on RISC-V chips and Alphabet’s Google saying it will make Android, the world’s most popular mobile operating system, work on RISC-V chips.
Qualcomm declined to comment. Its executives said in August they believe RISC-V will speed up chip innovation and transform the tech industry.
Google did not respond to a request for comment.
If Biden’s administration were to regulate U.S. companies’ participation in the Swiss-based foundation in the manner lawmakers are seeking, the move could complicate how American and Chinese companies work together on open technical standards. It also could create hurdles for China’s pursuit of chip self-sufficiency, as well as for U.S. and European efforts to create cheaper and more versatile chips.
Jack Kang, vice president of business development at SiFive, a Santa Clara, California-based startup using RISC-V, said potential U.S. government restrictions on American companies regarding RISC-V would be a “tremendous tragedy.”
“It would be like banning us from working on the internet,” Kang said. “It would be a huge mistake in terms of technology, leadership, innovation and companies and jobs that are being created.”
Regulating the open discussion of technologies is rarer than regulating physical products, but not impossible, said Kevin Wolf, an export-control attorney at law firm Akin Gump who served in the Commerce Department under former President Barack Obama. Existing rules on chip exports could help provide a legal framework for such a proposal, Wolf said.",https://s1.reutersmedia.net/resources/r/?m=02&d=20231006&t=2&i=1646885122&w=1200&r=LYNXMPEJ950D2,2023-10-06 10:50:41
https://www.reuters.com/innovation/article/tech-antitrust-google-branch/google-stopped-samsung-from-expanding-search-app-offering-ex-executive-idUSKBN3151Y7,Google stopped Samsung from expanding search app offering - ex-executive,"FILE PHOTO: The logo of Google is seen at the Viva Technology conference dedicated to innovation and startups at Porte de Versailles exhibition center in Paris, France, June 14, 2023. REUTERS/Gonzalo Fuentes/File Photo
WASHINGTON (Reuters) - A former executive at Samsung Electronics’ venture capital arm who proposed that mobile app developer Branch Metrics’ software offering be expanded in Samsung smartphones faced pushback due to pressure from Google, he said on Thursday in a landmark antitrust trial against the Alphabet unit.
Patrick Chang, who worked at Samsung Next to invest in innovative companies, had urged the parent company to expand the offerings of Branch, which can search within apps, to its Android smartphones.
Branch Metrics founder and former CEO Alexander Austin testified in late September that his company eliminated some of its software’s functions to fend off Google’s complaints as it sought to make deals with wireless carriers and smartphone makers. Branch had to ensure that its searches remained within apps and never linked to the web, Austin noted.
Chang testified that Samsung also faced pushback from wireless carries, like AT&T, which sell Android phones.
Google is accused of paying $10 billion a year based on revenue share agreements to smartphone makers like Samsung Electronics, wireless carriers and others who agree to make its software the default and maintain its monopoly in search.
In its questioning, the Justice Department showed an August 2020 email by Samsung executive David Eun, who complained that “Google is clearly buying its way to squelch competitors.”
Under cross examination by an attorney for Google, Chang was asked about another possible explanation for Samsung’s disinterest in Branch, which is that the software was clunky and few users clicked on links that Branch offered.
Chang testified during the fourth week of a more than two-month trial in which the U.S. Justice Department is seeking to show that Google abused its monopoly of search and some search advertising. Google has said that its business practices were legal.
(This story has been corrected to say Google was accused of stopping the expansion of Branch Metrics software offering on smartphones, not blocking the installation, in the headline and paragraph 1)",https://s1.reutersmedia.net/resources/r/?m=02&d=20231005&t=2&i=1646818796&w=1200&r=LYNXMPEJ940X2,2023-10-05 22:22:02
https://www.reuters.com/innovation/article/britain-tech-regulation/uk-to-examine-amazon-and-microsofts-cloud-dominance-idUSKBN3150A7,UK to examine Amazon and Microsoft's cloud dominance,"LONDON (Reuters) -Britain’s media regulator on Thursday asked the country’s antitrust authority to investigate U.S. tech giants Amazon and Microsoft’s dominance of the UK cloud market.
Ofcom said it had identified features that made it more difficult for UK businesses to use multiple cloud suppliers.
Amazon Web Services (AWS) and Microsoft had a combined 70-80% share of Britain’s public cloud infrastructure services market in 2022, Ofcom said. Google was their closest competitor with 5-10%.
Britain is not the only country looking into cloud computing; the U.S. Federal Trade Commission asked for information about the market in March, citing similar interest in the UK, France, Japan, The Netherlands and South Korea.
“The CMA (Competition and Markets Authority) will now conduct an independent investigation to decide whether there is an adverse effect on competition, and if so, whether it should take action or recommend others to take action,” it said.
Amazon said it disagreed with Ofcom, whose findings were based on “a fundamental misconception of how the IT sector functions, and the services and discounts on offer”.
“Any unwarranted intervention could lead to unintended harm to IT customers and competition,” a spokesperson said.
But it said it would work constructively with the CMA.
Microsoft said it was committed to ensuring the UK cloud industry remained innovative and highly competitive. “We will engage constructively with the CMA,” a Microsoft spokesperson said.
Dan Ridsdale, TMT director at research company Edison, said the dominance of AWS, Microsoft and to a lesser extent Google was replicated across every major economy other than China.
But Britain was the most advanced in addressing the issue, he said, and was now on a path to potentially taking action.
3D printed clouds and figurines are seen in front of the AWS (Amazon Web Service) cloud service logo in this illustration taken February 8, 2022. REUTERS/Dado Ruvic/Illustration
“Other jurisdictions are likely to follow suit and regulatory action of one form or another looks inevitable,” he said.
The French antitrust authority said in June that practices in the sector could potentially restrict competition, while the EU regulator is scrutinising Microsoft’s cloud practices following a complaint by trade group Cloud Infrastructure Services Providers in Europe (CISPE) whose members include Amazon.
MICROSOFT-CMA HISTORY
The CMA and Microsoft have already clashed this year when the regulator blocked the company’s $69 billion acquisition of games company Activision Blizzard.
A restructured deal found favour but the episode made clear the CMA’s willingness to take on big tech.
Ofcom said in April it was worried about the practices of AWS and Microsoft because of their market positions in the cloud market, and planned to ask the competition regulator to investigate.
Reuters reported on Tuesday that Ofcom was expected to push for an antitrust investigation.
UK businesses told Ofcom they were concerned it was too difficult to switch or mix and match cloud providers.
“So, we’re referring the market to the CMA for further scrutiny,” Ofcom Director Fergal Farragher said.
The CMA welcomed the move, saying effective competition in the 7.5 billion pound ($9.1 billion) UK market was essential.
Google Vice President Amit Zavery said Ofcom’s referral demonstrated the need to create an open cloud market with no vendor lock-in.
3D printed clouds and figurines are seen in front of the Microsoft Azure cloud service logo in this illustration taken February 8, 2022. REUTERS/Dado Ruvic/Illustration
“UK government agencies, businesses, and consumers want to move easily across cloud platforms and choose which services best meet their needs,” he said, adding Google would continue to allow its products to run on any cloud without penalty.
The CMA will complete its investigation by April 2025.
($1 = 0.8232 pounds)",https://s2.reutersmedia.net/resources/r/?m=02&d=20231005&t=2&i=1646823526&w=1200&r=LYNXMPEJ9405G,2023-10-05 21:21:49
https://www.reuters.com/innovation/article/blackberry-separation/blackberry-to-separate-iot-and-cybersecurity-businesses-plans-ipo-idUSKBN3141WM,"BlackBerry to separate IoT and cybersecurity businesses, plans IPO","(Reuters) -Canadian technology company BlackBerry said on Wednesday it would separate its Internet of Things (IoT) and cybersecurity business units and target a subsidiary initial public offering for the IoT business next fiscal year.
FILE PHOTO: The Blackberry logo is shown on a office tower in Irvine, California, U.S., October 20, 2020. REUTERS/Mike Blake/File Photo
BlackBerry joins a number of companies that have split their units in recent years, favoring a leaner corporate structure to help investors better evaluate their separate businesses.
Earlier this week, the packaged food giant formerly known as Kellogg Co completed its spinoff. Healthcare giant Johnson & Johnson and industrial conglomerate General Electric have also spun off some of their units.
“Both the IoT and Cyber businesses ... address large and growing market opportunities. This new proposed structure will further increase both their operational agility and ability to focus on delivering exceptional solutions,” said BlackBerry CEO John Chen.
U.S.-listed shares of Waterloo, Ontario-based BlackBerry rose more than 4% in trading after the bell. The shares have fallen more than 18% since Reuters reported in August that private equity firm Veritas Capital had made an offer to buy the company.
BlackBerry said in May it would consider strategic options for its portfolio of businesses that could include the possible separation of one or more of its businesses.
Last year, it pulled the plug on its smartphones business and has since been trying to sell its legacy patents related to its mobile devices.
The company went public in 1997 and soon became popular for its ubiquitous business smartphones, which were toted by executives, politicians and legions of fans in the early 2000s.
Last week, the company reported its second-quarter results and posted total revenue of $132 million, down from $168 million a year earlier.
IoT revenue was $49 million, while cybersecurity revenue came in at $79 million.",https://s4.reutersmedia.net/resources/r/?m=02&d=20231005&t=2&i=1646821980&w=1200&r=LYNXMPEJ930ZY,2023-10-05 21:04:58
https://www.reuters.com/innovation/article/usa-stocks-clorox/clorox-shares-touch-more-than-5-year-low-on-financial-hit-from-cyber-attack-idUSKBN3151JD,Clorox shares touch more than 5-year low on financial hit from cyber attack,"(Reuters) - Shares in Clorox were down 8.1% on Thursday, after hitting their lowest level since May 2018, after the cleaning supplies company’s warned that an August cyber attack would push it into a quarterly loss and slash up to 28% off its revenue.
FILE PHOTO: Bottles of Clorox bleach are displayed for sale on the shelves of a Wal-Mart store in Rogers, Arkansas, June 4, 2009. REUTERS/Jessica Rinaldi/File Photo
Shares in Clorox last traded at $121.16 after earlier hitting a low of $119.56 and were eying their biggest one-day percentage loss since Feb. 2022.
Late Wednesday, Clorox forecast a loss per share between $0.35 and $0.75 for its fiscal first quarter ended Sept. 30, versus a year-ago profit of $0.68. It said net sales would fall year-over-year by 23% to 28%.
After this, Evercore ISI slashed its Clorox price target to $120 from $160 and Raymond James downgraded it to ‘market perform’ from ‘outperform’. Bank of America cut its price target to $120 from $145 while Deutsche Bank dropped its target to $136 from $155.
BoFA analyst Anna Lizzul, who rates Clorox ‘underperform’, said its warning of a first-quarter gross margin decline is “particularly notable” as she had expected it to be “the largest quarter for gross margin expansion” in its fiscal year 2024.
Along with the attack and a challenging consumer environment, Lizzul said rising shipment costs from higher oil prices may also push Clorox to reduce promotalsol activity in fiscal year 2024 to protect margins.
And Lizzul saw “little potential to raise prices,” since it had made four rounds of price increases in the last 2 years.
On Aug 14 Clorox said it took some systems offline after unauthorized activity disrupted operations. Then on Sept. 18 it said first-quarter results could see a “material impact.”
On Sept 29 it said all its manufacturing facilities resumed operations and that it was ramping up production to restock inventories after the attack.
But, Evercore ISI analyst Javier Escalante who rates Clorox ‘underperform,’ voiced concerns about how long the company took to work out the financial impact. He also pointed to its warning about “ongoing, but lessening operational impacts in the second quarter.”
Escalante described this as a “disconcerting” disconnect between operations, financial planning and reporting in his research note.",https://s4.reutersmedia.net/resources/r/?m=02&d=20231005&t=2&i=1646797076&w=1200&r=LYNXMPEJ940Q9,2023-10-05 16:10:41
https://techcrunch.com/2023/10/05/paradigm-matt-huang-testimony-sbf-trial-investor-fraud/,'Marked to zero': Paradigm testimony at SBF trial points to investor fraud,"The testimony of Matt Huang, co-founder and managing partner of crypto investment firm Paradigm, at Sam Bankman-Fried’s trial may help the prosecution convince jurors that the former crypto mogul defrauded investors.
Huang testified Thursday that he and his firm were in the dark about a range of business practices at FTX, red flags that would have affected his decision to invest in the company. Namely, FTX’s use of customer funds to prop up Bankman-Fried‘s hedge fund Alameda Research.
Government cooperation aside, Huang likely has his own motives for testifying against Bankman-Fried and distancing his firm from FTX. Paradigm is part of a class-action lawsuit (which was temporarily stayed in June) that accuses it, alongside Sequoia Capital and Thoma Bravo, of promoting FTX to the detriment of its users.
According to Huang’s testimony, Paradigm was duped, as well.
Over two funding rounds between 2021 and 2022, Paradigm invested $278 million into FTX. When prosecutor Thane Rehn asked what Paradigm estimates the current value of that investment to be, Huang replied, “We have marked it to zero.”
That establishes damage has been done in the form of financial losses, one of the things the prosecution will have to establish in order to prove fraud.
The government will also have to establish misrepresentation, showing that the defendant made false statements or concealed material information in order to convince investors to fork over money. Prosecutors also need to prove that the investors relied on Bankman-Fried’s misrepresentations. Finally, they’ll need to demonstrate that Bankman-Fried intended to defraud investors, which could be more difficult.
Huang’s testimony Thursday at least supports the establishment of three out of four of those elements.
Paradigm began considering investment into FTX in 2019, according to Huang. During that time, Huang testified that he was told FTX exchange wallets served as a custodian for customer deposits and would always be available if customers wished to withdraw. He wasn’t told that FTX could take those deposits out and use them for their own business purposes.
When asked if he would have still invested in FTX knowing that, Huang responded, “Likely not.”
“If it became known that they were doing that, I think the exchange would lose credibility in the brand and people wouldn’t want to use it, so it would be existential to the business,” said Huang.
Not only was Huang uninformed about FTX’s habit of using customer deposits for its own purposes, but he also testified that he didn’t know Alameda was able to access those deposits, and wouldn’t have invested in FTX if he had.
“Customer deposits are sort of sacred,” he said.
As Paradigm was considering investment into FTX, Huang said he raised concerns about the link between Alameda and FTX. Mainly, he was worried that Alameda — one of the largest traders on the platform — would get preferential treatment, which would also be damaging to FTX’s reputation.
Bankman-Fried told Huang Alameda didn’t have preferential treatment on the platform. But the prosecution pointed out that Alameda was exempt from FTX’s liquidation engine, a risk management strategy that’s designed to automatically trigger the sale of assets if certain risk parameters are exceeded.
Huang said FTX’s liquidation engine was a big part of why Paradigm was attracted to the company. He also agreed that Alameda’s exemption is inconsistent with Bankman-Fried’s statement that it didn’t get preferential treatment.
“It would have meant that Alameda could trade with leverage on the platform and, if those trades didn’t work out, could ultimately incur a negative balance that would have to be paid for somehow,” said Huang. “In a typical case, that might come from the money we were investing into the company that would go to fund operations. But in any case, it would leave the business at risk of becoming insolvent.”
Rehn also sought to establish that Bankman-Fried made false statements to lull Paradigm into investing. He pulled up an excel spreadsheet that had been attached to an email Bankman-Fried sent to Huang showing FTX’s financial stats as of April 2021. The balance sheet showed FTX’s annualized approximate revenue, estimating a net profit for Q1 2021 of $85 million. Rehn asserted that FTX had moved certain expenses off those financial statements in order to artificially inflate the reported net profits.
Throughout his testimony, Huang repeated that he had also expressed concerns with Bankman-Fried over FTX’s lack of a board and lack of governance, which he said could lead to unintended value leakage. While this did not ultimately stop Paradigm from investing in FTX, Huang testified that “SBF was very resistant to having investors on the board.”","https://techcrunch.com/wp-content/uploads/2023/10/GettyImages-1708738406.jpg?resize=1200,800",2023-10-06 03:35:40
https://techcrunch.com/2023/10/05/paradigm-matt-huang-testimony-sbf-trial-investor-fraud/,'Marked to zero': Paradigm testimony at SBF trial points to investor fraud,"The testimony of Matt Huang, co-founder and managing partner of crypto investment firm Paradigm, at Sam Bankman-Fried’s trial may help the prosecution convince jurors that the former crypto mogul defrauded investors.
Huang testified Thursday that he and his firm were in the dark about a range of business practices at FTX, red flags that would have affected his decision to invest in the company. Namely, FTX’s use of customer funds to prop up Bankman-Fried‘s hedge fund Alameda Research.
Government cooperation aside, Huang likely has his own motives for testifying against Bankman-Fried and distancing his firm from FTX. Paradigm is part of a class-action lawsuit (which was temporarily stayed in June) that accuses it, alongside Sequoia Capital and Thoma Bravo, of promoting FTX to the detriment of its users.
According to Huang’s testimony, Paradigm was duped, as well.
Over two funding rounds between 2021 and 2022, Paradigm invested $278 million into FTX. When prosecutor Thane Rehn asked what Paradigm estimates the current value of that investment to be, Huang replied, “We have marked it to zero.”
That establishes damage has been done in the form of financial losses, one of the things the prosecution will have to establish in order to prove fraud.
The government will also have to establish misrepresentation, showing that the defendant made false statements or concealed material information in order to convince investors to fork over money. Prosecutors also need to prove that the investors relied on Bankman-Fried’s misrepresentations. Finally, they’ll need to demonstrate that Bankman-Fried intended to defraud investors, which could be more difficult.
Huang’s testimony Thursday at least supports the establishment of three out of four of those elements.
Paradigm began considering investment into FTX in 2019, according to Huang. During that time, Huang testified that he was told FTX exchange wallets served as a custodian for customer deposits and would always be available if customers wished to withdraw. He wasn’t told that FTX could take those deposits out and use them for their own business purposes.
When asked if he would have still invested in FTX knowing that, Huang responded, “Likely not.”
“If it became known that they were doing that, I think the exchange would lose credibility in the brand and people wouldn’t want to use it, so it would be existential to the business,” said Huang.
Not only was Huang uninformed about FTX’s habit of using customer deposits for its own purposes, but he also testified that he didn’t know Alameda was able to access those deposits, and wouldn’t have invested in FTX if he had.
“Customer deposits are sort of sacred,” he said.
As Paradigm was considering investment into FTX, Huang said he raised concerns about the link between Alameda and FTX. Mainly, he was worried that Alameda — one of the largest traders on the platform — would get preferential treatment, which would also be damaging to FTX’s reputation.
Bankman-Fried told Huang Alameda didn’t have preferential treatment on the platform. But the prosecution pointed out that Alameda was exempt from FTX’s liquidation engine, a risk management strategy that’s designed to automatically trigger the sale of assets if certain risk parameters are exceeded.
Huang said FTX’s liquidation engine was a big part of why Paradigm was attracted to the company. He also agreed that Alameda’s exemption is inconsistent with Bankman-Fried’s statement that it didn’t get preferential treatment.
“It would have meant that Alameda could trade with leverage on the platform and, if those trades didn’t work out, could ultimately incur a negative balance that would have to be paid for somehow,” said Huang. “In a typical case, that might come from the money we were investing into the company that would go to fund operations. But in any case, it would leave the business at risk of becoming insolvent.”
Rehn also sought to establish that Bankman-Fried made false statements to lull Paradigm into investing. He pulled up an excel spreadsheet that had been attached to an email Bankman-Fried sent to Huang showing FTX’s financial stats as of April 2021. The balance sheet showed FTX’s annualized approximate revenue, estimating a net profit for Q1 2021 of $85 million. Rehn asserted that FTX had moved certain expenses off those financial statements in order to artificially inflate the reported net profits.
Throughout his testimony, Huang repeated that he had also expressed concerns with Bankman-Fried over FTX’s lack of a board and lack of governance, which he said could lead to unintended value leakage. While this did not ultimately stop Paradigm from investing in FTX, Huang testified that “SBF was very resistant to having investors on the board.”","https://techcrunch.com/wp-content/uploads/2023/10/GettyImages-1708738406.jpg?resize=1200,800",2023-10-06 03:35:40
https://techcrunch.com/2023/10/06/ohms-quest-is-an-electronic-puzzle-console-inspired-by-escape-rooms/,Ohm’s Quest is an electronic puzzle console inspired by escape rooms,"Ohm’s Quest is a steampunk-inspired cubical device that acts as a sort of escape game console. You can scan an NFC-enabled card on a side of the cube, and it starts a new story with interactive challenges that you should solve as a team.
While we don’t cover board games very often on TechCrunch, there was something fun about Ohm’s Quest when I talked with the team behind it. This project sits at the intersection of escape rooms, board games and tech creativity.
The team already launched pre-orders on Kickstarter and Indiegogo. It raised €230,000 from more than a thousand backers and it expects to ship the game in early 2024. The starter kit currently costs $249.
“We design audio stories in which you are the hero. You play together with a team against the story. As a result, there are characters in the story who need your help to solve problems,” co-founder and CTO Allison Klopp told me.
And the interface with the game is these cubes pictured above. You get two cubes in the box and you can connect them with a cable — they communicate wirelessly but there are multiple slots that will be used differently depending on the story. On one side of the cube, there is a control panel with LED-enabled buttons and a directional joystick and a dial.
There’s a speaker to hear the story as well as a built-in accelerometer. On another side, there’s a tiny display that can be used to display messages or the time remaining before something dramatic happens.
“As these interfaces come without any context, we add context with cardboard elements, such as cards, instruction manuals, game boards,” co-founder and CEO Etienne Pouget told me. Some cards have an NFC tag, which means that the cube can also receive some information from specific cards.
Some challenges involve sound mixing, solving a labyrinth, asking questions to potential murderers using cards, passing a chemical element from one cube to another, etc.
It’s a hardware/software play and Ohm’s Quest expects to ship a new story every month when the cubes are available. The team is also working on a mobile app so that you can buy new stories and transfer them to the cube.
Some stories will be purely digital — you’ll be able buy them at home and print the instructions to play them. Other stories will come with new accessories — game board, figurines and cards.
Ohm’s Quest also hopes that it can create a community of players around its game. There will be a creator mode so that the most enthusiastic players can design their own stories. The Ohm’s Quest team could then work with an illustrator to create cards for those stories — story creators would be compensated.
As you can see, the team behind Ohm’s Quest has plenty of creative ideas for its puzzle-meet-story platform. There could be new cubes in the future as well with new interaction methods. “The one we’re dreaming of is a cube with an olfactory interface to create investigations using scents,” Pouget said.",https://techcrunch.com/wp-content/uploads/2023/10/Ohms-Quest-1.jpg?w=1080,2023-10-06 08:10:00
https://techcrunch.com/2023/10/06/premji-invest-and-zerodha-eye-stake-in-nainital-bank/,Premji Invest and Zerodha eye stake in Nainital Bank,"A number of venture investors and startups are engaging with Bank of Baroda to acquire a stake in the lender’s subsidiary Nainital, according to people familiar with the matter.
Premji Invest and stock broking giant Zerodha are among the prospective backers that have held conversations with Bank of Baroda, which has agreed to sell a significant stake in the subsidiary, the people said, requesting anonymity as the deliberations are private.
Private equity firm Multiples has also engaged with the lender, one person said.
Bank of Baroda, which owns over 98% stake in Nainital Bank, has been looking to divest its stake in Nainital Bank, which operates in five Indian states and has over 140 branches, for over a year at the direction of the regulator. The talks have reached serious deliberations in recent weeks.
Bank of Baroda, the second largest PSU bank in India, plans to initially divest about 40 to 50% stake in Nainital Bank and eventually sell the remaining shares, another person familiar with the matter said. A consortium of multiple entities is likely to win the bid, one of the people said.
A deal hadn’t been reached at the time of publishing, and existing prospective investors may still not end up forging the investment, people familiar with the situation cautioned.
Bank of Baroda, Multiples, and Premji Invest didn’t respond to a request for comment. Zerodha declined to comment.
The investment talks come as the Reserve Bank of India evaluates permitting external investors back a handful of lenders. Accel and Quona last year backed Shivalik Bank and fintech unicorn Slice said this week that it had received the approval from the central bank to merge with North East Small Finance Bank.
Two high-profile venture investors told TechCrunch on the condition of anonymity that VCs and PEs are hunting for deals with banks partly as a hedge against their fintech investments following growing regulatory scrutiny on younger financial services firms.","https://techcrunch.com/wp-content/uploads/2023/10/GettyImages-952877364.jpg?resize=1200,800",2023-10-06 07:44:39
https://techcrunch.com/2023/10/05/netflix-india-subscribers/,"Netflix's 6.5M India subscribers dwarfed by Prime Video and Disney, Bernstein says","Netflix has “not succeeded” in scaling up its business in India despite the global streaming giant consistently lowering the subscription costs in the country, analysts at AllianceBernstein wrote in a report to clients Thursday.
The U.S. streamer has about 6.5 million subscribers in India, compared to Prime Video’s 20 million in the South Asian market, the analysts wrote. Disney+ Hotstar continues to dominate the market with over 40 million subscribers.
AllianceBernstein attributed Netflix slower growth in India to lack of local content, saying only 12% of the titles the global streamer offers in the country were local content. About 60% of Prime Video’s catalog in India, in comparison, was in domestic languages.
The poor reception in India comes despite Netflix consistently lowering the prices in the country even as it has virtually raised the prices in all other key markets. Netflix inked a “first-of-its-kind” deal with Jio Platforms, India’s largest telecom operator, to bundle the streaming service with the carrier’s pay-as-you-go plans in August.
“Perhaps the lesson from India points to both the need for higher density of local-language content as we described above, but also a recognition that in many emerging markets, value is less tied to a comparison with other streaming services and more tied to a much lower cost of linear TV or Internet video. India, for example, is likely YouTube’s largest market, and a key growth area for social media names,” the analysts wrote.
Netflix didn’t immediately respond to a request for comment.
Disney’s Hotstar continues to dominate its competitors in India, thanks to its cricket streaming offerings, which consistently attract millions of live viewers during matches. The platform is even offering free streaming of the ongoing ICC Cricket World Cup, an event that will last over 45 days, to all mobile users. JioCinema, the latest venture by billionaire Mukesh Ambani, is taking a page from Disney’s strategy — of acquiring rights to high-profile cricket matches — and is increasingly emerging as a formidable contender.","https://techcrunch.com/wp-content/uploads/2023/08/GettyImages-1247248367.jpg?resize=1200,800",2023-10-06 05:33:31
https://techcrunch.com/2023/10/05/paradigm-matt-huang-testimony-sbf-trial-investor-fraud/,'Marked to zero': Paradigm testimony at SBF trial points to investor fraud,"The testimony of Matt Huang, co-founder and managing partner of crypto investment firm Paradigm, at Sam Bankman-Fried’s trial may help the prosecution convince jurors that the former crypto mogul defrauded investors.
Huang testified Thursday that he and his firm were in the dark about a range of business practices at FTX, red flags that would have affected his decision to invest in the company. Namely, FTX’s use of customer funds to prop up Bankman-Fried‘s hedge fund Alameda Research.
Government cooperation aside, Huang likely has his own motives for testifying against Bankman-Fried and distancing his firm from FTX. Paradigm is part of a class-action lawsuit (which was temporarily stayed in June) that accuses it, alongside Sequoia Capital and Thoma Bravo, of promoting FTX to the detriment of its users.
According to Huang’s testimony, Paradigm was duped, as well.
Over two funding rounds between 2021 and 2022, Paradigm invested $278 million into FTX. When prosecutor Thane Rehn asked what Paradigm estimates the current value of that investment to be, Huang replied, “We have marked it to zero.”
That establishes damage has been done in the form of financial losses, one of the things the prosecution will have to establish in order to prove fraud.
The government will also have to establish misrepresentation, showing that the defendant made false statements or concealed material information in order to convince investors to fork over money. Prosecutors also need to prove that the investors relied on Bankman-Fried’s misrepresentations. Finally, they’ll need to demonstrate that Bankman-Fried intended to defraud investors, which could be more difficult.
Huang’s testimony Thursday at least supports the establishment of three out of four of those elements.
Paradigm began considering investment into FTX in 2019, according to Huang. During that time, Huang testified that he was told FTX exchange wallets served as a custodian for customer deposits and would always be available if customers wished to withdraw. He wasn’t told that FTX could take those deposits out and use them for their own business purposes.
When asked if he would have still invested in FTX knowing that, Huang responded, “Likely not.”
“If it became known that they were doing that, I think the exchange would lose credibility in the brand and people wouldn’t want to use it, so it would be existential to the business,” said Huang.
Not only was Huang uninformed about FTX’s habit of using customer deposits for its own purposes, but he also testified that he didn’t know Alameda was able to access those deposits, and wouldn’t have invested in FTX if he had.
“Customer deposits are sort of sacred,” he said.
As Paradigm was considering investment into FTX, Huang said he raised concerns about the link between Alameda and FTX. Mainly, he was worried that Alameda — one of the largest traders on the platform — would get preferential treatment, which would also be damaging to FTX’s reputation.
Bankman-Fried told Huang Alameda didn’t have preferential treatment on the platform. But the prosecution pointed out that Alameda was exempt from FTX’s liquidation engine, a risk management strategy that’s designed to automatically trigger the sale of assets if certain risk parameters are exceeded.
Huang said FTX’s liquidation engine was a big part of why Paradigm was attracted to the company. He also agreed that Alameda’s exemption is inconsistent with Bankman-Fried’s statement that it didn’t get preferential treatment.
“It would have meant that Alameda could trade with leverage on the platform and, if those trades didn’t work out, could ultimately incur a negative balance that would have to be paid for somehow,” said Huang. “In a typical case, that might come from the money we were investing into the company that would go to fund operations. But in any case, it would leave the business at risk of becoming insolvent.”
Rehn also sought to establish that Bankman-Fried made false statements to lull Paradigm into investing. He pulled up an excel spreadsheet that had been attached to an email Bankman-Fried sent to Huang showing FTX’s financial stats as of April 2021. The balance sheet showed FTX’s annualized approximate revenue, estimating a net profit for Q1 2021 of $85 million. Rehn asserted that FTX had moved certain expenses off those financial statements in order to artificially inflate the reported net profits.
Throughout his testimony, Huang repeated that he had also expressed concerns with Bankman-Fried over FTX’s lack of a board and lack of governance, which he said could lead to unintended value leakage. While this did not ultimately stop Paradigm from investing in FTX, Huang testified that “SBF was very resistant to having investors on the board.”","https://techcrunch.com/wp-content/uploads/2023/10/GettyImages-1708738406.jpg?resize=1200,800",2023-10-06 03:35:40
https://techcrunch.com/2023/10/05/all-eyes-on-vw-after-hyundai-kia-adopt-tesla-charging-standard/,"All eyes on VW after Hyundai, Kia adopt Tesla charging standard","Hyundai and Kia have finally announced their plans to adopt Tesla’s North American Charging Standard (NACS) ports for their electric vehicles in the U.S. and Canada, joining the swells of automakers that have also promised to do so.
The move will give Hyundai and Kia drivers — as well as drivers of Ford, General Motors, Mercedes-Benz, Honda and Rivian vehicles — access to thousands of Tesla Superchargers across the two countries and Mexico.
As NACS seems to outstrip the Combined Charging System (CCS) as the new charging standard, the question on the auto industry’s mind is when will Volkswagen ante up?
In June, VW’s EV charging subsidiary Electrify America said it would add the NACS connector to Electrify America and Electrify Canada’s fast charging networks by 2025. Many thought that day wouldn’t happen, given how much money VW had to shell out to build that CCS-based charging network in the first place. VW poured $2 billion into building out the Electrify America (EA) as part of a settlement of the VW diesel emissions scandal.
Like most other charging companies, EA said it would continue to provide CCS connectors throughout its network, as well. And Tesla will include CCS connectors at some of its U.S. charging stations to reap some of the rewards of the Biden administration’s IRA subsidies. Tesla’s Supercharger network accounts for about 60% of fast chargers in the U.S., according to the Department of Energy.
Volkswagen didn’t respond in time to TechCrunch’s request for comment, but the company has been in talks with Tesla to adopt the NACS charge port on future vehicles since summer 2023. VW is one of the largest automakers in the world, representing brands like Audi, Bentley, Bugatti, Porsche and Lamborghini.
Over the next few years, under the VW brand, the automaker hopes to release a range of new EV models, including the 2024 ID.3, 2024 ID.7 and the 2025 ID.7 Wagon.
Most of the automakers that have signed up to build EVs equipped with NACS ports are aiming for 2025 models. Hyundai is aiming for even earlier.
The automaker said Thursday that new Hyundai EVs in the U.S. — like the Ioniq 5, Ioniq 6 and upcoming Ioniq 7 — will come with the NACS port starting in the fourth quarter of 2024. That will begin in Canada in the first half of 2025. Genesis, Hyundai’s luxury brand, will also jump on the NACS train.
Kia also said it would build the NACS port into new EVs sold in North America in the fourth quarter of 2024.
Both Hyundai and Kia said they expect to have adapters available at dealers in the first quarter of 2025, for customers who own vehicles with CCS ports.
Tesla’s NACS is quickly becoming the industry standard, in part due to Tesla’s already strong footprint of Superchargers at good locations along highways. EV drivers also say Tesla offers a more streamlined and simpler charging process.
In late June, SAE International, formerly the Society of Automotive Engineers, said it would develop an industry standard around NACS, which would assuage other companies wary of letting a competitor control a key part of the EV experience.","https://techcrunch.com/wp-content/uploads/2023/06/GettyImages-1252172149.jpg?resize=1200,736",2023-10-05 23:17:53
https://techcrunch.com/2023/10/05/a16z-backed-castelion-wants-to-mass-produce-defense-hardware-starting-with-hypersonics/,"a16z-backed Castelion wants to mass produce defense hardware, starting with hypersonics","One builds weapons in hopes that they are not used. Thus goes the central premise of deterrence theory, which says it is the credible threat of aggression — not the use of aggression — that will ensure states avoid war.
This theory has dominated much of America’s strategic thinking over the past 50-plus years, but new technologies and new adversaries threaten to upend the status quo. For the first time, China has started to outpace the U.S. in critical weapons programs — the country developed a new type of weapon called a hypersonic glide vehicle as early as 2014, which can strike Taipei and the Taiwan Strait in about 20 minutes from the country’s strategic bases in the South China Sea. America’s comparative sluggishness to develop such tech could result in the U.S. falling catastrophically behind its adversaries.
The founders of Castelion, a startup that emerged from stealth this week, cut straight to the point: “Simply put — this cannot be allowed to happen.”
The 11-month-old defense startup wants to completely rethink defense hardware development for complex systems, starting with long-range strike hypersonic weapons, a capability that Castelion co-founder and CEO Bryon Hargis called “a national, strategic-level non-nuclear deterrent.”
“China is going faster than us in basically every area,” he said. “They pass the U.S. in some areas, but if you give them enough time, they’re going to pass us in all areas if we don’t do something different. It’s, in my opinion, existential. We grew up in an era of fairly good security and I don’t know necessarily that our children are to have that opportunity if somebody doesn’t do something about it.”
Making American deterrence credible again
Castelion was founded by a trio of ex-SpaceXers, Bryon Hargis, Sean Pitt and Andrew Kreitz, in November 2022. The company is part of a wave of new defense tech startups that have little faith in large American primes and their ability to ensure the country retains its dominant position in the global asymmetry of military power.
In a blog post announcing Castelion, the trio say as much, writing that conditions in the defense industrial base, like consolidation, production delays and ballooning program costs, “have left our nation in a worse position to protect democracy and confront our adversaries around the world.”
The startup wants to do things differently: move faster, design hardware to be produced at scale, and vertically integrate to cut costs. Pitt said that long-range strike weapons were a clear opportunity for an agile hardware development approach.
Its thesis has caught investor support, with the company closing a $14.2 million initial funding round co-led by Andreessen Horowitz and Lavrock Ventures, with participation from First In, BlueYard Capital and Champion Hill Ventures.
Castelion’s founding team is notable for their individual success in the aerospace industry. Hargis, a mechanical engineer by training, joined SpaceX in 2017 and eventually became a senior director of government sales, essentially building out an entire government sales team and that enormous line of business for the company; Pitt was the original salesperson for SpaceX’s hugely successful ride-share program and eventually became director of launch and human spaceflight sales for the European continent; and Kreitz was a senior investment banker at Goldman Sachs before joining SpaceX as senior finance manager.
Hargis and Pitt worked alongside each other at SpaceX’s D.C. office, and Hargis and Kreitz worked directly together regarding finance matters. The three would talk on the evenings and weekends, Pitt said, and the thesis for the company started forming. It was clear that they would have to leave SpaceX if they wanted to focus on defense hardware: SpaceX is not a defense company, even if its technologies do much to serve the national interest.
“SpaceX is fundamentally a Mars company,” Kreitz said. “It will do great defense work if it’s along that development path, but [it] isn’t core, and that’s what precipitated us leaving.”
Hargis echoed these comments: “I think we did some amazing work at SpaceX for national security that will continue to pay dividends for the country for probably multiple decades to come. But I really wanted to be more focused on defense than SpaceX wanted to be.”
Castelion is kicking off its focus on hypersonic missile systems. The U.S. wants to procure these capabilities for a handful of reasons, many of which have to do with the particulars of the Western Pacific theater. These systems offer a big boost in range without a commensurate energy cost, which is critical for safely covering the roughly 1,800 miles between the U.S. territory of Guam and the coast of China. As two officials from the U.S. Department of Defense put it in a recent op-ed, all of the missiles in America’s arsenal “appropriate for the Western Pacific theater” will need to fly at Mach speeds.
Hypersonic missiles are also highly maneuverable, which makes it difficult to predict where they will strike. But perhaps most importantly, they offer a non-nuclear deterrence option — a way for both the United States and China to avoid a severely catastrophic outcome that both countries have vowed to avoid via the adoption of no-first use policies.
Of course, Castelion can’t simply turn up on Uncle Sam’s doorstep one day with a fully finished hypersonic weapon and a bill. Instead, the El Segundo, California–based startup is taking time to build its credibility with missile subsystems: solid rocket motors, low-cost avionics and ultra-high temperature ceramic matrix composite (CMC) materials. The idea is to first become a supplier to a prime working on an existing hypersonic missile program, before eventually building complete missile systems all in-house.
Because rapid design-build-test cycles are built into the company’s strategic mission, the company is also focused on building a hypersonic test platform both for customers looking to test and for in-house testing.
Castelion’s primary engineering efforts, which include developing the avionics and manufacturing the high-temperature CMCs, are taking place in El Segundo. Castelion also has a special use permit for outside of Naval Air Station Fallon in Nevada to do rocket motor production and testing. Looking ahead, the company plans on conducting its first full flight test of its solid motors using a single-stage rocket later this year, and the company plans on scaling its materials testing, starting with a subscale hypersonic glide vehicle shell to demonstrate that it can make complex shapes using the CMC material.
Next year, the 15-person company is planning on making a two-stage test vehicle. It also plans on executing out its three government contracts (the details of which the company couldn’t disclose) and to continue building out its team. It’s more than a little ambitious.
“We’re fairly used to being called crazy,” Hargis joked. “I could see it from the outside, being slightly skeptical, but I think that after you’ve done several crazy things successfully, you realize it’s not crazy to dream big.”","https://techcrunch.com/wp-content/uploads/2023/10/image003.jpg?resize=1200,800",2023-10-05 22:30:01
https://techcrunch.com/2023/10/05/sbf-trial-gary-wang/,Alameda had a $65B line of credit and 'unlimited withdrawals',"The Sam Bankman-Fried trial gained steam after a somewhat sleepier first half of the day. That’s when prosecutors and the defense asked a witness and former FTX developer about the technical details of the crypto exchange as well as Alameda Research.
But that changed around 4 p.m. when FTX co-founder and CTO Gary Wang took the stand, wearing a wrinkled suit. Prior to Wang taking the stand, there was a 15-minute break during which Bankman-Fried looked visibly irritated.
Bankman-Fried’s parents were also there. During the break, they went to their son seemingly in an effort to provide support. At one point his father, Joseph Bankman, patted his mother, Barbara Fried, on the back, said something and laughed. She didn’t laugh back but continued to look away toward her son.
On the stand, Wang admitted that he committed wire fraud, securities fraud and commodities fraud. He added that Bankman-Fried, Nishad Singh and Caroline Ellison were the individuals he committed the crimes with.
Wang, Singh and Ellison pleaded guilty in late December 2022 as part of a deal to cooperate with the government and testify during this trial.
Wang said that they were given “special privileges from Alameda Research,” the crypto trading firm that he said he and Bankman-Fried started prior to launching FTX. Those privileges included getting large lines of credit, unlimited withdrawals and being able to have negative balances. Wang said that the “unlimited funds” came from FTX customers; a special code was added to customer transactions that funneled the money to Alameda.
He shared during his testimony that he was in charge of writing and reviewing code. And while Bankman-Fried did not write the code, Wang said Bankman-Fried did tell him and other developers what to implement. “Sometimes we talked [disagreements] out, but in the end, it’s Sam’s decision,” Wang said.
Negative balances, unlimited withdrawals
Because of these special privileges, Alameda had a $65 billion line of credit, Wang said. “Normal large businesses have single to double digits [of credit] in the millions.” By the time the two businesses filed for bankruptcy in mid November 2022, Alameda withdrew $8 billion, Wang said.
These internal financial advantages were not disclosed to the public, he shared.
Alameda and FTX were both started by Bankman-Fried and Wang, with ownership split 90% and 10%, and then 17% equity and 65% equity, respectively. Singh also had 5% equity of FTX, and a number of outside investors held other positions, Wang noted.
The ownership percentages never changed, he added. At the time, both Wang and Bankman-Fried were billionaires.
During his time at the companies, Wang also disclosed that Alameda “loaned” him around $200 million to $300 million. But the money never went to his bank account, and it instead went to investments that FTX made into other companies.
Naming the business
The company also picked its name to outsmart other businesses, which might have negative connotations toward companies with crypto jargon in their titles. “Alameda” derived from Alameda County in California and “Research,” was because it “sounds prestigious” and is not using a crypto-related name, Wang said.
The initial funds for Alameda came from Bankman-Fried personally as well as various lenders. Wang said Bankman-Fried also believed it would be easier to get bank accounts, rental leases, investors and so on, with a more “normal” company name.
The prosecutors aired a clip of Bankman-Fried from April 2021 on a podcast, where he explained Alameda’s name. “If we named our company Shitcoin Day Trader’s Inc., no one would do business [with us],” he said at the time.
Wang’s testimony is expected to continue on Friday morning until midday, according to prosecutors at the trial.","https://techcrunch.com/wp-content/uploads/2022/11/ftx-broken-on-fire.jpg?resize=1200,645",2023-10-05 21:35:03
https://techcrunch.com/2023/10/05/spyhide-oospy-hacked-phone-spyware-shuts-down/,Hacked phone spyware shuts down… again,"A short-lived spyware operation called Oospy, which emerged earlier this year after its predecessor Spyhide was hacked, is no longer operational and has shut down.
Oospy appeared online in late July as a rebrand of a phone monitoring app called Spyhide, which was facilitating the surveillance of tens of thousands of Android device owners around the world. Spyhide shut down after a breach exposed the operation and its administrators who were profiting from it.
Although Spyhide’s website disappeared from the internet after the hack burned the operation, the spyware’s back-end server stayed online and was still communicating with the tens of thousands of phones it was monitoring since the server was hosted on an entirely different domain. That allowed the administrators to rebrand Spyhide to Oospy without affecting the spyware operation itself.
That back-end server, which stored the victim’s stolen phone data from thousands of Android devices around the world, was taken offline Thursday by the web host Hetzner, which said the service violated its terms of service.
“In addition, we have terminated the customer’s server contract in due time,” Christian Fitz, a spokesperson for Hetzner, told TechCrunch.
In their time online, Spyhide and Oospy had at least 60,000 victims across the world, including thousands of victims in the United States. These stalkerware (also known as spouseware) apps are planted on a victim’s phone, often by someone with knowledge of their passcode. Once planted, these apps continually steal a victim’s contacts, messages, photos, call logs and recordings, and granular location history.
Following the Spyhide hack, TechCrunch identified two of the administrators behind Spyhide and Oospy. One of the administrators, Mohammad (also goes by Mojtaba) Arasteh, confirmed to TechCrunch that he worked on the project “several years ago as a programmer,” but denied involvement with Oospy.
But a mistake on Oospy’s checkout page, which used PayPal to process customer payments, exposed the name of the PayPal account holder, who shares the same family name as Arasteh.
It’s not uncommon for spyware operations to rely on payment services like PayPal to handle customer payments, despite PayPal’s policies broadly prohibiting customers from using its service to buy or sell software that facilitate illegal activity, like spyware. PayPal spokesperson Caitlin Girouard did not comment on the accounts when reached by TechCrunch. Oospy stopped accepting PayPal for payments a short time later, though it’s not known if PayPal took action against the account.
Arasteh did not comment on the PayPal account when contacted by TechCrunch. Soon after contacting Arasteh, Oospy’s website went offline altogether.
The shutdown of the spyware’s back-end server marks the end of Spyhide and Oospy’s ability to operate, for now.
Oospy and Spyhide are the latest phone surveillance operations to drop off the internet in recent months. Polish-made stalkerware LetMeSpy shut down after an earlier data breach in June. And last year, one of the largest known Android spyware apps, SpyTrac, disappeared following a TechCrunch investigation linked the spyware operation to Support King, which was banned from the surveillance industry by the FTC following an earlier data breach.","https://techcrunch.com/wp-content/uploads/2021/09/android-spyware-malloc.jpg?resize=1200,751",2023-10-05 21:15:51
https://techcrunch.com/2023/10/05/sec-to-compel-elon-musks-testimony-in-twitter-stock-purchase-probe/,SEC to compel Elon Musk's testimony in Twitter stock purchase probe,"The U.S. Securities and Exchange Commission will try to force Elon Musk to testify over his Twitter stock purchases.
The federal agency charged with regulating securities markets is currently investigating Musk for allegedly violating securities laws when he bought Twitter shares before buying the social media platform, which he has since renamed X.
Buying Twitter stock before acquiring the company could mean Musk was guilty of insider trading, market manipulation or even violation for fair market disclosure.
The SEC said on Thursday that Musk failed to appear to testify last month as requested. According to a filing by the agency in federal court in San Francisco, first spotted by Bloomberg, the agency is auditing Musk’s statements and disclosures about the stock transactions.
Since the SEC began its probe in April 2022, Musk has sent hundreds of documents and testified twice in July 2022, according to the filing. The investigation is ongoing and nonpublic.
The agency said Musk agreed to an interview with the SEC last month in San Francisco, but two days before the scheduled September 15 meeting, the billionaire raised objections, saying San Francisco wasn’t a good location for it. He has claimed that San Francisco jurors dislike him after a questionnaire sent out to 200 prospective jurors came back with majority negative opinions of Musk.
The SEC suggested moving the interview to Fort Worth, Texas, where Musk resides, but the agency says he refused to meet at all.
This isn’t Musk’s first tussle with the SEC. Famously, the Tesla CEO has been ordered to have a lawyer review his Tesla-related tweets after Musk tweeted in 2018 that he had “funding secured” to take Tesla private for $420 per share and that investor support for the deal was confirmed. Tesla’s share price fluctuated in the weeks that followed, which prompted an SEC investigation into whether Musk had committed securities fraud.
The SEC is also investigating Musk and Tesla over their claims regarding Tesla vehicles’ “full self-driving” capabilities, as well as Tesla’s use of company funds to build Musk a “glass house.“","https://techcrunch.com/wp-content/uploads/2023/05/GettyImages-1234732042.jpg?resize=1200,675",2023-10-05 21:15:11
https://techcrunch.com/2023/10/05/stoke-space-raises-100m-series-b-as-it-looks-to-reach-orbit-by-2025/,Stoke Space raises $100M Series B as it looks to reach orbit by 2025,"Stoke Space is flying high. Fresh on the heels of a successful test of its reusable second stage, the four-year-old startup announced today that it closed $100 million in new funding led by Industrious Ventures.
This newest round of funding included participation from the University of Michigan, Sparta Group, Long Journey and other investors. Existing investors Breakthrough Energy, Y Combinator, Point72 Ventures, NFX, MaC Ventures, Toyota Ventures and In-Q-Tel also participated. Stoke has now raised $175 million to date, including a $65 million Series A the company closed in December 2021.
Stoke said it would use the new capital to fund the development of its first rocket, which the company has finally christened, giving it the name “Nova.” That includes the development of the first-stage engine and structure, an orbital version of the second stage and building out launch infrastructure at Cape Canaveral in Florida.
The company recently completed a critical “hop” test of its reusable upper stage, successfully flying the development vehicle to an altitude of around 30 feet and vertically landing it about 15 feet away. While those numbers might seem unimpressive on the face of it, the hop proved out the stage’s novel oxygen-hydrogen rocket engine design. Unlike other nozzled rocket engines, the one on Stoke’s second stage is a distributed system, with thrusters that ring the circumference of the second stage.
The flight essentially concluded the development cycle of the second stage, meaning that the architecture is now complete and the company can move on to the rest of the vehicle’s structure. As Stoke co-founder CEO Andy Lapsa told TechCrunch last month, the company had to finalize the architecture of the second stage before building out the rest of the vehicle.
“The first step on our journey was figuring out what a fully reusable upper stage and space vehicle looks like,” he said. “We really believe that it’s hard to build the rest of the vehicle until you know an answer. So that’s why a lot of our focus so far has been on the reusable second stage.”
The company also announced that multinational chemical company Linde plc’s chairman, Steve Angel, will join Stoke’s board of directors. Angel is the former CEO of Linde and also sits on the board of GE.
The new funding will no doubt aid the company as it looks to conduct its first orbital flight test in 2025.
“We are pushing really hard to get to orbit by 2025,” Lapsa said. “There are some interesting opportunities there to do things even before that. That’s our target. We’re going to step back from this a little bit, recalibrate, crystallize our plan. We do have a plan. We’re just going to get more energy behind it and then get back to knocking off milestones.”","https://techcrunch.com/wp-content/uploads/2023/09/20230917-DSC_0796.jpg?resize=1200,797",2023-10-05 21:00:42
https://techcrunch.com/2023/10/05/lawsuit-alleges-discriminatory-pay-schemes-at-spacex/,Lawsuit alleges discriminatory pay schemes at SpaceX,"SpaceX is facing a class action lawsuit over allegations that the company pays women and minority employees less than their white and male colleagues.
The lawsuit was filed on Tuesday in Los Angeles Superior Court by SpaceX engineer Ashley Foltz, who says she was hired at a salary of $92,000, even though men with similar or less experience were offered as much as $115,000. According to her LinkedIn, Ashley was hired in September 2022 as a propulsion engineer. She did not immediately respond to TechCrunch’s request for comment.
According to the complaint, Foltz learned about the salary discrepancies when a new California law went into effect requiring employers to include pay scale in their job postings. The salary range for her job was $95,000 to $115,000, so SpaceX gave her a raise — but only to the lowest end of the band.
The lawsuit further alleged that job titles — like “technical writer” versus “engineer 1” — are used as a way to pay women and minorities lower pay. For example, these groups “are forced to work as engineers under a different title of technical writer” and are subsequently paid less, the complaint says. Promotion rates also differ between woman and minorities and their white and male peers, it says.
This is not the first time claims of discriminatory hiring and promotion practices have been lobbed at SpaceX. In August, the U.S. Department of Justice brought a suit against the company for allegedly discriminating against asylum recipients and refugees in hiring under the guise of adhering to export control laws.","https://techcrunch.com/wp-content/uploads/2023/10/GettyImages-1230844804.jpg?resize=1200,800",2023-10-05 20:10:50
https://techcrunch.com/2023/10/05/how-to-stretch-your-venture-dollars/,How to stretch your venture dollars,"I didn’t know exactly where I was driving, but the sun was setting behind a field full of cows, the battery in my hybrid was nearly depleted, and the fuel light was blinking. I needed a plan.
Despite intermittent cell phone service, I navigated to a gas station, driving 5 miles per hour the entire way. If you’re managing runway at a seed-stage or Series A startup in Q3 2023, that’s what English majors call an allegory.
Follow-on financing is hard to raise these days, which means founders must watch their spending like hawks while keeping the peace with their investors like sweet, cooing doves.
Which proofs are investors looking for before they’ll commit to additional funding, what’s an acceptable burn rate, and how much runway do you need before raising more? At TechCrunch Disrupt, I spoke to three early-stage VCs to get their unfiltered advice for founders who are trying to keep the lights on long enough to reach product-market fit:
Anamitra Banerji, managing partner and founder, Afore Capital
Frédérique Dame, general partner, Google Ventures
Rick Yang, partner and head of technology, NEA
When is it time to start raising your next round?
If you haven’t found traction with customers and aren’t generating revenue, you should be in fundraising mode already.
“Pre product-market fit, you want to have as much runway as possible because that’s really the goal of being a seed stage startup,” Yang said. “It used to be [that] maybe you have six months of runway left, and you go and raise your next round. Now, more is better because of the market being a little bit more volatile.”
If you haven’t found traction with customers and aren’t generating revenue, you should be in fundraising mode already.
Series A fundraising “is much trickier now,” Dame said. “If you don’t have the right vision and the right unit economics, it’s really hard to raise the next round.” These days, it’s not enough to simply show “your path to profitability,” she added. “This is really an exercise of building great partnerships with investors so when you set up to raise, it makes it easier for you.”
A pre-seed startup generally needs at least 18 months of runway, Banerji said. “It allows you to make a number of tries without overhiring, pivot if you need to, [and] essentially figure out [how to get from] the first five customers to a pathway to a million ARR.”
Follow-on funding is a challenge, “but there’s a lot of capital available now, just from angels or just from pre-seed or seed funds,” he added. “So getting to $500K to $2 million is very achievable in a couple of months’ time frame.”
Every panelist agreed that a founder should know their burn rate and remaining cash balance off the top of their head: “It gives me a lot of comfort when they have basically thought about and are marinating and are obsessing over every aspect of their business,” Yang said.","https://techcrunch.com/wp-content/uploads/2023/10/53204504241_835307ecce_k.jpg?resize=1200,800",2023-10-05 19:44:09
https://techcrunch.com/2023/10/05/hungryroot-founder-debuts-every-an-ai-powered-app-for-self-reflection-and-human-connection/,"Hungryroot founder debuts Every, an AI-powered app for self-reflection and human connection","As founder and CEO of healthy grocery delivery service Hungryroot, Ben McKean has been investigating the power of AI technologies to improve his business. But with the launch of his new side project — an app called Every — McKean wants to explore the use of AI to help people establish deeper relationships with themselves and others and to find common ground.
Currently structured as a nonprofit, Every’s iOS app leverages AI technologies to create “thought-provoking games” aimed at self-discovery.
For example, all users begin with a game called “Inner Odyssey” that challenges you to pick a photo that best represents the place you’d like to explore, from options like a cobblestoned city street, a natural landscape featuring a river and trees, a fantastical castle, or a remote island. You’re then asked follow-up questions like who would you travel with, what role would you play, what advice for your trip resonates with you best and so on.
As you play, the app shows you how others respond to the same question, and when you finish you’re prompted to see who among your connections — that is, your uploaded contact list — also answered similarly.
McKean says the idea to create an app focused on human connection was an idea that’s been brewing for some time — particularly after the COVID pandemic led to a world where everyone felt more disconnected than ever.
“There’s a very large number of people who feel disconnected from even people very close to them,” he explains. “Fifty-eight percent of Americans report feeling like no one in their life knows them well, which was just a shocking stat. And 70% of Americans feel that distrust is hurting American society,” McKean notes, citing various stats on the loneliness epidemic and connection.
In addition, McKean says he also feels impacted by these issues through his own entrepreneurial experiences leading teams and finding how difficult it can be to form connections at work. In fact, McKean foresees the potential to tweak Every’s model for use in the workplace to help colleagues bond, but with fewer personal questions.
Despite the app’s focus on human connectivity, it may be a surprise, then, to learn that Every’s games were created using AI — specifically, by training large language models and leveraging technology from OpenAI and Midjourney. In addition to scratching his own itch, so to speak, McKean said this process helped him to develop his AI skills, which could impact his main business at Hungryroot, which is a heavily AI-driven company.
All the games in the app are inspired by a topic or a person, which is the initial input for the AI.
For the latter, the company is partnering with inspirational leaders for some of the topics, like Hector Guadalupe, founder of A Second U Foundation, which helps people develop skills to be successful in life after serving time in prison. The topic or the person is used to set the context for the generative AI. Then the team uses a structured format for the games they built into the prompts to create the questions. (Guadalupe’s AI-inspired game will release on October 25).
The AI’s output may still need some human intervention as the team has only been training their models for six months, McKean notes, but essentially, the AI creates the games in their entirety. The images that accompany the game’s questions are then created using Midjourney.
The plan is to release one new game every day — hence the app’s name — with each day of the week having a particular theme. For example, Monday’s games may be focused on careers, while Friday’s games may be about fun, Saturday’s games may be about family connections, and Sunday’s are about spirituality or philosophy. McKean says Every also intends the games to be tailored to timely events. So in the case of the upcoming presidential elections, you might see a game tied to politics, for example.
After playing the games, the app offers inspirational content to explore based on your responses, like videos that highlight particular topics — like pursuing your dreams or the importance of creativity.
Another tab in the app, “Map,” uses AI to generate a map of your traits based on the points you earn while playing Every’s games. After trying out the first game, the map informed me my top traits included things like reason and happiness in the simplest things, which I don’t think I’d dispute. You can also thumbs up and thumbs down its findings if you agree or disagree to improve its analysis.
The idea is that, by playing these games, you aren’t only developing more self-awareness, you’re also learning how you share common ground with other people you know, which could lead you to deepen those relationships. For instance, you might find an old friend also enjoys international travel or your colleague prioritizes humility in the workplace. As you learn from the insights the app shares, you may be inspired to take further action, like engaging in conversations about your discoveries.
“A lot of the mission around this is about facilitating connection with people — one to one connection — but it’s also about helping to surface common ground a little more holistically,” McKean says. “And so part of the belief is that if you present the same game to every single person, you’re able to actually find common ground between two people who may be very different people.”
Every was self-funded by McKean and is run by two women, Sarah McKean (Ben’s cousin) and Maya Valliath, while app development was handled through an outsourced firm. The plan for now is to run Every as a free app and side project. But if it takes off, McKean is leaving the door open to scale it as more of a business, potentially with investor backing.
The app has been running in beta since March, but today launched publicly on the App Store. It’s available as a free download with no in-app purchases.",https://techcrunch.com/wp-content/uploads/2023/10/every-app.jpeg?w=800,2023-10-05 19:17:51
https://techcrunch.com/2023/10/05/future-of-ai-survey/,10 investors talk about the future of AI and what lies beyond the ChatGPT hype,"10 investors talk about the future of AI and what lies beyond the ChatGPT hype
When I mentioned “the rise of AI” in a recent email to investors, one of them sent me an interesting reply: “The ‘rise of AI’ is a bit of a misnomer.”
What that investor, Rudina Seseri, a managing partner at Glasswing Ventures, means to say is that sophisticated technologies like AI and deep learning have been around for a long time now, and all this hype around AI is ignoring the simple fact that they have been in development for decades. “We saw the earliest enterprise adoption in 2010,” she pointed out.
Still, we can’t deny that AI is enjoying unprecedented levels of attention, and companies across sectors around the world are busy pondering the impact it could have on their industry and beyond.
Dr. Andre Retterath, a partner at Earlybird Venture Capital, feels several factors are working in tandem to generate this momentum. “We are witnessing the perfect AI storm, where three major ingredients that evolved throughout the past 70 years have finally come together: Advanced algorithms, large-scale datasets, and access to powerful compute,” he said.
Still, we couldn’t help but be skeptical at the number of teams that pitched a version of “ChatGPT for X” at Y Combinator’s winter Demo Day earlier this year. How likely is it that they will still be around in a few years?
Karin Klein, a founding partner at Bloomberg Beta, thinks it’s better to run the race and risk failing than sit it out, since this is not a trend companies can afford to ignore. “While we’ve seen a bunch of ‘copilots for [insert industry]’ that may not be here in a few years, the bigger risk is to ignore the opportunity. If your company isn’t experimenting with using AI, now is the time or your business will fall behind.”
And what’s true for the average company is even more true for startups: Failing to give at least some thought to AI would be a mistake. But a startup also needs to be ahead of the game more than the average company does, and in some areas of AI, “now” may already be “too late.”
To better understand where startups still stand a chance, and where oligopoly dynamics and first-mover advantages are shaping up, we polled a select group of investors about the future of AI, which areas they see the most potential in, how multilingual LLMs and audio generation could develop, and the value of proprietary data.
This is the first of a three-part survey that aims to dive deep into AI and how the industry is shaping up. In the next two parts to be published soon, you will hear from other investors on the various parts of the AI puzzle, where startups have the highest chance of winning, and where open source might overtake closed source.
We spoke with:
Manish Singhal, founding partner, pi Ventures
Will today’s leading gen AI models and the companies behind them retain their leadership in the coming years?
This is a dynamically changing landscape when it comes to applications of LLMs. Many companies will form in the application domain, and only a few will succeed in scaling. In terms of foundation models, we do expect OpenAI to get competition from other players in the future. However, they have a strong head start and it will not be easy to dislodge them.
Which AI-related companies do you feel aren’t innovative enough to still be around in 5 years?
I think in the applied AI space, there should be significant consolidation. AI is becoming more and more horizontal, so it will be challenging for applied AI companies, which are built on off-the-shelf models, to retain their moats.
However, there is quite a bit of fundamental innovation happening on the applied front as well as on the infrastructure side (tools and platforms). They are likely to do better than the others.
Is open source the most obvious go-to-market route for AI startups?
It depends on what you are solving for. For the infrastructure layer companies, it is a valid path, but it may not be that effective across the board. One has to consider whether open source is a good route or not based on the problem they are solving.
Do you wish there were more LLMs trained in other languages than English? Besides linguistic differentiation, what other types of differentiation do you expect to see?
We are seeing LLMs in other languages as well, but of course, English is the most widely used. Based on the local use cases, LLMs in different languages definitely make sense.
Besides linguistic differentiation, we expect to see LLM variants that are specialized in certain domains (e.g., medicine, law and finance) to provide more accurate and relevant information within those areas. There is already some work happening in this area, such as BioGPT and Bloomberg GPT.
LLMs suffer from hallucination and relevance when you want to use them in real production-grade applications. I think there will be considerable work done on that front to make them more usable out of the box.
What are the chances of the current LLM method of building neural networks being disrupted in the upcoming quarters or months?
It can surely happen, although it may take longer than a few months. Once quantum computing goes mainstream, the AI landscape will change significantly again.
Given the hype around ChatGPT, are other media types like generative audio and image generation comparatively underrated?
Multimodal generative AI is picking up pace. For most of the serious applications, one will need those to build, especially for images and text. Audio is a special case: There is significant work happening in auto-generation of music and speech cloning, which has wide commercial potential.
Besides these, auto-generation of code is becoming more and more popular, and generating videos is an interesting dimension — we will soon see movies completely generated by AI!
Are startups with proprietary data more valuable in your eyes these days than they were before the rise of AI?
Contrary to what the world may think, proprietary data gives a good head start, but eventually, it is very difficult to keep your data proprietary.
Hence, the tech moat comes from a combination of intelligently designed algorithms that are productized and fine-tuned for an application along with the data.
When could AGI become a reality, if ever?
We are getting close to human levels with certain applications, but we are still far from a true AGI. I also believe that it is an asymptotic curve after a while, so it may take a very long time to get there across the board.
For true AGI, several technologies, like neurosciences and behavioral science, may also have to converge.
Is it important to you that the companies you invest in get involved in lobbying and/or discussion groups around the future of AI?
Not really. Our companies are more targeted toward solving specific problems, and for most applications, lobbying does not help. It’s useful to participate in discussion groups, as one can keep a tab on how things are developing.
Rudina Seseri, founder and managing partner, Glasswing Ventures
Will today’s leading gen AI models and the companies behind them retain their leadership in the coming years?
The foundation layer model providers such as Alphabet, Microsoft/OpenAI and Meta will likely maintain their market leadership and function as an oligopoly over the long-term. However, there are opportunities for competition in models that provide significant differentiation, like Cohere and other well-funded players at the foundational level, placing a strong emphasis on trust and privacy.
We have not invested and likely will not invest in the foundation layer of generative AI. This layer will probably end in one of two states: In one scenario, the foundation layer will have oligopoly dynamics akin to what we saw with the cloud market, where a select few players will capture most of the value.
The other possibility is that foundation models are largely supplied by the open source ecosystem. We see the application layer holding the biggest opportunity for founders and venture investors. Companies that deliver tangible, measurable value to their customers can displace large incumbents in existing categories and dominate new ones.
Our investment strategy is explicitly focused on companies offering value-added technology that augments foundation models.
Just as value creation in the cloud did not end with the cloud computing infrastructure providers, significant value creation has yet to arrive across the gen AI stack. The gen AI race is far from over.
Which AI-related companies do you feel aren’t innovative enough to still be around in 5 years?
A few market segments in AI might not be sustainable as long-term businesses. One such example is the “GPT wrapper” category — solutions or products built around OpenAI’s GPT technology. These solutions lack differentiation and can be easily disrupted by features launched by existing dominant players in their market. As such, they will struggle to maintain a competitive edge in the long run.
Similarly, companies that do not provide significant business value or do not solve a problem in a high-value, expensive space will not be sustainable businesses. Consider this: A solution streamlining a straightforward task for an intern will not scale into a significant business, unlike a platform that resolves complex challenges for a chief architect, offering distinct and high-value benefits.
Finally, companies with products that do not seamlessly integrate within current enterprise workflows and architectures, or require extensive upfront investments, will face challenges in implementation and adoption. This will be a significant obstacle for successfully generating meaningful ROI, as the bar is far higher when behavior changes and costly architecture changes are required.","https://techcrunch.com/wp-content/uploads/2023/09/GettyImages-1477386306.jpg?resize=1200,679",2023-10-05 19:15:45
https://techcrunch.com/2023/10/05/following-the-sbf-trial-3ac-arrest-and-q3-web3-funding-drops/,"Following the SBF trial, 3AC arrest and Q3 web3 funding drops","Welcome back to Chain Reaction.
To get a roundup of TechCrunch’s biggest and most important crypto stories delivered to your inbox every Thursday at 12 p.m. PT, subscribe here.
I’ve been taking a bit of an electronics detox, meaning I haven’t been looking at my phone — or laptop — for most of this week. As a reporter, that seems ridiculous. But when I say I’ve spent the past few days in the Southern District of New York (SDNY) federal court, that might make more sense, given that they confiscate most people’s electronics (as I learned, this includes AirPods!).
The SDNY is becoming a second home for me because the highly anticipated trial for Sam Bankman-Fried, often referred to as SBF, has begun. If you don’t know who he is or what he’s allegedly done, we’ve got a refresher for you.
Before FTX collapsed and filed for bankruptcy, Bankman-Fried also apparently had a plan to buy off former President Trump, to get him to not run for re-election, author Michael Lewis shared in a 60 Minutes broadcast interview. How much would that cost? Apparently, $5 billion.
I’ll be in-and-out of the courthouse over the next six weeks, following the trial closely. Prosecutors shared that Matt Huang, co-founder and managing partner of Paradigm, and Gary Wang, co-founder of FTX, are on the docket to testify this week as witnesses.
Prior to Paradigm, Huang was a partner at Sequoia Capital; both firms previously invested in FTX, so we imagine the testimony will dive into investors’ losses from the crypto exchange’s downfall.
As for Wang, well, he co-founded FTX with Bankman-Fried but agreed to take a plea deal in December 2022. This means Wang is cooperating with authorities in exchange for a better sentencing, which the judge presiding over the case mentioned to jurors on Wednesday.
For the most in-depth trial coverage to date, check out everything that has transpired below.
The SBF Trial
This week in web3
The latest pod
For this week’s episode, Chain Reaction (and Jacquelyn) did a crossover episode with Alex Wilhelm, editor in chief of TechCrunch+ and co-host of Equity, TechCrunch’s podcast focused on the business of startups.
The highly anticipated criminal trial for Sam Bankman-Fried, former CEO of now-bankrupt crypto exchange FTX, started on Tuesday to determine whether he’s guilty of seven counts of fraud and conspiracy.
Jacquelyn has been on the ground at the Southern District of New York courthouse, listening in to the trial in the same room as Bankman-Fried, so there was lots to talk about.
We dove deep into what transpired the first two days of Bankman-Fried’s trial, as well as who the jurors are, the first two witnesses and who else is expected to speak. We also got into the nitty-gritty details, which you can’t read about on a transcript.
Subscribe to Chain Reaction on Apple Podcasts, Spotify or your favorite pod platform to keep up with the latest episodes, and please leave us a review if you like what you hear!
Follow the money
Resy and Eater co-founder raises $24 million for Blackbird, a restaurant loyalty platform Web3 social app Phaver raised $7 million from Polygon Ventures and others Cicada, a credit risk firm focused on blockchain infrastructure, raised $9.7 million DeFi derivative lending platform ParaFinance raised $5 million Web3 esports startup NexGami raised $2 million in seed funding
This list was compiled with information from Messari as well as TechCrunch’s own reporting.
What else we’re writing
Want to branch out from the world of web3? Here are some articles on TechCrunch that caught our attention this week.
Follow me on Twitter @Jacqmelinek for breaking crypto news, memes and more.","https://techcrunch.com/wp-content/uploads/2022/11/GettyImages-1238326571.jpg?resize=1200,675",2023-10-05 19:00:13
https://techcrunch.com/2023/10/05/paypal-faces-new-antitrust-lawsuit-claiming-it-unfairly-stifles-competition-with-stripe-shopify-and-more/,"PayPal faces new antitrust lawsuit claiming it unfairly stifles competition with Stripe, Shopify and more","PayPal has been hit with a class action lawsuit by consumers represented by law firm Hagens Berman alleging that the fintech giant’s anti-steering rules stifle competition against lower-cost payment platforms such as Stripe and Shopify.
Specifically, according to an investigation conducted by the firm’s consumer rights attorneys, PayPal has subjected consumers to excess charges when purchasing from online merchants that accept PayPal or Venmo.
The suit states that PayPal’s merchant agreements, which all merchants must sign to accept payments via its platform, leads to consumers paying more to make purchases. The attorneys charge that “if PayPal’s agreements were transparent, consumers would quickly see a price difference between PayPal and Venmo and its competitors.”
Specifically, per PayPal’s anti-steering rules, if a retailer accepts PayPal or Venmo payments, they agree not to offer any discounts or inducements to persuade consumers to use other payment options that have a lower cost. These discounts are treated as a “surcharge” on PayPal transactions and prohibited by PayPal’s anti-steering rules.
Merchants also cannot tell customers that other payment methods are more cost-effective or preferred, according to the complaint, which was filed in the U.S. District Court for the Northern District of California. Merchants are also not allowed to present other forms of payment earlier in the checkout process.
For example, the attorneys say that without PayPal’s anti-steering rules, a merchant could charge $5.83 for a box of Kleenex when PayPal is used as the payment method, and less than $5.83 when the consumer paid with credit card or other payment. Or, a merchant could maintain the same $5.83 price but provide consumers with a discount when they paid with a method other than PayPal or Venmo.
“Either way, the price differential would result in consumers paying lower all-in prices,” the lawsuit says.
Calling the policies “draconian” and “illegally anticompetitive,” the attorneys compared PayPal’s anti-steering rules to those that Visa and Mastercard used to impose before they were sued by the Department of Justice in 2010.
In a statement, the attorneys representing the class said: “Consumers end up paying more for all transactions as a result of PayPal’s policies and industry-high rates. PayPal generated total revenues in 2022 exceeding $27 billion, most of it coming from these fees.”
Per the firm’s lawsuit, more than 400 million consumers have PayPal accounts, including 75% of all Americans. Nearly 1 million U.S. e-commerce websites accept PayPal as a means of payment, and PayPal processes 41 million transactions daily.
“If consumers were allowed to see behind PayPal’s pricing veil, they would see a clear and distinct difference between using PayPal and Venmo to complete their transactions and using its competitors,” said Steve Berman, managing partner and co-founder of Hagens Berman. “For a service named for its friendliness, PayPal is far from consumer friendly.”
The story was updated post-publication with the following statement from PayPal: “PayPal continues to put our customers first in everything that we do, and we take this responsibility seriously. We are reviewing the filing and have no further information to share at this time.”
Want more fintech news in your inbox? Sign up for The Interchange here.","https://techcrunch.com/wp-content/uploads/2021/02/GettyImages-1184251295.jpg?resize=1200,800",2023-10-05 18:29:58
https://techcrunch.com/2023/10/05/ai-detection-bad-actors/,Want to detect bad actors? Look on the bright side,"“You will find that 99.9% of people in this world are actually really good. When they use your product, they use it for all the right reasons. But then once in a while when something bad happens, it also feels like one too many,” Airbnb’s director of Trust Product and Operations, Naba Banerjee, said onstage at TechCrunch Disrupt 2023.
Banerjee knows what she is talking about: Not long before she joined Airbnb’s trust and safety team in 2020, the company had declared a ban on “party houses” and taken other measures after five people died at a Halloween party hosted at a house that was rented on the platform.
Since then, the executive has become a bit of a “party pooper,” in the words of a recent CNBC profile. “As the person in charge of Airbnb’s worldwide ban on parties,” the piece noted, “Naba Banerjee has spent more than three years figuring out how to battle party ‘collusion’ by users, flag ‘repeat party houses’ and, most of all, design an anti-party AI system.”
It is this AI element that I found particularly interesting to discuss on Disrupt’s Builders Stage with Banerjee and her fellow panelist, Remote CEO Job van der Voort. While Remote is growing fast, the vast majority of its users still behave exactly as expected. But even a company the size of Airbnb, it turns out, doesn’t have that much data on rule-breaking behavior.","https://techcrunch.com/wp-content/uploads/2023/10/Naba-Banerjee-Airbnb-and-Job-van-der-Voort-Remote-How-to-Build-Intelligent-Startup-Ops-that-Will-Scale-with-Your-Business-panel-at-TechCrunch-Disrupt-2023-by-E.-Slomonson-The-Photo-Group-for-TechCrunch.jpg?resize=1200,800",2023-10-05 18:14:42
https://techcrunch.com/2023/10/05/uber-slow-on-algo-transparency/,"Uber still dragging its feet on algorithmic transparency, Dutch court finds","Uber has been found to have failed to comply with European Union algorithmic transparency requirements in a legal challenge brought by two drivers whose accounts were terminated by the ride-hailing giant, including with the use of automated account flags.
Uber also failed to convince the court to cap daily fines of €4,000 being imposed for ongoing non-compliance — which now exceed over half a million euros (€584,000).
The Amsterdam District Court found in favor of two of the drivers who are litigating over data access over what they couch as ‘robo-firings’. But the appeals court decided Uber had provided sufficient information to a third driver regarding the reasons why its algorithm flagged the account for potential fraud.
The drivers are suing Uber to obtain information they argue they are legally required to regarding significant automated decisions taken about them.
The European Union’s General Data Protection Regulation (GDPR) provides both for a right for individuals not to be subject to solely automated decisions with a legal or significant impact and to receive information about such algorithmic decision-making, including receiving “meaningful information” about the logic involved; its significance; and envisaged consequences of such processing for the data subject.
The nub of the issue relates not to fraud and/or risk reviews purportedly carried out on flagged driver accounts by (human) Uber staff — but to the automated account flags themselves which triggered these reviews.
Back in April an appeals court in the Netherlands also found largely in favor of platform workers litigating against Uber and another ride-hailing platform, Ola, over data access rights related to alleged robo-firing — ruling the platforms cannot rely on trade secrets exemptions to deny drivers access to data about these sorts of AI-powered decisions.
Per the latest ruling, Uber sought to rehash a commercial secrets argument to argue against disclosing more data to drivers about the reasons why its AIs flagged their accounts. It also generally argues that its anti-fraud systems would not function if full details were provided to drivers about how they work.
In the case of two of the drivers who prevailed against Uber’s arguments the company was found not to have provided any information at all about the “exclusively” automated flags that triggered account reviews. Hence the finding of an ongoing breach of EU algorithmic transparency rules.
The judge further speculated Uber may be “deliberately” trying to withhold certain information because it does not want to give an insight into its business and revenue model.
In the case of the other driver, for whom the Court found — conversely — that Uber had provided “clear and, for the time being, sufficient information”, per the ruling, the company explained that the decision-making process which triggered the flag began with an automated rule that looked at (i) the number of cancelled rides for which this driver received a cancellation fee; (ii) the number of rides performed; and (iii) the ratio of the driver’s number of cancelled and performed rides in a given period.
“It was further explained that because [this driver] performed a disproportionate number of rides within a short period of time for which he received a cancellation fee the automated rule signalled potential cancellation fee fraud,” the court also wrote in the ruling [which is translated into English using machine translation].
The driver had sought more information from Uber, arguing the data it provided was still unclear or too brief and was not meaningful because he does not know where the line sits for Uber to label a driver as a fraudster.
However, in this case, the interim relief judge agreed with Uber that the ride-hailing giant did not have to provide this additional information because that would make “fraud with impunity to just below that ratio childishly easy”, as Uber put it.
The wider question of whether Uber was right to classify this driver (or the other two) as a fraudster has not been assessed at this point in the litigation.
The long-running litigation in the Netherlands looks to be working towards establishing where the line might lie in terms of how much information platforms that deploy algorithmic management on workers must provide them with on request under EU data protection rules vs how much ‘blackboxing’ of their AIs they can claim is necessary to fuzz details so that anti-fraud systems can’t be gamed via driver reverse engineering.
Reached for a response to the ruling, an Uber spokesperson sent TechCrunch this statement:
The ruling related to three drivers who lost access to their accounts a number of years ago due to very specific circumstances. At the time when these drivers’ accounts were flagged, they were reviewed by our Trust and Safety Teams, who are specially trained to spot the types of behaviour that could potentially impact rider safety. The Court confirmed that the review process was carried out by our human teams, which is standard practice when our systems spot potentially fraudulent behaviour.
The drivers in the legal challenge are being supposed by the data access rights advocacy organization, Worker Info Exchange (WIE), and by the App Drivers & Couriers union.
In a statement, Anton Ekker of Ekker law which is representing the drivers, said: “Drivers have been fighting for their right to information on automated deactivations for several years now. The Amsterdam Court of Appeal confirmed this right in its principled judgment of 4 April 2023. It is highly objectionable that Uber has so far refused to comply with the Court’s order. However, it is my belief that the principle of transparency will ultimately prevail.”
In a statement commenting on the ruling, James Farrar, director of WIE, added: “Whether it is the UK Supreme Court for worker rights or the Netherlands Court of Appeal for data protection rights, Uber habitually flouts the law and defies the orders of even the most senior courts. Uber drivers and couriers are exhausted by years of merciless algorithmic exploitation at work and grinding litigation to achieve some semblance of justice while government and local regulators sit back and do nothing to enforce the rules. Instead, the UK government is busy dismantling the few protections workers do have against automated decision making in the Data Protection and Digital Information Bill currently before Parliament. Similarly, the proposed EU Platform Work Directive will be a pointless paper tiger unless governments get serious about enforcing the rules.”","https://techcrunch.com/wp-content/uploads/2023/05/GettyImages-1142304853-a.jpg?resize=1200,675",2023-10-05 18:00:06
https://techcrunch.com/2023/10/05/as-its-workers-strike-over-burnout-and-low-wages-kaiser-permanente-strikes-a-deal-to-use-an-ai-copilot-from-nabla/,"As its workers strike over burnout and low wages, Kaiser Permanente strikes a deal to use an AI Copilot from Nabla","Yesterday, 75,000 workers at healthcare giant Kaiser Permanente embarked on a three-day strike to protest understaffing, burnout and low wages — setting a record for the biggest healthcare strike to date in U.S. history. But timing is everything in medicine. While Kaiser Permanente works through terms with union reps, another interesting development has emerged: it has inked a deal with Nabla, the AI healthcare startup from Paris, to provide an AI assistant to doctors and other clinicians in its network to reduce the amount of time they spend on admin: the AI will help with writing up notes and doing other administrative work, based on conversations that it listens to and transcribes.
Nabla’s Copilot product, which was launched in March of this year, will be rolled out to Kaiser Permanente physicians in Northern California initially, covering 10,000 doctors in all. The service will be available to all of them, but using it will be optional. If the service proves to work well, the idea will be potentially to roll it out across the rest of Kaiser Permanente’s footprint in the U.S.
From what we understand, Nabla and Kaiser Permanente first ran a two-week pilot of the service in August of this year. The process of turning that into a commercial deal might have normally taken much longer, so it’s worth wondering if the current labor actions had a role to play in speeding that up.
Still, it’s worth making clear that for now, neither Nabla nor Kaiser Permanente are working on tools to take over the clinical work the doctors and others are doing.
That’s not to say that others are not. Corti, another AI healthcare startup, raised $60 million in funding to continue building out its technology: another assistant for clinicians, but one where the aim is to help them with their patient assessments. Corti has some impressive deals in place already, too, and it says that it’s already working with more than 100 million patients/year.
And there are other industries where AI has become a major point of contention with labor groups. In the world of entertainment, anticipating the growing use of AI to recreate human likeness and voices, the SAG-AFTRA actors union is striking right now over the very issue of AI and how it will impact how they work and how they are compensated.
The pain point that Nabla is addressing is that the admin that doctors and others are required to do after seeing patients — forms that are needed for compliance and other purposes — can take hours to get through each day.
“A doctor might make as many as 4,000 mouse clicks in a 10-hour shift,” Alexandre Lebrun, the CEO and founder of Nabla, said in an interview.
So most of the time, those clinicians will put off getting to it. As a result, that work stretch, and the work that’s done in that stretch, are often referred to as “pajama time,” a reference to how clinicians get to it typically at the end of the day, in their nightclothes. The burnout that results from these extra hours of work on top of work has been a persistent problem in the industry for years.
Nabla’s copilot, as we have described before, essentially works as a virtual assistant. It listens to conversations and other interactions that are taking place with patients and matches up what it hears with other supplementary documents. And then it translates the resulting data into different document-based endpoints — such as prescriptions, follow-up appointment letters, consultation summaries — which typically result from those meetings. Doctors in the pilot cut out 1.5 hours of admin time using Nabla’s Copilot, the company said.
When we first wrote about the service, it had been based around GPT-3, the large language model built by OpenAI, which is used to generate human text and is powering hundreds of applications. Since then, Copilot has upgraded to GPT-4, but it’s also largely running the majority of its services now on its own LLM, although Lebrun said that it does still use GPT-4 in some areas to verify the work of its own LLM.
“GPT-4 is still the gold standard,” he said. “Because it’s very accurate and powerful, we use it to process feedback to correct what we do.”
(Lebrun, who has a long and interesting background in the world of virtual assistants and natural language processing, is very much a founder to watch. His sold his first startup, VirtuOz, a “Siri for enterprise,” in 2013 to Nuance to spearhead its development of digital assistant technology for businesses. He then founded and eventually sold his next startup, Wit.ai, to Facebook, where he and his team then worked on the social network’s foray into chatbots in Messenger. He then helped establish and run FAIR, Facebook’s AI research centre in Paris, which is headed up by Yann LeCun, the Turing Award winner who is Meta’s chief scientist. LeCun is one of his advisers now at Nabla.)
Nabla has raised just under $23 million from investors that include Tony Fadell, Firstminute Capital and Artemis. From what we understand, it’s starting discussions now with investors to raise more.","https://techcrunch.com/wp-content/uploads/2023/03/GettyImages-1347476924.jpg?resize=1200,600",2023-10-05 16:42:43
https://techcrunch.com/2023/10/05/rivian-evs-costly/,Rivian reminds investors that making EVs is incredibly expensive,"In 2023, the EV market is no longer about startups. Instead, the race to shift to electric vehicles has morphed into a competition between the world’s largest automotive companies and a host of smaller rivals that have gone public. The latter are often deeply unprofitable.
The Exchange explores startups, markets and money.
Read it every morning on TechCrunch+ or get The Exchange newsletter every Saturday.
In fact, this set of smaller EV companies is bleeding so much cash that there’s a row going on at the moment between China and other economies over subsidies and fair competition.
Subsidies are just part of the issue, though. There’s lots of talk about how central China is to the global battery supply chain and if new laws could shake up the present dynamic. Much as food security has long been a priority for countries, joined by semiconductors in recent years, nations and economic blocs also want to ensure that their ability to manufacture green (or greener) technologies can meet their needs.
The stakes are more focused for EV companies simply trying to scale production and prove to investors that they are viable, long-term businesses. They need to scale manufacturing to sell more cars, which will in turn increase manufacturing and research cost efficiencies, and all that will hopefully snowball into a bottom line that’s not deep in the red all the time. So it makes sense that we often see high levels of spending, and massive losses, at EV companies that are ramping up production.
The New York Times recently reported that Nio, a Chinese EV company also listed in the U.S., is losing around $35,000 per car. It’s hardly alone in losing so much money. U.S.-based Rivian in August said it delivered 12,640 cars in the second quarter of 2023, which resulted in revenue of $1.12 billion, gross loss of $412 million, operating loss of $1.29 billion and a free cash flow deficit of $1.62 billion. Gross margin came in at –37%.","https://techcrunch.com/wp-content/uploads/2023/05/rivian-Hero_1_R1S_Max_Pack.jpg?resize=1200,675",2023-10-05 16:15:06
https://www.innovationnewsnetwork.com/protein-guard-mechanism-identified-future-infectious-disease-cancer-treatment/37988/,Protein guard mechanism identified for future of infectious disease and cancer treatment,"Researchers have found a guard mechanism for protein which attacks microbes in infected cells.
The University of Birmingham-led study has identified a guard mechanism that controls the attack protein GBP1. GBP1 is activated during inflammation and has the potential to attack membranes within cells and destroy them.
The lock and key mechanism found has opened the possibility for new treatments for Toxoplasma, Chlamydia, Tuberculosis and even cancer.
The study, ‘PIM1 controls GBP1 activity to limit self-damage and to guard against pathogen infection,’ is published in the journal Science.
How does the protein guard mechanism work?
The research showed that the attack protein is controlled through a process called phosphorylation. This process involves a phosphate group being added to a protein by enzymes called protein kinases.
The kinase targeting GBP1 is called PIM1 and can also become activated during inflammation.
In turn, phosphorylated GBP1 is bound to a scaffold protein, keeping uninfected bystander cells safe from uncontrolled GBP1 membrane attack and cell death.
The guard mechanism prevents GBP1 from attacking cell membranes indiscriminately, creating a protective shield that is sensitive to disruption by the actions of pathogens inside the cells.
The new discovery was made by Daniel Fisch, a former PhD student in the Frickel lab working on the study.
Dr Eva Frickel, Senior Wellcome Trust Fellow at the University of Birmingham, who led the study explained: “This discovery is significant for several reasons. Firstly, guard mechanisms such as the one that controls GBP1 were known to exist in plant biology but less so in mammals. Think of it as a lock and key system. GBP1 wants to go out and attack cellular membranes, but PIM1 is the key, meaning GBP1 is locked safely away.
“The second reason is that this discovery could have multiple therapeutic applications. Now we know how GBP1 is controlled, we can explore ways to switch this function on and off at will, using it to kill pathogens.”
The initial research was conducted on Toxoplasma gondii
The research team first conducted their study on Toxoplasma gondii, a single-celled parasite that is common in cats.
In South American countries, Toxoplasma infections are particularly dangerous for pregnant women and can cause reoccurring eye infections and blindness.
The team discovered that Toxoplasma blocks inflammatory signalling within cells, preventing the production of PIM1. This means that the guard mechanism disappears, allowing GBP1 to attack the parasite.
Using an inhibitor to switch PIM1 off or manipulating the cell’s genome also resulted in GBP1 attacking Toxoplasma and removing the infected cells.
Dr Frickel stated: “This mechanism could also work on other pathogens, such as Chlamydia, Mycobacterium tuberculosis, and Staphylococcus all major disease-causing pathogens which are increasingly becoming more resistant to antibiotics.
“By controlling the guard mechanism, we could use the attack protein to eliminate the pathogens in the body.
“We have already begun looking at this opportunity to see if we are able to replicate what we saw in our Toxoplasma experiments. We are also incredibly excited about how this could be used to kill cancer cells.”
The implications for the research in cancer treatment
GBP1 is activated by the inflammatory effect of cancer, while PIM1 is a key molecule in the survival of cancer cells.
The team believe that blocking the interaction between PIM1 and GBP1 could eliminate cancer cells.
Dr Frickel concluded: “The implication for cancer treatment is huge. We think this guard mechanism is active in cancer cells, so the next step is to explore this and see if we can block the guard and selectively eliminate cancer cells.
“There is an inhibitor on the market which we used to disrupt PIM1 and GBP1 interaction. So, if this works, you could use this drug to unlock GBP1 and attack the cancer cells
“There is still a very long way to go, but the discovery of the PIM1 guard mechanism could be a massive first step in finding new ways to treat cancer and increasingly antibiotic-resistant pathogens.”
[bsa_pro_ad_space id=""102"" crop=""no""]
[bsa_pro_ad_space id=""43"" crop=""no""]",https://www.innovationnewsnetwork.com/wp-content/uploads/2023/10/©-shutterstockGorodenkoff_691548586.jpg,2023-10-06 11:15:37
https://www.innovationnewsnetwork.com/success-of-initiate-project-using-carbon-capture-and-utilisation-technology/35879/,The success of the INITIATE project using carbon capture and utilisation technology,"Antonio La Mantia, Director of Communications and Events, and Anastasios Perimenis, Secretary General at CO 2 Value Europe, explore the INITIATE project that uses carbon capture and utilisation to contribute to a climate-neutral and circular economy.
Scientists estimate that roughly 34 billion tonnes of carbon dioxide is emitted globally each year. This gives us a sense of the immense amount of CO 2 emissions going into the atmosphere yearly without being seen or very well perceived by the public.
To grasp the scale of this phenomenon, imagine putting on magic glasses able to show you just a tonne of these CO 2 emissions. We would then see a cube of about 8x8m (almost as tall, wide, and long as a utility pole) filled with carbon dioxide.
This enormous CO 2 landfill floating above our heads is identified by the global scientific community as the primary driver of climate change. However, the good news is that what has been considered so far as a waste product can be captured and become a lower-cost feedstock for several industries.
Carbon capture and utilisation technology
Thanks to a broad portfolio of existing and developing carbon capture and utilisation (CCU) technologies, carbon dioxide can be captured and converted into a feedstock to create essential products. This is particularly true for the chemical sectors, including the production of chemicals, synthetic fuels and polymers, and at the same time for the energy sector, as it can provide useful storage solutions.
The most promising aspect of these technologies is not only that they can reduce CO 2 emissions and avoid emissions but also that they can create a circular carbon economy able to de-fossilise our society, as captured CO 2 is used by the industry as an alternative carbon feedstock to create different fuels and chemicals which are part of our daily life, via the so-called Power-to-X approach.
This approach sees the use of renewable electricity (Power), water and carbon dioxide as a feedstock to convert CO 2 into products (X), like fuels, chemicals or commodity blocks. Against this context, first comes the source of CO 2 , which can be either an industrial point source like steel mills, incinerators, cement factories or the air via the so-called direct air capture. Then the approach, which can be electrochemical, thermochemical or biological, is able to form low and high-carbon molecules such as methanol, formic acid and ethylene, butanol and many others.
Captured CO 2 can also be bound in mineral-rich industrial wastes (like ashes, slags, and construction wastes) to create solid materials (e.g. carbonates, bricks, and building materials). This process, known as mineralisation, is an industrially accelerated form of natural carbonation that already occurs in nature, though at a slow pace. Mineralising carbon does not only allow us to store carbon dioxide in products for hundreds of years, but it also allows us to create products that can substitute carbon-intensive products (e.g. cement).
This broad range of carbon capture and utilisation technology pathways are not emerging technologies anymore, as some of them are already at TRL 9 (commercialisation level), while others are in this wide spectrum range of TRLs starting from one to nine, so still in labs or prototype or pilot phase.
Challenges in commercialising CCU technologies
However, the route towards the scalability of CCU technologies is also faced with several challenges. First is the business case. As CCU solutions are often energy-intensive and require a significant initial investment for their implementation, they require significant investment in the CapEx and OpEx phases.
Secondly, there might be future unpredictable competition between fossil, biogenic and atmospheric CO 2 to provide chemical feedstocks, material and fuel needs, and that shows the importance of assessing the future demand trends and potential penetration of these products via accurate marketing investigations. Third, as CCU has been envisioned as a ‘circular solution’, conflicting expectations and misconceptions may arise when it is mixed up with carbon capture and storage solutions (CCS), especially at the political level, given the different needs and challenges of these two different sectors. Fourth, when it comes to risk perception and public acceptance, it is now clear that the general public is not very well aware of CCU, and this may lead to relevant difficulties in assessing the acceptance in various areas of Europe. Last but not least, there are difficulties associated with assessing the impact of CCU technologies on the environment and the economy.
Tackling climate change with CCU
In 2022, the role of carbon capture and utilisation technology as a solution to mitigating climate change was recognised by the United Nations’ Intergovernmental Panel on Climate Change (IPCC).
In its sixth assessment report titled ‘Mitigation of Climate Change’, the UN panel not only identifies CCU technology as a solution to decrease net CO 2 emissions but also stresses the importance of its critical role to end our reliance on fossil carbon by using CO 2 as an alternative feedstock for the production of renewable fuels and chemicals.
In this context, the three major contributions of CCU technologies to mitigating climate change are:
CCU technologies are drop-in solutions with limited new infrastructure needs and have the potential to utilise up to 8 Gt of CO 2 per year by 2050; 1
per year by 2050; CCU allows to reduce or avoid CO 2 emissions while maintaining essential services historically based on fossil resources; and
emissions while maintaining essential services historically based on fossil resources; and CCU can provide CO 2 removal solutions when atmospheric or biogenic CO 2 is durably stored in products.
However, it is important to note once again that the impacts of these applications on the climate and also on the economy are contextual and dependent on various factors. The only fact that we are using CO 2 to make a product does not automatically mean that the product is good for the planet or economically viable. As such, the role of carbon capture and utilisation technology in mitigating climate change should be determined through a comprehensive and systematic full life cycle assessment (LCA) to find the best possible ways for its scalability. At the same time, the economic factors influencing its commercialisation and deployment must be assessed via techno-economic assessment (TEA) to ensure the market will ultimately engage in this technology.
As stated by the IPCC, the different solutions to mitigate climate change should be based on sobriety, energy efficiency and circularity of goods, waste, and resources. The panel has also shown that industrial symbiosis and intersectoral co-operation are key to success.
INITIATE project
Against this context, the INITIATE project brings forward a concept of industrial symbiosis to contribute to the EU’s goal for a climate-neutral and circular economy. The concept is demonstrated by coupling energy-intensive industries like the iron and steel sector and the ammonia and urea sector.
Carbon capture and utilisation technology work to capture and transform residual gases like basic oxygen furnace gases (BOFG) from steelmaking into suitable feedstocks for urea production, namely NH 3 and CO 2 used as feedstock for the production of ammonia and urea.
This is a challenge beyond the state-of-the-art, following the variability and different properties of this new circular feedstock. Overall, the transformation is happening in sequence: the first step is the steel gases conditioning, comprising a water-gas-shift (WGS) reactor and a sorption-water-gas-shift (SEWGS) reactive-separation multi columns unit. In this section, residual steel gases are conditioned and separated into CO 2 and H 2 /N 2 streams. INITIATE optimises the intermediate H 2 /N 2 product ratio to produce ammonia (NH 3 ) and, via SEWGS, decarbonises this stream.
The resulting CO 2 can be added to ammonia to produce urea, further used for the production of other carbon-containing molecules, or sent to geological sequestration. The NH 3 synthesis loop is also designed for the flexible intake of green H 2 from renewable energy electrolysis but does not rely on this for normal operation with Basic Oxygen Furnace Gas (BOFG) and Blast Furnace Gas (BFG).
INITIATE is an interdisciplinary project combining the disciplines of process modelling to model the dynamic elements of, among others, the NH 3 synthesis loop and the SEWGS multi-column process concerning the varying feed-gas composition; catalysis and functional material characterisation to identify the appropriate sorbents and catalysts to deal with contaminants in the input; engineering and process control to design, construct and test both the individual components and the integrated value chain at demonstration and full implementation scale; LCA to assess the energy, economic and environmental advantages of the process over reference cases; business model development for a bankable design of a first-of-a-kind commercial plant to convert BOFG and BFG to NH 3 -based and carbon-containing products; and communication and stakeholder engagement to ensure synergies at local and European scale and replication of the concept for future successful deployment of this CCU technology.
The INITIATE project aims at a 30% decrease in primary energy use, a 40% decrease in raw material demand and an up to 90% reduction in direct CO 2 emissions. Additionally, Europe is made more independent and robust, given the volatility of feedstock prices and trade uncertainties. Further benefits of this symbiotic concept are the provision of grid balancing services through flexibly using green H 2 and by proving CO 2 for circular use, accelerating the transition towards locally closed loop and integrated renewable energy systems.
The INITIATE project has received funding from the European Commission under the Horizon 2020 programme Ref: 958318.
References
Hepburn, C. et al. (2019) The technological and economic prospects for CO 2 utilization and removal. Nature, 575 (7781), pp. 87-97
Please note, this article will also appear in the fifteenth edition of our quarterly publication.
Contributor Details
[bsa_pro_ad_space id=""102"" crop=""no""]
[bsa_pro_ad_space id=""43"" crop=""no""]",https://www.innovationnewsnetwork.com/wp-content/uploads/2023/08/CO2VALU1-image-1.png,2023-10-06 11:01:07
https://venturebeat.com/ai/streamingllm-shows-how-one-token-can-keep-ai-models-running-smoothly-indefinitely/,StreamingLLM keeps AI models running smoothly indefinitely,"VentureBeat presents: AI Unleashed - An exclusive executive event for enterprise data leaders. Network and learn with industry peers. Learn More
Text-to-text large language models (LLMs) such as OpenAI’s ChatGPT, Meta’s Llama 2, Anthropic’s Claude 2 have been at the center of the current AI gold rush in Silicon Valley and the wider enterprise tech world — but by and large, all of them share some of the same issues.
One of these issues is consistently high quality performance over time during a single conversation with a user — where the LLM provides responses that are as helpful, fast, and relevant in the middle of the conversation and at the very end as it does at the beginning, no matter how long that conversation lasts or how many exchanges of dialog it encompasses. This is because LLMs are pre-trained on blocks of data, or sequences, of certain lengths — 4,000 tokens in the case of Llama 2 and many other leading LLMs.
Once a user inputs more tokens than this — even if they are doing so across multiple different prompts — the LLM begins to suffer reduced performance, that is, worse quality responses. This is not acceptable for enterprises looking to have LLMs helping customers or employees in an open-ended fashion.
A new paper published recently by researchers at Meta, the Massachusetts Institute of Technology (MIT), and Carnegie Mellon University (CMU), finds that there is a simple way to help LLMs maintain their performance even for indefinitely long conversations, where the user’s prompts collectively add up to be longer than what the LLM was trained to handle at once.
Event AI Unleashed An exclusive invite-only evening of insights and networking, designed for senior enterprise executives overseeing data stacks and strategies. Learn More
Their work, a new framework for training and deploying LLM inferences dubbed “StreamingLLM,” reveals a number of important findings for other AI researchers and enterprises looking to use LLMs to aid with their business.
The problem StreamingLLM seeks to solve
As anyone who has interacted with a human customer support specialist or even an internal IT tech at your employer knows, it can often take a lengthy conversation and multiple messages exchanged between you and your assigned helper to solve the problem at hand.
But no matter whether you’re a customer or an employee — you want the person assigned to help you to be consistently responsive, informed, and helpful in their communications with you throughout your entire exchange. It can be very frustrating and counterproductive if suddenly, deep into the conversation where you’ve already spent time and energy explaining your issue, your helper begins responding with one-word answers, more slowly, or without giving you the information you need.
Although this can be an issue with some people who are distracted, unmotivated, or exhausted with the conversation, it is endemic for LLMs, as their performance suffers once a conversation with them goes beyond the length of the “context window,” the maximum number of tokens the LLM can respond to at once, and which was used to pre-train them. This is true even though most LLMs are designed to handle open-ended conversations that may go on for many lines.
Even if each of those lines fits within the context window of an LLM — and all of them should, as most LLMs have an upper boundary on the amount of text you can enter in for them to respond to in a single message — together, the cumulative sum of multiple messages in a single conversation adds up to a number of tokens that is larger than those included the LLM’s initial pre-training context window, which causes the LLM’s performance after this point to suffer.
It would be as though when you were talking to a human customer support agent, if once you said a certain number of words to them across a few sentences that added up to some limit unknown to you, they abruptly became stupider and less attentive.
The researchers behind the StreamingLLM framework summarize the problem in their paper as follows: “For example, an ideal ChatBot assistant can stably work over the content of recent day-long conversations. However, it is very challenging for LLM to generalize to longer sequence lengths than they have been pre-trained on.”
While it is possible to expand the length of the token sequences in pre-training LLMs, and already, a number of researchers have done this, it is not possible to account for how long a unique conversation with a given user will last.
So, how do you get an LLM with a fixed context-window length used in pre-training — however long that is — to be able to retain its performance once that length has been eclipsed over multiple messages?
The solution the researchers developed
The researchers developed an innovative solution for maintaining LLM performance once the amount of information in a conversation ballooned past the number of tokens used in the pre-training sequence.
What the researchers discovered was that LLMs pay closer attention to the tokens they are prompted with early on in a conversation or in training.
“A surprisingly large amount of attention score is allocated to the initial tokens,” they write. Why is this the case?
“Due to the sequential nature of autoregressive language modeling, initial tokens are visible to all subsequent tokens, while later tokens are only visible to a limited set of subsequent tokens,” they write. “As a result, initial tokens are more easily trained to serve as attention sinks, capturing unnecessary attention.”
In other words: whatever you put in front of an LLM first when conversing with it can and will be used by it later on in subsequent exchanges of prompt and output, but whatever you prompt it with later on will not necessarily be what the LLM chooses to focus on or reference in its responses.
Yet, the researchers discovered that if the user provides some of the initial tokens later in the conversation with an LLM, in subsequent responses, it’s enough to restore the LLMs performance back to near its peak.
Remember our human customer support analogy earlier? Imagine if, by saying four of the same magic words you said at the beginning of your conversation with them, you could suddenly get them to deliver high-quality responses with you even much later in the conversation.
The researchers dub these initial tokens that grab most of the LLM’s attention, fittingly, as “attention sinks,” and note that for most LLMs, “the introduction of four initial tokens, as attention sinks, suffices to restore the LLM’s performance…adding just one or two doesn’t achieve full recovery.”
By reintroducing attention sink tokens in every single subsequent prompt from a user, the researchers were able to maintain the performance of leading models including LLama 2 and Falcon 40B across prompts consisting of 4 million tokens (a 1000-fold increase from the original context window of just 4,000 tokens) “and potentially even more”, and increased its speed in subsequent responses by 22.2 times.
In other words, Streaming LLM “enables LLMs trained with a finite attention window to work on text of infinite length without finetuning.” Importantly — this “infinite” length text would still need to be delivered to the LLM in chunks limited to the size of its context window. However, it means the LLM could have a never-ending conversation with someone and retain its performance throughout (theoretically).
One token to rule them all (their attention, at least)
Taking their findings another step further, the researchers hypothesized and proved that you could actually get away with adding just a single special token to act as an “attention sink” for an LLM early on, and that, by reintroducing this token later manually or automatically (behind the scenes of a user-or-employee facing LLM), the LLM’s performance could continue to be kept high.
“Introducing a sink token is highly effective in stabilizing the attention mechanism,” the researchers explain. “Simply pairing this sink token with recent tokens sufficiently anchors the model’s performance…Given these findings, we recommend training future LLMs with a sink token in all samples to optimize streaming deployment.”
Asked what specific data should be used for an attention sink, one of the paper’s authors, Guangxuan Xiao of MIT, wrote to VentureBeat in an email that “the ‘attention sinks’ can be any initial tokens; the focus is more on their position than semantics…. These aren’t specific words or concepts; even tokens (e.g., linebreak “
”) without semantic meanings work effectively.”
As for what the researchers hope StreamingLLM will be used for, Xiao said: “We designed StreamingLLM for continuous applications, like multi-round dialogues. It’s perfect for use cases where a model must function non-stop without relying too heavily on past data. A daily assistant LLM exemplifies this. With our method, the model can persist, drawing from recent interactions, eliminating the need for frequent cache refreshes.”
However, the researchers are also clear to note the limitations of their work as well, and were careful to emphasize StreamingLLM does not extend the context window of LLMs, contrary to some hype on X (formerly Twitter) about their work. It also does not ensure that LLM will remember everything said at every point during the conversation.
“In fact, we neither expand the LLMs’ context window nor do we improve their long-term memory,” Xiao told VentureBeat.",https://venturebeat.com/wp-content/uploads/2023/10/cfr0z3n_a_waterfall_of_code_and_data_0763a90d-2214-4536-b4d7-5554cac56d24.png?w=1200&strip=all,2023-10-05 23:51:51
https://venturebeat.com/ai/nucleus-ai-emerges-from-stealth-with-22b-model-to-transform-agriculture/,"Nucleus AI emerges from stealth with ag focus, releases 22B model","VentureBeat presents: AI Unleashed - An exclusive executive event for enterprise data leaders. Network and learn with industry peers. Learn More
California-based Nucleus AI, a four-member startup with talent from Amazon and Samsung Research, today emerged from stealth with the launch of its first product: a 22-billion-parameter large language model (LLM).
Available under an open-source MIT license and commercial license, the general-purpose model sits between 13B and 34B segments and can be fine-tuned for different generation tasks and products. Nucleus says it outperforms models of comparable size and will eventually help the company build towards its goal of using AI for transforming agriculture.
“We’re starting with our 22-billion model, which is a transformer model. Then, in about two weeks’ time, we’ll be releasing our state-of-the-art RetNet models, which would give significant benefits in terms of costs and inference speeds,” Gnandeep Moturi, the CEO of the company, told VentureBeat.
The new Nucleus AI model
Nucleus started training the 22B model about three and a half months ago after receiving compute resources from an early investor.
Event AI Unleashed An exclusive invite-only evening of insights and networking, designed for senior enterprise executives overseeing data stacks and strategies. Learn More
The company tapped existing research and the open-source community to pre-train the LLM on a context length of 2,048 tokens and eventually trained it on a trillion tokens of data, covering large-scale deduplicated and cleaned information scraped from the web, Wikipedia, Stack Exchange, arXiv and code.
This established a well-rounded knowledge base for the model, covering general information to academic research and coding insights.
As the next step, Nucleus plans to release additional versions of the 22B model, trained on 350 billion tokens and 700 billion tokens, as well as two RetNet models – 3 billion parameters and 11 billion parameters – that have been pre-trained on the larger context length of 4,096 tokens.
These smaller-sized models will bring the best of RNN and transformer neural network architectures and deliver huge gains in terms of speed and costs. In internal experiments, Moturi said, they were found to be 15 times faster and required only a quarter of the GPU memory that comparable transformer models generally demand.
“So far, there’s only been research to prove that this could work. No one has actually built a model and released it to the public,” the CEO added.
Bigger ambitions
While the models will be available for enterprise applications, Nucleus has bigger ambitions with its AI research.
Instead of building straight-up chatbots like other LLM companies OpenAI, Anthropic, and Cohere, Moturi said they plan to leverage AI to build an intelligent operating system for agriculture, aimed at optimizing supply and demand and mitigating uncertainties for farmers.
“We have a marketplace-type of idea where demand and supply will be hyper-optimized for farmers in such a way that Uber does for taxi drivers,” he said.
This could solve multiple challenges for farmers, right from issues from climate change and lack of knowledge to optimizing supply and maintaining distribution.
“Right now, we’re not competing against anybody else’s algorithms. When we got access to compute, we were trying to build internal products to step into the farming landscape. But then we figured we need language models as the core of the marketplace itself and started building that with the contribution from the open-source community,” he added.
More details about the farming-centric OS and the RetNet models will be announced later this month.",https://venturebeat.com/wp-content/uploads/2023/10/cfr0z3n_aerial_view_of_a_farm_with_overlaid_glowing_UI_and_data_858fae5f-8d90-4c8a-8cb6-14c96d554b0f-1.png?w=1200&strip=all,2023-10-05 20:40:20
https://venturebeat.com/data-infrastructure/docker-dives-into-ai-to-help-developers-build-genai-apps/,Docker dives into AI to help developers build GenAI apps,"VentureBeat presents: AI Unleashed - An exclusive executive event for enterprise data leaders. Network and learn with industry peers. Learn More
Underneath just about every generative AI application for training or inference today you’ll likely find Docker containers as the primary approach to deployment.
Today at the Dockercon conference in Los Angeles, Docker Inc., the eponymous company behind the open source docker container technology, is taking a dive into the deep end of AI with a series of initiatives designed to help developers more rapidly build generative AI applications.
Among the efforts is the launch of a new GenAI stack that integrates docker with the Neo4j graph database, LangChain model chaining technology and Ollama for running large language models (LLMs). The new Docker AI product is also debuting at Dockercon, as an integrated way for developers to get AI powered insights and direction for development with containers.
The critical importance of Docker to the modern development ecosystem cannot be overstated, and the new AI efforts could have a big impact on GenAI development efforts. Docker has doubled down on its developer focus in recent years, which is an effort the company’s CEO said is paying off.
Event AI Unleashed An exclusive invite-only evening of insights and networking, designed for senior enterprise executives overseeing data stacks and strategies. Learn More
“For four years running, Stack Overflow’s community of developers has voted us number one most wanted, number one most loved developer tool,” Docker CEO, Scott Johnston told VentureBeat. “And we’re now up to 20 million monthly active developers from all around the world.”
Credit: Docker Inc.
What the Docker GenAI stack brings to developers
While the use of Docker containers to help share and deploy AI is pervasive, Johnston said that there is also a need to make development of GenAI applications easier.
GenAI applications all typically require a few core elements, such as a vector database, which is something that Neo4j now has as part of its graph database platform. Then of course GenAI requires an LLM, which is what Ollama provides with its platform that enables users to run LLMs including Llama 2, to run locally. Modern GenAI applications are also commonly multi-step, which is where LangChain fits in with its framework. Getting all those different pieces configured in containers to work together normally would require a bit of effort that can now be significantly simplified with the GenAI stack.
The Docker GenAI stack is designed to help developers and the enterprises they work for to more easily get started with AI development using containers. With the GenAI stack there are several use cases that are being targeted including the ability to build a support agent bot with a retrieval augmented generation (RAG) capability, a python coding assistant and automated content generation.
“It’s pre configured, it’s ready to go and they [developers] can start coding and experimenting to help get the ball rolling,” Johnston said.
The whole stack is designed so it can run locally on a developer system and is being made freely available. As developers build out applications and need deployment and commercial support, Johnston said that there will be options available from Docker and its partners.
Docker AI: a ‘mech suit’ for developers
There is no shortage of GenAI developer tools in the market today, with popular options such as GitHub Copilot and Amazon CodeWhisper among others.
Docker is now entering that fray with its own GenAI tool, simply called Docker AI. Rather than referring to Docker AI as a copilot, which is a term that Microsoft and other vendors are increasingly using for GenAI tools that assist users, Docker is using the term- mech suit. The basic idea is that with the mech suit, developers have more power and strength to accomplish tasks.
Docker AI has been trained on Docker’s proprietary data from millions of Dockerfiles, compose files, and error logs. Docker AI integrates directly into developers’ workflows to provide assistance when errors occur. It will display potential fixes within the development environment and allow developers to test the fix before committing changes. The goal is to create a better experience for developers to troubleshoot and fix issues when they arise.
Johsnton noted that while tools like Github Copilot are useful and powerful, Docker AI is specifically tuned to help enable container development.
“It has been trained on a rich proprietary stream of Docker data that other LLMs don’t have access to,” he said.",https://venturebeat.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-04-at-5.20.26-PM.png?w=1200&strip=all,2023-10-05 19:18:16
https://venturebeat.com/programming-development/observe-raises-50m-adds-generative-ai-to-help-enterprises-visualize-all-their-data/,"Observe raises $50M, adds GenAI to enterprise data visibility tools","VentureBeat presents: AI Unleashed - An exclusive executive event for enterprise data leaders. Network and learn with industry peers. Learn More
San Mateo-based Observe, a startup working to accelerate application troubleshooting and incident resolution with a unified observability cloud, today announced it has raised $50 million in series A3 debt financing, led by Sutter Hill Ventures. The company also debuted the latest version of its platform ‘Hubble’ with new generative AI smarts.
According to Observe, the release brings a revamped interface and gives users generative tools to help with things like product support, coding, RegEx generation, and incident workflows. It can improve the productivity of users of the platform by up to 25%, the company said.
The funding and update come at a time when enterprises are racing to adopt observability solutions that can actively monitor and flag potential software issues, giving them the necessary insights to fix the incident and prevent downtimes (and the associated cost overheads).
According to Future Market Insights, the market for these solutions is expected to grow from $2.17 billion in 2022 to $5.55 billion by 2032, with a CAGR of over 8%.
Event AI Unleashed An exclusive invite-only evening of insights and networking, designed for senior enterprise executives overseeing data stacks and strategies. Learn More
Observe’s ‘unified cloud’ for observability
Most enterprise technology stacks today are a web of complex and distributed applications that run aggressively and generate an exponential amount of telemetry spanning logs, metrics and traces.
These data points usually remain siloed, requiring teams to use different tools to put everything together with context and correlations and identify potential incidents.
This takes time and is not suitable, especially at a time when the application surface is constantly growing.
Observe — founded in 2017 by executives from Snowflake, Splunk, Wavefront and Roblox — solves this challenge by offering a unified Observability cloud that brings all the data to one place, allowing for faster troubleshooting, incident detection and resolution.
“Observe puts all data in a single, low-cost Data Lake (built on Snowflake) and eliminates silos for logs, metrics and traces. By storing all data in one place, Observe is able to compress data 10x and store it for 13 months, resulting in inexpensive long-term storage,” Jeremy Burton, the CEO of the company, told VentureBeat.
Once the information is ingested in the data lake, it is curated to form a “data graph” that enables analysis of the information and provides users with relevant context to quickly identify and resolve incidents.
Since its launch, Observe has netted around 60 paying customers, including TopGolf, Edgio, Linedata and Auditboard. Burton also noted that the company’s annual contract value has more than doubled every year since it started selling and the current year is expected to continue that trend.
Standing out with generative AI smarts
While Observe claims to solve a major issue for enterprises, it is not the only one in this space. Well-funded players like Datadog, Dynatrace, New Relic, Grafana and Splunk (recently acquired by Cisco) are also targeting the observability problem with their respective APM and log analytics solutions and introducing new features to gain share in the market.
On its part, Observe claims to be the only one that eliminates silos of logs, metrics and traces by storing everything in a single, low-cost data lake. To further stand out, the company is pushing out the Hubble update which revamps its Explorer interface for logs, metrics and traces and adds new generative AI features.
This includes an in-product chatbot assistant that responds to queries about Observe’s capabilities, ‘how-to’ tasks or error messages as well as a RegEx generation tool that parses data to add structure to logs on the fly.
O11Y GPT help in Observe
Beyond this, the interface will also include a co-pilot to generate the OPAL code – Observe’s query language – in response to natural language inputs, a dedicated assistant for troubleshooting via Slack and a new ‘live’ mode enabling data to be queried in 20 seconds or less from the time it was created.
“Hubble also features improved scalability and performance. With this launch, Observe is now capable of ingesting over one petabyte of data per day into a single instance,” Burton said. He added that the funding from this round will help the company grow its sales team to meet the accelerating demand for a modern approach to observability.
By the end of 2024, he expects to grow the team headcount from 150 to 250 employees.",https://venturebeat.com/wp-content/uploads/2023/10/cfr0z3n_a_telescope_peers_at_a_night_sky_filled_with_glowing_co_8a37777e-a45e-405f-ad75-2f1239bb067f-2.png?w=1200&strip=all,2023-10-05 17:47:57
